{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13caf5f",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "This notebook demonstrates the hybrid RAG pipeline using BM25 and vector search over the RDMkit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f479da-d649-4133-9190-0104f5109456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T14:41:30.565903Z",
     "iopub.status.busy": "2025-10-08T14:41:30.565678Z",
     "iopub.status.idle": "2025-10-08T14:44:35.563189Z",
     "shell.execute_reply": "2025-10-08T14:44:35.562019Z",
     "shell.execute_reply.started": "2025-10-08T14:41:30.565884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -r /kaggle/input/chatbotcorpus/requirements.txt\n",
    "!pip install chromadb sentence-transformers\n",
    "!pip install langchain langchain-core langchain-community\n",
    "!pip install langchain faiss-cpu whoosh\n",
    "!pip install rank-bm25\n",
    "!pip install langchain-huggingface\n",
    "!pip install -U FlagEmbedding\n",
    "!pip install whoosh langchain python-dotenv typing_extensions numpy langchain-google-genai langchain-huggingface sentence-transformers langgraph langchain-chroma\n",
    "!pip install ragas datasets evaluate openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5dc19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T14:45:43.760100Z",
     "iopub.status.busy": "2025-10-08T14:45:43.759801Z",
     "iopub.status.idle": "2025-10-08T14:46:23.201872Z",
     "shell.execute_reply": "2025-10-08T14:46:23.200944Z",
     "shell.execute_reply.started": "2025-10-08T14:45:43.760075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "import logging\n",
    "import hashlib\n",
    "import threading\n",
    "import numpy as np\n",
    "import torch\n",
    "from tempfile import mkdtemp\n",
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional, Tuple, Union\n",
    "from typing_extensions import TypedDict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from enum import Enum\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain import hub\n",
    "\n",
    "# Vector store and embeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Whoosh imports\n",
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh.qparser import QueryParser, MultifieldParser, OrGroup\n",
    "from whoosh.query import Or\n",
    "\n",
    "# Other model-specific imports\n",
    "from sentence_transformers import CrossEncoder\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658fd9d-c776-475f-8c63-4adacd8e81a8",
   "metadata": {},
   "source": [
    "# RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6d2ad8-f3f2-429d-8ca7-007676b0072b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T14:47:03.925649Z",
     "iopub.status.busy": "2025-10-08T14:47:03.924890Z",
     "iopub.status.idle": "2025-10-08T14:47:03.989716Z",
     "shell.execute_reply": "2025-10-08T14:47:03.988814Z",
     "shell.execute_reply.started": "2025-10-08T14:47:03.925621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RDMkitRAGPipeline:\n",
    "\tdef __init__(self, json_file_path: str = \"rdmkit_chunks_cleaned.json\"):\n",
    "\t\tself.store = {}\n",
    "\t\t# Load environment variables\n",
    "\t\tpath_env = '/kaggle/input/chatbotcorpus/.env'\n",
    "\t\tload_dotenv(path_env)\n",
    "\t\t\n",
    "\t\t# Set Google API key for LLM\n",
    "\t\tself.google_api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "\t\tif not self.google_api_key:\n",
    "\t\t\traise ValueError(\"GOOGLE_API_KEY is not set in environment variables or .env file (needed for Gemini LLM).\")\n",
    "\t\tos.environ[\"GOOGLE_API_KEY\"] = self.google_api_key\n",
    "\t\t\n",
    "\t\t# LangChain tracing setup (optional)\n",
    "\t\tlangchain_api_key = os.environ.get(\"LANGCHAIN_API_KEY_V2\")\n",
    "\t\tif langchain_api_key:\n",
    "\t\t\tos.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
    "\t\t\tos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\t\telse:\n",
    "\t\t\tos.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\t\t\n",
    "\t\tself.embeddings = HuggingFaceEmbeddings(\n",
    "\t\t\tmodel_name=\"BAAI/bge-large-en-v1.5\",\n",
    "\t\t\tmodel_kwargs={'device': 'cuda'}, \n",
    "\t\t\tencode_kwargs={'normalize_embeddings': True}\n",
    "\t\t)\n",
    "\t\tself.llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# Initialize cross-encoder for re-ranking\n",
    "\t\ttry:\n",
    "\t\t\tself.reranker = FlagReranker('BAAI/bge-reranker-base', use_fp16=True)\n",
    "\t\t\tself.reranking_enabled = True\n",
    "\t\t\tself.reranker_model_name = 'BAAI/bge-reranker-base'\n",
    "\t\t\t\n",
    "\t\t\tdevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tself.reranker = None\n",
    "\t\t\tself.reranking_enabled = False\n",
    "\t\t\n",
    "\t\tself.vectorstore = None\n",
    "\t\tself.retriever = None\n",
    "\t\tself.json_file_path = json_file_path\n",
    "\t\tself.corpus_summary = None\n",
    "\t\n",
    "\t\tself.relevance_cache = {}\n",
    "\t\tself.cache_size_limit = 1000\n",
    "\t\tself.corpus_summary = None\n",
    "\t\t\n",
    "\t\t# Configurable threshold parameters\n",
    "\t\tself.min_relevance_threshold = 0.2\n",
    "\t\tself.dynamic_threshold_factor = 0.5\n",
    "\t\tself.max_llm_verification_docs = 10\n",
    "\n",
    "\tdef get_session_history(self, session_id: str) -> BaseChatMessageHistory:\n",
    "\t\tif session_id not in self.store:\n",
    "\t\t\tself.store[session_id] = ChatMessageHistory()\n",
    "\t\treturn self.store[session_id]\n",
    "\n",
    "\tdef _infer_category(self, source_file: str) -> str:\n",
    "\t\t\"\"\"Infer the category from the source file path.\"\"\"\n",
    "\t\tparts = source_file.split(os.sep)\n",
    "\t\tif 'pages' in parts:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tidx = parts.index('pages')\n",
    "\t\t\t\tif idx + 1 < len(parts) and not parts[idx+1].endswith('.md'):\n",
    "\t\t\t\t\treturn parts[idx+1]\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\tpass\n",
    "\t\tif '_data' in parts:\n",
    "\t\t\treturn 'data_file'\n",
    "\t\treturn 'general'\n",
    "\n",
    "\tdef initialize_vectorstore(self) -> Dict[str, Any]:\n",
    "\t\t\"\"\"Load RDMkit preprocessed chunks from the JSON file and return status information.\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\twith open(self.json_file_path, 'r', encoding='utf-8') as f:\n",
    "\t\t\t\tchunks = json.load(f)\n",
    "\t\t\t\n",
    "\t\t\tif not chunks:\n",
    "\t\t\t\treturn {\n",
    "\t\t\t\t\t\"success\": False,\n",
    "\t\t\t\t\t\"message\": \"No chunks found in the JSON file\",\n",
    "\t\t\t\t\t\"error\": \"NoChunksError\"\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\tdocuments = []\n",
    "\t\t\tcategory_counts = {}\n",
    "\t\t\ttotal_char_count = 0\n",
    "\n",
    "\t\t\tfor chunk in chunks:\n",
    "\t\t\t\tsource_file = chunk.get('file_path', '')\n",
    "\n",
    "\t\t\t\tdoc_title = chunk.get('file_name', os.path.basename(source_file))\n",
    "\t\t\t\t\n",
    "\t\t\t\tcategory = self._infer_category(source_file)\n",
    "\t\t\t\tif category:\n",
    "\t\t\t\t\tcategory_counts[category] = category_counts.get(category, 0) + 1\n",
    "\n",
    "\t\t\t\tmetadata = {\n",
    "\t\t\t\t\t'chunk_id': chunk.get('id', ''),\n",
    "\t\t\t\t\t'source_file': source_file,\n",
    "\t\t\t\t\t'file_stem': os.path.splitext(os.path.basename(source_file))[0],\n",
    "\t\t\t\t\t'category': category,\n",
    "\t\t\t\t\t'doc_title': doc_title,\n",
    "\t\t\t\t\t'description': '', \n",
    "\t\t\t\t\t'section_title': '',\n",
    "\t\t\t\t\t'section_level': 0,\n",
    "\t\t\t\t\t'content_type': chunk.get('source', 'text'),\n",
    "\t\t\t\t\t'chunk_index': chunk.get('chunk_index', 0),\n",
    "\t\t\t\t\t'total_chunks': chunk.get('total_chunks', 1),\n",
    "\t\t\t\t\t'keywords': '',\n",
    "\t\t\t\t\t'tags': '',\n",
    "\t\t\t\t\t'contributors': '',\n",
    "\t\t\t\t\t'word_count': len(chunk.get('content', '').split()),\n",
    "\t\t\t\t\t'char_count': len(chunk.get('content', '')),\n",
    "\t\t\t\t\t'rdm_lifecycle': '',\n",
    "\t\t\t\t}\n",
    "\t\t\t\t\n",
    "\t\t\t\ttotal_char_count += metadata['char_count']\n",
    "\t\t\t\t\n",
    "\t\t\t\tclean_metadata = {}\n",
    "\t\t\t\tfor k, v in metadata.items():\n",
    "\t\t\t\t\tif isinstance(v, (str, int, float, bool)):\n",
    "\t\t\t\t\t\tclean_metadata[k] = v\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tclean_metadata[k] = str(v)\n",
    "\t\t\t\t\n",
    "\t\t\t\tdocuments.append(Document(\n",
    "\t\t\t\t\tpage_content=chunk.get('content', ''),\n",
    "\t\t\t\t\tmetadata=clean_metadata\n",
    "\t\t\t\t))\n",
    "\n",
    "\t\t\tself.corpus_summary = {\n",
    "\t\t\t\t\"total_files\": len(set(d.metadata['source_file'] for d in documents)),\n",
    "\t\t\t\t\"total_chunks\": len(documents),\n",
    "\t\t\t\t\"categories\": category_counts,\n",
    "\t\t\t\t\"average_chunk_size\": total_char_count / len(documents) if documents else 0\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t# Create vector store\n",
    "\t\t\tself.vectorstore = Chroma.from_documents(\n",
    "\t\t\t\tdocuments=documents,\n",
    "\t\t\t\tcollection_name=\"rdmkit-rag-chroma-test\",\n",
    "\t\t\t\tembedding=self.embeddings,\n",
    "\t\t\t)\n",
    "\t\t\tself.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\t\t\tself.raw_documents = documents\n",
    "\t\t\t\n",
    "\t\t\tself._setup_unified_retrieval_system()\n",
    "\t\t\t\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"success\": True,\n",
    "\t\t\t\t\"message\": \"RDMkit vector database creation completed from json file\",\n",
    "\t\t\t\t\"loaded_docs\": len(documents),\n",
    "\t\t\t\t\"total_files\": self.corpus_summary.get('total_files', 0),\n",
    "\t\t\t\t\"categories\": self.corpus_summary.get('categories', {}),\n",
    "\t\t\t\t\"average_chunk_size\": self.corpus_summary.get('average_chunk_size', 0)\n",
    "\t\t\t}\n",
    "\n",
    "\t\texcept FileNotFoundError:\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"success\": False,\n",
    "\t\t\t\t\"message\": f\"RDMkit JSON file {self.json_file_path} not found\",\n",
    "\t\t\t\t\"error\": \"FileNotFoundError\"\n",
    "\t\t\t}\n",
    "\t\texcept Exception as e:\n",
    "\t\t\timport traceback\n",
    "\t\t\tprint(traceback.format_exc())\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"success\": False,\n",
    "\t\t\t\t\"message\": f\"Error loading RDMkit data: {str(e)}\",\n",
    "\t\t\t\t\"error\": str(e)\n",
    "\t\t\t}\n",
    "\n",
    "\tdef _setup_unified_retrieval_system(self):\n",
    "\t\t\"\"\"Setup unified retrieval system with history awareness and advanced features.\"\"\"\n",
    "\n",
    "\t\tretriever_prompt = (\n",
    "\t\t\t\"Given a chat history and the latest user question which might reference context in the chat history, \"\n",
    "\t\t\t\"formulate a standalone question which can be understood without the chat history. \"\n",
    "\t\t\t\"Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tcontextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "\t\t\t(\"system\", retriever_prompt),\n",
    "\t\t\tMessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "\t\t\t(\"human\", \"{input}\"),\n",
    "\t\t])\n",
    "\t\t\n",
    "\n",
    "\t\tdef unified_retriever_func(input_dict: dict) -> List[Document]:\n",
    "\t\t\t\"\"\"Unified retriever with history awareness and re-ranking (BM25 removed).\"\"\"\n",
    "\t\t\tquestion = input_dict.get(\"input\", \"\")\n",
    "\t\t\tchat_history = input_dict.get(\"chat_history\", [])\n",
    "\t\t\t\n",
    "\t\t\tif chat_history:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tstandalone_question_result = (contextualize_q_prompt | self.llm | StrOutputParser()).invoke({\n",
    "\t\t\t\t\t\t\"input\": question,\n",
    "\t\t\t\t\t\t\"chat_history\": chat_history\n",
    "\t\t\t\t\t})\n",
    "\t\t\t\t\tsearch_question = standalone_question_result\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tsearch_question = question\n",
    "\t\t\telse:\n",
    "\t\t\t\tsearch_question = question\n",
    "\t\t\t\n",
    "\t\t\tdocuments = self._vector_retrieve_documents(search_question, k=10)\n",
    "\t\t\treranked_docs = self._rerank_documents(search_question, documents, top_k=5)\n",
    "\n",
    "\t\t\treturn reranked_docs\n",
    "\t\t\n",
    "\t\tsystem_prompt = (\n",
    "\t\t\t\"You are the RDMkit Assistant, a specialized AI guide for research data management (RDM). You help researchers, data managers, librarians, and institutions implement best practices for research data management throughout the entire data lifecycle.\\n\\n\"\n",
    "\t\t\t\"Your Expertise Areas:\\n\"\n",
    "\t\t\t\"- FAIR Data Principles: Findable, Accessible, Interoperable, Reusable data practices\\n\"\n",
    "\t\t\t\"- Data Lifecycle Management: Planning, collecting, processing, analyzing, preserving, sharing, reusing\\n\"\n",
    "\t\t\t\"- Domain-Specific Guidance: Life sciences, social sciences, humanities, engineering, etc.\\n\"\n",
    "\t\t\t\"- Role-Based Support: Researchers, data managers, IT support, institutional administrators\\n\"\n",
    "\t\t\t\"- Tools & Resources: Recommend appropriate tools, standards, and best practices\\n\"\n",
    "\t\t\t\"- Compliance & Policies: GDPR, institutional policies, funder requirements\\n\"\n",
    "\t\t\t\"- National Resources: Country-specific RDM infrastructure and support\\n\\n\"\n",
    "\t\t\t\"Response Guidelines:\\n\\n\"\n",
    "\t\t\t\"1. Direct & Actionable Answers\\n\"\n",
    "\t\t\t\"- For \\\"write/create/generate\\\" requests: Provide the actual document, template, or content requested\\n\"\n",
    "\t\t\t\"- For \\\"how to\\\" questions: Provide step-by-step guidance and implementation advice\\n\"\n",
    "\t\t\t\"- For informational queries: Give clear, concise explanations with practical context\\n\"\n",
    "\t\t\t\"- Always match the response format to what the user is actually asking for\\n\\n\"\n",
    "\t\t\t\"2. RDMkit-Specific Context\\n\"\n",
    "\t\t\t\"- Reference specific RDMkit pages, sections, or tools when available\\n\"\n",
    "\t\t\t\"- Use RDM terminology consistently (e.g., \\\"data lifecycle stages\\\", \\\"FAIR principles\\\")\\n\"\n",
    "\t\t\t\"- Mention relevant domain or role-specific considerations\\n\"\n",
    "\t\t\t\"- Connect answers to broader RDM workflows and best practices\\n\\n\"\n",
    "\t\t\t\"3. Professional RDM Tone\\n\"\n",
    "\t\t\t\"- Maintain an expert but approachable tone\\n\"\n",
    "\t\t\t\"- Use inclusive language for diverse research communities\\n\"\n",
    "\t\t\t\"- Acknowledge complexity while providing clear guidance\\n\"\n",
    "\t\t\t\"- Be authoritative about established best practices\\n\\n\"\n",
    "\t\t\t\"4. Contextual Awareness\\n\"\n",
    "\t\t\t\"- Adapt recommendations based on research domain (if mentioned)\\n\"\n",
    "\t\t\t\"- Consider institutional vs. individual researcher perspectives\\n\"\n",
    "\t\t\t\"- Address different levels of RDM maturity (beginner to advanced)\\n\"\n",
    "\t\t\t\"- Mention compliance and policy considerations when relevant\\n\\n\"\n",
    "\t\t\t\"5. Knowledge Boundaries\\n\"\n",
    "\t\t\t\"- If the RDMkit context doesn't contain sufficient information, clearly state:\\n\"\n",
    "\t\t\t\"  \\\"This specific topic is not covered in the available RDMkit documentation.\\\"\\n\"\n",
    "\t\t\t\"- Suggest alternative approaches: \\\"For this question, I recommend consulting [relevant authority/resource]\\\"\\n\"\n",
    "\t\t\t\"- Never make up information outside the provided RDMkit context\\n\\n\"\n",
    "\t\t\t\"6. RDMkit Integration\\n\"\n",
    "\t\t\t\"- Always connect individual practices to the broader RDM ecosystem\\n\"\n",
    "\t\t\t\"- Mention how the guidance fits within data lifecycle stages\\n\"\n",
    "\t\t\t\"- Reference relevant national or institutional resources when available\\n\"\n",
    "\t\t\t\"- Emphasize community and collaborative approaches to RDM\\n\\n\"\n",
    "\t\t\t\"Use the following pieces of retrieved context to answer the question. If no relevant context is provided, clearly state that the information is not available in the RDMkit knowledge base.\\n\\n\"\n",
    "\t\t\t\"Context: {context}\"\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tqa_prompt = ChatPromptTemplate.from_messages([\n",
    "\t\t\t(\"system\", system_prompt),\n",
    "\t\t\tMessagesPlaceholder(\"chat_history\"),\n",
    "\t\t\t(\"human\", \"{input}\"),\n",
    "\t\t])\n",
    "\t\t\n",
    "\t\tdef format_docs(docs: List[Document]) -> str:\n",
    "\t\t\t\"\"\"Format documents for context.\"\"\"\n",
    "\t\t\tif not docs:\n",
    "\t\t\t\treturn \"No relevant documents found in the RDMkit knowledge base.\"\n",
    "\t\t\t\n",
    "\t\t\tformatted_context = []\n",
    "\t\t\tfor doc in docs:\n",
    "\t\t\t\tcategory = doc.metadata.get('category', 'general')\n",
    "\t\t\t\tsection = doc.metadata.get('section_title', '')\n",
    "\t\t\t\tcontent = doc.page_content\n",
    "\t\t\t\t\n",
    "\t\t\t\tcontext_piece = f\"[{category}]\"\n",
    "\t\t\t\tif section:\n",
    "\t\t\t\t\tcontext_piece += f\" {section}:\"\n",
    "\t\t\t\tcontext_piece += f\" {content}\"\n",
    "\t\t\t\t\n",
    "\t\t\t\tformatted_context.append(context_piece)\n",
    "\t\t\t\n",
    "\t\t\treturn \"\\n\\n\".join(formatted_context)\n",
    "\t\n",
    "\t\tretriever_runnable = RunnableLambda(unified_retriever_func)\n",
    "\t\n",
    "\t\tanswer_generation_chain = (\n",
    "\t\t\tRunnablePassthrough.assign(\n",
    "\t\t\t\tcontext=lambda x: format_docs(x[\"documents\"])\n",
    "\t\t\t)\n",
    "\t\t\t| qa_prompt\n",
    "\t\t\t| self.llm\n",
    "\t\t\t| StrOutputParser()\n",
    "\t\t)\n",
    "\t\n",
    "\t\tself.unified_rag_chain = RunnablePassthrough.assign(\n",
    "\t\t\tdocuments=retriever_runnable\n",
    "\t\t).assign(\n",
    "\t\t\tanswer=answer_generation_chain\n",
    "\t\t)\n",
    "\n",
    "\t\t\n",
    "\tdef query(self, question: str, session_id: str = \"default\") -> Dict[str, Any]:\n",
    "\t\tif self.vectorstore is None:\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"success\": False,\n",
    "\t\t\t\t\"message\": \"RDMkit vector database not loaded, please initialize first\",\n",
    "\t\t\t\t\"answer\": None\n",
    "\t\t\t}\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tchat_history = []\n",
    "\t\t\tif session_id in self.store:\n",
    "\t\t\t\thistory = self.store[session_id]\n",
    "\t\t\t\t# Convert message history to simple format\n",
    "\t\t\t\tfor message in history.messages:\n",
    "\t\t\t\t\tif hasattr(message, 'content'):\n",
    "\t\t\t\t\t\tif message.type == 'human':\n",
    "\t\t\t\t\t\t\tchat_history.append(f\"Human: {message.content}\")\n",
    "\t\t\t\t\t\telif message.type == 'ai':\n",
    "\t\t\t\t\t\t\tchat_history.append(f\"Assistant: {message.content}\")\n",
    "\t\t\t\n",
    "\t\t\tchain_input = {\n",
    "\t\t\t\t\"input\": question,\n",
    "\t\t\t\t\"chat_history\": chat_history\n",
    "\t\t\t}\n",
    "\t\t\t\n",
    "\t\t\tresult_from_chain = self.unified_rag_chain.invoke(chain_input)\n",
    "\t\t\t\n",
    "\t\t\tanswer = result_from_chain.get(\"answer\")\n",
    "\t\t\tfinal_docs = result_from_chain.get(\"documents\", [])\n",
    "\t\t\t\n",
    "\t\t\tif session_id not in self.store:\n",
    "\t\t\t\tself.store[session_id] = ChatMessageHistory()\n",
    "\t\t\t\n",
    "\t\t\tself.store[session_id].add_user_message(question)\n",
    "\t\t\tself.store[session_id].add_ai_message(answer)\n",
    "\t\t\t\n",
    "\t\t\tcitations = self._extract_rdmkit_citations(final_docs)\n",
    "\t\t\tcontexts = [doc.page_content for doc in final_docs]\n",
    "\t\t\t\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"success\": True,\n",
    "\t\t\t\t\"question\": question,\n",
    "\t\t\t\t\"answer\": answer,\n",
    "\t\t\t\t\"contexts\": contexts,\n",
    "\t\t\t\t\"documents_used\": len(final_docs),\n",
    "\t\t\t\t\"citations\": citations,\n",
    "\t\t\t\t\"categories_used\": self._get_categories_used(final_docs),\n",
    "\t\t\t\t\"rdm_lifecycle_stages\": self._get_lifecycle_stages(final_docs)\n",
    "\t\t\t}\n",
    "\t\t\n",
    "\t\texcept Exception as e:\n",
    "\t\t\timport traceback\n",
    "\t\t\treturn {\n",
    "\t\t\t\t\"success\": False,\n",
    "\t\t\t\t\"message\": f\"RDMkit query processing error: {str(e)}\",\n",
    "\t\t\t\t\"answer\": None,\n",
    "\t\t\t\t\"error\": str(e)\n",
    "\t\t\t}\n",
    "\n",
    "\tdef _rerank_documents(self, query: str, documents: List[Document], top_k: int = 5) -> List[Document]:\n",
    "\t\t\"\"\"\n",
    "\t\tRe-ranks documents using BGE Reranker if available (BM25 removed).\n",
    "\t\t\"\"\"\n",
    "\t\tif not documents or len(documents) <= top_k:\n",
    "\t\t\treturn documents\n",
    "\n",
    "\t\ttitle_filtered_docs = self._title_priority_filter(query, documents)\n",
    "\t\t\n",
    "\t\tif not (self.reranking_enabled and self.reranker):\n",
    "\t\t\treturn title_filtered_docs[:top_k]\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tdoc_scores = self._get_bge_reranker_scores_with_cache(query, title_filtered_docs)\n",
    "\t\t\tenhanced_scores = self._combine_scores_with_titles(doc_scores)\n",
    "\t\t\tfiltered_docs_with_scores = self._apply_dynamic_threshold_filtering(enhanced_scores, top_k)\n",
    "\t\t\tfinal_docs = [doc for doc, score in filtered_docs_with_scores[:top_k]]\n",
    "\t\t\t\n",
    "\t\t\tprint(f\"BGE re-ranking successful. Selected {len(final_docs)} documents.\")\n",
    "\t\t\treturn final_docs\n",
    "\t\t\t\n",
    "\t\texcept Exception as e:\n",
    "\t\t\timport traceback\n",
    "\t\t\treturn title_filtered_docs[:top_k]\n",
    "\n",
    "\tdef _extract_rdmkit_citations(self, documents: List[Document]) -> List[Dict[str, str]]: \n",
    "\t\tcitations = []\n",
    "\t\tseen_sources = set()\n",
    "\t\n",
    "\t\tfor doc in documents:\n",
    "\t\t\tsource_file = doc.metadata.get(\"source_file\", \"\")\n",
    "\t\t\tif source_file and source_file not in seen_sources:\n",
    "\t\t\t\tseen_sources.add(source_file)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Generate RDMkit link\n",
    "\t\t\t\tif source_file.endswith('.md'):\n",
    "\t\t\t\t\t# Handle nested paths\n",
    "\t\t\t\t\tif '/' in source_file:\n",
    "\t\t\t\t\t\t# For files in subdirectories, use the directory and filename\n",
    "\t\t\t\t\t\tparts = source_file.split('/')\n",
    "\t\t\t\t\t\tif len(parts) > 1:\n",
    "\t\t\t\t\t\t\tpage_name = os.path.splitext(parts[-1])[0]\n",
    "\t\t\t\t\t\t\tdirectory = parts[-2]\n",
    "\t\t\t\t\t\t\tlink = f\"https://rdmkit.elixir-europe.org/{page_name}\"\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tpage_name = os.path.splitext(source_file)[0]\n",
    "\t\t\t\t\t\t\tlink = f\"https://rdmkit.elixir-europe.org/{page_name}\"\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpage_name = os.path.splitext(source_file)[0]\n",
    "\t\t\t\t\t\tlink = f\"https://rdmkit.elixir-europe.org/{page_name}\"\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tcitations.append({\n",
    "\t\t\t\t\t\t\"source_file\": source_file,\n",
    "\t\t\t\t\t\t\"link\": link,\n",
    "\t\t\t\t\t\t\"doc_title\": doc.metadata.get(\"doc_title\", \"\"),\n",
    "\t\t\t\t\t\t\"section_title\": doc.metadata.get(\"section_title\", \"\"),\n",
    "\t\t\t\t\t\t\"category\": doc.metadata.get(\"category\", \"\"),\n",
    "\t\t\t\t\t\t\"content_type\": doc.metadata.get(\"content_type\", \"text\")\n",
    "\t\t\t\t\t})\n",
    "\t\t\n",
    "\t\treturn citations\n",
    "\n",
    "\tdef _get_categories_used(self, documents: List[Document]) -> List[str]:\n",
    "\t\tcategories = set()\n",
    "\t\tfor doc in documents:\n",
    "\t\t\tcategory = doc.metadata.get(\"category\", \"\")\n",
    "\t\t\tif category:\n",
    "\t\t\t\tcategories.add(category)\n",
    "\t\treturn list(categories)\n",
    "\t\n",
    "\tdef _get_lifecycle_stages(self, documents: List[Document]) -> List[str]:\n",
    "\t\tstages = set()\n",
    "\t\tfor doc in documents:\n",
    "\t\t\trdm_lifecycle = doc.metadata.get(\"rdm_lifecycle\", \"\")\n",
    "\t\t\tif rdm_lifecycle:\n",
    "\t\t\t\tstages.update(rdm_lifecycle.split(', '))\n",
    "\t\treturn list(stages)\n",
    "\t\n",
    "\tdef _vector_retrieve_documents(self, question: str, k: int = 10) -> List[Document]:\n",
    "\t\tvector_docs = self.retriever.invoke(question)\n",
    "\t\t\n",
    "\t\tenhanced_docs = []\n",
    "\t\tfor doc in vector_docs:\n",
    "\t\t\tdoc.metadata['retrieval_source'] = 'vector'\n",
    "\t\t\ttitle_relevance = self._calculate_title_relevance(question, doc)\n",
    "\t\t\tdoc.metadata['title_relevance'] = title_relevance\n",
    "\t\t\tenhanced_docs.append(doc)\n",
    "\t\t\n",
    "\t\treturn enhanced_docs[:k]\n",
    "\t\n",
    "\tdef _calculate_title_relevance(self, query: str, document: Document) -> float:\n",
    "\t\t\"\"\"\n",
    "\t\t- Compute the relevance between the document and the query title.\n",
    "\t\t- Add positive weight for matching titles or sections.\n",
    "\t\t- Apply penalty for mismatched categories or intents.\n",
    "\t\t\"\"\"\n",
    "\t\tquery_lower = query.lower()\n",
    "\t\tquery_words = {word for word in query_lower.split() if len(word) > 2}\n",
    "\t\t\n",
    "\t\tdoc_title_words = {word for word in document.metadata.get('doc_title', '').lower().split() if len(word) > 2}\n",
    "\t\tdoc_section_words = {word for word in document.metadata.get('section_title', '').lower().split() if len(word) > 2}\n",
    "\t\tdoc_category = document.metadata.get('category', '')\n",
    "\n",
    "\t\ttitle_bonus = 0.6 if query_words.intersection(doc_title_words) else 0.0\n",
    "\t\tsection_bonus = 0.3 if query_words.intersection(doc_section_words) else 0.0\n",
    "\n",
    "\t\tpenalty = 0.0\n",
    "\t\t\n",
    "\t\tgeneral_query_terms = ['template', 'guideline', 'best practice', 'example']\n",
    "\t\tspecific_doc_categories = ['national_resources', 'domain_specific']\n",
    "\t\tif any(term in query_lower for term in general_query_terms) and doc_category in specific_doc_categories:\n",
    "\t\t\tpenalty += 0.4\n",
    "\t\t\t\n",
    "\t\tconcept_query_terms = ['template', 'policy', 'guideline', 'concept']\n",
    "\t\tif any(term in query_lower for term in concept_query_terms) and doc_category == 'tool_assembly':\n",
    "\t\t\tpenalty += 0.5\n",
    "\n",
    "\t\tfinal_score = title_bonus + section_bonus - penalty\n",
    "\t\tfinal_score = max(0, final_score)\n",
    "\t\t\n",
    "\t\tdocument.metadata['relevance_score_breakdown'] = {\n",
    "\t\t\t'title_bonus': title_bonus,\n",
    "\t\t\t'section_bonus': section_bonus,\n",
    "\t\t\t'penalty': -penalty,\n",
    "\t\t\t'total': final_score\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\treturn final_score\n",
    "\t\n",
    "\tdef _title_priority_filter(self, query: str, documents: List[Document]) -> List[Document]:\n",
    "\t\tdocuments.sort(key=lambda x: x.metadata.get('title_relevance', 0.0), reverse=True)\n",
    "\t\t\n",
    "\t\thigh_title_docs = [doc for doc in documents if doc.metadata.get('title_relevance', 0.0) > 0.1]\n",
    "\t\tother_docs = [doc for doc in documents if doc.metadata.get('title_relevance', 0.0) <= 0.1]\n",
    "\t\t\n",
    "\t\tif len(high_title_docs) < len(documents) * 0.3:\n",
    "\t\t\tneeded = min(len(documents) - len(high_title_docs), len(other_docs))\n",
    "\t\t\tresult = high_title_docs + other_docs[:needed]\n",
    "\t\telse:\n",
    "\t\t\tresult = high_title_docs\n",
    "\t\t\n",
    "\t\tprint(f\"filter: {len(documents)} -> {len(result)} documents\")\n",
    "\t\treturn result\n",
    "\t\n",
    "\tdef _combine_scores_with_titles(self, doc_scores: List[Tuple[Document, float]]) -> List[Tuple[Document, float]]:\n",
    "\t\tenhanced_scores = []\n",
    "\t\t\n",
    "\t\tfor doc, cross_score in doc_scores:\n",
    "\t\t\ttitle_score = doc.metadata.get('title_relevance', 0.0)\n",
    "\n",
    "\t\t\tcombined_score = cross_score * 0.8 + title_score * 0.2\n",
    "\t\t\tdoc.metadata['combined_score'] = combined_score\n",
    "\t\t\tenhanced_scores.append((doc, combined_score))\n",
    "\t\t\n",
    "\t\treturn enhanced_scores\n",
    "\n",
    "\tdef format_response_with_citations(self, result: Dict[str, Any]) -> str:\n",
    "\t\tif not result[\"success\"]:\n",
    "\t\t\treturn f\" {result['message']}\"\n",
    "\t\t\n",
    "\t\tresponse = f\"\\n **Answer:** {result['answer']}\\n\"\n",
    "\t\t\n",
    "\t\tif result.get(\"categories_used\"):\n",
    "\t\t\tresponse += f\"\\n **RDMkit Categories:** {', '.join(result['categories_used'])}\\n\"\n",
    "\t\t\n",
    "\t\tif result.get(\"rdm_lifecycle_stages\"):\n",
    "\t\t\tresponse += f\"\\n **Data Lifecycle Stages:** {', '.join(result['rdm_lifecycle_stages'])}\\n\"\n",
    "\t\t\n",
    "\t\tif result.get(\"documents_used\", 0) == 0:\n",
    "\t\t\tresponse += \"\\n⚠️ **Note:** No relevant documents found in the RDMkit knowledge base for this query.\\n\"\n",
    "\t\telif result.get(\"citations\"):\n",
    "\t\t\tresponse += \"\\n **RDMkit References:**\\n\"\n",
    "\t\t\tfor i, citation in enumerate(result[\"citations\"], 1):\n",
    "\t\t\t\ttitle = citation.get('doc_title', citation.get('source_file', 'Unknown'))\n",
    "\t\t\t\tsection = citation.get('section_title', '')\n",
    "\t\t\t\tcategory = citation.get('category', '')\n",
    "\t\t\t\t\n",
    "\t\t\t\tcitation_text = f\"[{i}] {title}\"\n",
    "\t\t\t\tif section:\n",
    "\t\t\t\t\tcitation_text += f\" - {section}\"\n",
    "\t\t\t\tif category:\n",
    "\t\t\t\t\tcitation_text += f\" ({category})\"\n",
    "\t\t\t\tcitation_text += f\" - {citation['link']}\\n\"\n",
    "\t\t\t\t\n",
    "\t\t\t\tresponse += citation_text\n",
    "\t\t\n",
    "\t\treturn response\n",
    "\n",
    "\tdef get_status(self) -> Dict[str, Any]:\n",
    "\t\t\"\"\"Get RDMkit system status\"\"\"\n",
    "\t\tstatus = {\n",
    "\t\t\t\"vectorstore_initialized\": self.vectorstore is not None,\n",
    "\t\t\t\"retriever_ready\": self.retriever is not None,\n",
    "\t\t\t\"json_file_path\": self.json_file_path,\n",
    "\t\t\t\"model_loaded\": self.llm is not None,\n",
    "\t\t\t\"reranking_enabled\": self.reranking_enabled,\n",
    "\t\t\t\"reranking_method\": f\"bge-reranker ({self.reranker_model_name})\" if self.reranking_enabled else \"llm-based\"\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\tif self.corpus_summary:\n",
    "\t\t\tstatus.update({\n",
    "\t\t\t\t\"corpus_summary\": self.corpus_summary,\n",
    "\t\t\t\t\"total_files\": self.corpus_summary.get('total_files', 0),\n",
    "\t\t\t\t\"total_chunks\": self.corpus_summary.get('total_chunks', 0),\n",
    "\t\t\t\t\"categories\": self.corpus_summary.get('categories', {}),\n",
    "\t\t\t\t\"average_chunk_size\": self.corpus_summary.get('average_chunk_size', 0)\n",
    "\t\t\t})\n",
    "\t\t\n",
    "\t\treturn status\n",
    "\n",
    "\tdef update_keyword_config(self, \n",
    "\t\t\t\t\t\t keyword_boost_factor: float = None,\n",
    "\t\t\t\t\t\t bm25_boost_factor: float = None,\n",
    "\t\t\t\t\t\t min_keyword_relevance: float = None,\n",
    "\t\t\t\t\t\t keyword_exact_match_bonus: float = None):\n",
    "\t\tif keyword_boost_factor is not None:\n",
    "\t\t\tself.keyword_boost_factor = keyword_boost_factor\n",
    "\t\tif bm25_boost_factor is not None:\n",
    "\t\t\tself.bm25_boost_factor = bm25_boost_factor\n",
    "\t\tif min_keyword_relevance is not None:\n",
    "\t\t\tself.min_keyword_relevance = min_keyword_relevance\n",
    "\t\tif keyword_exact_match_bonus is not None:\n",
    "\t\t\tself.keyword_exact_match_bonus = keyword_exact_match_bonus\n",
    "\t\n",
    "\tdef _get_cached_relevance(self, query_hash: str, doc_id: str) -> Optional[float]:\n",
    "\t\tcache_key = f\"{query_hash}:{doc_id}\"\n",
    "\t\treturn self.relevance_cache.get(cache_key)\n",
    "\n",
    "\tdef _cache_relevance(self, query_hash: str, doc_id: str, score: float):\n",
    "\t\tcache_key = f\"{query_hash}:{doc_id}\"\n",
    "\t\n",
    "\t\tif len(self.relevance_cache) >= self.cache_size_limit:\n",
    "\t\t\toldest_key = next(iter(self.relevance_cache))\n",
    "\t\t\tdel self.relevance_cache[oldest_key]\n",
    "\t\n",
    "\t\tself.relevance_cache[cache_key] = score\n",
    "\n",
    "\tdef _get_crossencoder_scores_with_cache(self, query: str, documents: List[Document]) -> List[Tuple[Document, float]]:\n",
    "\t\timport hashlib\n",
    "\t\n",
    "\t\tquery_hash = hashlib.md5(query.encode()).hexdigest()[:10]\n",
    "\t\n",
    "\t\tcached_results = []\n",
    "\t\tuncached_docs = []\n",
    "\t\n",
    "\t\tfor doc in documents:\n",
    "\t\t\tdoc_id = doc.metadata.get('chunk_id', f\"doc_{hash(doc.page_content[:100])}\")\n",
    "\t\t\tcached_score = self._get_cached_relevance(query_hash, doc_id)\n",
    "\t\t\n",
    "\t\t\tif cached_score is not None:\n",
    "\t\t\t\tcached_results.append((doc, cached_score))\n",
    "\t\t\telse:\n",
    "\t\t\t\tuncached_docs.append(doc)\n",
    "\t\n",
    "\t\tif uncached_docs:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tquery_doc_pairs = [(query, doc.page_content) for doc in uncached_docs]\n",
    "\t\t\t\tscores = self.cross_encoder.predict(query_doc_pairs)\n",
    "\t\t\t\n",
    "\t\t\t\tfor doc, score in zip(uncached_docs, scores):\n",
    "\t\t\t\t\tdoc_id = doc.metadata.get('chunk_id', f\"doc_{hash(doc.page_content[:100])}\")\n",
    "\t\t\t\t\tself._cache_relevance(query_hash, doc_id, float(score))\n",
    "\t\t\t\t\tcached_results.append((doc, float(score)))\n",
    "\t\t\t\t\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tfor doc in uncached_docs:\n",
    "\t\t\t\t\tcached_results.append((doc, 0.1))\n",
    "\t\n",
    "\t\treturn cached_results\n",
    "\n",
    "\tdef _get_bge_reranker_scores_with_cache(self, query: str, documents: List[Document]) -> List[Tuple[Document, float]]:\n",
    "\t\timport hashlib\n",
    "\t\t\n",
    "\t\tquery_hash = hashlib.md5(query.encode()).hexdigest()[:10]\n",
    "\t\t\n",
    "\t\tcached_results = []\n",
    "\t\tuncached_docs = []\n",
    "\t\t\n",
    "\t\tfor doc in documents:\n",
    "\t\t\tdoc_id = doc.metadata.get('chunk_id', f\"doc_{hash(doc.page_content[:100])}\")\n",
    "\t\t\tcached_score = self._get_cached_relevance(query_hash, doc_id)\n",
    "\t\t\t\n",
    "\t\t\tif cached_score is not None:\n",
    "\t\t\t\tcached_results.append((doc, cached_score))\n",
    "\t\t\telse:\n",
    "\t\t\t\tuncached_docs.append(doc)\n",
    "\t\t\n",
    "\t\tif uncached_docs:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tquery_doc_pairs = []\n",
    "\t\t\t\tfor doc in uncached_docs:\n",
    "\t\t\t\t\tcontent = doc.page_content[:2000] if len(doc.page_content) > 2000 else doc.page_content\n",
    "\t\t\t\t\tquery_doc_pairs.append([query, content])\n",
    "\n",
    "\t\t\t\tscores = self.reranker.compute_score(query_doc_pairs)\n",
    "\t\t\t\t\n",
    "\t\t\t\tif not isinstance(scores, (list, np.ndarray)):\n",
    "\t\t\t\t\tscores = [scores]\n",
    "\t\t\t\t\n",
    "\t\t\t\tepsilon = 1e-9\n",
    "\t\t\t\tnormalized_scores = [1 / (1 + np.exp(-s)) if np.exp(-s) != np.inf else epsilon for s in scores]\n",
    "\t\t\t\t\n",
    "\t\t\t\tfor doc, raw_score, norm_score in zip(uncached_docs, scores, normalized_scores):\n",
    "\t\t\t\t\tdoc_id = doc.metadata.get('chunk_id', f\"doc_{hash(doc.page_content[:100])}\")\n",
    "\t\t\t\t\tself._cache_relevance(query_hash, doc_id, float(norm_score))\n",
    "\t\t\t\t\tcached_results.append((doc, float(norm_score)))\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tdoc.metadata['bge_raw_score'] = float(raw_score)\n",
    "\t\t\t\t\tdoc.metadata['bge_normalized_score'] = float(norm_score)\n",
    "\t\t\t\t\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tfor doc in uncached_docs:\n",
    "\t\t\t\t\tcached_results.append((doc, 0.1))\n",
    "\t\t\n",
    "\t\treturn cached_results\n",
    "\n",
    "\tdef _apply_dynamic_threshold_filtering(self, doc_scores: List[Tuple[Document, float]], top_k: int) -> List[Tuple[Document, float]]:\n",
    "\t\tif not doc_scores:\n",
    "\t\t\treturn doc_scores\n",
    "\t\n",
    "\t\tscores = [score for _, score in doc_scores]\n",
    "\n",
    "\t\tmean_score = np.mean(scores)\n",
    "\t\tstd_score = np.std(scores)\n",
    "\n",
    "\t\tdynamic_threshold = max(\n",
    "\t\t\tself.min_relevance_threshold, \n",
    "\t\t\tmean_score - self.dynamic_threshold_factor * std_score\n",
    "\t\t)\n",
    "\n",
    "\t\tfiltered_docs = [(doc, score) for doc, score in doc_scores if score >= dynamic_threshold]\n",
    "\n",
    "\t\tif len(filtered_docs) < 2:\n",
    "\t\t\tdoc_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\t\t\tfiltered_docs = doc_scores[:min(3, len(doc_scores))]\n",
    "\n",
    "\t\tfiltered_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "\t\n",
    "\t\treturn filtered_docs\n",
    "\n",
    "\n",
    "\tdef clear_cache(self):\n",
    "\t\tself.relevance_cache.clear()\n",
    "\n",
    "\tdef get_cache_stats(self) -> Dict[str, Any]:\n",
    "\t\treturn {\n",
    "\t\t\t\"cache_size\": len(self.relevance_cache),\n",
    "\t\t\t\"cache_limit\": self.cache_size_limit,\n",
    "\t\t\t\"cache_usage\": f\"{len(self.relevance_cache)}/{self.cache_size_limit} ({len(self.relevance_cache)/self.cache_size_limit*100:.1f}%)\"\n",
    "\t\t}\n",
    "\n",
    "\tdef update_reranking_config(self, \n",
    "\t\t\t\t\t\t\tmin_relevance_threshold: float = None,\n",
    "\t\t\t\t\t\t\tdynamic_threshold_factor: float = None,\n",
    "\t\t\t\t\t\t\tmax_llm_verification_docs: int = None):\n",
    "\t\tif min_relevance_threshold is not None:\n",
    "\t\t\tself.min_relevance_threshold = min_relevance_threshold\n",
    "\t\tif dynamic_threshold_factor is not None:\n",
    "\t\t\tself.dynamic_threshold_factor = dynamic_threshold_factor\n",
    "\t\tif max_llm_verification_docs is not None:\n",
    "\t\t\tself.max_llm_verification_docs = max_llm_verification_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd937f73",
   "metadata": {},
   "source": [
    "# Usage functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250acb26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T14:47:10.072079Z",
     "iopub.status.busy": "2025-10-08T14:47:10.071771Z",
     "iopub.status.idle": "2025-10-08T14:47:10.077102Z",
     "shell.execute_reply": "2025-10-08T14:47:10.076194Z",
     "shell.execute_reply.started": "2025-10-08T14:47:10.072057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_rdmkit_rag_service(json_path: str = \"rdmkit_chunks_cleaned.json\") -> RDMkitRAGPipeline:\n",
    "    rag = RDMkitRAGPipeline(json_path)\n",
    "    init_result = rag.initialize_vectorstore()\n",
    "    if not init_result[\"success\"]:\n",
    "        raise RuntimeError(f\"RDMkit RAG initialization failed: {init_result['message']}\")\n",
    "    return rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ceb0e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T14:47:12.409172Z",
     "iopub.status.busy": "2025-10-08T14:47:12.408510Z",
     "iopub.status.idle": "2025-10-08T14:47:12.416255Z",
     "shell.execute_reply": "2025-10-08T14:47:12.415334Z",
     "shell.execute_reply.started": "2025-10-08T14:47:12.409148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_rdmkit_cli_interface(json_path: str = \"rdmkit_chunks_cleaned.json\"):\n",
    "    print(\"Initializing RDMkit RAG system...\")\n",
    "    \n",
    "    try:\n",
    "        rag = RDMkitRAGPipeline(json_path)\n",
    "        init_result = rag.initialize_vectorstore()\n",
    "        \n",
    "        if not init_result[\"success\"]:\n",
    "            print(f\"RDMkit initialization failed: {init_result['message']}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"RDMkit system initialization successful!\")\n",
    "        print(f\"Loaded {init_result['loaded_docs']} document chunks from {init_result['total_files']} files\")\n",
    "        print(f\"Categories: {init_result['categories']}\")\n",
    "        print(f\"Average chunk size: {init_result['average_chunk_size']:.1f} characters\")\n",
    "        \n",
    "        status = rag.get_status()\n",
    "        rerank_method = status.get('reranking_method', 'unknown')\n",
    "        print(f\"Re-ranking method: {rerank_method}\")\n",
    "        print(f\"RDMkit knowledge base Q&A system is ready!\")\n",
    "        print(\"Enter 'exit' or 'quit' to exit the program\\n\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                question = input(\"Please enter your RDMkit question: \").strip()\n",
    "                \n",
    "                if question.lower() in ['exit', 'quit']:\n",
    "                    print(\"Thank you for using RDMkit RAG, goodbye!\")\n",
    "                    break\n",
    "                \n",
    "                if not question:\n",
    "                    print(\"Please enter a valid question about research data management\")\n",
    "                    continue\n",
    "                \n",
    "                print(\"Processing your RDMkit question...\")\n",
    "                result = rag.query(question)\n",
    "                response = rag.format_response_with_citations(result)\n",
    "                print(response)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\nThank you for using RDMkit RAG, goodbye!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error during processing: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"RDMkit system initialization failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84692a06-4078-46be-b69d-119b63bedc86",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bb872-b28d-47b0-a1b5-85ecb69dca59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T14:47:17.924688Z",
     "iopub.status.busy": "2025-10-08T14:47:17.923987Z",
     "iopub.status.idle": "2025-10-08T14:52:05.925710Z",
     "shell.execute_reply": "2025-10-08T14:52:05.924755Z",
     "shell.execute_reply.started": "2025-10-08T14:47:17.924652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_rdmkit_cli_interface(\"/kaggle/input/chatbotcorpus/rdmkit_chunks_cleaned.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f2415-e29c-48f1-a76a-8b052cba6817",
   "metadata": {},
   "source": [
    "# RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980cb05d-2914-4863-8a5c-e0cc4e2c8628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T14:52:33.162108Z",
     "iopub.status.busy": "2025-10-08T14:52:33.161806Z",
     "iopub.status.idle": "2025-10-08T14:56:00.624518Z",
     "shell.execute_reply": "2025-10-08T14:56:00.623867Z",
     "shell.execute_reply.started": "2025-10-08T14:52:33.162086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    LLMContextPrecisionWithoutReference\n",
    ")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    google_api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "results_dir = \"/kaggle/working/ragas_evaluation_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "evaluation_questions = [\n",
    "    \"How do I ensure my sensitive data complies with GDPR?\"\n",
    "]\n",
    "\n",
    "json_file_path = \"/kaggle/input/chatbotcorpus/rdmkit_chunks_cleaned.json\"\n",
    "pipeline = RDMkitRAGPipeline(json_file_path=json_file_path)\n",
    "pipeline.initialize_vectorstore()\n",
    "\n",
    "metrics_to_evaluate = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    LLMContextPrecisionWithoutReference(),\n",
    "]\n",
    "\n",
    "ragas_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
    "ragas_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "all_qa_data = []\n",
    "\n",
    "for i, question in enumerate(evaluation_questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" {i}/{len(evaluation_questions)}: {question[:50]}...\")\n",
    "    print('='*60)\n",
    "    \n",
    "    result = pipeline.query(question, session_id=f\"ragas-eval-{i}\")\n",
    "    \n",
    "    if not result[\"success\"]:\n",
    "        continue\n",
    "        \n",
    "    if not result[\"answer\"] or not result[\"contexts\"]:\n",
    "        continue\n",
    "    \n",
    "    qa_item = {\n",
    "        \"question\": result[\"question\"],\n",
    "        \"answer\": result[\"answer\"],\n",
    "        \"contexts\": result[\"contexts\"],\n",
    "    }\n",
    "    all_qa_data.append(qa_item)\n",
    "    \n",
    "    single_dataset = Dataset.from_list([qa_item])\n",
    "    \n",
    "    try:\n",
    "        single_results = evaluate(\n",
    "            dataset=single_dataset,\n",
    "            metrics=metrics_to_evaluate,\n",
    "            llm=ragas_llm,\n",
    "            embeddings=ragas_embeddings,\n",
    "            batch_size=1,\n",
    "            raise_exceptions=True,\n",
    "        )\n",
    "        \n",
    "        single_df = single_results.to_pandas()\n",
    "        evaluation_scores = single_df.iloc[0].to_dict()\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        evaluation_scores = {\"error\": str(e)}\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"question_{i:02d}_{timestamp}.txt\"\n",
    "    filepath = os.path.join(results_dir, filename)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"RAGAS result {i}\\n\")\n",
    "        f.write(f\"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Questioin:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"{result['question']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"FINAL DOCUMENTS USED FOR ANSWER GENERATION:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if result.get('contexts') and isinstance(result['contexts'], list):\n",
    "            for idx, context in enumerate(result['contexts'], 1):\n",
    "                f.write(f\"DocumentDocument {idx}:\\n\")\n",
    "                f.write(f\"{context}\\n\")\n",
    "                f.write(\"-\" * 20 + \"\\n\")\n",
    "        else:\n",
    "            f.write(\"ERROR\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"Answer:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"{result['answer']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"RAGAS:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if \"error\" not in evaluation_scores:\n",
    "            for metric_name, score in evaluation_scores.items():\n",
    "                if metric_name not in ['question', 'answer', 'contexts']:\n",
    "                    if isinstance(score, (int, float)) and not pd.isna(score):\n",
    "                        f.write(f\"{metric_name}: {score:.4f}\\n\")\n",
    "                    else:\n",
    "                        f.write(f\"{metric_name}: {score}\\n\")\n",
    "        else:\n",
    "            f.write(f\"{evaluation_scores['error']}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7787844,
     "sourceId": 12747288,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
