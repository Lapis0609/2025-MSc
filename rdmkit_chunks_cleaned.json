[
    {
        "id":"yaml_tool_and_resource_list_yml_0",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":0,
        "total_chunks":185,
        "content":"- description: scikit-learn is a free software machine learning library for the Python\n    programming language. id: scikit-learn\n  name: scikit-learn\n  registry:\n    biotools: scikit-learn\n    tess: scikit-learn\n  url: https:\/\/scikit-learn.org\n- description: The CUDA Toolkit from NVIDIA provides everything you need to develop\n    GPU-accelerated applications\n  id: cuda\n  name: CUDA toolkit\n  url: https:\/\/developer.nvidia.com\/cuda-toolkit\n- description: A free and open-source software library for machine learning and artificial\n    intelligence. id: tensorflow\n  name: Tensorflow\n  registry:\n    biotools: tensorflow\n    tess: Tensorflow\n  url: https:\/\/www.tensorflow.org\n- description: Keras is an open-source library that provides a Python interface for\n    artificial neural networks. id: keras\n  name: Keras\n  registry:\n    tess: Keras\n  url: https:\/\/keras.io\/\n- description: BioImage is a collaborative effort to bring AI models to the bioimaging\n    community.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_1",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":1,
        "total_chunks":185,
        "content":" description: BioImage is a collaborative effort to bring AI models to the bioimaging\n    community. id: bioimage\n  name: BioImage Model Zoo\n  registry: fairsharing: 77fc63\n    tess: BioImage Model Zoo\n  url: https:\/\/bioimage.io\/#\/\n- description: Data, Optimisation, Model and Evaluation in Machine Learning (DOME-ML)\n    is a set of community guidelines, recommendations and checklists for supervised\n    ML validation in biology. id: dome\n  name: DOME-ML\n  registry:\n    fairsharing: cf62c2\n  url: https:\/\/dome-ml.org\/\n- description: ONNX is an open format built to represent machine learning models. id: onnx\n  name: Open Neural Network Exchange (ONNX)\n  url: https:\/\/onnx.ai\/\n- description: The platform where the machine learning community collaborates on models,\n    datasets, and applications. id: huggingface\n  name: HuggingFace\n  registry:\n    tess: HuggingFace\n  url: https:\/\/huggingface.co\/\n- description: CatBoost is a high-performance open source library for gradient boosting\n    on decision trees. id: catboost\n  name: CatBoost\n  url: https:\/\/catboost.ai\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_2",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":2,
        "total_chunks":185,
        "content":"ting\n    on decision trees. id: catboost\n  name: CatBoost\n  url: https:\/\/catboost.ai\/\n- description: BRAVA is a tool designed to help developers test servers that comply\n    with the BrAPI specifications. id: brava\n  name: BRAVA\n  url: https:\/\/webapps.ipk-gatersleben.de\/brapivalidator\n- description: Plant 3D is a plant phenotyping toolkit for 3D point clouds. Plant\n    3D (P3D) automatically extracts common phenotyping features of interest from high-resolution\n    3D scans of plant architectures. id: plant3d\n  name: Plant 3D\n  registry:\n    biotools: plant-3d\n  url: https:\/\/github.com\/iziamtso\/P3D\/\n- description: LeafNet is a convenient tool that can robustly localise stomata and\n    segment pavement cells for light-microscope images of leaves\n  id: leafnet\n  name: LeafNet\n  registry:\n    biotools: leafnet\n  url: https:\/\/leafnet.whu.edu.cn\/\n- description: Plant Computer Vision (PlantCV)is an image processing toolkit for plant\n    phenotyping analysis.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_3",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":3,
        "total_chunks":185,
        "content":"n: Plant Computer Vision (PlantCV)is an image processing toolkit for plant\n    phenotyping analysis. id: plantcv\n  name: PlantCV\n  registry:\n    biotools: plantcv_v2\n  url: https:\/\/github.com\/danforthcenter\/plantcv-v2-paper\n- description: Phenomenal-3D is an automatic open-source library for 3D shoot architecture\n    reconstruction and analysis for image-based plant phenotyping\n  id: phenomenal-3d\n  name: Phenomenal 3D\n  registry:\n    biotools: phenomenal-3d\n  url: https:\/\/github.com\/openalea\/phenomenal\n- description: C library that provides a simple interface to read whole-slide images\n    (also known as virtual slides) id: openslide\n  name: OpenSlide\n  url: https:\/\/openslide.org\/\n- description: Image Reading, Metadata Conversion, and Image Writing for Microscopy\n    Images in Pure Python\n  id: aicsimageio\n  name: AICSImageIO\n  url: https:\/\/github.com\/AllenCellModeling\/aicsimageio\n- description: Bio-Formats is a software tool for reading and writing image data using\n    standardized, open formats.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_4",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":4,
        "total_chunks":185,
        "content":"-Formats is a software tool for reading and writing image data using\n    standardized, open formats. id: bioformats\n  name: Bio-Formats\n  registry:\n    biotools: bio-formats\n    tess: Bio-Formats\n  url: https:\/\/www.openmicroscopy.org\/bio-formats\/\n- description: Java application to convert image file formats, including .mrxs, to\n    an intermediate Zarr structure compatible with the OME-NGFF specification. id: bioformats2raw\n  name: bioformats2raw\n  url: https:\/\/github.com\/glencoesoftware\/bioformats2raw\n- description: Java application to convert a directory of tiles to an OME-TIFF pyramid. This is the second half of iSyntax\/.mrxs => OME-TIFF conversion. id: raw2ometiff\n  name: raw2ometiff\n  url: https:\/\/github.com\/glencoesoftware\/raw2ometiff\n- description: The bfconvert command line tool can be used to convert files between\n    supported formats.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_5",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":5,
        "total_chunks":185,
        "content":"ription: The bfconvert command line tool can be used to convert files between\n    supported formats. id: bfconvert\n  name: bfconvert\n  url: https:\/\/bio-formats.readthedocs.io\/en\/stable\/users\/comlinetools\/conversion.html\n- description: Aggregating critical information to accelerate COVID-19 drug discovery\n    for the molecular modeling and simulation community. id: molssi\n  name: MolSSI - BioExcel COVID-19 therapeutics hub\n  url: https:\/\/covid.bioexcel.eu\/\n- description: The open source PIA software helps to carry out data protection impact\n    assessment\n  id: pia\n  name: Privacy Impact Assessment Tool (PIA) registry:\n    biotools: pia\n  url: https:\/\/www.cnil.fr\/en\/open-source-pia-software-helps-carry-out-data-protection-impact-assessment\n- description: The Japanese Genotype-phenotype Archive (JGA) is a service for permanent\n    archiving and sharing of all types of individual-level genetic and de-identified\n    phenotypic data resulting from biomedical research projects. id: jga\n  name: JGA\n  url: https:\/\/www.ddbj.nig.ac.jp\/jga\/index-e.html\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_6",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":6,
        "total_chunks":185,
        "content":"arch projects. id: jga\n  name: JGA\n  url: https:\/\/www.ddbj.nig.ac.jp\/jga\/index-e.html\n- description: Network providing unified programmatic access to experimentally determined\n    and predicted structure models\n  id: 3d-beacons\n  name: 3D-Beacons\n  registry:\n    biotools: 3d-beacons\n  url: https:\/\/3d-beacons.org\n- description: Rigorous record-keeping and quality control are required to ensure\n    the quality, reproducibility and value of imaging data. The 4DN Initiative and\n    BINA have published light Microscopy Metadata Specifications that extend the OME\n    Data Model, scale with experimental intent and complexity, and make it possible\n    for scientists to create comprehensive records of imaging experiments.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_7",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":7,
        "total_chunks":185,
        "content":"ity, and make it possible\n    for scientists to create comprehensive records of imaging experiments. The Microscopy\n    Metadata Specifications have been adopted by QUAREP-LiMi and are being revised\n    in QUAREP-LiMi in collaboration with instrument manufacturers\n  id: 4dn-bina-ome-quarep\n  name: 4DN-BINA-OME-QUAREP (NBO-Q)\n  registry:\n    fairsharing: 87756d\n  url: https:\/\/www.nature.com\/articles\/s41592-021-01327-9\n- description: A standard schema for primary biodiversity data\n  id: access-to-biological-collection-data-schema\n  name: Access to Biological Collection Data Schema (ABCD) registry:\n    biotools: NA\n  url: https:\/\/www.tdwg.org\/standards\/abcd\/\n- description: Ada is a performant and highly configurable system for secured integration,\n    visualization, and collaborative analysis of heterogeneous data sets, primarily\n    targeting clinical and experimental sources.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_8",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":8,
        "total_chunks":185,
        "content":"tive analysis of heterogeneous data sets, primarily\n    targeting clinical and experimental sources. id: ada-discovery-analytics\n  name: Ada Discovery Analytics (Ada)\n  url: https:\/\/ada-discovery.github.io\/\n- description: A searchable repository with a focus on plasmids\n  id: addgene\n  name: Addgene\n  registry:\n    biotools: addgene\n    fairsharing: 8hcczk\n    tess: Addgene\n  url: https:\/\/www.addgene.org\/browse\/\n- description: Browser for ontologies for agricultural science based on NBCO BioPortal. id: agroportal\n  name: AgroPortal\n  registry:\n    biotools: AgroPortal\n    fairsharing: z4xpxx\n  url: http:\/\/agroportal.lirmm.fr\/\n- description: Amazon Web Services\n  id: amazon-web-services\n  name: Amazon Web Services\n  registry:\n    tess: Amazon Web Services\n  url: https:\/\/aws.amazon.com\/\n- description: AOP4EUpest web server is devoted to the identification of pesticides\n    involved in an Adverse Outcome Pathway via text mining approaches.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_9",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":9,
        "total_chunks":185,
        "content":" identification of pesticides\n    involved in an Adverse Outcome Pathway via text mining approaches. id: aop4eupest\n  name: AOP4EUpest\n  registry:\n    biotools: aop4eupest\n  url: http:\/\/www.biomedicale.parisdescartes.fr\/aop4EUpest\/home.php\n- description: APID (Agile Protein Interactomes DataServer) is a server that provides\n    a comprehensive collection of protein interactomes for more than 400 organisms\n    based in the integration of known experimentally validated protein-protein physical\n    interactions (PPIs) id: apid-interactomes\n  name: APID Interactomes\n  registry:\n    biotools: apid\n  url: http:\/\/apid.dep.usal.es\/\n- description: Plan and follow your data. Bring your Data Management Plans closer\n    to where data are generated, analysed and stored. id: argos\n  name: Argos\n  registry:\n    tess: Argos\n  url: https:\/\/argos.openaire.eu\/splash\/\n- description: A collection in BioStudies for archiving and publishing data from high-throughput\n    functional genomics experiments.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_10",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":10,
        "total_chunks":185,
        "content":"oStudies for archiving and publishing data from high-throughput\n    functional genomics experiments. id: arrayexpress\n  name: ArrayExpress\n  registry:\n    biotools: arrayexpress\n    fairsharing: 6k0kwd\n    tess: ArrayExpress\n  url: https:\/\/www.ebi.ac.uk\/arrayexpress\/\n- description: With Arvados, bioinformaticians run and scale compute-intensive workflows,\n    developers create biomedical applications, and IT administrators manage large\n    compute and storage resources. id: arvados\n  name: Arvados\n  url: https:\/\/arvados.org\n- description: Biological materials resource including cell-lines, strains and genomics\n    tools\n  id: atcc\n  name: ATCC\n  registry:\n    biotools: atcc\n  url: https:\/\/www.atcc.org\/\n- description: Free, publicly available web-based, open-source software application\n    developed by the OHDSI community to support the design and execution of observational\n    analyses to generate real world evidence from patient level observational data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_11",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":11,
        "total_chunks":185,
        "content":"of observational\n    analyses to generate real world evidence from patient level observational data. id: atlas\n  name: Atlas\n  registry:\n    biotools: atlas\n    fairsharing: NA\n    tess: Atlas\n  url: https:\/\/github.com\/OHDSI\/Atlas\/wiki\n- description: Store and publish your research data. Can be used to bridge between\n    domains\n  id: b2share\n  name: b2share\n  registry:\n    fairsharing: da9307\n  url: https:\/\/b2share.eudat.eu\/\n- description: A searchable database for bacteria specific information\n  id: bacdive\n  name: BacDive\n  registry:\n    biotools: bacdive\n    fairsharing: aSszvY\n    tess: BacDive\n  url: https:\/\/bacdive.dsmz.de\n- description: A repository specific to Bacillus strains\n  id: bacillus-genetic-stock-center\n  name: Bacillus Genetic Stock Center (BGSC)\n  registry:\n    biotools: NA\n  url: http:\/\/www.bgsc.org\/\n- description: The ELSI Knowledge Base is an open-access resource platform that aims\n    at providing practical know-how for responsible research.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_12",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":12,
        "total_chunks":185,
        "content":"pen-access resource platform that aims\n    at providing practical know-how for responsible research. id: bbmri-eric-s-elsi-knowledge-base\n  name: BBMRI-ERIC's ELSI Knowledge Base\n  url: https:\/\/www.bbmri-eric.eu\/elsi\/knowledge-base\/\n- description: The Beacon protocol defines an open standard for genomics data discovery. id: beacon\n  name: Beacon\n  registry:\n    biotools: ga4gh_beacon\n    fairsharing: 6fba91\n    tess: Beacon\n  url: https:\/\/beacon-project.io\/\n- description: R&D Platform for Life Sciences\n  id: benchling\n  name:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_13",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":13,
        "total_chunks":185,
        "content":"rl: https:\/\/beacon-project.io\/\n- description: R&D Platform for Life Sciences\n  id: benchling\n  name: Benchling\n  registry:\n    tess: Benchling\n  url: https:\/\/www.benchling.com\n- description: BIAFLOWS is an open-soure web framework to reproducibly deploy and\n    benchmark bioimage analysis workflows\n  id: biaflows\n  name: BIAFLOWS\n  registry:\n    biotools: biaflows\n  url: https:\/\/biaflows.neubias.org\/\n- description: Repository for Nucleic Acids MD simulations\n  id: bignasim\n  name: BigNASim\n  registry:\n    biotools: bignasim\n  url: https:\/\/mmb.irbbarcelona.org\/BigNASim\/\n- description: The BioImage Informatics Index is a registry of software tools, image\n    databases for benchmarking, and training materials for bioimage analysis\n  id: biii\n  name: BIII\n  registry:\n    biotools: BISE\n  url: https:\/\/biii.eu\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_14",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":14,
        "total_chunks":185,
        "content":"alysis\n  id: biii\n  name: BIII\n  registry:\n    biotools: BISE\n  url: https:\/\/biii.eu\/\n- description: Public, web-accessible database of measured binding affinities\n  id: bindingdb\n  name: BindingDB\n  registry:\n    biotools: bindingdb\n    fairsharing: 3b36hk\n  url: https:\/\/www.bindingdb.org\/\n- description: Bio-Formats is a software tool for reading and writing image data using\n    standardized, open formats\n  id: bio-formats\n  name: Bio-Formats\n  registry:\n    biotools: bio-formats\n    tess: Bio-Formats\n  url: https:\/\/www.openmicroscopy.org\/bio-formats\/\n- description: Platform designed to efficiently generate bioactive conformers and\n    speed up the drug discovery process. id: bioactive-conformational-ensemble\n  name: Bioactive Conformational Ensemble\n  registry:\n    biotools: bce\n  url: https:\/\/mmb.irbbarcelona.org\/BCE\/\n- description: Bioconda is a bioinformatics channel for the Conda package manager",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_15",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":15,
        "total_chunks":185,
        "content":"barcelona.org\/BCE\/\n- description: Bioconda is a bioinformatics channel for the Conda package manager id: bioconda\n  name: Bioconda\n  registry:\n    biotools: bioconda\n    fairsharing: 185b0d\n    tess: Bioconda\n  url: https:\/\/bioconda.github.io\/\n- description: Biodiversity Information Standards (TDWG), historically the Taxonomic\n    Databases Working Group, work to develop biodiversity information standards\n  id: biodiversity-information-standards\n  name: Biodiversity Information Standards (TDWG) registry:\n    fairsharing: '826786'\n  url: https:\/\/www.tdwg.org\n- description: The BioImage Archive stores and distributes biological images that\n    are useful to life-science researchers.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_16",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":16,
        "total_chunks":185,
        "content":"ge Archive stores and distributes biological images that\n    are useful to life-science researchers. id: bioimagearchive\n  name: BioImageArchive\n  registry:\n    fairsharing: x38D2k\n  url: https:\/\/www.ebi.ac.uk\/bioimage-archive\/\n- description: A repository of mathematical models for application in biological sciences\n  id: biomodels\n  name: BioModels\n  registry:\n    biotools: biomodels\n    fairsharing: paz6mh\n    tess: BioModels\n  url: https:\/\/www.ebi.ac.uk\/biomodels\/\n- description: BioSamples stores and supplies descriptions and metadata about biological\n    samples used in research and development by academia and industry.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_17",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":17,
        "total_chunks":185,
        "content":"and metadata about biological\n    samples used in research and development by academia and industry. id: biosamples\n  name: BioSamples\n  registry:\n    biotools: biosamples\n    fairsharing: ewjdq6\n    tess: BioSamples\n  url: https:\/\/www.ebi.ac.uk\/biosamples\/\n- description: Bioschemas aims to improve the Findability on the Web of life sciences\n    resources such as datasets, software, and training materials\n  id: bioschemas\n  name: Bioschemas\n  registry:\n    fairsharing: f3a3ca\n    tess: Bioschemas\n  url: https:\/\/bioschemas.org\n- description: A database hosting datasets from biological studies. Useful for storing\n    or accessing life sciences data without community-accepted repositories, and for\n    linking components of data from multi-omics studies.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_18",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":18,
        "total_chunks":185,
        "content":"ut community-accepted repositories, and for\n    linking components of data from multi-omics studies. id: biostudies\n  name: BioStudies\n  registry:\n    biotools: biostudies\n    fairsharing: mtjvme\n    tess: BioStudies\n  url: https:\/\/www.ebi.ac.uk\/biostudies\/\n- description: Resource for management and analysis of 5D biological images\n  id: bisque\n  name: BisQue\n  registry:\n    biotools: bisque\n  url: https:\/\/bioimage.ucsb.edu\/bisque\n- description: Git-based code hosting and collaboration tool, built for teams. id: bitbucket\n  name: Bitbucket\n  registry:\n    fairsharing: fc3431\n  url: https:\/\/bitbucket.org\/\n- description: Biological Magnetic Resonance Data Bank\n  id: bmrb\n  name: BMRB\n  registry:\n    biotools: bmrb\n  url: https:\/\/bmrb.io\/\n- description: BoostDM is a method to score all possible point mutations (single base\n    substitutions) in cancer genes for their potential to be involved in tumorigenesis. id: boostdm\n  name: BoostDM\n  registry:\n    biotools: boostdm\n    tess: BoostDM\n  url: https:\/\/www.intogen.org\/boostdm\/search\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_19",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":19,
        "total_chunks":185,
        "content":"    biotools: boostdm\n    tess: BoostDM\n  url: https:\/\/www.intogen.org\/boostdm\/search\n- description: Cloud storage and file sharing service\n  id: box\n  name: Box\n  registry:\n    tess: Box\n  url: https:\/\/www.box.com\n- description: 'Specification for a standard API for plant data: plant material, plant\n    phenotyping data'\n  id: brapi\n  name: BrAPI\n  registry:\n    tess: BrAPI\n  url: https:\/\/www.brapi.org\n- description: Database of enzyme and enzyme-ligand information, across all taxonomic\n    groups, manually extracted from primary literature and extended by text mining\n    procedures\n  id: brenda\n  name: BRENDA\n  registry:\n    biotools: brenda\n    fairsharing: etp533\n    tess: BRENDA\n  url: https:\/\/www.brenda-enzymes.org\/\n- description: File renaming software for Windows\n  id: bulk-rename-utility\n  name: Bulk Rename Utility\n  url: https:\/\/www.bulkrenameutility.co.uk\/\n- description: Open source tandem mass spectrometry (MS\/MS) sequence database search\n    tool.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_20",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":20,
        "total_chunks":185,
        "content":"o.uk\/\n- description: Open source tandem mass spectrometry (MS\/MS) sequence database search\n    tool. id: comet\n  name: Comet\n  registry:\n    biotools: comet\n  url: https:\/\/uwpr.github.io\/Comet\/\n- description: Continuous evaluation of the accuracy and reliability of protein structure\n    prediction methods in a fully automated manner\n  id: cameo\n  name: CAMEO\n  registry:\n    biotools: cameo\n    fairsharing: dq34p2\n  url: https:\/\/cameo3d.org\n- description: Cancer Genome Interpreter (CGI) is designed to support the identification\n    of tumor alterations that drive the disease and detect those that may be therapeutically\n    actionable. id: cancer-genome-interpreter\n  name: Cancer Genome Interpreter\n  registry:\n    biotools: cgi\n  url: https:\/\/www.cancergenomeinterpreter.org\/home\n- description: Critical assessment of structure prediction methods for protein-protein\n    interactions\n  id: capri\n  name: CAPRI\n  url: https:\/\/www.ebi.ac.uk\/pdbe\/complex-pred\/capri\/\n- description: The CAS Registry (Chemical Abstracts Service Registry) includes more\n    than 188 million unique chemicals.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_21",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":21,
        "total_chunks":185,
        "content":" Registry (Chemical Abstracts Service Registry) includes more\n    than 188 million unique chemicals. CAS Registry Numbers are broadly used as a\n    unique identifier for chemical substances. The Registry is maintained by CAS,\n    a subdivision of the American Chemical Society. id: cas-registry\n  name: CAS Registry\n  registry:\n    fairsharing: r7Kwy7\n  url: https:\/\/www.cas.org\/cas-data\/cas-registry\n- description: Biennial critical assessment of techniques for protein structure prediction\n  id: casp\n  name: CASP\n  registry:\n    biotools: casp\n    tess: CASP\n  url: https:\/\/predictioncenter.org\n- description: Castor is an EDC system for researchers and institutions. With Castor,\n    you can create and customize your own database in no time. Without any prior technical\n    knowledge, you can build a study in just a few clicks using our intuitive Form\n    Builder. Simply define your data points and start collecting high quality data,\n    all you need is a web browser.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_22",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":22,
        "total_chunks":185,
        "content":"y define your data points and start collecting high quality data,\n    all you need is a web browser. id: castor\n  name: Castor\n  registry:\n    biotools: castor\n    fairsharing: NA\n  url: https:\/\/www.castoredc.com\n- description: A hierarchical domain classification of protein structures in the Protein\n    Data Bank. id: cath\n  name: CATH\n  registry:\n    biotools: cath\n    fairsharing: xgcyyn\n    tess: CATH\n  url: http:\/\/www.cathdb.info\/\n- description: CEDAR is making data submission smarter and faster, so that scientific\n    researchers and analysts can create and use better metadata.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_23",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":23,
        "total_chunks":185,
        "content":"rter and faster, so that scientific\n    researchers and analysts can create and use better metadata. id: cedar\n  name: CEDAR\n  registry:\n    biotools: cedar\n    fairsharing: pmygc7\n  url: https:\/\/metadatacenter.org\n- description: Image analysis software\n  id: cellprofiler\n  name: CellProfiler\n  registry:\n    biotools: cellprofiler\n    tess: CellProfiler\n  url: https:\/\/cellprofiler.org\/\n- description: ilastik is a user-friendly tool for interactive image classification,\n    segmentation and analysis\n  id: ilastik\n  name: ilastik\n  registry:\n    biotools: ilastik\n  url: https:\/\/www.ilastik.org\/\n- description: A version management tool for modifying strains",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_24",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":24,
        "total_chunks":185,
        "content":"astik\n  url: https:\/\/www.ilastik.org\/\n- description: A version management tool for modifying strains id: cellrepo\n  name: CellRepo\n  url: https:\/\/www.cellrepo.com\/\n- description: An ontology for expressing cellular (or multi-cellular) terms with\n    applications in microscopy\n  id: cellular-microscopy-phenotype-ontology\n  name: Cellular Microscopy Phenotype Ontology (CMPO)\n  registry:\n    fairsharing: knp11s\n    tess: Cellular Microscopy Phenotype Ontology (CMPO)\n  url: https:\/\/www.ebi.ac.uk\/cmpo\/\n- description: CERNBox cloud data storage, sharing and synchronization\n  id: cernbox\n  name: CERNBox\n  url: https:\/\/cernbox.web.cern.ch\/cernbox\/\n- description: Dictionary of molecular entities focused on 'small' chemical compounds\n  id: chebi\n  name: ChEBI\n  registry:\n    biotools: chebi\n    fairsharing: 62qk8w\n    tess: ChEBI\n  url: https:\/\/www.ebi.ac.uk\/chebi\/\n- description: Database of bioactive drug-like small molecules, it contains 2-D structures,\n    calculated properties and abstracted bioactivities.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_25",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":25,
        "total_chunks":185,
        "content":"small molecules, it contains 2-D structures,\n    calculated properties and abstracted bioactivities. id: chembl\n  name: ChEMBL\n  registry:\n    biotools: chembl\n    fairsharing: m3jtpg\n    tess: ChEMBL\n  url: https:\/\/www.ebi.ac.uk\/chembl\/\n- description: Choose an open source license\n  id: choose-a-license\n  name: Choose a license\n  url: https:\/\/choosealicense.com\n- description: ClinicalTrials.gov is a resource depending on the National Library\n    of medicine which makes available private and public-funded clinical trials. id: clinicaltrials-gov\n  name: ClinicalTrials.gov\n  registry:\n    fairsharing: mewhad\n  url: https:\/\/clinicaltrials.gov\/\n- description: A collection of software applications which enables creation, storing\n    and publishing of Common Data Elements according to the CDE semantic model. id: common-data-elements-in-a-box\n  name: Common Data Elements (CDE) in a box\n  registry:\n    biotools: cde\n  url: https:\/\/github.com\/ejp-rd-vp\/cde-in-box\n- description: An open standard for describing workflows that are build from command\n    line tools",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_26",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":26,
        "total_chunks":185,
        "content":"\n- description: An open standard for describing workflows that are build from command\n    line tools id: common-workflow-language\n  name: Common Workflow Language (CWL)\n  registry:\n    fairsharing: 8y5ayx\n    tess: Common Workflow Language (CWL)\n  url: https:\/\/www.commonwl.org\n- description: The CompTox Chemicals Dashboard provides toxicological information\n    for over 800.000 chemical compounds. It is a part of a suite of databases and\n    web applications developed by the US Environmental Protection Agency's Chemical\n    Safety for Sustainability Research Program. These databases and apps support EPA's\n    computational toxicology research efforts to develop innovative methods to change\n    how chemicals are currently evaluated for potential health risks.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_27",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":27,
        "total_chunks":185,
        "content":"p innovative methods to change\n    how chemicals are currently evaluated for potential health risks. id: comptox\n  name: Comptox\n  registry:\n    biotools: comptox_chemistry_dashboard\n    fairsharing: tfj7gt\n  url: https:\/\/comptox. epa. gov\/dashboard\n- description: An initiative to bring together various formats and standard for computational\n    models in biology\n  id: computational-modeling-in-biology-network\n  name: COmputational Modeling in BIology NEtwork (COMBINE)\n  url: http:\/\/co. mbine. org\n- description: Open source package management system\n  id: conda\n  name: Conda\n  registry:\n    fairsharing: NA\n    tess: Conda\n  url: https:\/\/docs. conda. io\/en\/latest\/\n- description: A resource for researchers when drafting consent forms so they can\n    use language matching cutting-edge GA4GH international standards\n  id: consent-clauses-for-genomic-research\n  name: Consent Clauses for Genomic Research\n  url: https:\/\/drive. google. com\/file\/d\/1O5Ti7g7QJqS3h0ABm-LyTe02Gtq8wlKM\/view.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_28",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":28,
        "total_chunks":185,
        "content":"or Genomic Research\n  url: https:\/\/drive. google. com\/file\/d\/1O5Ti7g7QJqS3h0ABm-LyTe02Gtq8wlKM\/view. usp=sharing\n- description: A command-line utility that creates projects from cookiecutters (project\n    templates), e. g. creating a Python package project from a Python package project\n    template. id: cookiecutter\n  name: Cookiecutter\n  url: https:\/\/github.com\/cookiecutter\/cookiecutter\n- description: Portal for scientists to broker more easily rich metadata alongside\n    data to public repos. id: copo\n  name: COPO\n  registry:\n    biotools: copo\n    fairsharing: 91a79b\n  url: https:\/\/copo-project.org\/\n- description: Examples and tools to create a codebook by the Data Documentation Initiative\n    (DDI) id: create-a-codebook\n  name: Create a Codebook\n  url: https:\/\/ddialliance.org\/create-a-codebook\n- description: It helps you choose the right Creative Commons license for your needs.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_29",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":29,
        "total_chunks":185,
        "content":"ate-a-codebook\n- description: It helps you choose the right Creative Commons license for your needs. id: creative-commons-license-chooser\n  name: Creative Commons License Chooser\n  url: https:\/\/creativecommons.org\/choose\/\n- description: The Crop Ontology compiles concepts to curate phenotyping assays on\n    crop plants, including anatomy, structure and phenotype. id: crop-ontology\n  name: Crop Ontology\n  registry:\n    fairsharing: wgfrmg\n    tess: Crop Ontology\n  url: https:\/\/www.cropontology.org\n- description: A Python tool to encrypt, decrypt or re-encrypt files, according to\n    the GA4GH encryption file format. id: crypt4gh\n  name: Crypt4GH\n  registry:\n    tess: Crypt4GH\n  url: https:\/\/crypt4gh.readthedocs.io\/en\/latest\/\n- description: Cloud Storage Services for Synchronization and Sharing (CS3) id: cs3\n  name: CS3\n  url: https:\/\/www.cs3community.org\/\n- description: A database that aims to advance understanding about how environmental\n    exposures affect human health.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_30",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":30,
        "total_chunks":185,
        "content":"tabase that aims to advance understanding about how environmental\n    exposures affect human health. id: ctd\n  name: CTD\n  registry:\n    biotools: ctd\n    tess: CTD\n  url: http:\/\/ctdbase.org\/\n- description: Command line tool and library for transferring data with URLs\n  id: curl\n  name: cURL\n  registry:\n    tess: cURL\n  url: https:\/\/curl.se\n- description: Image Data management\n  id: cytomine-ims\n  name: Cytomine-IMS\n  url: https:\/\/github.com\/cytomine\/Cytomine-IMS\n- description: Data Information System to keep sensitive data inventory and meet GDPR\n    accountability requirement. id: daisy\n  name: DAISY\n  registry:\n    biotools: Data_Information_System_DAISY\n    tess: DAISY\n  url: https:\/\/daisy-demo.elixir-luxembourg.org\n- description: It guides you step by step through a DMP and lets you export a pre-filled\n    DMP as a Word document that you can customize and use for submission to funders. Also, DAMAP is compatible with the RDA recommendation for machine-actionable DMPs\n    and offers an export of JSON DMPs. DAMAP is open source and to be self deployed.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_31",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":31,
        "total_chunks":185,
        "content":"actionable DMPs\n    and offers an export of JSON DMPs. DAMAP is open source and to be self deployed. id: damap\n  name: DAMAP\n  url: https:\/\/damap.org\/\n- description: Unique collection of project-level metadata from large research initiatives\n    in a diverse range of fields, including clinical, molecular and observational\n    studies. Its aim is to improve the findability of these projects following FAIR\n    data principles. id: data-catalog\n  name: Data Catalog\n  registry:\n    fairsharing: NA\n    tess: Data Catalog\n  url: https:\/\/datacatalog.elixir-luxembourg.org\/\n- description: DCAT is an RDF vocabulary designed to facilitate interoperability between\n    data catalogs published on the Web. id: data-catalog-vocabulary\n  name: Data Catalog Vocabulary (DCAT)\n  registry:\n    fairsharing: h4j3qm\n  url: https:\/\/www.w3.org\/TR\/vocab-dcat-2\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_32",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":32,
        "total_chunks":185,
        "content":"(DCAT)\n  registry:\n    fairsharing: h4j3qm\n  url: https:\/\/www.w3.org\/TR\/vocab-dcat-2\/\n- description: List of metadata standards\n  id: data-curation-centre-metadata-list\n  name: Data Curation Centre Metadata list\n  url: https:\/\/www.dcc.ac.uk\/guidance\/standards\/metadata\/list\n- description: Publicly available online tool for composing smart data management\n    plans\n  id: data-stewardship-wizard\n  name: Data Stewardship Wizard\n  registry:\n    biotools: Data_Stewardship_Wizard\n    tess: Data Stewardship Wizard\n  url: https:\/\/ds-wizard.org\/\n- description: This service provides simple estimation of storage costs based on desired\n    properties and local\/actual configuration. id: data-stewardship-wizard-storage-costs-evaluator\n  name: Data Stewardship Wizard Storage Costs Evaluator\n  url: https:\/\/storage-costs-evaluator.ds-wizard.org\/\n- description: DUO allows to semantically tag datasets with restriction about their\n    usage.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_33",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":33,
        "total_chunks":185,
        "content":".org\/\n- description: DUO allows to semantically tag datasets with restriction about their\n    usage. id: data-use-ontology\n  name: Data Use Ontology (DUO)\n  registry:\n    fairsharing: 5dnjs2\n    tess: Data Use Ontology (DUO)\n  url: https:\/\/github.com\/EBISPOT\/DUO\n- description: Overview of typical licenses used for data resources\n  id: data-world-data-license-list\n  name: data.world Data License list\n  url: https:\/\/help.data.world\/hc\/en-us\/articles\/115006114287-Common-license-types-for-datasets\n- description: A search engine for the complete collection of publicly available DataCite\n    DOIs\n  id: datacite\n  name: DataCite\n  registry: fairsharing: yknezb\n  url: https:\/\/search.datacite.org\/\n- description: Open source research data respository software. id: dataverse\n  name: DATAVERSE\n  registry:\n    fairsharing: NA\n    tess: DATAVERSE\n  url: https:\/\/dataverse.org\/\n- description: The Data Agreement Wizard is a tool developed by ELIXIR-Luxembourg\n    to facilitate data sharing agreements.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_34",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":34,
        "total_chunks":185,
        "content":"Agreement Wizard is a tool developed by ELIXIR-Luxembourg\n    to facilitate data sharing agreements. id: dawid\n  name: Data Agreement Wizard (DAWID)\n  url: https:\/\/dawid.elixir-luxembourg.org\/\n- description: The database of Genotypes and Phenotypes (dbGaP) archives and distributes\n    data from studies investigating the interaction of genotype and phenotype in Humans\n  id: dbgap\n  name: dbGAP\n  registry:\n    biotools: dbgap\n    fairsharing: 88v2k0\n    tess: dbGAP\n  url: https:\/\/www.ncbi.nlm.nih.gov\/gap\/\n- description: A discovery platform containing collections of genes and variants associated\n    to human diseases.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_35",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":35,
        "total_chunks":185,
        "content":" A discovery platform containing collections of genes and variants associated\n    to human diseases. id: disgenet\n  name: DisGeNET\n  registry:\n    biotools: disgenet\n    fairsharing: fssydn\n    tess: DisGeNET\n  url: https:\/\/www.disgenet.org\/\n- description: A database of intrinsically disordered proteins\n  id: disprot\n  name: DisProt\n  registry:\n    biotools: disprot\n    fairsharing: dt9z89\n    tess: DisProt\n  url: https:\/\/disprot.org\/\n- description: Questionnaire, which generates a pre-filled a DMP\n  id: dmp-canvas-generator\n  name: DMP Canvas Generator\n  url: https:\/\/dmp.vital-it.ch\n- description: Semi-automatically generated, searchable catalogue of resources that\n    are relevant to data management plans.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_36",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":36,
        "total_chunks":185,
        "content":"tically generated, searchable catalogue of resources that\n    are relevant to data management plans. id: dmplanner\n  name: DMPlanner\n  url: https:\/\/dmplanner.athenarc.gr\/\n- description: DMP Roadmap is a Data Management Planning tool\n  id: dmproadmap\n  name: DMPRoadmap\n  url: https:\/\/github.com\/DMPRoadmap\/roadmap\n- description: Build your Data Management Plan\n  id: dmptool\n  name: DMPTool\n  registry:\n    tess: DMPTool\n  url: https:\/\/dmptool.org\n- description: A database of DNA sequences\n  id: dna-data-bank-of-japan\n  name: DNA Data Bank of Japan (DDBJ) registry:\n    biotools: ddbj\n    fairsharing: k337f0\n  url: https:\/\/www.ddbj.nig.ac.jp\/index-e.html\n- description: Docker is a software for the execution of applications in virtualized\n    environments called containers.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_37",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":37,
        "total_chunks":185,
        "content":"r is a software for the execution of applications in virtualized\n    environments called containers. It is linked to DockerHub, a library for sharing\n    container images\n  id: docker\n  name: Docker\n  registry:\n    fairsharing: NA\n    tess: Docker\n  url: https:\/\/www.docker.com\/\n- description: A DSW knowledge model guiding users through a set of questions to collect\n    information necessary for a research project Data Protection Impact Assessment\n    (DPIA). id: dpia-knowledge-model\n  name: DPIA Knowledge Model\n  url: https:\/\/converge.dsw.elixir-europe.org\/knowledge-models\/elixir.lu:dpia-research:0.1.0\n- description: Cloud storage and file sharing service\n  id: dropbox\n  name: Dropbox\n  url: https:\/\/www.dropbox.com\/?landing=dbv2\n- description: A toxicogenomic resource that provides access to the gene expression\n    profiles of over 600 different compounds in several cell types from rats and primary\n    rat hepatocytes.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_38",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":38,
        "total_chunks":185,
        "content":"les of over 600 different compounds in several cell types from rats and primary\n    rat hepatocytes. id: drug-matrix\n  name: Drug Matrix\n  url: https:\/\/ntp.niehs.nih.gov\/data\/drugmatrix\/\n- description: Open-source, community-led data curation, publishing, and preservation\n    platform for CC0 publicly available research data\n  id: dryad\n  name: Dryad\n  registry:\n    fairsharing: wkggtx\n  url: https:\/\/datadryad.org\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_39",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":39,
        "total_chunks":185,
        "content":"dryad\n  name: Dryad\n  registry:\n    fairsharing: wkggtx\n  url: https:\/\/datadryad.org\/\n- description: Database of folding \/ unfolding pathway of representatives from all\n    known protein folds by MD simulation\n  id: dynameomics\n  name: Dynameomics\n  url: http:\/\/www.dynameomics.org\/\n- description: Electronic data archive library is a framework for publishing and sharing\n    research data\n  id: e-dal\n  name: e!DAL\n  registry:\n    biotools: edal\n    tess: e!DAL\n  url: https:\/\/edal.ipk-gatersleben.de\/\n- description: Plant Genomics and Phenomics Research Data Repository\n  id: e-dal-pgp\n  name: e!DAL-PGP\n  registry:\n    fairsharing: rf3m4g\n    tess: e!DAL-PGP\n  url: https:\/\/edal-pgp.ipk-gatersleben.de\/\n- description: The ECOTOXicology Knowledgebase (ECOTOX) is a comprehensive, publicly\n    available Knowledgebase providing single chemical environmental toxicity data\n    on aquatic life, terrestrial plants, and wildlife. id: ecotox\n  name: ECOTOX\n  registry:\n    fairsharing: 4b2234\n  url: https:\/\/cfpub.epa.gov\/ecotox\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_40",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":40,
        "total_chunks":185,
        "content":"name: ECOTOX\n  registry:\n    fairsharing: 4b2234\n  url: https:\/\/cfpub.epa.gov\/ecotox\/\n- description: Hub for the identification of plant genetic resources in Europe\n  id: ecpgr\n  name: ECPGR\n  url: https:\/\/www.ecpgr.cgiar.org\/\n- description: 'Endocrine Disruptor Knowledge Base is a platform designed to foster\n    the development of computational predictive toxicology. This platform allows direct\n    access to ten libraries containing the following resources: a biological activity\n    database, QSAR training sets, in vitro and in vivo experimental data for more\n    than 3,000 chemicals, literature citations, chemical-structure search capabilities.'",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_41",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":41,
        "total_chunks":185,
        "content":"ta for more\n    than 3,000 chemicals, literature citations, chemical-structure search capabilities.' id: edkb\n  name: EDKB\n  url: https:\/\/www.fda.gov\/science-research\/bioinformatics-tools\/endocrine-disruptor-knowledge-base\n- description: Set of European data resources of fundamental importance to the wider\n    life-science community and the long-term preservation of biological data\n  id: elixir-core-data-resources\n  name: ELIXIR Core Data Resources\n  registry:\n    fairsharing: 7cbcb7\n    fairsharing-coll: 3527\n  url: https:\/\/elixir-europe.org\/platforms\/data\/core-data-resources\n- description: List of discipline-specific deposition databases recommended by ELIXIR.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_42",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":42,
        "total_chunks":185,
        "content":"ata-resources\n- description: List of discipline-specific deposition databases recommended by ELIXIR. id: elixir-deposition-databases-for-biomolecular-data\n  name: ELIXIR Deposition Databases for Biomolecular Data\n  registry:\n    fairsharing-coll: 3527\n  url: https:\/\/elixir-europe.org\/platforms\/data\/elixir-deposition-databases\n- description: An authentication service from EOSC-Life\n  id: life-science-login\n  name: Life Science Login (LS Login)\n  url: https:\/\/lifescience-ri.eu\/ls-login\/\n- description: EMBL-EBI's web portal for finding ontologies\n  id: ontology-lookup-service\n  name: Ontology Lookup Service\n  registry:\n    biotools: ols\n    fairsharing: Mkl9RR\n    tess: Ontology Lookup Service\n  url: https:\/\/www.ebi.ac.uk\/ols\/index\n- description: EMBL-EBI's wizard for finding the right EMBL-EBI repository for your\n    data. id: embl-ebi-s-data-submission-wizard\n  name: EMBL-EBI's data submission wizard\n  url: https:\/\/www.ebi.ac.uk\/submission\/\n- description: Electron Microscopy Public Image Archive is a public resource for raw,\n    2D electron microscopy images.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_43",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":43,
        "total_chunks":185,
        "content":"ron Microscopy Public Image Archive is a public resource for raw,\n    2D electron microscopy images. You can browse, upload and download the raw images\n    used to build a 3D structure\n  id: empiar\n  name: EMPIAR\n  registry:\n    biotools: empiar\n    fairsharing: dff3ef\n    tess: EMPIAR\n  url: https:\/\/www.ebi.ac.uk\/pdbe\/emdb\/empiar\/\n- description: This tool carries out data hub set up at the European Nucleotide Archive\n    (ENA). id: ena-compare-data-hubs\n  name: ENA COMPARE Data Hubs\n  url: https:\/\/github.com\/nadimm-rahman\/ena-datahub-setup\n- description: The program submits experimental data and respective metadata to the\n    European Nucleotide Archive (ENA). id: ena-upload-tool\n  name: ENA upload tool\n  registry:\n    tess: ENA upload tool\n  url: https:\/\/github.com\/usegalaxy-eu\/ena-upload-cli\n- description: Genome browser for vertebrate genomes that supports research in comparative\n    genomics, evolution, sequence variation and transcriptional regulation.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_44",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":44,
        "total_chunks":185,
        "content":" research in comparative\n    genomics, evolution, sequence variation and transcriptional regulation. id: ensembl\n  name: Ensembl\n  registry:\n    biotools: ensembl\n    fairsharing: fx0mw7\n    tess: Ensembl\n  url: https:\/\/www.ensembl.org\/index.html\n- description: Open-access database of full genomes of plant species. id: ensembl-plants\n  name: Ensembl Plants\n  registry:\n    fairsharing: j8g2cv\n    tess: Ensembl Plants\n  url: https:\/\/plants.ensembl.org\/\n- description: Web-based tool allowing users to create and manage a register of personal\n    data processing activities (ROPA). id: erpa\n  name: ERPA\n  url: https:\/\/gitlab.sib.swiss\/clinbio\/erpa-app\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_45",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":45,
        "total_chunks":185,
        "content":"vities (ROPA). id: erpa\n  name: ERPA\n  url: https:\/\/gitlab.sib.swiss\/clinbio\/erpa-app\n- description: Regulation (eu) 2016\/679 of the european parliament and of the council\n    on the protection of natural persons with regard to the processing of personal\n    data and on the free movement of such data, and repealing directive 95\/46\/ec (general\n    data protection regulation).\n  id: eu-general-data-protection-regulation\n  name: EU General Data Protection Regulation\n  url: https:\/\/eur-lex.europa.eu\/legal-content\/EN\/TXT\/HTML\/?uri=CELEX:32016R0679&from=EN\n- description: EUDAT's wizard for finding the right licence for your data or code. id: eudat-licence-selector-wizard\n  name: EUDAT licence selector wizard\n  url: https:\/\/ufal.github.io\/public-license-selector\/\n- description: The European database of suspected adverse drug reaction reports is\n    a public resource aimed to provide access to reported suspected side-effects of\n    drugs. Side-effects are defined according to the MedDRA ontology.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_46",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":46,
        "total_chunks":185,
        "content":"rted suspected side-effects of\n    drugs. Side-effects are defined according to the MedDRA ontology. id: eudravigilance\n  name: EudraVigilance\n  url: https:\/\/www.ema.europa.eu\/en\/human-regulatory\/research-development\/pharmacovigilance\/eudravigilance\n- description: EUPID provides a method for identity management, pseudonymisation and\n    record linkage to bridge the gap between multiple contexts. id: eupid\n  name: EUPID\n  url: https:\/\/eupid.eu\/#\/concept\n- description: European Search Catalogue for Plant Genetic Resources\n  id: eurisco\n  name: EURISCO\n  registry:\n    biotools: eurisco\n  url: https:\/\/eurisco.ipk-gatersleben.de\n- description: Europe PMC is a repository, providing access to worldwide life sciences\n    articles, books, patents and clinical guidelines. id: europe-pmc\n  name: Europe PMC\n  registry:\n    biotools: europe_pmc\n    fairsharing: cmw6mm\n    tess: Europe PMC\n  url: https:\/\/europepmc.org\/\n- description: A programme aiming to create an effective rare diseases research ecosystem\n    for progress, innovation and for the benefit of everyone with a rare disease.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_47",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":47,
        "total_chunks":185,
        "content":"research ecosystem\n    for progress, innovation and for the benefit of everyone with a rare disease. id: european-joint-programme-on-rare-diseases\n  name: European Joint Programme on Rare Diseases (EJP RD)\n  url: https:\/\/www.ejprarediseases.org\/\n- description: This core model is designed to represent data about a rare disease\n    patient and biosample registries. The model is based on and builds on existing\n    standards, such as the European Rare Disease Registry Infrastructure and the Common\n    Data Elements from the rare disease community and other more generalised standards\n    for data sharing such as the W3C DCAT vocabulary.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_48",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":48,
        "total_chunks":185,
        "content":"community and other more generalised standards\n    for data sharing such as the W3C DCAT vocabulary. id: european-joint-programme-on-rare-diseases-metadata-model\n  name: European Joint Programme on Rare Diseases Metadata Model\n  url: https:\/\/github.com\/ejp-rd-vp\/resource-metadata-schema\n- description: 'The Virtual Platform is a federated ecosystem, in which resources\n    are enhanced to be amenable to rare disease research, and made Findable, Accessible,\n    Interoperable and Reusable: data stays at the source level but can be queyrable\n    at distance from an EJP RD query point.'",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_49",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":49,
        "total_chunks":185,
        "content":"le: data stays at the source level but can be queyrable\n    at distance from an EJP RD query point.' id: european-joint-programme-on-rare-diseases-virtual-platform\n  name: European Joint Programme on Rare Diseases Virtual Platform (EJP RD)\n  url: https:\/\/vp.ejprarediseases.org\/\n- description: A record of sequence information scaling from raw sequcning reads to\n    assemblies and functional annotation\n  id: european-nucleotide-archive\n  name: European Nucleotide Archive (ENA)\n  registry:\n    biotools: ena\n    fairsharing: dj8nt8\n    tess: European Nucleotide Archive (ENA)\n  url: https:\/\/www.ebi.ac.uk\/ena\/browser\/home\n- description: ERDRI.dor provides an overview of participating rare disease registries\n    with their main characteristics and description.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_50",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":50,
        "total_chunks":185,
        "content":"erview of participating rare disease registries\n    with their main characteristics and description. id: european-rare-disease-registry-infrastructure-directory-of-registries\n  name: European Rare Disease Registry Infrastructure directory of registries (ERDRI.dor)\n  url: https:\/\/eu-rd-platform.jrc.ec.europa.eu\/erdridor\/\n- description: ERDRI.mdr serves to ease the integration of heterogeneous data from\n    different rare disease registries. For this purpose, it contains a collection\n    of metadata which specifies the used data elements of a registry including the\n    designation of the used data elements, their definition and units of measurement. id: european-rare-disease-registry-infrastructure-metadata-repository\n  name: European Rare Disease Registry Infrastructure metadata repository (ERDRI.mdr)\n  url: https:\/\/eu-rd-platform.jrc.ec.europa.eu\/mdr\/\n- description: Virtual networks involving healthcare providers across Europe.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_51",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":51,
        "total_chunks":185,
        "content":".jrc.ec.europa.eu\/mdr\/\n- description: Virtual networks involving healthcare providers across Europe. They\n    aim to facilitate discussion on complex or rare diseases and conditions that require\n    highly specialised treatment, and concentrated knowledge and resources. id: european-reference-networks\n  name: European Reference Networks (ERNs) registry:\n    tess: European Reference Networks (ERNs)\n  url: https:\/\/health.ec.europa.eu\/european-reference-networks_en\n- description: Open-access database of all types of genetic variation data from all\n    species. id: european-variation-archive\n  name: European Variation Archive (EVA)\n  registry:\n    biotools: eva\n    fairsharing: 6824pv\n    tess: European Variation Archive (EVA)\n  url: https:\/\/www.ebi.ac.uk\/eva\/\n- description: Controlled vocabulary that describes types of evidence and assertion\n    methods\n  id: evidence-and-conclusion-ontology\n  name:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_52",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":52,
        "total_chunks":185,
        "content":"describes types of evidence and assertion\n    methods\n  id: evidence-and-conclusion-ontology\n  name: Evidence and Conclusion Ontology (ECO)\n  registry:\n    biotools: NA\n    fairsharing: wvpgwn\n  url: https:\/\/evidenceontology.org\/\n- description: The FDA Adverse Event Reporting System (FAERS) is an american resource\n    that contains adverse event reports, medication error reports and product quality\n    complaints submitted by healthcare professionals, consumers, and manufacturers. MedDRA ontology is used for coding adverse effects. Note that reports available\n    in FAERS do not require a causal relationship between a product and an adverse\n    event and further evaluations are conducted by FDA to monitor the safety of products. id: faers\n  name: FAERS\n  registry:\n    biotools: faers\n  url: https:\/\/www.fda.gov\/drugs\/surveillance\/questions-and-answers-fdas-adverse-event-reporting-system-faers\n- description: FAIDARE is a tool allowing to search data across dinstinct databases\n    that implemented BrAPI.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_53",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":53,
        "total_chunks":185,
        "content":"on: FAIDARE is a tool allowing to search data across dinstinct databases\n    that implemented BrAPI. id: faidare\n  name: FAIDARE\n  registry:\n    biotools: faidare\n    tess: FAIDARE\n  url: https:\/\/urgi.versailles.inra.fr\/faidare\/\n- description: FAIR Cookbook is an online resource for the Life Sciences with recipes\n    that help you to make and keep data Findable, Accessible, Interoperable and Reusable\n    (FAIR) id: fair-cookbook\n  name: FAIR Cookbook\n  registry:\n    biotools: fair_cookbook\n    tess: FAIR Cookbook\n  url: https:\/\/fairplus.github.io\/the-fair-cookbook\/content\/recipes\/assessing-fairness.html#\n- description: A FAIR Data Point stores metadata in a standardized and sharable way. id: fair-data-point\n  name: FAIR Data Point (FDP)\n  registry:\n    fairsharing: '298'\n    tess: FAIR Data Point\n  url: https:\/\/www.fairdatapoint.org\/\n- description: Resources and guidelines to assess the FAIRness of digital resources.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_54",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":54,
        "total_chunks":185,
        "content":"rdatapoint.org\/\n- description: Resources and guidelines to assess the FAIRness of digital resources. id: fair-evaluation-services\n  name: FAIR Evaluation Services\n  url: https:\/\/fairsharing.github.io\/FAIR-Evaluator-FrontEnd\/#!\/#%2F!\n- description: The FIP is a collection of FAIR implementation choices made by a community\n    of practice for each of the FAIR Principles. id: fair-implementation-profile\n  name: FAIR Implementation Profile\n  registry:\n    fairsharing: '343864'\n  url: https:\/\/www.go-fair.org\/how-to-go-fair\/fair-implementation-profile\/\n- description: The FAIR wizard utilizes FAIRification resources developed by the FAIRplus\n    project and other platforms, suggests FAIRification materials based on the FAIRification\n    requirements, and designs FAIRification solutions for data owners, data stewards,\n    and other people involved in FAIRification. id: fair-wizard\n  name: FAIR-Wizard\n  registry:\n    tess: FAIR-Wizard\n  url: https:\/\/fair-wizard.com\/\n- description: Help you discover resources to measure and improve FAIRness.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_55",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":55,
        "total_chunks":185,
        "content":"https:\/\/fair-wizard.com\/\n- description: Help you discover resources to measure and improve FAIRness. id: fairassist-org\n  name: FAIRassist.org\n  url: https:\/\/fairassist.org\/#!\/\n- description: A data Management Platform for organising, sharing and publishing research\n    datasets, models, protocols, samples, publications and other research outcomes. id: fairdom-seek\n  name: FAIRDOM-SEEK\n  registry:\n    biotools: seek\n  url: https:\/\/seek4science.org\/\n- description: Data, model and SOPs management for projects, from preliminary data\n    to publication, support for running SBML models, etc. (public SEEK instance)\n  id: fairdomhub\n  name: FAIRDOMHub\n  registry:\n    fairsharing: nnvcr9\n    tess: FAIRDOMHub\n  url: https:\/\/fairdomhub.org\n- description: A System to Evaluate the FAIRness of Digital Objects\n  id: fairshake\n  name: FAIRshake\n  url: https:\/\/fairshake.cloud\n- description: A curated, informative and educational resource on data and metadata\n    standards, inter-related to databases and data policies.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_56",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":56,
        "total_chunks":185,
        "content":"ucational resource on data and metadata\n    standards, inter-related to databases and data policies. id: fairsharing\n  name: FAIRsharing\n  registry:\n    fairsharing: 2abjs5\n    tess: FAIRsharing\n  url: https:\/\/fairsharing.org\/\n- description: Data publishing platform\n  id: figshare\n  name: FigShare\n  registry:\n    fairsharing: drtwnh\n    tess: FigShare\n  url: https:\/\/figshare.com\/\n- description: A free FTP (FTPS and SFTP) solution with graphical interface id: filezilla\n  name: FileZilla\n  registry:\n    tess: FileZilla\n  url: https:\/\/filezilla-project.org\n- description: FIP Wizard is a toolset to facilitate the capture of data in FAIR Convergence\n    Matrix questionnaire prompting communities to explicitly declare their FAIR Implementation\n    Profiles. These profiles can be then stored and published as nanopublications.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_57",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":57,
        "total_chunks":185,
        "content":"IR Implementation\n    Profiles. These profiles can be then stored and published as nanopublications. id: fip-wizard\n  name: FIP Wizard\n  url: https:\/\/fip-wizard.readthedocs.io\/en\/latest\/\n- description: Fiji is an image processing package\n  id: fiji\n  name: Fiji\n  registry:\n    biotools: fiji\n    tess: Fiji\n  url: https:\/\/fiji.sc\/\n- description: FreeIPA is an integrated Identity and Authentication solution for Linux\/UNIX\n    networked environments. id: free-ipa\n  name: Free-IPA\n  url: https:\/\/www.freeipa.org\/\n- description: Repository of IP-free synthetic biological parts\n  id: freegenes\n  name: Freegenes\n  url: https:\/\/stanford.freegenes.org\/collections\/open-genes\n- description: Principled and practical framework for the responsible sharing of genomic\n    and health-related data. id: ga4gh-data-security-toolkit\n  name: GA4GH Data Security Toolkit\n  url: https:\/\/www.ga4gh.org\/genomic-data-toolkit\/data-security-toolkit\/\n- description: Open standards for genomic data sharing.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_58",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":58,
        "total_chunks":185,
        "content":"\/genomic-data-toolkit\/data-security-toolkit\/\n- description: Open standards for genomic data sharing. id: ga4gh-genomic-data-toolkit\n  name: GA4GH Genomic Data Toolkit\n  url: https:\/\/www.ga4gh.org\/genomic-data-toolkit\/\n- description: Framework for Responsible Sharing of Genomic and Health-Related Data\n  id: ga4gh-regulatory-and-ethics-toolkit\n  name: GA4GH Regulatory and Ethics toolkit\n  url: https:\/\/www.ga4gh.org\/genomic-data-toolkit\/regulatory-ethics-toolkit\/\n- description: Open, web-based platform for data intensive biomedical research. Whether\n    on the free public server or your own instance, you can perform, reproduce, and\n    share complete analyses. id: galaxy\n  name: Galaxy\n  registry:\n    biotools: galaxy\n    tess: Galaxy\n  url: https:\/\/galaxyproject.org\/\n- description: A database of genetic sequence information. GenBank may also refer\n    to the data format used for storing information around genetic sequence data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_59",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":59,
        "total_chunks":185,
        "content":"ank may also refer\n    to the data format used for storing information around genetic sequence data. id: genbank\n  name: GenBank\n  registry:\n    biotools: genbank\n    fairsharing: 9kahy4\n    tess: GenBank\n  url: https:\/\/www.ncbi.nlm.nih.gov\/genbank\/\n- description: A repository of MIAME-compliant genomics data from arrays and high-throughput\n    sequencing\n  id: gene-expression-omnibus\n  name: Gene Expression Omnibus (GEO)\n  registry:\n    fairsharing: 5hc8vt\n  url: https:\/\/www.ncbi.nlm.nih.gov\/geo\/\n- description: GHS (Globally Harmonized System of Classification and Labelling of\n    Chemicals) classification was developed by the United Nations in an attempt to\n    align standards and chemical regulations in different countries. GHS includes\n    criteria for the classification of health, physical and environmental hazards,\n    and what information should be included on labels of hazardous chemicals and safety\n    data sheets.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_60",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":60,
        "total_chunks":185,
        "content":"and what information should be included on labels of hazardous chemicals and safety\n    data sheets. id: ghs-classification\n  name: GHS Classification\n  url: https:\/\/pubchem.ncbi.nlm.nih.gov\/ghs\/\n- description: Distributed version control system designed to handle everything from\n    small to very large projects\n  id: git\n  name: Git\n  registry:\n    tess: Git\n  url: https:\/\/git-scm.com\/\n- description: Versioning system, used for sharing code, as well as for sharing of\n    small data\n  id: github\n  name: GitHub\n  registry: fairsharing: c55d5e\n    tess: GitHub\n  url: https:\/\/github.com\n- description: GitLab is an open source end-to-end software development platform with\n    built-in version control, issue tracking, code review, CI\/CD, and more. Self-host\n    GitLab on your own servers, in a container, or on a cloud provider.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_61",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":61,
        "total_chunks":185,
        "content":", CI\/CD, and more. Self-host\n    GitLab on your own servers, in a container, or on a cloud provider. id: gitlab\n  name: GitLab\n  registry:\n    fairsharing: 530e61\n    tess: GitLab\n  url: https:\/\/gitlab.com\/gitlab-org\/gitlab\n- description: High-performance data transfers between systems within and across organizations\n  id: globus\n  name: Globus\n  url: https:\/\/www.globus.org\n- description: A multispecies integrative information system dedicated to plant and\n    fungi pests. It allows researchers to access genetic, phenotypic and genomic data. It is used by both large international projects and the French National Research\n    Institute for Agriculture, Food and Environment.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_62",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":62,
        "total_chunks":185,
        "content":"ional projects and the French National Research\n    Institute for Agriculture, Food and Environment. id: gnpis\n  name: GnpIS\n  registry:\n    biotools: gnpis\n    fairsharing: dw22y3\n  url: https:\/\/urgi.versailles.inrae.fr\/gnpis\/\n- description: Search engine for datasets\n  id: google-dataset-search\n  name: Google Dataset Search\n  url: https:\/\/datasetsearch.research.google.com\/\n- description: Cloud Storage for Work and Home\n  id: google-drive\n  name: Google Drive\n  url: https:\/\/www.google.com\/intl\/en_us\/drive\/\n- description: Repository of GPCR protein simulations\n  id: gpcrmd\n  name: GPCRmd\n  registry:\n    biotools: GPCRmd\n  url: http:\/\/gpcrmd.org\/\n- description: ELN Comparison Grid by Hardvard Medical School\n  id: harvard-medical-school-electronic-lab-notebooks\n  name: Harvard Medical School - Electronic Lab Notebooks\n  url: https:\/\/datamanagement.hms.harvard.edu\/analyze\/electronic-lab-notebooks\n- description: Haz-Map is an occupational health database that makes available information\n    about the adverse effects of exposures to chemical and biological agents at the\n    workplace.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_63",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":63,
        "total_chunks":185,
        "content":"n\n    about the adverse effects of exposures to chemical and biological agents at the\n    workplace. These associations have been established using current scientific evidence. id: haz-map\n  name: Haz-Map\n  url: https:\/\/haz-map.com\/\n- description: Guidelines about how to license research data from Digital Curation\n    Centre\n  id: how-to-license-research-data-dcc\n  name: How to License Research Data - DCC\n  url: https:\/\/www.dcc.ac.uk\/guidance\/how-guides\/license-research-data\n- description: The Human Protein Atlas contains information for a large majority of\n    all human protein-coding genes regarding the expression and localization of the\n    corresponding proteins based on both RNA and protein data. id: human-protein-atlas\n  name: Human Protein Atlas\n  registry:\n    fairsharing: j0t0pe\n    tess: Human Protein Atlas\n  url: https:\/\/www.proteinatlas.org\/\n- description: HumanMine integrates many types of human data and provides a powerful\n    query engine, export for results, analysis for lists of data and FAIR access via\n    web services.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_64",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":64,
        "total_chunks":185,
        "content":"  query engine, export for results, analysis for lists of data and FAIR access via\n    web services. id: humanmine\n  name: HumanMine\n  registry:\n    biotools: humanmine\n    fairsharing: RJ99Pj\n    tess: HumanMine\n  url: https:\/\/www.humanmine.org\/\n- description: With fast file transfer and streaming solutions built on the award-winning\n    IBM FASP protocol, IBM Aspera software moves data of any size across any distance\n  id: ibm-aspera\n  name: IBM Aspera\n  url: https:\/\/www.ibm.com\/products\/aspera\n- description: The Identifiers.org Resolution Service provides consistent access to\n    life science data using Compact Identifiers. Compact Identifiers consist of an\n    assigned unique prefix and a local provider designated accession number (prefix:accession).",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_65",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":65,
        "total_chunks":185,
        "content":"f an\n    assigned unique prefix and a local provider designated accession number (prefix:accession). id: identifiers-org\n  name: Identifiers.org\n  registry:\n    biotools: identifiers.org\n    fairsharing: n14rc8\n    tess: Identifiers.org\n  url: http:\/\/identifiers.org\n- description: A collection of standard biological parts to which all entrants in\n    the iGEM competition must submit their parts\n  id: igem-parts-registry\n  name: iGEM Parts Registry\n  url: http:\/\/parts.igem.org\/Main_Page\n- description: A repository of image datasets from scientific publications\n  id: image-data-resource\n  name: Image Data Resource (IDR)\n  registry:\n    biotools: idr\n    fairsharing: 6wf1zw\n  url: https:\/\/idr.openmicroscopy.org\n- description: The Informed Consent Ontology (ICO) is an ontology for the informed\n    consent and informed consent process in the medical field.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_66",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":66,
        "total_chunks":185,
        "content":"(ICO) is an ontology for the informed\n    consent and informed consent process in the medical field. id: informed-consent-ontology\n  name: Informed Consent Ontology (ICO)\n  registry:\n    fairsharing: b9znd5\n  url: http:\/\/purl.obolibrary.org\/obo\/ICO.owl\n- description: The International Compilation of Human Research Standards enumerates\n    over 1,000 laws, regulations, and guidelines (collectively referred to as standards)\n    that govern human subject protections in 133 countries, as well as standards from\n    a number of international and regional organizations\n  id: international-compilation-of-human-research-standards\n  name: International Compilation of Human Research Standards\n  url: https:\/\/www.hhs.gov\/ohrp\/sites\/default\/files\/2020-international-compilation-of-human-research-standards.pdf\n- description: A collaborative database of genetic sequence datasets from DDBJ, EMBL-EBI\n    and NCBI\n  id: international-nucleotide-sequence-database-collaboration\n  name: International Nucleotide Sequence Database Collaboration (INSDC)",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_67",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":67,
        "total_chunks":185,
        "content":"ence-database-collaboration\n  name: International Nucleotide Sequence Database Collaboration (INSDC) registry:\n    biotools: insdc\n    tess: International Nucleotide Sequence Database Collaboration (INSDC)\n  url: http:\/\/www.insdc.org\n- description: Data standards and formats for reporting flow cytometry data\n  id: international-society-for-the-advancement-of-cytometry\n  name: International Society for the Advancement of Cytometry (ISAC)\n  registry:\n    biotools: NA\n  url: https:\/\/isac-net.org\/page\/Data-Standards\n- description: Resource for naming standards in biochemistry and molecular biology\n  id: international-union-of-biochemistry-and-molecular-biology\n  name: International Union of Biochemistry and Molecular Biology (IUBMB)\n  url: https:\/\/www.qmul.ac.uk\/sbcs\/iubmb\/\n- description: Functional analysis of protein sequences by classifying them into families\n    and predicting the presence of domains and important sites\n  id: interpro\n  name: InterPro\n  registry:\n    biotools: interpro\n    fairsharing: pda11d\n    tess: InterPro\n  url: https:\/\/www.ebi.ac.uk\/interpro\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_68",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":68,
        "total_chunks":185,
        "content":"pro\n    fairsharing: pda11d\n    tess: InterPro\n  url: https:\/\/www.ebi.ac.uk\/interpro\/\n- description: IntoGen collects and analyses somatic mutations in thousands of tumor\n    genomes to identify cancer driver genes. id: intogen\n  name: IntoGen\n  registry:\n    biotools: intogen\n    tess: IntoGen\n  url: https:\/\/www.intogen.org\/search\n- description: Intrinsically disordered proteins ontology\n  id: idpo\n  name: Intrinsically disordered proteins ontology (IDPO) registry:\n    biotools: idpo\n    fairsharing: bc973b\n  url: https:\/\/disprot.org\/ontology\n- description: The Integrated Risk Information System (IRIS) resource evaluates information\n    on health that might arise after exposure to environmental contaminants. id: iris\n  name: IRIS\n  registry:\n    biotools: iris\n    tess: IRIS\n  url: https:\/\/www.epa.gov\/iris\n- description: Integrated Rule-Oriented Data System (iRODS) is open source data management\n    software for a cancer genome analysis workflow.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_69",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":69,
        "total_chunks":185,
        "content":"ta System (iRODS) is open source data management\n    software for a cancer genome analysis workflow. id: irods\n  name: iRODS\n  registry:\n    biotools: irods\n  url: https:\/\/irods.org\/\n- description: Open source framework and tools helping to manage a diverse set of\n    life science, environmental and biomedical experiments using the Investigation\n    Study Assay (ISA) standard\n  id: isa-tools\n  name: ISA-tools\n  registry: fairsharing: 53gp75\n  url: https:\/\/isa-tools.org\/\n- description: Open source software library that can be used to generate a ISA-TAB\n    export from in-house data sets. These comprises e.g. local database or local file\n    system based experimental.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_70",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":70,
        "total_chunks":185,
        "content":"in-house data sets. These comprises e.g. local database or local file\n    system based experimental. id: isa4j\n  name: ISA4J\n  registry:\n    biotools: isa4j\n  url: https:\/\/mvnrepository.com\/artifact\/de.ipk-gatersleben\/isa4j\n- description: International information security standard\n  id: iso-iec-27001\n  name: ISO\/IEC 27001\n  registry:\n    fairsharing: b2744f\n  url: https:\/\/en.wikipedia.org\/wiki\/ISO\/IEC_27001\n- description: A collaborative resource from IUPAC and IUBMB for naming standards\n    in biochemistry\n  id: iupac-iubmb-joint-commission-on-biochemical-nomenclature\n  name: IUPAC-IUBMB Joint Commission on Biochemical Nomenclature (JCBN)\n  url: https:\/\/www.qmul.ac.uk\/sbcs\/iupac\/jcbn\/\n- description: A registry platform for biological parts\n  id: jbei-ice\n  name: JBEI-ICE\n  url: https:\/\/ice.jbei.org\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_71",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":71,
        "total_chunks":185,
        "content":"form for biological parts\n  id: jbei-ice\n  name: JBEI-ICE\n  url: https:\/\/ice.jbei.org\n- description: Jupyter notebooks allow to share code, documentation\n  id: jupyter\n  name: Jupyter\n  registry:\n    tess: Jupyter\n  url: https:\/\/jupyter.org\n- description: JWS-Online is a systems biology tool for the construction, modification\n    and simulation of kinetic models and for the storage of curated models. id: jws-online\n  name: JWS Online\n  registry:\n    fairsharing: r09jt6\n  url: https:\/\/jjj.mib.ac.uk\/\n- description: Keycloak is an open source identity and data access management solution. id: keycloak\n  name: Keycloak\n  registry:\n    tess: Keycloak\n  url: https:\/\/www.keycloak.org\/\n- description: The LiMTox system is a text mining approach that tries to extract associations\n    between compounds and a particular toxicological endpoint at various levels of\n    granularity and evidence types, all inspired by the content of toxicology reports.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_72",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":72,
        "total_chunks":185,
        "content":"ous levels of\n    granularity and evidence types, all inspired by the content of toxicology reports. It integrates direct ranking of associations between compounds and hepatotoxicity\n    through combination of heterogeneous complementary strategies from term co-mention,\n    rules, and patterns to machine learning-based text classification. It also provides\n    indirect associations to hepatotoxicity through the extraction of relations reflecting\n    the effect of compounds at the level of metabolism and liver enzymes. id: limtox\n  name: LimTox\n  registry:\n    biotools: limtox\n  url: http:\/\/limtox.bioinfo.cnio.es\/\n- description: Web portal for finding ontologies\n  id: linked-open-vocabularies\n  name: Linked Open Vocabularies (LOV)\n  url: https:\/\/lov.linkeddata.es\/dataset\/lov\/\n- description: A database of prokaryote specific biodiversity information\n  id: list-of-prokaryotic-names-with-standing-in-nomenclature\n  name: List of Prokaryotic names with Standing in Nomenclature (LPSN)",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_73",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":73,
        "total_chunks":185,
        "content":"with-standing-in-nomenclature\n  name: List of Prokaryotic names with Standing in Nomenclature (LPSN) registry:\n    biotools: lpsn\n    fairsharing: 8c6a6b\n  url: https:\/\/lpsn.dsmz.de\n- description: EuroHPC world-class supercomputer\n  id: lumi\n  name: LUMI\n  registry:\n    biotools: lumi\n  url: https:\/\/www.lumi-supercomputer.eu\/\n- description: MarDB includes all non-complete marine microbial genomes regardless\n    of level of completeness. Each entry contains 120 metadata fields including information\n    about sampling environment or host, organism and taxonomy, phenotype, pathogenicity,\n    assembly and annotation. id: mardb\n  name: MarDB\n  registry:\n    biotools: mardb\n  url: https:\/\/sfb.mmp2.sigma2.no\/mardb\/\n- description: MarFun is a manually curated marine fungi genome database.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_74",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":74,
        "total_chunks":185,
        "content":"\/sfb.mmp2.sigma2.no\/mardb\/\n- description: MarFun is a manually curated marine fungi genome database. id: marfun\n  name: MarFun\n  url: https:\/\/sfb.mmp2.sigma2.no\/marfun\/\n- description: High-quality curated and freely accessible microbial genomics and metagenomics\n    resources for the marine scientific community\n  id: marine-metagenomics-portal\n  name: Marine Metagenomics Portal (MMP)\n  registry:\n    biotools: mmp\n  url: https:\/\/sfb.mmp2.sigma2.no\n- description: MarRef is a manually curated marine microbial reference genome database\n    that equenced genomes. Each entry contains 120 metadata fields including information\n    about sampling environment or host, organism and taxonomy, phenotype, pathogenicity,\n    assembly and annotation information\n  id: marref\n  name: MarRef\n  registry:\n    biotools: marref\n  url: https:\/\/sfb.mmp2.sigma2.no\/marref\/\n- description: Powerful search engine which uses mass spectrometry data to identify\n    proteins from DNA, RNA and protein sequence databases as well as spectral libraries.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_75",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":75,
        "total_chunks":185,
        "content":"to identify\n    proteins from DNA, RNA and protein sequence databases as well as spectral libraries. id: mascot\n  name: Mascot\n  registry:\n    biotools: MASCOT\n    fairsharing: 8e1ce0\n    tess: Mascot\n  url: https:\/\/www.matrixscience.com\/server.html\n- description: Powerful search engine which uses mass spectrometry data to identify\n    proteins from DNA, RNA and protein sequence databases as well as spectral libraries. id: massive\n  name: MassIVE\n  registry:\n    fairsharing: LYsiMd\n    tess: MassIVE\n  url: https:\/\/massive.ucsd.edu\/ProteoSAFe\/static\/massive.jsp\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_76",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":76,
        "total_chunks":185,
        "content":"YsiMd\n    tess: MassIVE\n  url: https:\/\/massive.ucsd.edu\/ProteoSAFe\/static\/massive.jsp\n- description: Database of over 5000 intrinsic membrane protein structures\n  id: memprotmd\n  name: MemProtMD\n  registry:\n    biotools: memprotmd\n  url: http:\/\/memprotmd.bioch.ox.ac.uk\/\n- description: Multidisciplinary, free-to-use open repository specialized for research\n    data\n  id: mendeley-data\n  name: Mendeley data\n  registry:\n    fairsharing: 3epmpp\n  url: https:\/\/data.mendeley.com\/\n- description: A repository of genomics data relating to the study of the metabolome\n  id: metabolomexchange\n  name: Metabolome Exchange\n  url: http:\/\/www.metabolomexchange.org\/site\/\n- description: Cleans metagenomic reads to remove adapters, low-quality bases and\n    host (e.g. human) contamination\n  id: metagen-fastqc\n  name: Metagen-FastQC\n  url: https:\/\/github.com\/alakob\/Metagen-FastQC-Docker\n- description: Minimum information guidelines for experiments structurally characterising\n    intrinsically disordered protein regions.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_77",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":77,
        "total_chunks":185,
        "content":"guidelines for experiments structurally characterising\n    intrinsically disordered protein regions. id: miade\n  name: Minimum Information About Disorder Experiments (MIADE)\n  registry:\n    fairsharing: ff0b20\n    tess: Minimum Information About Disorder Experiments\n  url: https:\/\/www.psidev.info\/intrinsically-disordered-proteins\n- description: Minimum Information About a Plant Phenotyping Experiment\n  id: miappe\n  name: MIAPPE\n  registry:\n    fairsharing: nd9ce9\n    tess: MIAPPE\n  url: https:\/\/www.miappe.org\/\n- description: Cloud storage and file sharing service from Microsoft\n  id: microsoft-azure\n  name: Microsoft Azure\n  url: https:\/\/azure.microsoft.com\/en-gb\/\n- description: Cloud storage and file sharing service from Microsoft\n  id: microsoft-onedrive\n  name: Microsoft OneDrive\n  url: https:\/\/www.microsoft.com\/en-us\/microsoft-365\/onedrive\/online-cloud-storage\n- description: a conceptual structure for extending the core INSDC information to\n    describe genomic and metagenomic sequences.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_78",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":78,
        "total_chunks":185,
        "content":"tructure for extending the core INSDC information to\n    describe genomic and metagenomic sequences. id: migs-mims\n  name: Minimum Information about a (Meta)Genome Sequence (MIxS - MIGS\/MIMS)\n  registry:\n    fairsharing: va1hck\n  url: https:\/\/www.gensc.org\/pages\/projects\/mixs-gsc-project.html\n- description: A stand-alone server for structural proteome curation\n  id: mineprot\n  name: MineProt\n  registry:\n    biotools: mineprot\n  url: https:\/\/github.com\/huiwenke\/MineProt\n- description: An overarching framework of standard metadata that includes sequence-type\n    and technology-specific checklists. id: mixs\n  name: Minimum Information about any (x) Sequence (MIxS)\n  registry:\n    fairsharing: 9aa0zp\n  url: https:\/\/genomicsstandardsconsortium.github.io\/mixs\/\n- description: Provides a set of open-source, cross-platform software libraries and\n    tools that facilitate proteomics data analysis.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_79",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":79,
        "total_chunks":185,
        "content":"en-source, cross-platform software libraries and\n    tools that facilitate proteomics data analysis. id: msconvert\n  name: msconvert\n  registry:\n    biotools: msconvert\n    tess: msconvert\n  url: https:\/\/proteowizard.sourceforge.io\/\n- description: A database of protein disorder and mobility annotations\n  id: mobidb\n  name: MobiDB\n  registry:\n    biotools: mobidb\n    fairsharing: jwra3e\n    tess: MobiDB\n  url: https:\/\/mobidb.org\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_80",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":80,
        "total_chunks":185,
        "content":" biotools: mobidb\n    fairsharing: jwra3e\n    tess: MobiDB\n  url: https:\/\/mobidb.org\/\n- description: Database of Protein Molecular Dynamics simulations representing different\n    structural clusters of the PDB\n  id: model\n  name: MoDEL\n  registry:\n    biotools: model\n    fairsharing: NA\n    tess: MoDEL\n  url: https:\/\/mmb.irbbarcelona.org\/MoDEL\/\n- description: Repository for Central Nervous System-related mainly membrane protein\n    MD simulations\n  id: model-cns\n  name: MoDEL-CNS\n  url: https:\/\/mmb.irbbarcelona.org\/MoDEL-CNS\/#\/\n- description: Repository for theoretical models of macromolecular structures with\n    DOIs for models\n  id: modelarchive\n  name: ModelArchive\n  registry:\n    biotools: modelarchive\n    fairsharing: tpqndj\n  url: https:\/\/www.modelarchive.org\/\n- description: Molgenis is a modular web application for scientific data. Molgenis\n    provides researchers with user friendly and scalable software infrastructures\n    to capture, exchange, and exploit the large amounts of data that is being produced\n    by scientific organisations all around the world.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_81",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":81,
        "total_chunks":185,
        "content":"e large amounts of data that is being produced\n    by scientific organisations all around the world. id: molgenis\n  name: MOLGENIS\n  registry:\n    biotools: molgenis\n  url: https:\/\/molgenis.gitbooks.io\/molgenis\/content\/\n- description: Database about interactions of molecules with membranes\n  id: molmedb\n  name: MolMeDB\n  registry:\n    biotools: MolMeDB\n    fairsharing: cwzk3c\n  url: https:\/\/molmedb.upol.cz\/\n- description: A risk assessment tool that can be used to do Data Protection Impact\n    Assessments\n  id: monarc\n  name: MONARC\n  registry:\n    fairsharing: NA\n  url: https:\/\/open-source-security-software.net\/project\/MONARC\n- description: a Magnetic Resonance Imaging (MRI) converter from ParaVision (Bruker,\n    Inc. Billerica, MA) file format to DICOM standard\n  id: mri2dicom\n  name: MRI2DICOM\n  url: https:\/\/github.com\/szullino\/XNAT-PIC\n- description: The Multi-Crop Passport Descriptor is the metadata standard for plant\n    genetic resources maintained ex situ by genbanks. id: multi-crop-passport-descriptor\n  name: Multi-Crop Passport Descriptor (MCPD)",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_82",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":82,
        "total_chunks":185,
        "content":"x situ by genbanks. id: multi-crop-passport-descriptor\n  name: Multi-Crop Passport Descriptor (MCPD) registry:\n    biotools: NA\n    fairsharing: hn155r\n    tess: Multi-Crop Passport Descriptor\n  url: https:\/\/www.bioversityinternational.org\/e-library\/publications\/detail\/faobioversity-multi-crop-passport-descriptors-v21-mcpd-v21\/\n- description: A file-system based platform handling the transfer of data\n  id: mytardis\n  name: MyTARDIS\n  url: http:\/\/www.mytardis.org\/\n- description: Online database hosting a vast amount of biotechnological information\n    including nucleic acids, proteins, genomes and publications. Also boasts integrated\n    tools for analysis.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_83",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":83,
        "total_chunks":185,
        "content":"ng nucleic acids, proteins, genomes and publications. Also boasts integrated\n    tools for analysis. id: national-center-for-biotechnology-information\n  name: National Center for Biotechnology Information (NCBI)\n  registry:\n    tess: National Center for Biotechnology Information (NCBI)\n  url: https:\/\/www.ncbi.nlm.nih.gov\n- description: The National Biomonitoring Program (NBP) is a public resource that\n    offers an assessment of nutritional status and the exposure of the U.S. population\n    to environmental chemicals and toxic substances.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_84",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":84,
        "total_chunks":185,
        "content":" status and the exposure of the U.S. population\n    to environmental chemicals and toxic substances. id: nbp\n  name: NBP\n  url: https:\/\/www.cdc.gov\/biomonitoring\/\n- description: NCBI's taxonomy browser is a database of biodiversity information\n  id: ncbi-taxonomy\n  name: NCBI Taxonomy\n  registry:\n    fairsharing: fj07xj\n  url: https:\/\/www.ncbi.nlm.nih.gov\/Taxonomy\/taxonomyhome.html\/\n- description: Hosts information relating to strains, cultures and more\n  id: ncimb\n  name: NCIMB\n  url: https:\/\/www.ncimb.com\/culture-collection\/\n- description: As fully on-premises solution, Nextcloud Hub provides the benefits\n    of online collaboration without the compliance and security risks\n  id: nextcloud\n  name: Nextcloud\n  url: https:\/\/nextcloud.com\n- description: Nextflow is a framework for data analysis workflow execution\n  id: nextflow\n  name: Nextflow\n  registry:\n    biotools: nextflow\n    tess: Nextflow\n  url: https:\/\/www.nextflow.io\n- description: Repository for lipid MD simulations to validate force fields with NMR\n    data\n  id: nmrlipids\n  name: NMRlipids\n  registry:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_85",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":85,
        "total_chunks":185,
        "content":"simulations to validate force fields with NMR\n    data\n  id: nmrlipids\n  name: NMRlipids\n  registry: fairsharing: d32bc8\n  url: http:\/\/nmrlipids.blogspot.com\/\n- description: The National Poison Data System (NPDS) is a resource that provides\n    poisson exposure occurring in the US and some freely associated states. id: npds\n  name: NPDS\n  url: https:\/\/www.aapcc.org\/national-poison-data-system\n- description: Multi-stakeholder, interdisciplinary collaborative to bring out the\n    value of health data through large-scale analytics. All our solutions are open-source.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_86",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":86,
        "total_chunks":185,
        "content":"g out the\n    value of health data through large-scale analytics. All our solutions are open-source. id: ohdsi\n  name: OHDSI\n  registry:\n    biotools: ohdsi\n  url: https:\/\/ohdsi.org\/\n- description: OMERO is an open-source client-server platform for managing, visualizing\n    and analyzing microscopy images and associated metadata\n  id: omero\n  name: OMERO\n  registry:\n    biotools: omero\n    fairsharing: NA\n    tess: OMERO\n  url: https:\/\/www.openmicroscopy.org\/omero\/\n- description: Omics Discovery Index (OmicsDI) provides a knowledge discovery framework\n    across heterogeneous omics data (genomics, proteomics, transcriptomics and metabolomics) id: omicsdi\n  name: OmicsDI\n  registry:\n    biotools: omicsdi\n    fairsharing: re1278\n    tess: OmicsDI\n  url: https:\/\/www.omicsdi.org\n- description: OMOP is a common data model for the harmonisation for of observational\n    health data. id: omop-cdm\n  name: OMOP-CDM\n  url: https:\/\/ohdsi.github.io\/CommonDataModel\/\n- description: OntoMaton facilitates ontology search and tagging functionalities within\n    Google Spreadsheets.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_87",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":87,
        "total_chunks":185,
        "content":"n: OntoMaton facilitates ontology search and tagging functionalities within\n    Google Spreadsheets. id: onotomaton\n  name: OnotoMaton\n  url: https:\/\/github.com\/ISA-tools\/OntoMaton\n- description: A web portal to search and visualise ontologies\n  id: ontobee\n  name: Ontobee\n  registry:\n    fairsharing: q8fx1b\n    tess: Ontobee\n  url: http:\/\/www.ontobee.org\n- description: Licenses that are conformant with the principles laid out in the Open\n    Definition.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_88",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":88,
        "total_chunks":185,
        "content":"- description: Licenses that are conformant with the principles laid out in the Open\n    Definition. id: open-definition-conformant-licenses\n  name: Open Definition Conformant Licenses\n  url: https:\/\/opendefinition.org\/licenses\/\n- description: Explore Open Access research outcomes from OpenAIRE network\n  id: openaire-explore\n  name: OpenAIRE Explore\n  url: https:\/\/explore.openaire.eu\/\n- description: ELIXIR benchmarking platform to support community-led scientific benchmarking\n    efforts and the technical monitoring of bioinformatics reosurces\n  id: openebench\n  name: OpenEBench\n  registry:\n    biotools: openebench\n  url: https:\/\/openebench.bsc.es\/\n- description: OpenMS offers an open-source C++ library (+ Python bindings) for LC\/MS\n    data management, analysis and visualization.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_89",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":89,
        "total_chunks":185,
        "content":"en-source C++ library (+ Python bindings) for LC\/MS\n    data management, analysis and visualization. id: openms\n  name: OpenMS\n  registry:\n    biotools: openms\n    tess: OpenMS\n  url: https:\/\/openms.de\/\n- description: Data curation tool for working with messy data\n  id: openrefine\n  name: OpenRefine\n  registry:\n    tess: OpenRefine\n  url: https:\/\/openrefine.org\/\n- description: 'free and open source project management tool that supports the entire\n    research lifecycle: planning, execution, reporting, archiving, and discovery'\n  id: openscienceframework\n  name: OpenScienceFramework\n  registry:\n    fairsharing: g4z879\n  url: https:\/\/osf.io\/\n- description: OpenStack is an open source cloud computing infrastructure software\n    project and is one of the three most active open source projects in the world id: openstack\n  name: OpenStack\n  registry:\n    tess: OpenStack\n  url: https:\/\/www.openstack.org\/\n- description: OSF (Open Science Framework) is a free, open platform to support your\n    research and enable collaboration.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_90",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":90,
        "total_chunks":185,
        "content":"n Science Framework) is a free, open platform to support your\n    research and enable collaboration. id: osf\n  name: OSF\n  registry:\n    tess: OSF\n  url: https:\/\/osf.io\n- description: One Touch Pipeline (OTP) is a data management platform for running\n    bioinformatics pipelines in a high-throughput setting, and for organising the\n    resulting data and metadata. id: otp\n  name: OTP\n  registry:\n    biotools: otp\n  url: https:\/\/gitlab.com\/one-touch-pipeline\/otp\n- description: Cloud storage and file sharing service\n  id: owncloud\n  name: ownCloud\n  url: https:\/\/owncloud.com\n- description: PAA is an R\/Bioconductor tool for protein microarray data analysis\n    aimed at biomarker discovery.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_91",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":91,
        "total_chunks":185,
        "content":"PAA is an R\/Bioconductor tool for protein microarray data analysis\n    aimed at biomarker discovery. id: paa\n  name: PAA\n  registry:\n    biotools: paa\n  url: https:\/\/bioconductor.org\/packages\/PAA\/\n- description: Data Publisher for Earth and Environmental Science\n  id: pangaea\n  name: PANGAEA\n  registry:\n    biotools: pangaea\n    fairsharing: 6yw6cp\n    tess: PANGAEA\n  url: https:\/\/www.pangaea.de\/\n- description: The Protein Circular Dichroism Data Bank\n  id: pcddb\n  name: PCDDB\n  registry:\n    biotools: pcddb\n  url: https:\/\/pcddb.cryst.bbk.ac.uk\/\n- description: The Protein Data Bank (PDB) id: pdb\n  name: PDB\n  registry:\n    biotools: pdb\n    tess: PDB\n  url: https:\/\/www.wwpdb.org\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_92",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":92,
        "total_chunks":185,
        "content":"  name: PDB\n  registry:\n    biotools: pdb\n    tess: PDB\n  url: https:\/\/www.wwpdb.org\/\n- description: Prototype archiving system for structural models obtained using integrative\n    or hybrid modeling\n  id: pdb-dev\n  name: PDB-Dev\n  url: https:\/\/pdb-dev.wwpdb.org\/\n- description: Information about the standard PDB archive format PDBx\/mmCIF, its dictionaries\n    and related software tools\n  id: pdbx-mmcif-format-and-tools\n  name: PDBx\/mmCIF format and tools\n  registry:\n    fairsharing: fd28en\n  url: https:\/\/mmcif.wwpdb.org\/\n- description: Extension of the PDBx\/mmCIF dictionary for theoretical models of macromolecular\n    structures\n  id: pdbx-mmcif-modelcif-extension-dictionary\n  name: PDBx\/mmCIF ModelCIF Extension Dictionary\n  url: https:\/\/mmcif.wwpdb.org\/dictionaries\/mmcif_ma.dic\/Index\/\n- description: Database of multi-organism, publicly accessible compendium of peptides\n    identified in a large set of tandem mass spectrometry proteomics experiments.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_93",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":93,
        "total_chunks":185,
        "content":"endium of peptides\n    identified in a large set of tandem mass spectrometry proteomics experiments. id: peptideatlas\n  name: PeptideAtlas\n  registry:\n    biotools: peptideatlas\n    fairsharing: dvyrsz\n  url: https:\/\/peptideatlas.org\/\n- description: A resource that curates knowledge about the impact of genetic variation\n    on drug response. id: pharmgkb\n  name: PharmGKB\n  registry:\n    biotools: pharmgkb\n  url: https:\/\/www.pharmgkb.org\/\n- description: Pharos provides hazard, use, and exposure information on 140,872 chemicals\n    and 180 different kinds of building products. id: pharos\n  name: Pharos\n  registry:\n    biotools: pharos\n    fairsharing: 52d6ae\n  url: https:\/\/pharosproject.net\/\n- description: The open-source Phenotyping Hybrid Information System (PHIS) manages\n    and collects data from plants phenotyping and high throughput phenotyping experiments\n    on a day to day basis.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_94",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":94,
        "total_chunks":185,
        "content":" data from plants phenotyping and high throughput phenotyping experiments\n    on a day to day basis. id: phis\n  name: PHIS\n  registry:\n    tess: PHIS\n  url: https:\/\/opensilex.github.io\/phis-docs-community\/\n- description: PIA is a toolbox for mass spectrometrey based protein inference and\n    identification analysis. id: pia-protein-inference-algorithms\n  name: PIA - Protein Inference Algorithms\n  registry:\n    biotools: pia\n  url: https:\/\/github.com\/mpc-bioinformatics\/pia\n- description: A data management solution for intra-institutional organization and\n    structured storage of life science project-associated research data, with emphasis\n    on the generation of adequate metadata. id: pisa-tree\n  name: pISA-tree\n  registry:\n    biotools: pisa-tree\n  url: https:\/\/github.com\/NIB-SI\/pISA-tree\n- description: Access point for plant comparative genomics, centralizing genomic data\n    produced by different genome sequencing initiatives.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_95",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":95,
        "total_chunks":185,
        "content":"arative genomics, centralizing genomic data\n    produced by different genome sequencing initiatives. id: plaza\n  name: PLAZA\n  registry:\n    fairsharing: wBOua0\n    tess: PLAZA\n  url: https:\/\/bioinformatics.psb.ugent.be\/plaza\/\n- description: Python3 module that help in the prediction of pathology in protein\n    mutations.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_96",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":96,
        "total_chunks":185,
        "content":"za\/\n- description: Python3 module that help in the prediction of pathology in protein\n    mutations. id: pymut\n  name: PyMut\n  registry:\n    biotools: pymut\n  url: http:\/\/mmb. irbbarcelona. org\/PMut\/pymut\n- description: PRoteomics IDEntifications (PRIDE) Archive database\n  id: pride\n  name: PRIDE\n  registry:\n    biotools: pride\n    fairsharing: e1byny\n    tess: PRIDE\n  url: https:\/\/www. ebi. ac. uk\/pride\/\n- description: Main tool used to submit proteomics datasets to PRIDE Archive\n  id: pride-submission-tool\n  name: PRIDE Submission Tool\n  url: https:\/\/www. ebi. ac. uk\/pride\/markdownpage\/pridesubmissiontool\n- description: ProteomeXchange provides globally coordinated standard data submission\n    and dissemination pipelines\n  id: proteomexchange\n  name: ProteomeXchange\n  registry:\n    biotools: proteomexchange\n    fairsharing: 92dt9d\n    tess: ProteomeXchange\n  url: http:\/\/www. proteomexchange.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_97",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":97,
        "total_chunks":185,
        "content":"roteomexchange\n    fairsharing: 92dt9d\n    tess: ProteomeXchange\n  url: http:\/\/www. proteomexchange. org\/\n- description: The HUPO Proteomics Standards Initiative defines community standards\n    for data representation in proteomics and interactomics to facilitate data comparison,\n    exchange and verification. id: proteomics-standards-initiative\n  name: HUPO Proteomics Standards Initiative\n  registry:\n    fairsharing: 9f60e7\n  url: https:\/\/www.psidev.info\/\n- description: A secure platform for developing and sharing reproducible methods. id: protocols-io\n  name: protocols.io\n  registry:\n    fairsharing: 132b10\n  url: https:\/\/www.protocols.io\n- description: PROV-DM is the conceptual data model that forms a basis for the W3C\n    provenance (PROV) family of specifications. id: prov-dm-the-prov-data-model\n  name: 'PROV-DM: The PROV Data Model'\n  url: https:\/\/www.w3.org\/TR\/prov-dm\/\n- description: R Markdown documents are fully reproducible. Use a productive notebook\n    interface to weave together narrative text and code to produce elegantly formatted\n    output.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_98",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":98,
        "total_chunks":185,
        "content":"k\n    interface to weave together narrative text and code to produce elegantly formatted\n    output. Use multiple languages including R, Python, and SQL. id: r-markdown\n  name: R Markdown\n  registry:\n    tess: R Markdown\n  url: https:\/\/rmarkdown.rstudio.com\n- description: The RD-Connect GPAP is an online tool for diagnosis and gene discovery\n    in rare disease research. id: rd-connect-genome-phenome-analysis-platform\n  name: RD-Connect Genome Phenome Analysis Platform\n  registry:\n    biotools: rd-connect_platform\n    tess: RD-Connect Genome Phenome Analysis Platform\n  url: https:\/\/platform.rd-connect.eu\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_99",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":99,
        "total_chunks":185,
        "content":"ss: RD-Connect Genome Phenome Analysis Platform\n  url: https:\/\/platform.rd-connect.eu\n- description: Directory of standard metadata, divided into different research areas\n  id: rda-standards\n  name: RDA Standards\n  url: https:\/\/rd-alliance.github.io\/metadata-directory\/standards\/\n- description: Registry of Research Data Repositories\n  id: re3data\n  name: re3data\n  registry:\n    tess: re3data\n  url: https:\/\/www.re3data.org\/\n- description: Portal with public data submitted to ECHA in REACH registration dossiers\n    by substance manufacturers, importers, or their representatives, as laid out by\n    the REACH Regulation (see Understanding REACH regulation). id: reach-registered-substances\n  name: REACH registered substances\n  url: https:\/\/echa.europa.eu\/information-on-chemicals\/registered-substances\n- description: REDCap is a secure web application for building and managing online\n    surveys and databases.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_100",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":100,
        "total_chunks":185,
        "content":"tion: REDCap is a secure web application for building and managing online\n    surveys and databases. While REDCap can be used to collect virtually any type\n    of data in any environment, it is specifically geared to support online and offline\n    data capture for research studies and operations. id: redcap\n  name: REDCap\n  registry:\n    biotools: redcap\n    tess: REDCap\n  url: https:\/\/projectredcap.org\n- description: Database of A-to-I (deamination of adenosines to inosines) events that\n    enables to search RNA editing sites by genomic region, gene name and other relevant\n    features as the tissue of origin. id: rediportal\n  name: REDIportal\n  registry:\n    biotools: rediportal\n  url: http:\/\/srv00.recas.ba.infn.it\/atlas\/\n- description: Python scripts to detect RNA editing events in RNAseq experiments\n  id: reditools\n  name: REDItools\n  registry:\n    biotools: reditools\n  url: https:\/\/github.com\/BioinfoUNIBA\/REDItools\n- description: REDItools2 is the optimized, parallel multi-node version of REDItools.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_101",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":101,
        "total_chunks":185,
        "content":"NIBA\/REDItools\n- description: REDItools2 is the optimized, parallel multi-node version of REDItools. id: reditools2\n  name: REDItools2\n  url: https:\/\/github.com\/BioinfoUNIBA\/REDItools2\n- description: REMS (Resource Entitlement Management System), developed by CSC, is\n    a tool that can be used to manage researchers access rights to datasets. id: rems\n  name: REMS\n  registry:\n    biotools: rems\n    tess: REMS\n  url: https:\/\/github.com\/CSCfi\/rems\n- description: File renaming software for Mac\n  id: renamer4mac\n  name: Renamer4Mac\n  url: https:\/\/renamer.com\/\n- description: Repository Finder can help you find an appropriate repository to deposit\n    your research data. The tool is hosted by DataCite and queries the re3data registry\n    of research data repositories.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_102",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":102,
        "total_chunks":185,
        "content":". The tool is hosted by DataCite and queries the re3data registry\n    of research data repositories. id: repository-finder\n  name: Repository Finder\n  url: https:\/\/repositoryfinder.datacite.org\n- description: Supports the systematic planning, organisation and implementation of\n    research data management throughout the course of a project\n  id: research-data-management-organiser\n  name: Research Data Management Organiser\n  url: https:\/\/rdmorganiser.github.io\/en\n- description: Data management platform for automated loading, storage, linkage and\n    provision of data sets\n  id: research-data-management-platform\n  name: Research Data Management Platform (RDMP) registry:\n    biotools: rdmp\n  url: https:\/\/www.dundee.ac.uk\/hic\/data-team\/researchdatamanagementplatform\/\n- description: Machine actionable DMPs.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_103",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":103,
        "total_chunks":185,
        "content":"w.dundee.ac.uk\/hic\/data-team\/researchdatamanagementplatform\/\n- description: Machine actionable DMPs. id: research-management-plan\n  name: Research Management Plan\n  url: https:\/\/researcheracademy.elsevier.com\/research-preparation\/research-data-management\/creating-good-research-data-management-plan\n- description: RO-Crate is a lightweight approach to packaging research data with\n    their metadata, using schema.org. An RO-Crate is a structured archive of all the\n    items that contributed to the research outcome, including their identifiers, provenance,\n    relations and annotations. id: research-object-crate\n  name: Research Object Crate (RO-Crate)\n  registry:\n    fairsharing: wUoZKE\n    tess: Research Object Crate\n  url: https:\/\/w3id.org\/ro\/crate\n- description: Reva connects cloud storages and application providers",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_104",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":104,
        "total_chunks":185,
        "content":"url: https:\/\/w3id.org\/ro\/crate\n- description: Reva connects cloud storages and application providers id: reva\n  name: Reva\n  registry:\n    biotools: reva\n    tess: Reva\n  url: https:\/\/reva.link\/\n- description: RightField is an open-source tool for adding ontology term selection\n    to Excel spreadsheets\n  id: rightfield\n  name: Rightfield\n  registry:\n    biotools: rightfield\n  url: https:\/\/rightfield.org.uk\n- description: Rstudio notebooks allow to share code, documentation\n  id: rstudio\n  name: Rstudio\n  registry:\n    biotools: rstudio\n    tess: Rstudio\n  url: https:\/\/rstudio.com\n- description: Rucio - Scientific Data Management\n  id: rucio\n  name: Rucio\n  url: https:\/\/rucio.cern.ch\/\n- description: RxNorm is a normalized naming system for medications that is maintained\n    by the National Library of Medicine. Rxnorm provides unique identifiers and allows\n    unambiguous communication of drug-related information across the American health\n    computer systems.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_105",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":105,
        "total_chunks":185,
        "content":"ambiguous communication of drug-related information across the American health\n    computer systems. id: rxnorm\n  name: RxNorm\n  registry:\n    biotools: rxnorm\n    fairsharing: 36pf8q\n  url: https:\/\/www.nlm.nih.gov\/research\/umls\/rxnorm\/index.html\n- description: SalDB is a salmon specific database of genome sequenced prokaryotes\n    representing the microbiota of fishes found in the taxonomic family of Salmonidae. id: saldb\n  name: salDB\n  url: https:\/\/sfb.mmp2.sigma2.no\/databases\/saldb\/\n- description: Small Angle Scattering Biological Data Bank\n  id: sasbdb\n  name: SASBDB\n  url: https:\/\/www.sasbdb.org\/\n- description: A standard library of visual glyphs used to represent SBOL designs\n    and interactions. id: sbol-visual\n  name: SBOL Visual\n  url: https:\/\/sbolstandard.org\/visual-glyphs\/\n- description: A CAD tool to create SBOL designs through the use of SBOL Visual glyphs.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_106",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":106,
        "total_chunks":185,
        "content":"sual-glyphs\/\n- description: A CAD tool to create SBOL designs through the use of SBOL Visual glyphs. id: sboldesigner\n  name: SBOLDesigner\n  url: https:\/\/sboldesigner.github.io\n- description: Schema.org is a collaborative, community activity with a mission to\n    create, maintain, and promote schemas for structured data on the Internet, on\n    web pages, in email messages, and beyond. id: schema-org\n  name: Schema.org\n  registry:\n    fairsharing: hzdzq8\n    tess: Schema.org\n  url: https:\/\/schema.org\n- description: ScienceMesh - frictionless scientific collaboration and access to research\n    services\n  id: sciencemesh\n  name: ScienceMesh\n  url: https:\/\/sciencemesh.io\/\n- description: List of respositories recommended by Scientific Data, contains both\n    discipline-specific and general repositories.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_107",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":107,
        "total_chunks":185,
        "content":"ries recommended by Scientific Data, contains both\n    discipline-specific and general repositories. id: scientific-data-s-recommended-repositories\n  name: Scientific Data's Recommended Repositories\n  url: https:\/\/www.nature.com\/sdata\/policies\/repositories\n- description: SeaFile File Synchronization and Share Solution\n  id: seafile\n  name: SeaFile\n  url: https:\/\/www.seafile.com\/\n- description: A semantic data model describing the common data elements for rare\n    diseases registration. id: semantic-data-model-of-the-set-of-common-data-elements-for-rare-diseases-registration\n  name: Semantic data model of the set of common data elements for rare diseases registration\n  url: https:\/\/github.com\/ejp-rd-vp\/CDE-semantic-model\n- description: All-in-one platform for life science data management, semantic data\n    integration, data analysis and visualization\n  id: semares\n  name: Semares\n  url: https:\/\/www.genevention.com\/products\n- description: Contains 16 data elements to be registered by each rare disease registry\n    across Europe, which are considered to be essential for further research.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_108",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":108,
        "total_chunks":185,
        "content":" rare disease registry\n    across Europe, which are considered to be essential for further research. id: set-of-common-data-elements-for-rare-diseases-registration\n  name: Set of common data elements for rare diseases registration\n  url: https:\/\/eu-rd-platform.jrc.ec.europa.eu\/set-of-common-data-elements_en\n- description: A scripting language for creating Synthetic Biology Open Language (SBOL)\n    in a more abstract way. id: shortbol\n  name: ShortBOL\n  url: http:\/\/shortbol.org\n- description: Structure integration with function, taxonomy and sequence\n  id: sifts\n  name: SIFTS\n  url: https:\/\/www.ebi.ac.uk\/pdbe\/docs\/sifts\/\n- description: Singularity is a container platform. id: singularity\n  name: Singularity\n  registry:\n    tess: Singularity\n  url: https:\/\/sylabs.io\n- description: Freely-available, open-source Windows client application for building\n    Selected Reaction Monitoring (SRM) \/ Multiple Reaction Monitoring (MRM), Parallel\n    Reaction Monitoring (PRM), DIA\/SWATH and targeted DDA quantitative methods and\n    analyzing the resulting mass spectrometer data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_109",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":109,
        "total_chunks":185,
        "content":"\/SWATH and targeted DDA quantitative methods and\n    analyzing the resulting mass spectrometer data. id: skyline\n  name: Skyline\n  registry:\n    biotools: skyline\n  url: https:\/\/skyline.ms\/project\/home\/begin.view\n- description: SMASCH (Smart Scheduling) system, is a web-based tooldesigned for longitudinal\n    clinical studies requiring recurrent follow-upvisits of the participants. SMASCH\n    controls and simplifies the scheduling of big database of patients. Smasch is\n    also used to organize the daily plannings (delegation of tasks) for the different\n    medical professionals such as doctors, nurses and neuropsychologists.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_110",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":110,
        "total_chunks":185,
        "content":"f tasks) for the different\n    medical professionals such as doctors, nurses and neuropsychologists. id: smasch\n  name: SMASCH\n  url: https:\/\/smasch.pages.uni.lu\n- description: Snakemake is a framework for data analysis workflow execution\n  id: snakemake\n  name: Snakemake\n  registry:\n    biotools: snakemake\n    tess: Snakemake\n  url: https:\/\/snakemake.github.io\n- description: Added-value database for biological dynamics images\n  id: ssbd-database\n  name: SSBD:database\n  registry:\n    fairsharing: we2r5a\n  url: https:\/\/ssbd.riken.jp\/database\/\n- description: An open data archive that stores and publishes bioimaging and biological\n    quantitative datasets\n  id: ssbd-repository\n  name: SSBD:repository\n  url: https:\/\/ssbd.riken.jp\/repository\/\n- description: Resource of standards for reporting enzyme data\n  id: standards-for-reporting-enzyme-data\n  name: Standards for Reporting Enzyme Data (STRENDA)\n  registry:\n    fairsharing: 8ntfwm\n  url: https:\/\/www.beilstein-institut.de\/en\/projects\/strenda\/\n- description: Known and predicted protein-protein interactions.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_111",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":111,
        "total_chunks":185,
        "content":"in-institut.de\/en\/projects\/strenda\/\n- description: Known and predicted protein-protein interactions. id: string\n  name: STRING\n  registry:\n    biotools: string\n    fairsharing: 9b7wvk\n    tess: STRING\n  url: https:\/\/string-db.org\/\n- description: A searchable design repository for biological constructs\n  id: synbiohub\n  name: SynBioHub\n  registry:\n    biotools: synbiohub\n    fairsharing: 7CVoS6\n  url: https:\/\/synbiohub.org\n- description: An open standard for the representation of in silico biological designs\n    and their place in the Design-Build-Test-Learn cycle of synthetic biology. id: synthetic-biology-open-language\n  name: Synthetic Biology Open Language (SBOL)",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_112",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":112,
        "total_chunks":185,
        "content":"ynthetic biology. id: synthetic-biology-open-language\n  name: Synthetic Biology Open Language (SBOL) registry:\n    biotools: sbol\n    fairsharing: cwf4py\n  url: https:\/\/sbolstandard.org\n- description: An open format for computational models of biological processes\n  id: systems-biology-markup-language\n  name: Systems Biology Markup Language (SBML)\n  registry:\n    biotools: sbml\n    fairsharing: 9qv71f\n  url: https:\/\/sbml.org\/\n- description: The Toxin and Toxin Target Database is a bioinformatics resource that\n    combines exhaustive toxin data with toxin target information. Currently it presents\n    more than 42,000 toxin-target associations extracted from other databases, government\n    documents, books and scientific literature. Each toxin record includes data on\n    chemical properties and descriptors, toxicity values and medical information. id: t3db\n  name: Toxin and Toxin Target Database (T3DB)\n  registry:\n    biotools: t3db\n    fairsharing: psn0h2\n  url: http:\/\/www.t3db.ca\/\n- description: Talend is an open source data integration platform.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_113",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":113,
        "total_chunks":185,
        "content":"psn0h2\n  url: http:\/\/www.t3db.ca\/\n- description: Talend is an open source data integration platform. id: talend\n  name: Talend\n  url: https:\/\/www.talend.com\/\n- description: A toxicogenomics database that stores gene expression data and biochemistry,\n    hematology, and histopathology findings derived from in vivo (rat) and in vitro\n    (primary rat hepatocytes, primary human hepatocytes) exposure to 170 compounds\n    at multiple dosages and time points.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_114",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":114,
        "total_chunks":185,
        "content":"cytes, primary human hepatocytes) exposure to 170 compounds\n    at multiple dosages and time points. id: tg-gates\n  name: TG-GATES\n  registry:\n    biotools: open_tg-gates\n  url: https:\/\/toxico.nibiohn.go.jp\/english\/\n- description: An ontology for expressing environmental terms\n  id: the-environment-ontology\n  name: The Environment Ontology (EnvO)\n  url: https:\/\/sites.google.com\/site\/environmentontology\/\n- description: EGA is a service for permanent archiving and sharing of all types of\n    personally identifiable genetic and phenotypic data resulting from biomedical\n    research projects\n  id: the-european-genome-phenome-archive\n  name: The European Genome-phenome Archive (EGA)\n  registry:\n    biotools: ega\n    fairsharing: mya1ff\n    tess: The European Genome-phenome Archive (EGA)\n  url: https:\/\/ega-archive.org\/\n- description: The Genomic Standards Consortium (GSC) is an open-membership working\n    body enabling genomic data integration, discovery and comparison through international\n    community-driven standards.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_115",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":115,
        "total_chunks":185,
        "content":"mic data integration, discovery and comparison through international\n    community-driven standards. id: genomic-standards-consortium\n  name: Genomic Standards Consortium (GSC)\n  registry:\n    biotools: NA\n    fairsharing: 9aa0zp\n  url: https:\/\/www.gensc.org\/\n- description: Collaborative effort to develob interoperable ontologies for the biological\n    sciences\n  id: the-open-biological-and-biomedical-ontology-foundry\n  name: The Open Biological and Biomedical Ontology (OBO) Foundry\n  registry:\n    fairsharing: 847069\n  url: http:\/\/obofoundry.org\n- description: The Toxicology in the 21st Century program, or Tox21, is a unique collaboration\n    between several federal agencies to develop new ways to rapidly test whether substances\n    adversely affect human health. The Tox21 Toolbox contains data-analysis tools\n    for accessing and visualizing Tox21 quantitative high-throughput screening (qHTS)\n    10K library data, as well as integrating with other publicly available data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_116",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":116,
        "total_chunks":185,
        "content":"ut screening (qHTS)\n    10K library data, as well as integrating with other publicly available data. id: tox21-toolbox\n  name: Tox21_Toolbox\n  url: https:\/\/ntp.niehs.nih.gov\/whatwestudy\/tox21\/toolbox\/index.html\n- description: The Toxicology in the 21st Century program, or Tox21, is a unique collaboration\n    between several federal agencies to develop new ways to rapidly test whether substances\n    adversely affect human health. This portal contains diverse downloadable results\n    of the ToxCast project. id: toxcast-data\n  name: ToxCast_data\n  url: https:\/\/www.epa.gov\/chemical-research\/exploring-toxcast-data-downloadable-data\n- description: Knowledge management and high-content analysis platform enabling analysis\n    of integrated data for the purposes of hypothesis generation, hypothesis validation,\n    and cohort discovery in translational research.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_117",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":117,
        "total_chunks":185,
        "content":"of hypothesis generation, hypothesis validation,\n    and cohort discovery in translational research. id: transmart\n  name: tranSMART\n  registry:\n    biotools: transmart\n  url: https:\/\/github.com\/transmart\n- description: A list of Ethical, Legal, and Societal Implications (ELSI) to consider\n    for research projects on human subjects\n  id: tryggve-elsi-checklist\n  name: Tryggve ELSI Checklist\n  url: https:\/\/neic.no\/tryggve\/links\/\n- description: TU Delft costing tool helps to budget for data management personnel\n    costs in proposals. id: tu-delft-data-management-costing-tool\n  name: TU Delft data management costing tool\n  url: https:\/\/www.tudelft.nl\/en\/library\/research-data-management\/r\/plan\/data-management-costs\n- description: A tool that contains weighted gene co-expression networks obtained\n    from the Primary Human Hepatocytes, rat kidney, and liver TG-GATEs dataset. id: txg-mapr\n  name: TXG-MAPr\n  registry:\n    biotools: txg-mapr\n  url: https:\/\/txg-mapr.eu\/\n- description: UK Data Service activity-based costing tool.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_118",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":118,
        "total_chunks":185,
        "content":"ls: txg-mapr\n  url: https:\/\/txg-mapr.eu\/\n- description: UK Data Service activity-based costing tool. id: uk-data-service-data-management-costing-tool\n  name: UK Data Service Data Management costing Tool\n  url: https:\/\/ukdataservice.ac.uk\/learning-hub\/research-data-management\/plan-to-share\/costing\/\n- description: The Unified Medical Language System (UMLS) is a set of tools that establishes\n    a mapping structure among different vocabularies in the biomedical sciences field\n    to enable interoperativity between computer systems. id: umls\n  name: UMLS\n  url: https:\/\/www.nlm.nih.gov\/research\/umls\/index.html\n- description: 'UniChem is a very simple, large-scale non-redundant database of pointers\n    between chemical structures and EMBL-EBI chemistry resources. Primarily, this\n    service has been designed to maintain cross references between EBI chemistry resources.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_119",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":119,
        "total_chunks":185,
        "content":"ly, this\n    service has been designed to maintain cross references between EBI chemistry resources. These include primary chemistry resources (ChEMBL and ChEBI), and other resources\n    where the main focus is not small molecules, but which may nevertheless contain\n    some small molecule information (eg: Gene Expression Atlas, PDBe).' id: unichem\n  name: UniChem\n  registry:\n    tess: UniChem\n  url: https:\/\/www.ebi.ac.uk\/unichem\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_120",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":120,
        "total_chunks":185,
        "content":"m\n  name: UniChem\n  registry:\n    tess: UniChem\n  url: https:\/\/www.ebi.ac.uk\/unichem\/\n- description: Protein modification for mass spectrometry\n  id: unimod\n  name: Unimod\n  registry:\n    biotools: unimod\n    fairsharing: zZHCUQ\n  url: https:\/\/www.unimod.org\n- description: Comprehensive resource for protein sequence and annotation data\n  id: uniprot\n  name: UniProt\n  registry:\n    biotools: uniprot\n    fairsharing: s1ne3g\n    tess: UniProt\n  url: https:\/\/www.uniprot.org\/\n- description: List of Electronic Research Notebook Products by University of Cambridge\n  id: university-of-cambridge-electronic-research-notebook-products\n  name: University of Cambridge - Electronic Research Notebook Products\n  url: https:\/\/www.data.cam.ac.uk\/data-management-guide\/electronic-research-notebooks\/electronic-research-notebook-products\n- description: A JavaScript library for the visualisation of SBOL. id: visbol\n  name: VisBOL\n  url: http:\/\/visbol.org\n- description: Wellcome Open Research requires that the source data underlying the\n    results are made available as soon as an article is published.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_121",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":121,
        "total_chunks":185,
        "content":"at the source data underlying the\n    results are made available as soon as an article is published. This page provides\n    information about data you need to include, where your data can be stored, and\n    how your data should be presented. id: wellcome-open-research-data-guidelines\n  name: Wellcome Open Research - Data Guidelines\n  registry:\n    fairsharing: wf9q40\n  url: https:\/\/wellcomeopenresearch.org\/for-authors\/data-guidelines\n- description: WinSCP is a popular SFTP client and FTP client for Microsoft Windows! Copy file between a local computer and remote servers using FTP, FTPS, SCP, SFTP,\n    WebDAV or S3 file transfer protocols. id: winscp\n  name: WinSCP\n  url: https:\/\/winscp.net\/eng\/index.php\n- description: WorkflowHub is a registry for describing, sharing and publishing scientific\n    computational workflows. id: workflowhub\n  name: WorkflowHub\n  registry:\n    biotools: workflowhub\n    fairsharing: 07cf72\n    tess: WorkflowHub\n  url: https:\/\/workflowhub.eu\n- description: Open source imaging informatics platform.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_122",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":122,
        "total_chunks":185,
        "content":": WorkflowHub\n  url: https:\/\/workflowhub.eu\n- description: Open source imaging informatics platform. It facilitates common management,\n    productivity, and quality assurance tasks for imaging and associated data. id: xnat\n  name: XNAT\n  registry:\n    biotools: xnat\n  url: https:\/\/www.xnat.org\/\n- description: Analysing of single or multiple subjects within the same project in\n    XNAT\n  id: xnat-pic-pipelines\n  name: XNAT-PIC Pipelines\n  url: https:\/\/github.com\/szullino\/XNAT-PIC\n- description: Import tool for multimodal DICOM image datasets to XNAT\n  id: xnat-pic-uploader\n  name: XNAT-PIC Uploader\n  url: https:\/\/github.com\/szullino\/XNAT-PIC\n- description: Generalist research data repository built and developed by OpenAIRE\n    and CERN\n  id: zenodo\n  name: Zenodo\n  registry:\n    fairsharing: wy4egf\n    tess: Zenodo\n  url: https:\/\/zenodo.org\/\n- description: Find possible ontology mappings for free text terms in the ZOOMA repository.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_123",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":123,
        "total_chunks":185,
        "content":"odo.org\/\n- description: Find possible ontology mappings for free text terms in the ZOOMA repository. id: zooma\n  name: Zooma\n  registry:\n    biotools: zooma\n    tess: Zooma\n  url: https:\/\/www.ebi.ac.uk\/spot\/zooma\/\n- description: A comprehensive repository of biomedical ontologies\n  id: bioportal\n  name: BioPortal\n  registry:\n    biotools: bioportal\n    fairsharing: 4m97ah\n    tess: BioPortal\n  url: https:\/\/bioportal.bioontology.org\n- description: PROAST (copyright RIVM National Institute for Public Health and the\n    Environment) is a software package for the statistical analysis of dose-response\n    data. id: proast\n  name: PROAST\n  url: https:\/\/www.rivm.nl\/en\/proast\n- description: EPA's Benchmark Dose Software (BMDS) collects and provides easy access\n    to numerous mathematical models that help risk assessors estimate the quantitative\n    relationship between a chemical dose and the test subjects response.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_124",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":124,
        "total_chunks":185,
        "content":" estimate the quantitative\n    relationship between a chemical dose and the test subjects response. id: bmds\n  name: BMDS\n  url: https:\/\/www.epa.gov\/bmds\n- description: Differential gene expression analysis based on the negative binomial\n    distribution\n  id: deseq2\n  name: DESEq2\n  registry:\n    biotools: deseq2\n    tess: DESEq2\n  url: https:\/\/bioconductor.org\/packages\/release\/bioc\/html\/DESeq2.html\n- description: Linear Models for Microarray Data\n  id: limma\n  name: limma\n  registry:\n    biotools: limma\n    tess: limma\n  url: https:\/\/bioconductor.org\/packages\/release\/bioc\/html\/limma.html\n- description: Flame is a flexible framework supporting predictive modeling and similarity\n    search within the eTRANSAFE project. id: flame\n  name: Flame\n  registry:\n    biotools: flame\n  url: https:\/\/github.com\/phi-grib\/flame\n- description: CDISC SEND Controlled Terminology\n  id: cdisc-send\n  name: CDISC\/SEND\n  url: https:\/\/evs.nci.nih.gov\/ftp1\/CDISC\/SEND\/SEND%20Terminology.html\n- description: The OntoBrowser tool was developed to manage ontologies and code lists.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_125",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":125,
        "total_chunks":185,
        "content":"minology.html\n- description: The OntoBrowser tool was developed to manage ontologies and code lists. id: ontobrowser\n  name: ONTOBROWSER\n  registry:\n    biotools: ontobrowser\n  url: https:\/\/opensource.nibr.com\/projects\/ontobrowser\/\n- description: ITER is an Internet database of human health risk values and cancer\n    classifications for over 680 chemicals of environmental concern from multiple\n    organizations worldwide. id: iter\n  name: ITER\n  registry:\n    tess: ITER\n  url: https:\/\/www.tera.org\/iter\/\n- description: ERDRI.spider (Secure Privacy-preserving Identity management in Distributed\n    Environments for Research) pseudonymisation tool generates pseudonyms for RD patients. id: spider-pseudonymisation-tool\n  name: SPIDER pseudonymisation tool\n  url: https:\/\/eu-rd-platform.jrc.ec.europa.eu\/spider\/\n- description: Metadata for machines\n  id: fair-data-points\n  name: FAIR Data Points\n  registry:\n    tess: FAIR Data Points\n  url: https:\/\/home.fairdatapoint.org\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_126",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":126,
        "total_chunks":185,
        "content":" Points\n  registry:\n    tess: FAIR Data Points\n  url: https:\/\/home.fairdatapoint.org\/\n- description: EJP RD - European Joint Programme on Rare Diseases - ERN Registries\n    Generic Informed Consent Forms\n  id: ern-registries-generic-informed-consent-forms\n  name: ERN Registries Generic Informed Consent Forms\n  url: https:\/\/www.ejprarediseases.org\/ern-registries-generic-icf\/\n- description: The International Nucleotide Sequence Database Collaboration (INSDC)\n    is a long-standing foundational initiative that operates between DDBJ, EMBL-EBI\n    and NCBI. INSDC covers the spectrum of data raw reads, through alignments and\n    assemblies to functional annotation, enriched with contextual information relating\n    to samples and experimental configurations.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_127",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":127,
        "total_chunks":185,
        "content":"ation, enriched with contextual information relating\n    to samples and experimental configurations. id: international-nucleotide-sequence-database-collaboration\n  name: International Nucleotide Sequence Database Collaboration\n  registry:\n    tess: International Nucleotide Sequence Database Collaboration\n  url: http:\/\/www.insdc.org\/\n- description: A number of ECPGR Central Crop Databases have been established through\n    the initiative of individual institutes and of ECPGR Working Groups. The databases\n    hold passport data and, to varying degrees, characterization and primary evaluation\n    data of the major collections of the respective crops in Europe.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_128",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":128,
        "total_chunks":185,
        "content":"rization and primary evaluation\n    data of the major collections of the respective crops in Europe. id: ecpgr-central-crop-databases\n  name: ECPGR Central Crop Databases and other Crop Databases\n  url: https:\/\/www.ecpgr.cgiar.org\/resources\/germplasm-databases\/ecpgr-central-crop-databases\n- description: A catalogue of relevant International Multicrop Databases\n  id: international-multicrop-databases\n  name: International Multicrop Databases\n  url: https:\/\/www.ecpgr.cgiar.org\/resources\/germplasm-databases\/international-multicrop-databases\n- description: Genesys is an online platform where you can find information about\n    Plant Genetic Resources for Food and Agriculture PGRFA conserved in genebanks\n    worldwide.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_129",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":129,
        "total_chunks":185,
        "content":"out\n    Plant Genetic Resources for Food and Agriculture PGRFA conserved in genebanks\n    worldwide. id: genesys\n  name: Genesys\n  url: https:\/\/www. genesys-pgr. org\/\n- description: This document describes the MIAPPE Checklist and Data Model\n  id: miappe-checklist-data-model\n  name: MIAPPE_Checklist-Data-Model\n  url: https:\/\/github. com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1. 1\n- description: BioSamples Plant MIAPPE checklist in JSON format\n  id: plant-miappe-json\n  name: plant-miappe. json\n  url: https:\/\/www. ebi. ac. uk\/biosamples\/schemas\/certification\/plant-miappe. json\n- description: An ecosystem for sharing and opening research data\n  id: recherche-data-gouv\n  name: Recherche Data Gouv\n  registry:\n    fairsharing: 59985a\n  url: https:\/\/recherche. data. gouv. fr\/\n- description: Submit a new BrAPI compatible server\n  id: brapi-compatible-server\n  name: BrAPI compatible server\n  url: https:\/\/www. brapi.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_130",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":130,
        "total_chunks":185,
        "content":"ible server\n  id: brapi-compatible-server\n  name: BrAPI compatible server\n  url: https:\/\/www. brapi. org\/servers\n- description: MIAPPE-compliant spreadsheet template\n  id: miappe-compliant-spreadsheet-template\n  name: MIAPPE-compliant spreadsheet template\n  url: https:\/\/github. com\/MIAPPE\/MIAPPE\/raw\/master\/MIAPPE_Checklist-Data-Model-v1. 1\/MIAPPE_templates\/MIAPPEv1. 1_training_spreadsheet. xlsx\n- description: The Common Workflow Language CWL is an emerging standard for writing\n    workflows that are portable across multiple workflow engines and platforms. Toil\n    has full support for the CWL v1.0, v1.1, and v1.2 standards. id: cwl-in-toil\n  name: CWL in Toil\n  url: https:\/\/toil.readthedocs.io\/en\/latest\/cwl\/running.html\n- description: This is the reference implementation of the Common Workflow Language\n    open standards. It is intended to be feature complete and provide comprehensive\n    validation of CWL files as well as provide other tools related to working with\n    CWL.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_131",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":131,
        "total_chunks":185,
        "content":"ehensive\n    validation of CWL files as well as provide other tools related to working with\n    CWL. id: cwltool\n  name: cwltool\n  url: https:\/\/pypi.org\/project\/cwltool\/\n- description: Kernel Zero is IPython, which you can get through ipykernel, and is\n    still a dependency of jupyter. The IPython kernel can be thought of as a reference\n    implementation, as CPython is for Python. id: jupyter-kernels\n  name: Jupyter kernels\n  url: https:\/\/github.com\/jupyter\/jupyter\/wiki\/Jupyter-kernels\n- description: The Missing Package Manager for macOS or Linux\n  id: homebrew\n  name: Homebrew\n  url: https:\/\/brew.sh\/\n- description: A database to quickly access all tryptic peptides of the UniProtKB\n  id: macpepdb\n  name: Mass Centric Peptide Database (MaCPepDB)\n  registry:\n    fairsharing: c756a7\n  url: https:\/\/macpepdb.mpc.rub.de\/\n- description: The MacPorts Project is an open-source community initiative to design\n    an easy-to-use system for compiling, installing, and upgrading either command-line,\n    X11 or Aqua based open-source software on the Mac operating system.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_132",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":132,
        "total_chunks":185,
        "content":"grading either command-line,\n    X11 or Aqua based open-source software on the Mac operating system. id: macports\n  name: MacPorts\n  url: https:\/\/www.macports.org\n- description: The Package Manager for Windows\n  id: chocolatey\n  name: Chocolatey\n  url: https:\/\/chocolatey.org\/\n- description: Windows Package Manager is a comprehensive package manager solution\n    that consists of a command line tool and set of services for installing applications\n    on Windows 10 and Windows 11. id: windows-package-manager\n  name: Windows Package Manager\n  url: https:\/\/docs.microsoft.com\/en-us\/windows\/package-manager\/\n- description: udocker is a basic user tool to execute simple docker containers in\n    user space without requiring root privileges. id: udocker\n  name: udocker\n  url: https:\/\/indigo-dc.gitbook.io\/udocker\/\n- description: Manage containers, pods, and images with Podman. Seamlessly work with\n    containers and Kubernetes from your local environment. id: podman\n  name: Podman\n  url: https:\/\/podman.io\/\n- description:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_133",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":133,
        "total_chunks":185,
        "content":"etes from your local environment. id: podman\n  name: Podman\n  url: https:\/\/podman.io\/\n- description: Docker Hub is the world's easiest way to create, manage, and deliver\n    your team's container applications. id: docker-hub\n  name: Docker Hub\n  registry:\n    fairsharing: afc2b3\n    tess: Docker Hub\n  url: https:\/\/hub.docker.com\/\n- description: BioContainers Flow\n  id: biocontainers\n  name: BioContainers\n  registry:\n    biotools: biocontainers\n    tess: BioContainers\n  url: https:\/\/biocontainers.pro\/\n- description: Volumes are the preferred mechanism for persisting data generated by\n    and used by Docker containers. id: volumes\n  name: Volumes\n  registry:\n    tess: Volumes\n  url: https:\/\/docs.docker.com\/storage\/volumes\/\n- description: Docker can build images automatically by reading the instructions from\n    a Dockerfile\n  id: dockerfile-reference\n  name: Dockerfile reference\n  url: https:\/\/docs.docker.com\/engine\/reference\/builder\/\n- description: Compose is a tool for defining and running multi-container Docker applications.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_134",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":134,
        "total_chunks":185,
        "content":"lder\/\n- description: Compose is a tool for defining and running multi-container Docker applications. id: docker-compose-overview\n  name: Docker Compose overview\n  url: https:\/\/docs.docker.com\/compose\/\n- description: Kubernetes, also known as K8s, is an open-source system for automating\n    deployment, scaling, and management of containerized applications. id: kubernetes\n  name: Kubernetes\n  registry:\n    tess: Kubernetes\n  url: https:\/\/kubernetes.io\/\n- description: Cromwell is a Workflow Management System geared towards scientific\n    workflows. id: cromwell\n  name: Cromwell\n  url: https:\/\/cromwell.readthedocs.io\/en\/stable\/tutorials\/Containers\/\n- description: Essential scientific and technical information about software tools,\n    databases and services for bioinformatics and the life sciences. id: bio-tools\n  name: bio.tools\n  registry:\n    biotools: bio.tools\n    fairsharing: 63520c\n    tess: bio.tools\n  url: https:\/\/bio.tools\/\n- description: Dockstore is a free and open source platform for sharing reusable and\n    scalable analytical tools and workflows.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_135",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":135,
        "total_chunks":185,
        "content":" free and open source platform for sharing reusable and\n    scalable analytical tools and workflows. Its developed by the Cancer Genome Collaboratory\n    and used by the GA4GH. id: dockstore\n  name: Dockstore\n  registry:\n    biotools: dockstore\n    tess: Dockstore\n  url: https:\/\/dockstore.org\n- description: LifeMonitor is a service to support the sustainability and reusability\n    of published computational workflows. id: life-monitor\n  name: Life-Monitor\n  registry:\n    tess: Life-Monitor\n  url: https:\/\/crs4.github.io\/life_monitor\/\n- description: Data Management Plans that meet institutional funder requirements. id: dmponline\n  name: DMPonline\n  registry:\n    tess: DMPonline\n  url: https:\/\/dmponline.dcc.ac.uk\n- description: Data Management Plan Generator\n  id: easy-dmp\n  name: easy.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_136",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":136,
        "total_chunks":185,
        "content":"tps:\/\/dmponline.dcc.ac.uk\n- description: Data Management Plan Generator\n  id: easy-dmp\n  name: easy. DMP\n  url: https:\/\/easydmp.no\n- description: Gene expression across species and biological conditions\n  id: expression-atlas\n  name: Expression Atlas\n  registry:\n    biotools: expression_atlas\n    fairsharing: f5zx00\n    tess: Expression Atlas\n  url: https:\/\/www.ebi.ac.uk\/gxa\/home\n- description: A web-based platform for sharing viral sequence data, initially for\n    influenza data, and now for other pathogens (including SARS-CoV-2). id: gisaid\n  name: Global Initiative on Sharing All Influenza Data (GISAID)\n  registry:\n    fairsharing: 2f7f9f\n  url: https:\/\/gisaid.org\n- description: Protein Data Bank in Europe Knowledge Base\n  id: pdbe-kb\n  name: PDBe-KB\n  registry:\n    biotools: pdbe-kb\n    tess: PDBe-KB\n  url: https:\/\/www.ebi.ac.uk\/pdbe\/pdbe-kb\n- description: 3DBIONOTES-WS  is a web application designed to automatically annotate\n    biochemical and biomedical information onto structural models.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_137",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":137,
        "total_chunks":185,
        "content":"esigned to automatically annotate\n    biochemical and biomedical information onto structural models. id: 3dbionotes\n  name: 3DBioNotes\n  registry:\n    biotools: 3dbionotes\n    tess: 3DBioNotes\n  url: http:\/\/3dbionotes-ws.cnb.csic.es\/\n- description: A software to make biological search more integrated, intuitive and\n    intelligent, enabling a better way to discover and share new insights. id: knetminer\n  name: KnetMiner\n  registry:\n    biotools: knetminer\n    fairsharing: 826b4a\n    tess: KnetMiner\n  url: https:\/\/knetminer.com\n- description: The RDF Knowledge-based Database for plant molecular networks\n  id: agronomic-linked-data\n  name: Agronomic Linked Data\n  registry:\n    fairsharing: ZPRtfG\n  url: http:\/\/agrold.southgreen.fr\/agrold\/\n- description: Increasing interoperability of small molecules by agregating many different\n    sources of information into a single, logically coherent and semantically interconnected\n    information source.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_138",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":138,
        "total_chunks":185,
        "content":"nformation into a single, logically coherent and semantically interconnected\n    information source. id: integrated-database-of-small-molecules\n  name: Integrated Database of Small Molecules (IDSM)\n  registry:\n    biotools: idsm\n    fairsharing: nn9r0d\n  url: https:\/\/idsm.elixir-czech.cz\/\n- description: The OME Model is a specification for storing data on biological imaging. id: ome-data-model-and-file-formats\n  name: OME Data Model and File Formats\n  url: https:\/\/docs.openmicroscopy.org\/ome-model\/\n- description: 'Documenting research data: Electronic Lab(oratory) Notebooks.' id: publisso\n  name: PUBLISSO\n  url: https:\/\/www.publisso.de\/en\/research-data-management\/rd-documenting\n- description: A public repository for electron cryo-microscopy maps and tomograms\n    of macromolecular complexes and subcellular structures. id: emdb\n  name: Electron Microscopy Data Bank (EMDB) registry:\n    biotools: emdb\n    fairsharing: 651n9j\n  url: https:\/\/www.ebi.ac.uk\/emdb\/\n- description: Integrated Resource for Reproducibility in Macromolecular Crystallography.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_139",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":139,
        "total_chunks":185,
        "content":"c.uk\/emdb\/\n- description: Integrated Resource for Reproducibility in Macromolecular Crystallography. Repository of diffraction experiments used to determine protein structures in\n    the PDB, contributed by the CSGID, SSGCID, JCSG, MCSG, SGC, and other large-scale\n    projects, as well as individual research laboratories. id: irrmc\n  name: IRRMC\n  url: https:\/\/www.proteindiffraction.org\/\n- description: Repository of X-ray diffraction, MicroED, LLSM datasets, as well as\n    structural models. id: sbgrid-data-bank\n  name: SBGrid Data Bank\n  url: https:\/\/data.sbgrid.org\/\n- description: Cryo em image processing framework. Integration, traceability and analysis. id: scipion\n  name: Scipion\n  registry:\n    biotools: scipion\n    fairsharing: EsY1WF\n  url: https:\/\/scipion.i2pc.es\/\n- description: The RRI Toolkit helps stakeholders across Europe put Responsible Research\n    and Innovation into practice.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_140",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":140,
        "total_chunks":185,
        "content":" Toolkit helps stakeholders across Europe put Responsible Research\n    and Innovation into practice. id: rri-toolkit\n  name: RRI Toolkit\n  url: https:\/\/rri-tools.eu\/\n- description: The Self-Reflection Tool provides questions and statements addressing\n    all stakeholder groups (policy makers, education representatives, civil society\n    organisations, industry and business, and the research community). id: rri-self-reflection-tool\n  name: RRI self reflection tool\n  url: https:\/\/rri-tools.eu\/self-reflection-tool\n- description: Information about a proposed standard for sample metadata annotations\n    in public repositories called Sample and Data Relationship File (SDRF)-Proteomics\n    format. id: sdrf\n  name: SDRF\n  url: https:\/\/github.com\/bigbio\/proteomics-sample-metadata\/tree\/master\/sdrf-proteomics\n- description: Structural information organiser, collecting structures deposited in\n    public repositories together with computationally predicted models from SARS-CoV-2,\n    as well as their interactions with host proteins.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_141",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":141,
        "total_chunks":185,
        "content":"putationally predicted models from SARS-CoV-2,\n    as well as their interactions with host proteins. id: covid-19-structural-hub\n  name: COVID-19 Structural Hub\n  registry:\n    tess: COVID-19 Structural Hub\n  url: https:\/\/3dbionotes.cnb.csic.es\/ws\/covid19\n- description: Cloud virtual machine with the Scipion software to process EM imaging\n    data either in a single server or in a cluster. id: scipioncloud\n  name: ScipionCloud\n  url: https:\/\/scipion-em.github.io\/docs\/release-3.0.0\/docs\/developer\/scipion-on-the-cloud.html#scipion-on-the-cloud\n- description: Access and data management platform that allows facilities to manage\n    outputs and associate them with proposal information and other research outputs. id: aria\n  name: Access to Research Infrastructure Administration (ARIA) registry:\n    biotools: aria_access\n  url: https:\/\/aria.services\n- description: Data Management Plan (DMP) generator that focuses on plant science.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_142",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":142,
        "total_chunks":185,
        "content":"s:\/\/aria.services\n- description: Data Management Plan (DMP) generator that focuses on plant science. id: dataplan\n  name: DataPLAN\n  registry:\n    biotools: dataplan\n  url: https:\/\/plan.nfdi4plants.org\n- description: Omnipy is a high level Python library for type-driven data wrangling\n    and scalable workflow orchestration. id: omnipy\n  name: Omnipy\n  registry:\n    biotools: omnipy\n    tess: Omnipy\n  url: https:\/\/github.com\/fairtracks\/omnipy\n- description: TrackFind is a search and curation engine for metadata of geneomic\n    tracks. It supports crawling of the TrackHub Registry and other portals. id: trackfind\n  name: TrackFind\n  registry:\n    biotools: trackfind\n  url: https:\/\/trackfind.elixir.no\/\n- description: Pydantic is the most widely used data validation library for Python. id: pydantic\n  name: Pydantic\n  registry:\n    tess: Pydantic\n  url: https:\/\/docs.pydantic.dev\/latest\/\n- description: Prefect is a workflow orchestration tool empowering developers to build,\n    observe, and react to data pipelines.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_143",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":143,
        "total_chunks":185,
        "content":"orkflow orchestration tool empowering developers to build,\n    observe, and react to data pipelines. id: prefect\n  name: Prefect\n  url: https:\/\/www.prefect.io\/\n- description: A global centralised collection of publicly accessible track hubs\n  id: track-hub-registry\n  name: Track Hub Registry\n  registry:\n    fairsharing: a1de61\n  url: https:\/\/www.trackhubregistry.org\/\n- description: Fast, sensitive and accurate integration of single-cell data. id: harmony\n  name: Harmony\n  registry:\n    biotools: Harmony-R\n    tess: Harmony\n  url: https:\/\/github.com\/immunogenomics\/harmony\n- description: A database of manually curated cell markers in human\/mouse and web\n    tools based on scRNA-seq data. id: cellmarker\n  name: CellMarker\n  registry:\n    biotools: cellmarker_2.0\n  url: http:\/\/bio-bigdata.hrbmu.edu.cn\/CellMarker\/\n- description: Seurat is an R package designed for QC, analysis, and exploration of\n    single-cell RNA-seq data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_144",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":144,
        "total_chunks":185,
        "content":": Seurat is an R package designed for QC, analysis, and exploration of\n    single-cell RNA-seq data. id: seurat\n  name: Seurat\n  registry:\n    biotools: seurat\n    tess: Seurat\n  url: https:\/\/satijalab.org\/seurat\/\n- description: Scalable toolkit for analyzing single-cell gene expression data. It\n    includes preprocessing, visualization, clustering, pseudotime and trajectory inference\n    and differential expression testing. id: scanpy\n  name: Scanpy\n  registry:\n    biotools: scanpy\n    tess: Scanpy\n  url: https:\/\/github.com\/theislab\/Scanpy\n- description: The Gene Ontology Consortium continues to develop, maintain and use\n    a set of structured, controlled vocabularies for the annotation of genes, gene\n    products and sequences. id: gene-ontology\n  name: Gene Ontology\n  registry:\n    biotools: go\n    fairsharing: FGJ2T8\n    tess: Gene Ontology\n  url: http:\/\/www.geneontology.org\/\n- description: Python package for handling annotated data matrices in memory and on\n    disk, positioned between pandas and xarray.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_145",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":145,
        "total_chunks":185,
        "content":"or handling annotated data matrices in memory and on\n    disk, positioned between pandas and xarray. id: anndata\n  name: AnnData\n  registry:\n    biotools: anndata\n    tess: AnnData\n  url: https:\/\/anndata.readthedocs.io\/en\/latest\/\n- description: Loom is an efficient file format for large omics datasets. id: loom\n  name: Loom\n  url: https:\/\/loompy.org\/\n- description: The main class used by Monocle to hold single cell expression data. CellDataSet extends the basic Bioconductor ExpressionSet class. id: celldataset\n  name: CellDataSet\n  url: https:\/\/rdrr.io\/bioc\/monocle\/man\/CellDataSet.html\n- description: The SingleCellExperiment class is a lightweight Bioconductor container\n    for storing and manipulating single-cell genomics data. id: singlecellexperiment\n  name: SingleCellExperiment\n  registry:\n    biotools: singlecellexperiment\n  url: https:\/\/www.bioconductor.org\/packages\/release\/bioc\/vignettes\/SingleCellExperiment\/inst\/doc\/intro.html\n- description: The Monocle 3 package provides a toolkit for analyzing single-cell\n    gene expression experiments.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_146",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":146,
        "total_chunks":185,
        "content":" The Monocle 3 package provides a toolkit for analyzing single-cell\n    gene expression experiments. id: monocle\n  name: Monocle\n  registry:\n    biotools: monocle\n    tess: Monocle\n  url: https:\/\/cole-trapnell-lab.github.io\/monocle3\/\n- description: Scater offers a collection of tools for analysis (such as quality control)\n    for single-cell gene expression data. id: scater\n  name: Scater\n  registry:\n    biotools: scater\n    tess: Scater\n  url: https:\/\/bioconductor.org\/packages\/release\/bioc\/html\/scater.html\n- description: sceasy is a package that helps easy conversion of different single-cell\n    data formats to each other. id: sceasy\n  name: SCEasy\n  registry:\n    biotools: sceasy\n  url: https:\/\/github.com\/cellgeni\/sceasy\n- description: Interactive portal for single-cell genomics data. id: single-cell-portal\n  name: Single Cell Portal\n  url: https:\/\/singlecell.broadinstitute.org\/single_cell\n- description: An entry point for novices in the field of single-cell (multi-)omic\n    analysis and guides advanced users to the most recent best practices.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_147",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":147,
        "total_chunks":185,
        "content":"f single-cell (multi-)omic\n    analysis and guides advanced users to the most recent best practices. id: single-cell-best-pratices\n  name: Single-cell best pratices\n  url: https:\/\/www.sc-best-practices.org\/preamble.html\n- description: A set of analysis pipelines that perform sample demultiplexing, barcode\n    processing, single cell gene counting, V(D)J transcript sequence assembly and\n    annotation, and Feature Barcode analysis from single cell data. id: cellranger\n  name: CellRanger\n  url: https:\/\/www.10xgenomics.com\/support\/software\/cell-ranger\n- description: A comprehensive turnkey solution for quantifying gene expression in\n    single-cell\/nucleus RNA-seq data, built into RNA-seq aligner STAR. id: starsolo\n  name: STARsolo\n  registry:\n    tess: STARsolo\n  url: https:\/\/github.com\/alexdobin\/STAR\/blob\/master\/docs\/STARsolo.md\n- description: HDF5 consists of a file format for storing HDF5 data, a data model\n    for logically organizing and accessing HDF5 data from an application, and the\n    software (libraries, language interfaces, and tools) for working with this format.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_148",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":148,
        "total_chunks":185,
        "content":"tion, and the\n    software (libraries, language interfaces, and tools) for working with this format. id: hierarchical-data-format\n  name: Hierarchical Data Format\n  registry:\n    fairsharing: wvgta9\n  url: https:\/\/www.10xgenomics.com\/support\/software\/cell-ranger\/analysis\/outputs\/cr-outputs-h5-matrices\n- description: Sequence Read Archive (SRA) data, available through multiple cloud\n    providers and NCBI servers, is the largest publicly available repository of high\n    throughput sequencing data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_149",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":149,
        "total_chunks":185,
        "content":"d NCBI servers, is the largest publicly available repository of high\n    throughput sequencing data. id: sequence-read-archive\n  name: Sequence Read Archive\n  registry:\n    fairsharing: g7t2hv\n    tess: Sequence Read Archive\n  url: https:\/\/www.ncbi.nlm.nih.gov\/sra\n- description: Minimum Information about a high-throughput SEQuencing Experiment\n  id: minseqe\n  name: MINSEQE\n  registry:\n    fairsharing: a55z32\n    tess: MINSEQE\n  url: https:\/\/doi.org\/10.5281\/zenodo.5706412\n- description: Minimum Information About a Microarray Experiment\n  id: miame\n  name: MIAME\n  registry:\n    fairsharing: 32b10v\n    tess: MIAME\n  url: https:\/\/www.fged.org\/projects\/miame\/\n- description: A fully managed REDCap system based in the cloud, provided by nPhase. id: redcap-cloud\n  name: REDCap Cloud\n  url: https:\/\/www.redcapcloud.com\n- description: European Commission's official multilingual online survey-management\n    system built for the creation and publishing of globally accessible forms.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_150",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":150,
        "total_chunks":185,
        "content":"ine survey-management\n    system built for the creation and publishing of globally accessible forms. id: eu-survey\n  name: EU Survey\n  url: https:\/\/ec.europa.eu\/eusurvey\n- description: A free and open source platform to develop and publish online surveys. id: limesurvey\n  name: LimeSurvey\n  url: https:\/\/github.com\/LimeSurvey\/LimeSurvey\n- description: Commercial online survey tool. id: alchemer\n  name: Alchemer\n  url: https:\/\/www.alchemer.com\n- description: Commercial online survey tool. id: jotform\n  name: Jotform\n  url: https:\/\/www.jotform.com\n- description: A standard used for health care data exchange. id: hl7-fhir\n  name: HL7 FHIR\n  url: https:\/\/www.hl7.org\/fhir\/\n- description: A minimal set of clinical research FHIR resources and elements in an\n    EHR that can be utilised in an interoperable and consistent manner for clinical\n    research. id: vulcan\n  name: Real World Data for Clinical Research (Vulcan)\n  registry:\n    biotools: vulcan\n  url: https:\/\/build.fhir.org\/ig\/HL7\/vulcan-rwd\/\n- description: Guidance on how FHIR can be used for supporting FAIR health data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_151",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":151,
        "total_chunks":185,
        "content":"\/ig\/HL7\/vulcan-rwd\/\n- description: Guidance on how FHIR can be used for supporting FAIR health data. id: fhir4fair\n  name: FHIR4FAIR\n  url: https:\/\/build.fhir.org\/ig\/HL7\/fhir-for-fair\/\n- description: A standard designed by the European Committee for Standardization to\n    define a information architecture for communicating part or all of the EHR of\n    a single patient between EHR systems or between EHR systems and a centralised\n    EHR data repository. id: iso13606\n  name: ISO 13606\n  url: https:\/\/www.iso.org\/standard\/67868.html\n- description: Recommended by the European Commission as the format to be used for\n    the exchange of EHR data for cross-border healthcare. id: eehrxf\n  name: European Electronic Health Record Exchange Format (EEHRxF)\n  url: https:\/\/www.x-ehealth.eu\/eehrxf\/\n- description: Domain model for data interchange that enables semantic interoperability\n    and intends to integrate biomedical, clinical research and routine healthcare\n    data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_152",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":152,
        "total_chunks":185,
        "content":"rability\n    and intends to integrate biomedical, clinical research and routine healthcare\n    data. id: isodis-14199\n  name: ISO\/DIS 14199\n  url: https:\/\/www.iso.org\/standard\/83433.html\n- description: Non-profit organisation that publishes technical standards for an EHR\n    platform along with domaindeveloped clinical models to define content. id: openehr\n  name: OpenEHR\n  registry:\n    fairsharing: 3fc9zf\n  url: https:\/\/openehr.org\n- description: Consortium which defines several open standards for regulatory approval\n    and case report forms in particular in the context of clinical trials meant for\n    submission to FDA and EMA. id: cdisc\n  name: Clinical Data Interchange Standards Consortium (CDISC)\n  url: https:\/\/www.cdisc.org\n- description: A CDISC Foundational Standard that defines dataset and metadata standards. id: adam\n  name: Analysis Data Model for data and metadata of clinical trial statistical analysis\n    (ADaM)",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_153",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":153,
        "total_chunks":185,
        "content":"\n  name: Analysis Data Model for data and metadata of clinical trial statistical analysis\n    (ADaM) registry:\n    biotools: adam\n  url: https:\/\/www.cdisc.org\/standards\/foundational\/adam\n- description: A CDISC Data Exchange Standard that lets technology vendors implement\n    tools that support a write once, use many times solution based on XML. id: ctr-xml\n  name: Clinical Trial Registry-XML (CTR-XML)\n  url: https:\/\/www.cdisc.org\/standards\/data-exchange\/ctr-xml\n- description: A CDISC Data Exchange Standard that  is a vendor-neutral, platform-independent\n    format for exchanging and archiving clinical and translational research data,\n    along with their associated metadata, administrative data, reference data, and\n    audit information. id: odm-xml\n  name: Operational Data Model-XML (ODM-XML)\n  url: https:\/\/www.cdisc.org\/standards\/data-exchange\/odm\n- description: A CDISC Foundational Standard that provides a standard for organizing\n    and formatting data to streamline processes in collection, management, analysis\n    and reporting.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_154",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":154,
        "total_chunks":185,
        "content":"  and formatting data to streamline processes in collection, management, analysis\n    and reporting. id: sdtm\n  name: Study Data Tabulation Model (SDTM)\n  url: https:\/\/www.cdisc.org\/standards\/foundational\/sdtm\n- description: Open community standard for observational health care data obtained\n    from health records. id: cdm\n  name: OMOP Common Data Model\n  registry:\n    tess: OMOP Common Data Model\n  url: https:\/\/ohdsi.github.io\/CommonDataModel\/\n- description: A UML-based logical health information model defined by the Open Group,\n    intended to achieve interoperability between multiple healthcare standards and\n    protocols. id: fhim\n  name: Federated Health Information Model (FHIM)\n  url: https:\/\/fhim.org\/fhim-model\n- description: Defines data elements, the relationships between such data elements\n    and terminologies for detailed small, reusable clinical models. id: iso139722022\n  name: ISO 13972:2022\n  url: https:\/\/www.iso.org\/standard\/79498.html\n- description: REDCap feature which allows a REDCap project to interact with an EHR\n    system and pull EHR data into REDCap.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_155",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":155,
        "total_chunks":185,
        "content":"ture which allows a REDCap project to interact with an EHR\n    system and pull EHR data into REDCap. id: cdis\n  name: Clinical Data Interoperability Services (CDIS)\n  url: https:\/\/projectredcap.org\/software\/cdis\/\n- description: Open-source tool to map datasets to the OMOP CDM. id: carrot-mapper\n  name: Convenient And Reusable Rapid OMOP Transformer (CaRROT-Mapper)\n  url: https:\/\/github.com\/Health-Informatics-UoN\/CaRROT-Mapper\n- description: Repository of ontologies for use with the OMOP CDM. id: ohdsi-athena\n  name: OHDSI Athena\n  url: https:\/\/athena.ohdsi.org\/search-terms\/start\n- description: Codes for diseases, signs and symptoms, abnormal findings, complaints,\n    social circumstances, and external causes of injury or diseases. Replaced by ICD-11\n    on 1\/1\/2022. id: icd10\n  name: International Classification of Diseases 10th Revision (ICD-10)\n  registry:\n    biotools: icd-10\n  url: https:\/\/icd.who.int\/browse10\/2019\/en\n- description: Replaces the ICD-10 as the global standard for recording health information\n    and causes of death.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_156",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":156,
        "total_chunks":185,
        "content":"Replaces the ICD-10 as the global standard for recording health information\n    and causes of death. It is developed by the World Health Organization and is annually\n    updated. id: icd11\n  name: International Classification of Diseases 11th Revision (ICD-11) registry:\n    biotools: icd-11\n  url: https:\/\/icd.who.int\/en\n- description: Terminology standard for health measurements, observations, and documents. id: loinc\n  name: Logical Observation Identifiers Names and Codes (LOINC)\n  url: https:\/\/loinc.org\n- description: Terminology standard consisting of codes, terms, synonyms and definitions\n    used in clinical documentation and reporting. id: snomed-ct\n  name: Systematized Nomenclature of Medicine - Clinical Terms (SNOMED-CT)\n  url: https:\/\/www.snomed.org\n- description: Standardised vocabulary of phenotypic abnormalities encountered in\n    human disease.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_157",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":157,
        "total_chunks":185,
        "content":"- description: Standardised vocabulary of phenotypic abnormalities encountered in\n    human disease. id: hpo\n  name: Human Phenotype Ontology (HPO)\n  registry:\n    biotools: hpo\n    fairsharing: kbtt7f\n  url: https:\/\/hpo.jax.org\/app\/\n- description: MinSCe is a minimum set of metadata categories used to describe a single-cell\n    assay in sufficient detail to enable the analysis of transcriptomic data. id: minsce\n  name: Minimum Information about a Single-Cell Experiment (minSCe)\n  registry:\n    fairsharing: 77c3d3\n  url: https:\/\/github.com\/ebi-gene-expression-group\/sc-metadata-fields\n- description: Annotare is a tool for submitting functional genomics data to the ArrayExpress\n    collection in BioStudies. id: annotare\n  name: Annotare\n  registry:\n    tess: Annotare\n  url: https:\/\/www.ebi.ac.uk\/fg\/annotare\/\n- description: Free and open-source reference management software to manage bibliographic\n    data and related research materials.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_158",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":158,
        "total_chunks":185,
        "content":"ource reference management software to manage bibliographic\n    data and related research materials. id: zotero\n  name: Zotero\n  url: https:\/\/www.zotero.org\/\n- description: A plugin for Zotero and Juris-M that makes it easier to manage bibliographic\n    data. id: better-bibtex\n  name: Better BibTeX (BBT)\n  url: https:\/\/retorque.re\/zotero-better-bibtex\/\n- description: Beacon for OMOP (B4OMOP) software allows for the integration of a Beacon\n    onto any OMOP Common Data Model (CDM) database. id: b4omop\n  name: Beacon for OMOP (B4OMOP)\n  url: https:\/\/gitlab.bsc.es\/impact-data\/impd-beacon_omopcdm\n- description: Developed through the Global Alliance for Genomics and Health (GA4GH) Discovery workstream with support from ELIXIR, Beacon is a data discovery protocol\n    defining an open standard for discovering genomic and phenoclinic data in research\n    and clinical applications. id: beacon-v2\n  name: Beacon v2\n  registry:\n    tess: Beacon v2\n  url: https:\/\/docs.genomebeacons.org\/implementations-options\/\n- description: An open-source out-of-the-box toolkit to initiate a Beacon v2.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_159",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":159,
        "total_chunks":185,
        "content":"plementations-options\/\n- description: An open-source out-of-the-box toolkit to initiate a Beacon v2. B2RI\n    includes tools for loading metadata, such as phenotypic data and genomic variants\n    into a MongoDB database, and features a Beacon query engine (REST API). id: beacon-ri\n  name: Beacon v2 Reference Implementation (B2RI)\n  url: https:\/\/github.com\/EGA-archive\/beacon2-ri-tools-v2\n- description: Discover tools and best practices for working with infectious disease\n    data. IDTk provides general guidance as well as specific information for pathogen\n    characterisation, socioeconomic data, human biomolecular data, and human clinical\n    and health data. id: idtk\n  name: Infectious Diseases Toolkit (IDTk)\n  url: https:\/\/www.infectious-diseases-toolkit.org\/\n- description: The Federated EGA is an infrastructure built upon the European Genome-phenome\n    Archive (EGA), an EMBL-EBI and CRG data resource for secure archiving and sharing\n    of human sensitive biomolecular and phenotypic data resulting from biomedical\n    research projects.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_160",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":160,
        "total_chunks":185,
        "content":"of human sensitive biomolecular and phenotypic data resulting from biomedical\n    research projects. id: fega\n  name: Federated EGA\n  registry:\n    tess: Federated EGA\n  url: https:\/\/ega-archive.org\/about\/projects-and-funders\/federated-ega\/\n- description: The Pathogens Portal aims to provide access to data and tools relating\n    to pathogens, their human and animal hosts and their vectors. Current content\n    spans bacterial, viral and eukaryotic parasite lineages alongside human host data. id: pathogens-portal\n  name: Pathogens Portal\n  registry:\n    fairsharing: a085b2\n    tess: Pathogens Portal\n  url: https:\/\/www.pathogensportal.org\/\n- description: NCBI Pathogen Detection integrates bacterial and fungal pathogen genomic\n    sequences from numerous ongoing surveillance and research efforts whose sources\n    include food, environmental sources such as water or production facilities, and\n    patient samples. Foodborne, hospital-acquired, and other clinically infectious\n    pathogens are included.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_161",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":161,
        "total_chunks":185,
        "content":"t samples. Foodborne, hospital-acquired, and other clinically infectious\n    pathogens are included. id: pathogen-detection\n  name: Pathogen Detection\n  registry:\n    tess: Pathogen Detection\n  url: https:\/\/www.ncbi.nlm.nih.gov\/pathogens\/\n- description: The COVID-19 Data Portal enables researchers to upload, access and\n    analyse COVID-19 related reference data and specialist datasets. The aim of the\n    COVID-19 Data Portal is to facilitate data sharing and analysis, and to accelerate\n    coronavirus research. The portal includes relevant datasets submitted to EMBL-EBI\n    as well as other major centres for biomedical data. The COVID-19 Data Portal is\n    the primary entry point into the functions of a wider project, the European COVID-19\n    Data Platform.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_162",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":162,
        "total_chunks":185,
        "content":" primary entry point into the functions of a wider project, the European COVID-19\n    Data Platform. id: covid-19-data-portal\n  name: COVID-19 Data Portal\n  registry:\n    biotools: covid-19-data-portal\n    fairsharing: f3b7a9\n    tess: COVID-19 Data Portal\n  url: https:\/\/www.covid19dataportal.org\/\n- description: The Disease Ontology has been developed as a standardised ontology\n    for human disease to provide the biomedical community with consistent, reusable\n    and sustainable descriptions of human disease terms, phenotype characteristics,\n    underlying mechanisms and related medical vocabulary disease concepts. id: doid\n  name: Disease Ontology (DOID)\n  registry:\n    fairsharing: 8b6wfq\n  url: http:\/\/www.disease-ontology.org\n- description: The Genomic Epidemiology Ontology (GenEpiO) covers vocabulary necessary\n    to identify, document and research food-borne pathogens, infectious disease surveillance\n    and outbreak investigations.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_163",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":163,
        "total_chunks":185,
        "content":" and research food-borne pathogens, infectious disease surveillance\n    and outbreak investigations. id: genepio\n  name: Genomic Epidemiology Ontology (GenEpiO)\n  registry:\n    fairsharing: y1mmbv\n  url: https:\/\/genepio.org\/\n- description: PATO is an ontology of phenotypic qualities, intended for use primarily\n    in phenotype annotation. id: pato\n  name: Phenotypic QualiTy Ontology (PATO)\n  registry:\n    biotools: pato\n    fairsharing: ezwdhz\n  url: https:\/\/github.com\/pato-ontology\/pato\/\n- description: ChEBI) is a dictionary describing small chemical compounds including\n    distinct synthetic or natural atoms, molecules, ions, ion pairs, radicals, radical\n    ions, complexes, and conformers. id: chebi\n  name: Chemical Entities of Biological Interest (ChEBI) registry:\n    biotools: chebi\n    fairsharing: 62qk8w\n    tess: Chemical Entities of Biological Interest (ChEBI)\n  url: https:\/\/www.ebi.ac.uk\/chebi\/\n- description: Uberon is an integrated cross-species anatomy ontology covering animals\n    and bridging multiple species-specific ontologies.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_164",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":164,
        "total_chunks":185,
        "content":"oss-species anatomy ontology covering animals\n    and bridging multiple species-specific ontologies. id: uberon\n  name: UBER anatomy ONtology (UBERON)\n  registry: fairsharing: 4c0b6b\n  url: http:\/\/uberon.org\/\n- description: A free and open source electronic lab notebook. id: elabftw\n  name: eLabFTW\n  registry:\n    tess: eLabFTW\n  url: https:\/\/www.elabftw.net\/\n- description: A tool to aid in choosing the most suitable Electronic Lab Notebook\n    (ELN) for a specific purpose. id: eln-finder\n  name: ELN Finder\n  url: https:\/\/eln-finder.ulb.tu-darmstadt.de\/home\n- description: List of minimum information standards on Wikipedia\n  id: min-info-standards\n  name: Minimum information standards in life sciences\n  url: https:\/\/en.wikipedia.org\/wiki\/Minimum_information_standard\n- description: draw.io is a free online diagram software for making flowcharts, process\n    diagrams, org charts, UML, ER and network diagrams. id: draw-io\n  name: draw.io\n  url: https:\/\/www.drawio.com\/\n- description: Inkscape is a versatile and free graphic design editor suitable for\n    both personal and professional use.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_165",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":165,
        "total_chunks":185,
        "content":"e is a versatile and free graphic design editor suitable for\n    both personal and professional use. It offers a comprehensive suite of design\n    tools, enabling users to create and edit vector graphics, primarily in the SVG\n    format. Additionally, Inkscape supports working with rasterized images (bitmaps),\n    making it a powerful tool for diverse design projects. id: inkscape\n  name: Inkscape\n  registry:\n    tess: Inkscape\n  url: https:\/\/inkscape.org\/\n- description: LibreOffice Draw is a free, open-source vector graphics editor that\n    is part of the LibreOffice suite, developed by The Document Foundation. This tool\n    allows users to create designs with ease, offering a variety of features such\n    as shape tools, straight and curved line tools, polygon tools, and more. It provides\n    a robust platform for crafting illustrations and diagrams. id: libre-office-draw\n  name: Libre Office Draw\n  url: https:\/\/www.libreoffice.org\/discover\/draw\/\n- description: The Research Organization Registry (ROR) is a project developing open\n    unique identifiers for research organisations.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_166",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":166,
        "total_chunks":185,
        "content":"ation Registry (ROR) is a project developing open\n    unique identifiers for research organisations. id: ror\n  name: Research Organization Registry (ROR)\n  registry:\n    fairsharing: 1jKfji\n  url: https:\/\/ror.org\/\n- description: The Open Funder Registry (OFR) is a registry of persistent identifiers\n    for grant-giving organisations. id: ofr\n  name: Open Funder Registry (OFR)\n  registry:\n    fairsharing: odf1nG\n  url: https:\/\/www.crossref.org\/services\/funder-registry\/\n- description: Pathoplexus is an open-source database designed to enhance the sharing\n    and analysis of human viral pathogen genomic data. id: pathoplexus\n  name: Pathoplexus\n  registry:\n    fairsharing: f7ec51\n  url: https:\/\/pathoplexus.org\/\n- description: The International Committee on Taxonomy of Viruses (ICTV) taxonomic\n    database is a maintained resource comprised of a universal taxonomic scheme for\n    all the viruses infecting animals (vertebrates, invertebrates and protozoa), plants\n    (higher plants and algae), fungi, bacteria and archaea.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_167",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":167,
        "total_chunks":185,
        "content":"tes, invertebrates and protozoa), plants\n    (higher plants and algae), fungi, bacteria and archaea. id: ictv\n  name: ICTV\n  registry:\n    biotools: ictv\n    fairsharing: c92ffe\n  url: https:\/\/ictv.global\/taxonomy\n- description: Nextstrain is an open-source project to harness the scientific and\n    public health potential of pathogen genome data. id: nextstrain\n  name: Nextstrain\n  registry:\n    biotools: nextstrain.org\n    fairsharing: dba7ba\n    tess: Nextstrain\n  url: http:\/\/nextstrain.org\n- description: ORCID is an open, non-profit, community-driven registry of unique researcher\n    identifiers and offers a transparent method of attributing outputs. id: orcid\n  name: Open Researcher and Contributor ID Registry (ORCID) registry:\n    biotools: orcid\n    fairsharing: nx58jg\n  url: https:\/\/orcid.org\/\n- description: A standard for medical imaging data storage and transmission. id: dicom\n  name: Digital Imaging and Communications in Medicine (DICOM)",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_168",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":168,
        "total_chunks":185,
        "content":"a storage and transmission. id: dicom\n  name: Digital Imaging and Communications in Medicine (DICOM) registry:\n    fairsharing: b7z8by\n  url: https:\/\/www.dicomstandard.org\n- description: A classification system for oncology, used in cancer registries and\n    pathology reporting. id: icd-o-3\n  name: ICD-O-3 Coding Materials\n  url: https:\/\/www.who.int\/standards\/classifications\n- description: An open-source data warehouse for clinical and translational research. id: i2b2\n  name: Informatics for Integrating Biology & the Bedside (i2b2)\n  registry:\n    tess: Informatics for Integrating Biology & the Bedside (i2b2)\n  url: https:\/\/www.i2b2.org\n- description: A platform for exploring, analysing, and visualising cancer genomics\n    data. id: cbioportal\n  name: cBioPortal\n  registry:\n    biotools: cbioportal\n    fairsharing: 6L6MjA\n    tess: cBioPortal\n  url: https:\/\/www.cbioportal.org\n- description: A common file format that contains information about variants found\n    at specific positions in a reference genome.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_169",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":169,
        "total_chunks":185,
        "content":"rmat that contains information about variants found\n    at specific positions in a reference genome. id: vcf\n  name: Variant Call Format (VCF)\n  registry:\n    fairsharing: cfzz0h\n  url: https:\/\/gatk.broadinstitute.org\/hc\/en-us\/articles\/360035531692-VCF-Variant-Call-Format\n- description: The standard for diagnostic oncology, defining tumor types and classifications. id: who-tc\n  name: WHO Classification of Tumours\n  url: https:\/\/tumourclassification.iarc.who.int\n- description: A repository of medical images related to cancer. id: tcia\n  name: The Cancer Imaging Archive (TCIA)\n  registry:\n    fairsharing: jrfd8y\n  url: https:\/\/www.cancerimagingarchive.net\n- description: AI-powered pathology tools for cancer diagnosis and research. id: path-ai\n  name: PathAI\n  url: https:\/\/www.pathai.com\n- description: AI-based medical imaging analysis for radiology and oncology. id: qure-ai\n  name: Qure.ai\n  registry:\n    biotools: qure.ai\n  url: https:\/\/www.qure.ai\n- description: AI solutions for digital pathology in cancer detection.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_170",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":170,
        "total_chunks":185,
        "content":"ai\n  url: https:\/\/www.qure.ai\n- description: AI solutions for digital pathology in cancer detection. id: paige-ai\n  name: Paige AI\n  url: https:\/\/www.paige.ai\n- description: Guidelines for reporting predictive model studies in medicine. id: tripod\n  name: Transparent Reporting of a Multivariable Prediction Model\n  registry:\n    fairsharing: a6ad4e\n  url: https:\/\/www.tripod-statement.org\n- description: Integrated clinical and genomic data for over 100,000 cancer patients\n    from the International Cancer Genome Consortium. id: icgc-argo\n  name: ICGC-ARGO\n  url: https:\/\/www.icgc-argo.org\n- description: Real-world cancer genomic dataset aggregated from multiple institutions. id: aacr-genie\n  name: AACR-GENIE\n  url: https:\/\/www.aacr.org\/professionals\/research\/aacr-project-genie\/\n- description: Platform from Memorial Sloan Kettering providing molecular and clinical\n    data to support precision oncology.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_171",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":171,
        "total_chunks":185,
        "content":"om Memorial Sloan Kettering providing molecular and clinical\n    data to support precision oncology. id: msk-chord\n  name: MSK-CHORD\n  url: https:\/\/datacatalog.mskcc.org\/dataset\/11458\n- description: Multi-omic cancer dataset of >7000 patients, including whole genome\n    sequencing and clinical outcomes. id: hmf\n  name: Hartwig Medical Foundation (HMF)\n  url: https:\/\/www.hartwigmedicalfoundation.nl\/en\/\n- description: A federated real-world evidence platform containing clinical and genomic\n    data from patients with solid tumours. id: wayfind-r\n  name: WAYFIND-R\n  url: https:\/\/wayfindr.eu\/\n- description: A federated platform for cancer imaging data. id: eucaim\n  name: European Cancer Imaging Initiative (EUCAIM)\n  url: https:\/\/cancerimage.eu\/\n- description: NIH research program with diverse patient health, genetic, and lifestyle\n    data. id: all-of-us\n  name: All of Us\n  registry:\n    tess: All of Us\n  url: https:\/\/www.researchallofus.org\/\n- description: Large-scale biomedical database with genetic, clinical, and lifestyle\n    data from UK participants.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_172",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":172,
        "total_chunks":185,
        "content":"Large-scale biomedical database with genetic, clinical, and lifestyle\n    data from UK participants. id: uk-biobank\n  name: UK Biobank\n  registry:\n    biotools: uk-biobank\n    tess: UK Biobank\n  url: https:\/\/www.ukbiobank.ac.uk\/\n- description: Database of drug sensitivity and genomic data from cancer cell lines. id: gdsc\n  name: Genomics of Drug Sensitivity in Cancer (GDSC)\n  url: https:\/\/www.cancerrxgene.org\/\n- description: Resource to explore relationships between cancer cell line genotypes\n    and drug response. id: ctrp\n  name: Cancer Therapeutics Response Portal (CTRP)\n  url: https:\/\/portals.broadinstitute.org\/ctrp\n- description: A database of cancer-related drugs, including descriptions, uses, and\n    approvals. id: nci-drug-database\n  name: National Cancer Institute (NCI) treatment drugs\n  registry:\n    tess: National Cancer Institute\n  url: https:\/\/www.cancer.gov\/about-cancer\/treatment\/drugs\/\n- description: European Medicines Agency's (EMA) portal for authorised medicines in\n    the EU.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_173",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":173,
        "total_chunks":185,
        "content":"ugs\/\n- description: European Medicines Agency's (EMA) portal for authorised medicines in\n    the EU. id: ema-medicine-finder\n  name: European Medicines Agency's (EMA) medicine finder\n  url: https:\/\/www.ema.europa.eu\/en\/medicines\n- description: Comprehensive database containing information on drugs and drug targets. id: drugbank\n  name: DrugBank\n  registry:\n    biotools: drugbank\n    fairsharing: 353yat\n    tess: DrugBank\n  url: https:\/\/go.drugbank.com\/\n- description: Drug-Gene Interaction Database linking drugs to their target genes. id: dgidb\n  name: Drug-Gene Interaction Database (DGIdb)\n  registry:\n    biotools: dgidb\n  url: https:\/\/dgidb.org\/\n- description: Database for drug mechanisms, targets, pathways, and indications. id: drugmap\n  name: DrugMap\n  registry:\n    biotools: drugmap\n  url: https:\/\/drugmap.idrblab.net\/\n- description: Database of known and explored therapeutic targets and their related\n    drugs.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_174",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":174,
        "total_chunks":185,
        "content":".net\/\n- description: Database of known and explored therapeutic targets and their related\n    drugs. id: ttd\n  name: Therapeutic Target Database (TTD)\n  registry:\n    biotools: ttd\n    fairsharing: fwzf0w\n  url: https:\/\/idrblab.net\/ttd\/\n- description: Pharmacogenomics knowledge base including cancer pharmacogenomic information. id: pharmgkb-cancer-pgx\n  name: Cancer Pharmacogenomics\n  url: https:\/\/www.pharmgkb.org\/page\/cancerPgx\n- description: Precision oncology knowledge base that annotates the effects and treatment\n    implications of somatic mutations in cancer. id: oncokb\n  name: OncoKB\n  url: https:\/\/www.oncokb.org\/\n- description: Side Effect Resource containing information on marketed medicines and\n    their recorded adverse drug reactions. id: sider\n  name: SIDER\n  registry:\n    biotools: sider\n  url: http:\/\/sideeffects.embl.de\/\n- description: Provides a general framework to interpret the functional and predictive\n    relevance of a list of gene variants through interactive reports.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_175",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":175,
        "total_chunks":185,
        "content":" the functional and predictive\n    relevance of a list of gene variants through interactive reports. id: mtb-portal\n  name: MTB Portal\n  url: https:\/\/www.mtbp.org\n- description: Platform to prioritise cancer drug treatments based on individual multi-omics\n    data including SNVs, CNVs, and gene expression. id: pandrugs\n  name: PanDrugs\n  registry:\n    biotools: pandrugs\n    fairsharing: dfdc11\n    tess: PanDrugs\n  url: https:\/\/www.pandrugs.org\/\n- description: A community knowledgebase for expert crowdsourcing the clinical interpretation\n    of variants in cancer\n  id: civic\n  name: Clinical Interpretations of Variants in Cancer (CIViC)\n  registry:\n    biotools: civic\n  url: https:\/\/civicdb.org\/\n- description: A cancer staging system that describes the size of the tumor (T), lymph\n    node involvement (N), and metastasis (M). id: uicc-tnm\n  name: Tumour, Nodes, Metastases (TNM) cancer staging system\n  registry:\n    biotools: NA\n  url: https:\/\/www.uicc.org\/who-we-are\/about-uicc\/uicc-and-tnm\n- description: A single standardised international medical terminology.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_176",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":176,
        "total_chunks":185,
        "content":"-are\/about-uicc\/uicc-and-tnm\n- description: A single standardised international medical terminology. id: meddra\n  name: Medical Dictionary for Regulatory Activities (MedDRA)\n  registry:\n    fairsharing: ad3137\n  url: https:\/\/www.meddra.org\/\n- description: A scale for assessing patient functional status. id: ecog\n  name: Eastern Cooperative Oncology Group (ECOG)\n  url: https:\/\/pubmed.ncbi.nlm.nih.gov\/7165009\/\n- description: A standardised method for assessing tumor response via PET imaging. id: percist\n  name: PET Response Criteria in Solid Tumors (PERCIST)\n  url: https:\/\/pmc.ncbi.nlm.nih.gov\/articles\/PMC2755245\/\n- description: A set of questionnaires developed to assess the quality of life of\n    cancer patients. id: eortc-qlq\n  name: European Organisation for Research and Treatment of Cancer (EORTC) Quality\n    of Life Questionnaires (QLQ)\n  url: https:\/\/qol.eortc.org\/questionnaires\/\n- description: A set of person-centred measures that evaluates and monitors physical,\n    mental, and social health in adults and children.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_177",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":177,
        "total_chunks":185,
        "content":"measures that evaluates and monitors physical,\n    mental, and social health in adults and children. id: promis\n  name: Patient-Reported Outcomes Measurement Information System (PROMIS)\n  url: https:\/\/www.promishealth.org\/57461-2\/\n- description: Various digital health tools approved by the FDA for medical use (e.g.,\n    wearables, software, diagnostics). id: fda-approved-tools\n  name: FDA-approved tools\n  url: https:\/\/www.fda.gov\/medical-devices\/digital-health-center-excellence\n- description: A framework for health and fitness data integration on Apple devices. id: apple-health-kit\n  name: Apple HealthKit\n  url: https:\/\/developer.apple.com\/health-fitness\/\n- description: An open-source Clinical Interpretations platform for integrating mobile\n    health data to improve healthcare insights. id: open-mhealth\n  name: Open mHealth\n  registry:\n    fairsharing: mrpMBj\n  url: https:\/\/www.openmhealth.org\/\n- description: A health-tracking platform by Google for collecting and accessing fitness\n    data.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_178",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":178,
        "total_chunks":185,
        "content":"\/\n- description: A health-tracking platform by Google for collecting and accessing fitness\n    data. id: google-fit\n  name: Google Fit\n  url: https:\/\/www.google.com\/fit\/\n- description: EnzymeML is a standardised data format for catalytic reaction data,\n    designed to ensure consistency and interoperability. It enables researchers to\n    store, share, and enrich reaction data with detailed metadata in JSON or XML formats. id: enzymeml\n  name: EnzymeML\n  registry:\n    biotools: enzymeml\n  url: https:\/\/enzymeml.org\/\n- description: The BioAssay Ontology (BAO) describes chemical biology screening assays\n    and their results, including high-throughput screening (HTS) data, to categorise\n    assays and data analysis. id: bioassay-ontology\n  name: Bioassay Ontology\n  registry:\n    fairsharing: mye76w\n  url: http:\/\/bioassayontology.org\/\n- description: The Cell Ontology (CL) is a candidate OBO Foundry ontology for the\n    representation of cell types.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_179",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":179,
        "total_chunks":185,
        "content":"The Cell Ontology (CL) is a candidate OBO Foundry ontology for the\n    representation of cell types. id: cell-ontology\n  name: Cell Ontology\n  registry:\n    fairsharing: j9y503\n  url: https:\/\/www.ebi.ac.uk\/ols4\/ontologies\/cl\n- description: A structured controlled vocabulary for the source of an enzyme. It\n    comprises terms for tissues, cell lines, cell types and cell cultures from uni-\n    and multicellular organisms. id: brenda-tissue-ontology\n  name: BRENDA Tissue Ontology\n  registry:\n    fairsharing: 1414v8\n    tess: BRENDA Tissue Ontology\n  url: https:\/\/www.ebi.ac.uk\/ols4\/ontologies\/bto\n- description: PSI-MOD is an ontology consisting of terms that describe protein chemical\n    modifications. id: protein-modification-ontology\n  name: Protein MODification (PSI-MOD)\n  registry:\n    fairsharing: 2m4ms9\n    tess: Protein MODification\n  url: https:\/\/github.com\/hupo-psi\/psi-mod-cv\n- description: Protein Ontology (PRO) provides an ontological representation of protein-related\n    entities by explicitly defining them and showing the relationships between them.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_180",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":180,
        "total_chunks":185,
        "content":"protein-related\n    entities by explicitly defining them and showing the relationships between them. id: protein-ontology\n  name: PRotein Ontology (PRO)\n  registry:\n    biotools: pro\n    fairsharing: 4ndncv\n  url: https:\/\/proconsortium.org\/\n- description: Chemotion is a repository for chemistry research data that provides\n    solutions for current challenges to store research data in a feasible manner,\n    allowing the conservation of domain specific information in a machine readable\n    format. id: chemotion\n  name: Chemotion\n  registry:\n    biotools: chemotion\n    fairsharing: iagXcR\n  url: https:\/\/www.chemotion-repository.net\/welcome\n- description: openBIS (open Biology Information System) is an Electronic Laboratory\n    Notebook and a Laboratory Information Management System (ELN-LIMS) solution suitable\n    for life science laboratories. id: openbis\n  name: openBIS\n  registry:\n    tess: openBIS\n  url: https:\/\/openbis.ch\/\n- description: STRENDA DB is a storage and search platform that incorporates the STRENDA\n    Guidelines in a user-friendly, web-based system.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_181",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":181,
        "total_chunks":185,
        "content":"d search platform that incorporates the STRENDA\n    Guidelines in a user-friendly, web-based system. id: strenda-db\n  name: STRENDA DB\n  registry:\n    fairsharing: ekj9zx\n  url: https:\/\/www.beilstein-strenda-db.org\/strenda\/\n- description: SABIO-RK is a curated database that contains information about biochemical\n    reactions, their kinetic rate equations with parameters and experimental conditions. id: sabiork\n  name: SABIO-RK\n  registry:\n    biotools: sabio-rk\n    fairsharing: cwx04e\n    tess: SABIO-RK\n  url: https:\/\/sabiork.h-its.org\/\n- description: M-CSA is a database of enzyme reaction mechanisms. id: m-csa\n  name: M-CSA (Mechanism and Catalytic Site Atlas)\n  registry: fairsharing: BrubDI\n  url: https:\/\/www.ebi.ac.uk\/thornton-srv\/m-csa\/\n- description: EzCatDB is a database of enzyme catalytic mechanisms. id: ezcatdb\n  name: EzCatDB\n  url: https:\/\/ezcatdb.cbrc.pj.aist.go.jp\/EzCatDB\/\n- description: The MetaCyc database is a comprehensive resource for metabolic pathways\n    and enzymes from all domains of life.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_182",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":182,
        "total_chunks":185,
        "content":"atabase is a comprehensive resource for metabolic pathways\n    and enzymes from all domains of life. id: metacyc\n  name: MetaCyc\n  registry:\n    biotools: metacyc\n    fairsharing: yytevr\n    tess: MetaCyc\n  url: https:\/\/metacyc.org\/\n- description: 'GotEnzymes: an extensive database of enzyme parameter predictions.' id: gotenzymes\n  name: GotEnzymes\n  url: https:\/\/metabolicatlas.org\/gotenzymes\n- description: TopEnzyme is a framework and database for structural coverage of the\n    functional enzyme space. id: topenzyme\n  name: TopEnzyme\n  registry:\n    biotools: topenzyme\n  url: https:\/\/cpclab.uni-duesseldorf.de\/topenzyme\/\n- description: COPASI is a software application for simulation and analysis of biochemical\n    networks and their dynamics. id: copasi\n  name: Copasi\n  registry:\n    biotools: copasi\n    tess: Copasi\n  url: https:\/\/copasi.org\/\n- description: PyEnzyme is a comprehensive software solution for manipulating EnzymeML\n    files.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_183",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":183,
        "total_chunks":185,
        "content":"g\/\n- description: PyEnzyme is a comprehensive software solution for manipulating EnzymeML\n    files. id: pyenzyme\n  name: PyEnzyme\n  url: https:\/\/enzymeml.github.io\/tools\/pyenzyme\/\n- description: The Python Simulator for Cellular Systems (PySCeS) is a a flexible,\n    user friendly tool for the analysis of cellular systems. id: pysces\n  name: PySCeS\n  registry:\n    biotools: pysces\n  url: https:\/\/pysces.github.io\/\n- description: MIxS - MIUViG (Minimum Information about an Uncultivated Virus Genome)\n    is a checklist that is a part of the larger MIxS standard. id: miuvig\n  name: Minimum Information about an Uncultivated Virus Genome (MIOViG)\n  registry:\n    fairsharing: bd9566\n  url: https:\/\/genomicsstandardsconsortium.github.io\/mixs\/0010012\/\n- description: A metadata standard for describing resources of any kind.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_tool_and_resource_list_yml_184",
        "source":"yaml",
        "file_path":"tool_and_resource_list.yml",
        "file_name":"tool_and_resource_list.yml",
        "chunk_index":184,
        "total_chunks":185,
        "content":"ium.github.io\/mixs\/0010012\/\n- description: A metadata standard for describing resources of any kind. id: dublincore\n  name: Dublin Core Metadata Terms\n  registry:\n    fairsharing: 9vtwjs\n  url: hhttps:\/\/www.dublincore.org\/\n- description: European Viral Outbreak Response Alliance Ontology\n  id: evora-ontology\n  name: EVORA Ontology\n  url: https:\/\/www.ebi.ac.uk\/ols4\/ontologies\/evorao\n- description: A comprehensive resource of channels, pores and tunnels found in biomacromolecular\n    structures deposited in the Protein Data Bank. id: channelsdb\n  name: ChannelsDB 2.0\n  registry:\n    biotools: channelsdb\n    fairsharing: d33rx4\n  url: https:\/\/channelsdb2.biodata.ceitec.cz\/\n- description: Minimum Information About Biobank data Sharing (MIABIS) is dedicated\n    to standardising data elements used to describe biobanks, research on samples,\n    and associated data. id: miabis\n  name: MIABIS\n  registry:\n    fairsharing: s0jj2t\n  url: https:\/\/github.com\/BBMRI-ERIC\/miabis",
        "metadata":{
            "source_type":"yaml",
            "original_file":"tool_and_resource_list.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_news_yml_0",
        "source":"yaml",
        "file_path":"news.yml",
        "file_name":"news.yml",
        "chunk_index":0,
        "total_chunks":14,
        "content":"- date: 2021-11-24\n  description: Due to a Converge WP2-WP3 hackathon, we improved many links towards\n    TeSS to ensure that people are linked to relevant trainings. linked_pr: 755\n  name: Improved TeSS links\n- date: 2021-11-29\n  description: Next to the edit me button you will now also find a history button\n    to discover when the latest changes were made on this page. linked_pr: 767\n  name: The history button\n- date: 2021-12-10\n  description: We have from now on a dedicated place on this website to list country\n    specific research data management resources! [Discover the section here](national_resources).",
        "metadata":{
            "source_type":"yaml",
            "original_file":"news.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_news_yml_2",
        "source":"yaml",
        "file_path":"news.yml",
        "file_name":"news.yml",
        "chunk_index":2,
        "total_chunks":14,
        "content":"Stewardship Wizard (DSW), where relevant. This is based on existing\n    links towards RDMkit in DSW. linked_pr: 803\n  name: Linking with DSW\n- date: 2022-01-24\n  description: This page gives an insight in RDM on national level in Finland. [Discover\n    the page here](fi_resources)\n  linked_pr: 816\n  name: 'New page: National resources Finland'\n- date: 2022-01-21\n  description: This page gives an insight in RDM on national level in Germany. [Discover\n    the page here](de_resources)\n  linked_pr: 812\n  name: 'New page: National resources Germany'\n- date: 2022-01-14\n  description: This page gives an insight in RDM on national level in Norway. [Discover\n    the page here](no_resources)\n  linked_pr: 792\n  name: 'New page: National resources Norway'\n- date: 2022-02-03\n  description: This page gives an insight in RDM on national level in France. [Discover\n    the page here](fr_resources)\n  linked_pr: 825\n  name: 'New page: National resources France'\n- date: 2022-02-11\n  description: This page gives an insight in RDM on national level in Sweden.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"news.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_news_yml_6",
        "source":"yaml",
        "file_path":"news.yml",
        "file_name":"news.yml",
        "chunk_index":6,
        "total_chunks":14,
        "content":"bout how to record information about data\n    provenance. [Discover the page here](data_provenance). linked_pr: 1053\n  name: 'New page: Data provenance'\n- date: 2022-12-06\n  description: This page gives an insight in RDM on national level in Switzerland. [Discover the page here](ch_resources)\n  linked_pr: 1076\n  name: 'New page: National resources Switzerland'\n- date: 2023-02-10\n  description: This page gives an insight in RDM on national level in Luxembourg. [Discover the page here](lu_resources)\n  linked_pr: 1063\n  name: 'New page: National resources Luxembourg'\n- date: 2023-02-14\n  description: This page gives insights about costs for data management, and related\n    solutions and resources. [Discover the page here](costs_data_management). linked_pr: 1171\n  name: 'New page: Costs for data management'\n- date: 2023-05-10\n  description: This page gives an insight in how we will govern and further develop\n    the RDMkit in the future. [Discover the page here](rdmkit_alliance).",
        "metadata":{
            "source_type":"yaml",
            "original_file":"news.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_news_yml_7",
        "source":"yaml",
        "file_path":"news.yml",
        "file_name":"news.yml",
        "chunk_index":7,
        "total_chunks":14,
        "content":" govern and further develop\n    the RDMkit in the future. [Discover the page here](rdmkit_alliance). linked_pr: 1239\n  name: 'New page: RDMkit alliance'\n- date: 2023-05-24\n  description: This page gives an insight in RDM on national level in Ireland. [Discover\n    the page here](ie_resources)\n  linked_pr: 1248\n  name: 'New page: National resources Ireland'\n- date: 2023-08-04\n  description: This page gives insights about data management solutions for Human\n    pathogen genomics. [Discover the page here](human_pathogen_genomics). linked_pr: 1263\n  name: 'New page: Human pathogen genomics'\n- date: 2023-08-10\n  description: These pages are rewritten from scratch and can be visited in the [Your\n    role](your_role) section. linked_pr: 1350\n  name: 'New content for following role pages: Data Steward, Policy maker, Researcher\n    and Research Software Engineer'\n- date: 2023-08-10\n  description: This page acts as a data management portal for PI's.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"news.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_news_yml_8",
        "source":"yaml",
        "file_path":"news.yml",
        "file_name":"news.yml",
        "chunk_index":8,
        "total_chunks":14,
        "content":"are Engineer'\n- date: 2023-08-10\n  description: This page acts as a data management portal for PI's. [Discover the\n    page here](principal_investigator).\n  linked_pr: 1344\n  name: 'New page: Principal Investigator (PI)'\n- date: 2023-08-16\n  description: This page acts as a data management portal for trainers. [Discover\n    the page here](trainer). linked_pr: 1355\n  name: 'New page: Trainer'\n- date: 2023-08-18\n  description: 'All items in the ''Tools and resources on this page'' tables are now\n    mentioned in the text. This means you have context of when it is appropriate to\n    use each one. Tools and resources in the text will also feature a popup providing\n    extra information about them. These changes means there is a new way to contribute\n    tools: see our [new guidelines](tool_resource_update)!'\n  linked_pr: 1249\n  name: All tools and resources are now described in the page text\n- date: 2023-08-22\n  description: This page gives insight into RDM on the national level in Cyprus.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"news.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_news_yml_10",
        "source":"yaml",
        "file_path":"news.yml",
        "file_name":"news.yml",
        "chunk_index":10,
        "total_chunks":14,
        "content":"age for CSC (Finnish IT Center\n    for Science) was updated. [Discover the page here](csc_assembly). linked_pr: 1429\n  name: 'Refreshed content: CSC tool assembly'\n- date: 2023-12-20\n  description: A new \"tool assembly\" page for FAIRtracks was added. [Discover the\n    page here](fairtracks_assembly).\n  linked_pr: 1419\n  name: 'New page: FAIRtracks tool assembly'\n- date: 2024-01-19\n  description: ELIXIR Recommended Interoperability Resources (RIR) are European tools\n    and registries that help make scientific research findable, accessible, interoperable\n    and reusable (FAIR). [ELIXIR News](https:\/\/elixir-europe.org\/news\/resource-announcement-2023).\n  linked_pr: 1449\n  name: RDMkit selected as ELIXIR Recommended Interoperability Resource\n- date: 2024-01-25\n  description: A new \"domain\" page for machine learning was added. [Discover the page\n    here](machine_learning).\n  linked_pr: 1443\n  name: 'New page: Machine learning'\n- date: 2024-03-24\n  description: By collapsing secondary information we hope to give more attention\n    to the main content of the RDMkit.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"news.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_news_yml_11",
        "source":"yaml",
        "file_path":"news.yml",
        "file_name":"news.yml",
        "chunk_index":11,
        "total_chunks":14,
        "content":"llapsing secondary information we hope to give more attention\n    to the main content of the RDMkit. Together with the improved navigation tiles,\n    multiple bugfixes and some style tweaks, we hope to improve the user experience. linked_pr: 1366\n  name: Improved navigation and user experience\n- date: 2024-03-27\n  description: A new \"domain\" page for human health data was added. [Discover the\n    page here](health_data).\n  linked_pr: 1432\n  name: 'New page: Health data'\n- date: 2024-06-10\n  description: We are gradually improving the icons that are in use on the RDMkit\n    by applying our own style. You can discover them throughout the whole website! linked_pr: 1489\n  name: New custom icon set\n- date: 2024-10-07\n  description: Our [contribute section](how_to_contribute) got an overhaul, with clear\n    ways in how to contribute and improved documentation. linked_pr: 1437\n  name: Improved contribute pages\n- date: 2024-10-10\n  description: A \"your task\" page about how to make your data more discoverable was\n    added.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"news.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_news_yml_12",
        "source":"yaml",
        "file_path":"news.yml",
        "file_name":"news.yml",
        "chunk_index":12,
        "total_chunks":14,
        "content":"10-10\n  description: A \"your task\" page about how to make your data more discoverable was\n    added. [Discover the page here](data_discoverability).\n  linked_pr: 1517\n  name: 'New page: Data discoverability'\n- date: 2024-10-24\n  description: The page is enriched with additional links and a bibliography. [Discover\n    the page here](human_pathogen_genomics). linked_pr: 1526\n  name: 'Revamped page: Human pathogen genomics'\n- date: 2024-12-06\n  description: This page guides you with capturing your planned data workflow in a\n    diagram. [Discover the page here](creating_dataflow_diagram).\n  linked_pr: 1528\n  name: 'New page: Creating a data-flow diagram'\n- date: 2025-02-27\n  description: This page provides insights into RDM on a national level in Greece. [Discover the page here](gr_resources)\n  linked_pr: 1568\n  name: 'New page: National resources Greece'\n- date: 2025-03-28\n  description: This paragraph in the Your task page Data publication, provides guidance\n    on whether to include dataset accession numbers in preprints and theses.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"news.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_events_yml_0",
        "source":"yaml",
        "file_path":"events.yml",
        "file_name":"events.yml",
        "chunk_index":0,
        "total_chunks":3,
        "content":"- description: We would like to invite you to highlight your set of data management\n    tools as a tool assembly in the RDMkit and describe how to use it, so others can\n    do the same (two half days). Registration has ended.\n  endDate: 2021-06-24\n  endTime: 13:30 CET\n  location: Online\n  name: Contentathon\n  startDate: 2021-06-23\n  startTime: '9:00'\n- description: Highlight your data management tool assembly in the RDMkit! Highlight\n    your data management tools assembly in the RDMkit!\n  endDate: 2021-11-12\n  location: Barcelona\n  name: BioHackathon Europe\n  startDate: 2021-11-08\n- description: Do you have experience in generating machine-readable metadata during\n    life sciences research projects? If yes, join this focus group! Help to describe\n    best practices on machine-readable metadata in a your task page. We are bundling\n    our expertise on this topic in a joint discussion and writing session.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"events.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_events_yml_1",
        "source":"yaml",
        "file_path":"events.yml",
        "file_name":"events.yml",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ask page. We are bundling\n    our expertise on this topic in a joint discussion and writing session. For more\n    information, please contact the rdm-editors@elixir-europe.org.\n  endTime: 15:00 CET\n  location: '[Zoom](https:\/\/cesnet.zoom.us\/j\/92001466230?pwd=V2lKc09pa0xGajFJRzA3a1FuS2Uxdz09)'\n  name: 'RDMkit Focus session: Machine-Readable Metadata'\n  startDate: 2021-09-24\n  startTime: '13:00'\n- description: Take the opportunity to revise RDMkit pages; editors will be available\n    in two time slots to help you with it. More information on the event can be found\n    [in this document](https:\/\/docs.google.com\/document\/d\/1HEemKzQikLrHvyaTyC7hqg8Lpp1NmS4R9hRwpeKkCXw). Registration has ended. endDate: 2022-12-09\n  location: Online\n  name: ELIXIR CONVERGE - RDMkit Virtual Hackathon\n  startDate: 2022-12-08\n- description: As a community, we want to make sure that the RDMkit content is regularly\n    revised, improved, and further developed for better learning of what data management\n    entails and how it works.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"events.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_events_yml_2",
        "source":"yaml",
        "file_path":"events.yml",
        "file_name":"events.yml",
        "chunk_index":2,
        "total_chunks":3,
        "content":"ved, and further developed for better learning of what data management\n    entails and how it works. With that, we would like to invite current and future\n    contributors to [join us](https:\/\/www.eventbrite.com\/e\/550843105557) at RDMkit\n    contentathon!\n  endDate: 2023-05-24\n  endTime: 12:00 CET\n  location: '[Monasterium](https:\/\/monasterium.be\/nl\/), Ghent, Belgium + virtual'\n  name: RDMkit Contentathon\n  startDate: 2023-05-22\n  startTime: '9:00'",
        "metadata":{
            "source_type":"yaml",
            "original_file":"events.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_affiliations_yaml_0",
        "source":"yaml",
        "file_path":"affiliations.yaml",
        "file_name":"affiliations.yaml",
        "chunk_index":0,
        "total_chunks":6,
        "content":"- expose: true\n  image_url: \/images\/institutions\/VIB-notagline-pos. svg\n  name: VIB\n  pid: https:\/\/ror. org\/03xrhmk39\n  type: institution\n  url: https:\/\/vib. be\/\n- expose: true\n  image_url: \/images\/institutions\/logo-university-of-manchester. svg\n  name: The Manchester University\n  pid: https:\/\/ror. org\/02aswte26\n  type: institution\n  url: https:\/\/www. manchester. ac. uk\/\n- expose: true\n  image_url: \/images\/institutions\/nbislogo-green-txt. svg\n  name: NBIS\n  pid: null\n  type: institution\n  url: https:\/\/nbis. se\/\n- expose: true\n  image_url: \/images\/institutions\/SciLifeLab_Logotype_Green_POS. svg\n  name: SciLifeLab\n  pid: https:\/\/ror. org\/04ev03g22\n  type: institution\n  url: https:\/\/www. scilifelab. se\/\n- expose: true\n  image_url: \/images\/institutions\/uib_logo. svg\n  name: University of Bergen\n  pid: https:\/\/ror. org\/03zga2b32\n  type: institution\n  url: https:\/\/www. uib. no\/en\n- expose: true\n  image_url: \/images\/institutions\/UiO_logo. svg\n  name: University of Oslo\n  pid: https:\/\/ror.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"affiliations.yaml",
            "language":"en"
        }
    },
    {
        "id":"yaml_affiliations_yaml_1",
        "source":"yaml",
        "file_path":"affiliations.yaml",
        "file_name":"affiliations.yaml",
        "chunk_index":1,
        "total_chunks":6,
        "content":" true\n  image_url: \/images\/institutions\/UiO_logo. svg\n  name: University of Oslo\n  pid: https:\/\/ror. org\/01xtthb56\n  type: institution\n  url: https:\/\/www. uio. no\/english\/index. html\n- expose: true\n  image_url: \/images\/institutions\/BSC-blue. svg\n  name: Barcelona Supercomputing Center\n  pid: https:\/\/ror. org\/05sd8tv96\n  type: institution\n  url: https:\/\/www. bsc. es\/\n- expose: true\n  image_url: \/images\/institutions\/DTL_logo. svg\n  name: Dutch Techcentre for Life Sciences\n  pid: https:\/\/ror. org\/055d8gs64\n  type: institution\n  url: https:\/\/www. dtls. nl\/\n- expose: true\n  image_url: \/images\/institutions\/hits-logo. svg\n  name: Heidelberg Institute for Theoretical Studies\n  pid: https:\/\/ror. org\/01f7bcy98\n  type: institution\n  url: https:\/\/www. h-its. org\/\n- expose: true\n  image_url: \/images\/institutions\/07_logotipo_web_ciencia_EN_50px-01. svg\n  name: Instituto Gulbenkian de Cincia\n  pid: https:\/\/ror. org\/04b08hq31\n  type: institution\n  url: https:\/\/gulbenkian. pt\/ciencia\/\n- expose: true\n  image_url: \/images\/institutions\/University-of-Luxembourg-Fr-01_noborder.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"affiliations.yaml",
            "language":"en"
        }
    },
    {
        "id":"yaml_affiliations_yaml_2",
        "source":"yaml",
        "file_path":"affiliations.yaml",
        "file_name":"affiliations.yaml",
        "chunk_index":2,
        "total_chunks":6,
        "content":"t\/ciencia\/\n- expose: true\n  image_url: \/images\/institutions\/University-of-Luxembourg-Fr-01_noborder. svg\n  name: University of Luxembourg\n  pid: https:\/\/ror. org\/036x5ad56\n  type: institution\n  url: https:\/\/wwwen. uni. lu\/\n- expose: true\n  image_url: \/images\/institutions\/CSC_2012_LOGO_RGB. svg\n  name: CSC\n  pid: https:\/\/ror. org\/04m8m1253\n  type: institution\n  url: https:\/\/www. csc. fi\/\n- expose: true\n  image_url: \/assets\/img\/converge_logo. svg\n  name: ELIXIR CONVERGE\n  pid: https:\/\/cordis. europa. eu\/project\/id\/871075\n  type: funder\n  url: https:\/\/elixir-europe. org\/about-us\/how-funded\/eu-projects\/converge\n- expose: true\n  image_url: \/images\/funders\/Forskningsdagene_Ikon_Rod_RGB. svg\n  name: Research Council of Norway\n  pid: http:\/\/dx. doi. org\/10. 13039\/501100005416\n  type: funder\n  url: https:\/\/www. forskningsradet. no\/en\/\n- expose: true\n  image_url: \/images\/funders\/FWO-logo. svg\n  name: FWO-IRI\n  pid: http:\/\/dx. doi. org\/10. 13039\/501100003130\n  type: funder\n  url: https:\/\/www. fwo. be\/\n- expose: true\n  image_url: \/images\/funders\/svart_liggande_eng.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"affiliations.yaml",
            "language":"en"
        }
    },
    {
        "id":"yaml_affiliations_yaml_3",
        "source":"yaml",
        "file_path":"affiliations.yaml",
        "file_name":"affiliations.yaml",
        "chunk_index":3,
        "total_chunks":6,
        "content":" funder\n  url: https:\/\/www. fwo. be\/\n- expose: true\n  image_url: \/images\/funders\/svart_liggande_eng. svg\n  name: Swedish Research Council\n  pid: http:\/\/dx. doi. org\/10. 13039\/501100004359\n  type: funder\n  url: https:\/\/www. vr. se\/\n- expose: true\n  image_url: \/images\/projects\/Bioexcel_logo_subheading_updated_RGB. svg\n  name: BioExcel\n  pid: https:\/\/cordis. europa. eu\/project\/id\/823830\n  type: project\n  url: https:\/\/bioexcel. eu\/\n- expose: true\n  image_url: \/images\/projects\/tess_logo. svg\n  name: TeSS\n  pid: null\n  type: project\n  url: https:\/\/tess. elixir-europe. org\/\n- expose: true\n  image_url: \/images\/projects\/FAIRsharing-sdp. svg\n  name: FAIRsharing\n  pid: null\n  type: project\n  url: https:\/\/fairsharing. org\/\n- expose: true\n  image_url: \/images\/projects\/bio. tools. svg\n  name: Bio. tools\n  pid: null\n  type: project\n  url: https:\/\/bio. tools\/\n- expose: true\n  image_url: \/images\/infrastructures\/ELIXIR-logo. svg\n  name: ELIXIR Europe\n  pid: null\n  type: infrastructure\n  url: https:\/\/elixir-europe. org\/\n- expose: false\n  image_url: \/images\/infrastructures\/Euro-BioImaging_logo.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"affiliations.yaml",
            "language":"en"
        }
    },
    {
        "id":"yaml_affiliations_yaml_4",
        "source":"yaml",
        "file_path":"affiliations.yaml",
        "file_name":"affiliations.yaml",
        "chunk_index":4,
        "total_chunks":6,
        "content":"tps:\/\/elixir-europe. org\/\n- expose: false\n  image_url: \/images\/infrastructures\/Euro-BioImaging_logo. svg\n  name: Euro BioImaging\n  pid: null\n  type: infrastructure\n  url: https:\/\/www. eurobioimaging. eu\/\n- expose: false\n  image_url: \/images\/institutions\/UiO_logo. svg\n  name: University of Oslo\n  pid: https:\/\/ror. org\/01xtthb56\n  type: institution\n  url: https:\/\/www. uio. no\/english\/\n- expose: false\n  image_url: \/images\/infrastructures\/NeLS_logo. svg\n  name: NeLS\n  pid: null\n  type: infrastructure\n  url: https:\/\/nels. bioinfo. no\/\n- expose: false\n  image_url: \/images\/funders\/European_Commission. svg\n  name: European Union\n  pid: http:\/\/dx. doi. org\/10. 13039\/501100000780\n  type: funder\n  url: https:\/\/ec. europa. eu\/\n- expose: true\n  image_url: \/images\/projects\/dsw-logo-full-color-filled. svg\n  name: Data Stewardship Wizard\n  pid: null\n  type: project\n  url: https:\/\/ds-wizard. org\/\n- expose: true\n  image_url: \/images\/projects\/cookbook-logo. png\n  name: FAIR Cookbook\n  pid: null\n  type: project\n  url: https:\/\/faircookbook. elixir-europe.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"affiliations.yaml",
            "language":"en"
        }
    },
    {
        "id":"yaml_affiliations_yaml_5",
        "source":"yaml",
        "file_path":"affiliations.yaml",
        "file_name":"affiliations.yaml",
        "chunk_index":5,
        "total_chunks":6,
        "content":"o. png\n  name: FAIR Cookbook\n  pid: null\n  type: project\n  url: https:\/\/faircookbook. elixir-europe. org\/\n- expose: true\n  image_url: \/images\/infrastructures\/BBMRI-NL_logo. svg\n  name: BBMRI-NL\n  pid: https:\/\/ror. org\/0003kpv33\n  type: infrastructure\n  url: https:\/\/www. bbmri. nl\/\n- expose: true\n  image_url: \/images\/institutions\/Ebi_official_logo. png\n  name: EMBL-EBI\n  pid: https:\/\/ror. org\/02catss52\n  type: project\n  url: https:\/\/www. ebi. ac. uk\/.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"affiliations.yaml",
            "language":"en"
        }
    },
    {
        "id":"yaml_footer_yml_0",
        "source":"yaml",
        "file_path":"footer.yml",
        "file_name":"footer.yml",
        "chunk_index":0,
        "total_chunks":2,
        "content":"columns:\n- alt: Converge logo\n  image_width: 120px\n  src: assets\/img\/elixir_logo.svg\n  type: image\n  width: 2\n- children:\n  - url: \/contributors\n    url_text: Contributors\n  - url: \/accessibility\n    url_text: Accessibility\n  - external_url: https:\/\/elixir-europe.org\n    url_text: ELIXIR\n  - url: \/support\n    url_text: Institutes, projects and funders\n  type: links\n  width: 3\n- children:\n  - url: \/about\n    url_text: About\n  - url: \/contact\n    url_text: Contact\n  - url: \/about#how-to-cite-the-rdmkit\n    url_text: How to cite\n  - url: \/privacy\n    url_text: Privacy\n  type: links\n  width: 3\n- alt: European flag\n  image_width: 100px\n  src: assets\/img\/Flag_of_Europe.svg\n  type: image\n  width: 1\n- alt: Jekyll Bootstrap theme logo\n  image_width: 88px\n  src: assets\/img\/RDMkit_logo_condensed_inverted.svg\n  type: image\n  width: 1\ncopyright: '[! [Creative Commons License](https:\/\/i.creativecommons.org\/l\/by\/4.0\/88x31.png)](http:\/\/creativecommons.org\/licenses\/by\/4.0\/)",
        "metadata":{
            "source_type":"yaml",
            "original_file":"footer.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_footer_yml_1",
        "source":"yaml",
        "file_path":"footer.yml",
        "file_name":"footer.yml",
        "chunk_index":1,
        "total_chunks":2,
        "content":"nse](https:\/\/i.creativecommons.org\/l\/by\/4.0\/88x31.png)](http:\/\/creativecommons.org\/licenses\/by\/4.0\/) RDMkit by [ELIXIR](https:\/\/elixir-europe.org\/) is licensed under a [Creative Commons\n  Attribution 4.0 International License](http:\/\/creativecommons.org\/licenses\/by\/4.0\/),\n  except where otherwise noted.' extra_line: Recommended in the <a href=\"https:\/\/ec.europa.eu\/info\/funding-tenders\/opportunities\/docs\/2021-2027\/horizon\/guidance\/programme-guide_horizon_en.pdf\">Horizon\n  Europe Program Guide<\/a> as the \"resource for Data Management guidelines and good\n  practices for the Life Sciences\"",
        "metadata":{
            "source_type":"yaml",
            "original_file":"footer.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_topnav_yml_0",
        "source":"yaml",
        "file_path":"topnav.yml",
        "file_name":"topnav.yml",
        "chunk_index":0,
        "total_chunks":1,
        "content":"subitems:\n- title: Data management\n  url: \/index\n- title: About\n  url: \/about\n- title: Contribute\n  url: \/how_to_contribute",
        "metadata":{
            "source_type":"yaml",
            "original_file":"topnav.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_data_management_yml_2",
        "source":"yaml",
        "file_path":"sidebars\/data_management.yml",
        "file_name":"data_management.yml",
        "chunk_index":2,
        "total_chunks":9,
        "content":"image_url: \/assets\/img\/section-icons\/dna. svg\n  subitems:\n  - title: Bioimaging data\n    url: \/bioimaging_data\n  - title: Biomolecular simulation data\n    url: \/biomolecular_simulation_data\n  - title: Cancer data\n    url: \/cancer_data\n  - title: Enzymology and biocatalysis\n    url: \/enzymology_and_biocatalysis\n  - title: Epitranscriptome data\n    url: \/epitranscriptome_data\n  - title: Health data\n    url: \/health_data\n  - title: Human data\n    url: \/human_data\n  - title: Human pathogen genomics\n    url: \/human_pathogen_genomics\n  - title: Intrinsically disordered proteins\n    url: \/intrinsically_disordered_proteins\n  - title: Machine learning\n    url: \/machine_learning\n  - title: Marine metagenomics\n    url: \/marine_metagenomics\n  - title: Microbial biotechnology\n    url: \/microbial_biotechnology\n  - title: Plant sciences\n    url: \/plant_sciences\n  - title: Proteomics\n    url: \/proteomics\n  - title: Rare disease data\n    url: \/rare_disease_data\n  - title: Single-cell sequencing\n    url: \/single_cell_sequencing\n  - title: Structural bioinformatics\n    url: \/structural_bioinformatics\n  - title: Toxicology data\n    url:.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"data_management.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_data_management_yml_4",
        "source":"yaml",
        "file_path":"sidebars\/data_management.yml",
        "file_name":"data_management.yml",
        "chunk_index":4,
        "total_chunks":9,
        "content":"\/your_domain\n- description: Find guidelines and solutions for tackling common data management tasks. image_url: \/assets\/img\/section-icons\/tick.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"data_management.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_data_management_yml_5",
        "source":"yaml",
        "file_path":"sidebars\/data_management.yml",
        "file_name":"data_management.yml",
        "chunk_index":5,
        "total_chunks":9,
        "content":"image_url: \/assets\/img\/section-icons\/tick. svg\n  subitems:\n  - title: Compliance monitoring\n    url: \/compliance_monitoring\n  - title: Costs of data management\n    url: \/costs_data_management\n  - title: Creating a data-flow diagram\n    url: \/creating_dataflow_diagram\n  - title: Data analysis\n    url: \/data_analysis\n  - title: Data brokering\n    url: \/data_brokering\n  - title: Data discoverability\n    url: \/data_discoverability\n  - title: Data management coordination\n    url: \/dm_coordination\n  - title: Data management plan\n    url: \/data_management_plan\n  - title: Data organisation\n    url: \/data_organisation\n  - title: Data security\n    url: \/data_security\n  - title: Data sensitivity\n    url: \/data_sensitivity\n  - title: Data provenance\n    url: \/data_provenance\n  - title: Data publication\n    url: \/data_publication\n  - title: Data quality\n    url: \/data_quality\n  - title: Data storage\n    url: \/storage\n  - title: Data transfer\n    url: \/data_transfer\n  - title: Documentation and metadata\n    url: \/metadata_management\n  - title: Ethical aspects\n    url: \/ethics\n  - title: Existing data\n    url: \/existing_data\n  - title: GDPR compliance\n    url: \/gdpr_compliance\n  - title: Identifiers\n    url: \/identifiers\n  - title: Licensing\n    url: \/licensing\n  - title: Machine actionability\n    url: \/machine_actionability\n  title: Your tasks\n  url: \/your_tasks\n- description: Find concrete combinations of tools and resources assembled into an\n    ecosystem for research data management.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"data_management.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_data_management_yml_6",
        "source":"yaml",
        "file_path":"sidebars\/data_management.yml",
        "file_name":"data_management.yml",
        "chunk_index":6,
        "total_chunks":9,
        "content":"te combinations of tools and resources assembled into an\n    ecosystem for research data management. image_url: \/assets\/img\/section-icons\/tool-assembly.svg\n  subitems:\n  - title: COVID-19 Data Portal\n    url: \/covid19_data_portal\n  - title: CSC\n    url: \/csc_assembly\n  - title: FAIRtracks\n    url: \/fairtracks_assembly\n  - title: Galaxy\n    url: \/galaxy_assembly\n  - title: IFB\n    url: \/ifb_assembly\n  - title: Marine Metagenomics\n    url: \/marine_metagenomics_assembly\n  - title: MOLGENIS\n    url: \/molgenis_assembly\n  - title: NeLS\n    url: \/nels_assembly\n  - title: OMERO\n    url: \/omero_assembly\n  - title: Plant Genomics\n    url: \/plant_genomics_assembly\n  - title: Plant Phenomics\n    url: \/plant_phenomics_assembly\n  - title: TransMed\n    url: \/transmed_assembly\n  - title: TSD\n    url: \/tsd_assembly\n  - title: XNAT-PIC\n    url: \/xnat_pic_assembly\n  title: Tool assembly\n  url: \/tool_assembly\n- description: Find pointers to country specific information resources and national\n    research data management practices.",
        "metadata":{
            "source_type":"yaml",
            "original_file":"data_management.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_data_management_yml_7",
        "source":"yaml",
        "file_path":"sidebars\/data_management.yml",
        "file_name":"data_management.yml",
        "chunk_index":7,
        "total_chunks":9,
        "content":"nters to country specific information resources and national\n    research data management practices. image_url: \/assets\/img\/section-icons\/flag.svg\n  subitems:\n  - title: Belgium\n    url: \/be_resources\n  - title: Cyprus\n    url: \/cy_resources\n  - title: Czech Republic\n    url: \/cz_resources\n  - title: Germany\n    url: \/de_resources\n  - title: Estonia\n    url: \/ee_resources\n  - title: Spain\n    url: \/es_resources\n  - title: Finland\n    url: \/fi_resources\n  - title: France\n    url: \/fr_resources\n  - title: Greece\n    url: \/gr_resources\n  - title: Italy\n    url: \/it_resources\n  - title: Ireland\n    url: \/ie_resources\n  - title: Luxembourg\n    url: \/lu_resources\n  - title: Netherlands\n    url: \/nl_resources\n  - title: Norway\n    url: \/no_resources\n  - title: Portugal\n    url: \/pt_resources\n  - title: Slovenia\n    url: \/si_resources\n  - title: Sweden\n    url:",
        "metadata":{
            "source_type":"yaml",
            "original_file":"data_management.yml",
            "language":"en"
        }
    },
    {
        "id":"yaml_data_management_yml_8",
        "source":"yaml",
        "file_path":"sidebars\/data_management.yml",
        "file_name":"data_management.yml",
        "chunk_index":8,
        "total_chunks":9,
        "content":"ortugal\n    url: \/pt_resources\n  - title: Slovenia\n    url: \/si_resources\n  - title: Sweden\n    url: \/se_resources\n  - title: Switzerland\n    url: \/ch_resources\n  - title: United Kingdom\n    url: \/uk_resources\n  title: National resources\n  url: \/national_resources\n- description: Browse the RDMkit's catalogue of tools and resources for research data\n    management. hr: true\n  image_url: \/assets\/img\/section-icons\/cogs.svg\n  title: All tools and resources\n  url: \/all_tools_and_resources\n- description: Browse all training resources mentioned in RDMkit pages. image_url: \/assets\/img\/section-icons\/training-icon.svg\n  title: All training resources\n  url: \/all_training_resources\ntitle: Data management\ntitle_url: \/index",
        "metadata":{
            "source_type":"yaml",
            "original_file":"data_management.yml",
            "language":"en"
        }
    },
    {
        "id":"md_fm_tool_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly.md",
        "file_name":"tool_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"search_exclude: true\ntitle: Tool assembly\ntoc: false",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"tool_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_tool_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly.md",
        "file_name":"tool_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"Tool Assemblies are examples of combining  tools to cover data management tasks across several stages of the data life cycle. These can be tools that one or several communities combine to support RDM that can be picked up or accessed and used by others. The assemblies are aimed for users in a specific location and\/or for users within a specific domain. {% include section-navigation-tiles.html type=\"tool_assembly\" affiliations=true search=true col=3 %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"tool_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Tool assembly",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_fm_national_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources.md",
        "file_name":"national_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"title: National resources\ntoc: false",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"national_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_national_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources.md",
        "file_name":"national_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"To carry out RDM tasks FAIRly and effectively, it is important to consider not only common global solutions but also existing, national solutions, that are often dependent on institute- and country-specific policies, funders, and infrastructures. Here, we point to non-exhaustive collection of country-specific information resources such as local funding agencies and research councils, and information on local policies for open science, national regulations on data ethics, and domain-specific infrastructures and tools. These country-specific RDM overviews will help readers to seek national advice and could be an inspirational guide for other countries to implement and promote data management practices at national level. {% include section-navigation-tiles-simple.html type=\"national_resources\" col=3 %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"national_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"National resources",
                "toc":false
            }
        }
    },
    {
        "id":"md_fm_all_tools_and_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/all_tools_and_resources.md",
        "file_name":"all_tools_and_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"custom_editme: pages\/contribute\/tool_resource_update.md\ndatatable: true\ntitle: All tools and resources\ntoc: false",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"all_tools_and_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_all_tools_and_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/all_tools_and_resources.md",
        "file_name":"all_tools_and_resources.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"This is the main tool and resource list of our website. This is a curated list which means that not all tools or resources that exist for a certain topic are listed here. This is mainly because we do not intend to be a registry. In most cases you will only find back the tools or resources that are mentioned in the different pages. Most pages will show a filtered list of this main table at the end of the page. We link tools and resources to related information in ELIXIR registries: related policies and standards in FAIRsharing, scientific and technical descriptions of the resource in bio.tools, and related training in TeSS. If you see a missing link with one of the registries or a mistake, please open an issue or check our how to add a tool or resource guide.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"all_tools_and_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"All tools and resources",
                "datatable":true,
                "toc":false,
                "custom_editme":"pages\/contribute\/tool_resource_update.md"
            }
        }
    },
    {
        "id":"md_content_all_tools_and_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/all_tools_and_resources.md",
        "file_name":"all_tools_and_resources.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":" the registries or a mistake, please open an issue or check our how to add a tool or resource guide. It is recommended to add:\n- your training materials and events into the training registry TeSS\n- your standards, databases and policies in fairsharing registry\n- your software tools, databases and services for bioinformatics and the life sciences in bio.tools registry\n{% include resource-table-all.html %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"all_tools_and_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"All tools and resources",
                "datatable":true,
                "toc":false,
                "custom_editme":"pages\/contribute\/tool_resource_update.md"
            }
        }
    },
    {
        "id":"md_fm_your_tasks_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks.md",
        "file_name":"your_tasks.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"title: Your tasks\ntoc: false",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"your_tasks.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_your_tasks_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks.md",
        "file_name":"your_tasks.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"In this section, information is organised around regular research data management tasks or challenges. You will find:\n- Best practices and guidelines for each data management task. - A list of all the considerations to be taken into account when performing a specific data management task.\n- Links to task-specific training materials.\n- Links to tool assemblies implemented by others to address specific data management challenges.\n- Links to a Data Stewardship Wizard for your DMP and to step-by-step instructions to make your data FAIR. - A summary table of tools and resources relevant for the specific task and recommended by communities. {% include section-navigation-tiles.html type=\"your_tasks\" search=true col=3 %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"your_tasks.md",
            "language":"en",
            "frontmatter":{
                "title":"Your tasks",
                "toc":false
            }
        }
    },
    {
        "id":"md_fm_your_role_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_role.md",
        "file_name":"your_role.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"title: Your role\ntoc: false",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"your_role.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_your_role_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_role.md",
        "file_name":"your_role.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"In this section, information is organised based on the different roles a professional can have in research data management. You will find:\n- A description of the main tasks usually handled by each role. - A collection of research data management responsibilities for each role.\n- Links to RDMkit guidelines and advice on useful information for getting started with data management specific to each role. {% include section-navigation-tiles.html type=\"your_role\" search=true col=3 %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"your_role.md",
            "language":"en",
            "frontmatter":{
                "title":"Your role",
                "toc":false
            }
        }
    },
    {
        "id":"md_content_your_domain_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain.md",
        "file_name":"your_domain.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"In this section, information is organised based on different domains in life sciences with different approaches on how they manage their data. You will find:\n- Domain-specific best practices and guidelines for data management.\n- A description of domain-specific data management challenges, considerations to be taken into account and solutions used by the community to address the challenges.\n- Links to domain-specific training materials.\n- Links to tool assemblies implemented by the communities to address specific data management challenges.\n- Links to a Data Stewardship Wizard for your DMP and to step-by-step instructions to make your data FAIR.\n- A summary table of the relevant tools and resources for the specific domain, recommended by the community. {% include section-navigation-tiles.html type=\"your_domain\" search=true col=3 %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"your_domain.md",
            "language":"en",
            "frontmatter":{
                "title":"Your domain",
                "toc":false
            }
        }
    },
    {
        "id":"md_fm_all_training_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/all_training_resources.md",
        "file_name":"all_training_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"datatable: true\ntitle: All training resources\ntoc: false",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"all_training_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_all_training_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/all_training_resources.md",
        "file_name":"all_training_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"Overview of all training resources mentioned in RDMkit pages. This overview is automatically generated. It is recommended to add your training materials and events into the ELIXIR training registry TeSS. {% include training-table-all.html %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"all_training_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"All training resources",
                "datatable":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_fm_data_life_cycle_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/data_life_cycle.md",
        "file_name":"data_life_cycle.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"title: Data life cycle\ntoc: false",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_life_cycle.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_life_cycle_md_0",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle.md",
        "file_name":"data_life_cycle.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"In the RDMkit, data can be defined as any information or materials that are collected, observed, generated, or used during the research process. Data can take various forms, including experimental results, numerical data, text documents, images, software code, surveys, and more. The RDMkit recognises the importance of managing data effectively through the research lifecycle, and the need to handle data in a structured, organised, and documented manner to ensure its quality, integrity, and long-term usability. In this section, information is organised according to the stages of the research data life cycle. You will find:\n- A general description and introduction of each  stage.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_life_cycle.md",
            "language":"en",
            "frontmatter":{
                "title":"Data life cycle",
                "toc":false
            }
        }
    },
    {
        "id":"md_content_data_life_cycle_md_1",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle.md",
        "file_name":"data_life_cycle.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"he research data life cycle. You will find:\n- A general description and introduction of each  stage. - A list of the main considerations that need to be taken into account during each stage.\n- Links to training materials related to each stage.\n- Links to related data management tasks that can be performed at each stage.\n- Links to a Data Stewardship Wizard for your DMP and to step-by-step instructions to make your data FAIR. Share\nReuse\nPreserve\nAnalyse\nProcess\nPlan\nCollect",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_life_cycle.md",
            "language":"en",
            "frontmatter":{
                "title":"Data life cycle",
                "toc":false
            }
        }
    },
    {
        "id":"md_fm_single_cell_sequencing_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Johan Rollin\n- Pavankumar Videm\n- Mehmet Tekman\ndescription: Managing data generated from single-cell sequencing experiments.\npage_id: single_cell_sequencing\nrelated_pages:\n  tool_assembly:\n  - galaxy\n  - fairtracks\n  your_tasks:\n  - dmp\n  - data_organisation\n  - data_publication\n  - metadata\n  - storage\ntitle: Single-cell sequencing\ntraining:\n- name: Single-cell training on the Galaxy Training Network\n  url: https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"single_cell_sequencing.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":0,
        "total_chunks":20,
        "content":"Introduction\nIn this section, we provide an overview of the data management challenges specific to single-cell sequencing experiments. Single-cell sequencing enables the analysis of gene expression at the individual cell level, leading to unique data management requirements due to the high dimensionality and complexity of the data. Single-cell sequencing encompasses a diverse array of techniques to sequence transcriptomics, epigenomics and combinations of multiple modalities (multiomics) at single-cell resolution, each presenting its own set of challenges and considerations. Additionally, the field embraces a wide range of data analysis approaches, further compounding the complexity. Consequently, addressing the standardised description and storage of data and associated metadata becomes paramount in this context. To ensure the reproducibility and reliability of research findings, it is crucial to proactively identify the specific steps in the data workflow that should be preserved.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":1,
        "total_chunks":20,
        "content":"is crucial to proactively identify the specific steps in the data workflow that should be preserved. Moreover, decisions regarding data formats must be made collectively to facilitate seamless data sharing, collaboration, and long-term data preservation within the single-cell user community. This page aims to explain these challenges and provide practical guidance to navigate them effectively. Preprocessing and quality control\nData preprocessing and quality control are integral components of the single-cell data analysis workflow, playing a pivotal role in ensuring the integrity of the data and facilitating accurate downstream analysis. These challenges encompass a spectrum of tasks aimed at enhancing data quality, reliability, and interpretation that help to make tasks conducive for subsequent analysis. By comprehensively addressing data preprocessing and quality control, we aim to provide researchers with a robust framework for navigating these critical stages of the single-cell sequencing process.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":2,
        "total_chunks":20,
        "content":" with a robust framework for navigating these critical stages of the single-cell sequencing process. This includes strategies for addressing technical variability, identifying and mitigating low-quality cells or outliers, managing batch effects, and other sources of variability that may arise within and between datasets. Data analysis rational\nDescription\nPreprocessing encompasses tasks such as the removal of empty droplets, quality control, batch correction, data normalisation, and transformation to mitigate technical variations. These steps aim to ensure that the data is in a suitable state for downstream analysis. Then, the next step's central objectives include the identification of individual cells within the dataset, the assignment of gene expression profiles to each cell, and the generation of count matrices that represent the expression levels of thousands of genes across all cells.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":3,
        "total_chunks":20,
        "content":"ation of count matrices that represent the expression levels of thousands of genes across all cells. To do so, tools like {% tool \"cellranger\" %} (for 10x data) or {% tool \"starsolo\" %} (a more generic and open-source tool that supports various droplet- and plate-based data) are used to facilitate the crucial process of cell and gene assignment. These tools are specifically designed to take the raw sequencing data and process it into quantifiable and interpretable information. This transformation of raw data into structured, cell-by-gene matrices is fundamental for downstream analyses, such as clustering cells by similar gene expression profiles, identifying cell types or inferring cell evolution trajectories. In essence, {% tool \"cellranger\" %} and {% tool \"starsolo\" %} play a pivotal role in converting large and complex sequencing data into a format that researchers can subsequently explore to extract these aforementioned biological insights. Following the cell type assignation, post-processing steps come into play.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":4,
        "total_chunks":20,
        "content":"oned biological insights. Following the cell type assignation, post-processing steps come into play. These post-processing stages involve activities like efficient clustering of cells and biologically relevant annotation of clusters. By carefully orchestrating both pre- and post-processing phases, researchers can enhance the quality, reliability, and interpretability of their single-cell sequencing data, ultimately leading to more accurate and biologically meaningful insights. Considerations\nPre-cell assignation\n\nLow-Quality Cell Detection: Explore methods for identifying and removing low-quality cells or outliers from the dataset. Normalisation and Transformation: Determine how to effectively normalise and transform the data to account for technical variability. Post-cell assignation\n\nBatch Effects Handling: Develop strategies to mitigate batch effects (cell corrlate base on technical and not biological parameter) and other sources of variability within and between datasets, usually done during quality control step.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":5,
        "total_chunks":20,
        "content":" other sources of variability within and between datasets, usually done during quality control step. Efficient Clustering: Consider techniques to achieve efficient and meaningful clustering of single-cell data. Biological Annotation: Determine how to annotate the identified cell clusters with biologically relevant labels. Solutions\n\nNormalisation and Transformation: Consider using established methods such as shifted logarithm, variance stabilizing transformation (sctransform) or cell pool-based size factor estimators (scran) to address differences in sequencing depth and monitor data quality. Alternative normalisation methods such as term frequency-inverse document frequency (TF-IDF) are well-suited for scATAC-seq data. Low-Quality Cell Detection: Evaluate metrics like the number of detected genes per cell, mitochondrial gene content, and Unique Molecular Identifier (UMI) counts to define quality criteria. The acceptance threshold for data quality varies depending on several factors such as the amount of replicated and\/or the cell type of organism (prokaryotic, eukaryotic, etc) used.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":6,
        "total_chunks":20,
        "content":"ch as the amount of replicated and\/or the cell type of organism (prokaryotic, eukaryotic, etc) used. Batch Effects Handling: Examining your data to check that the most important elements for the clustering\/cell comparison are biological and not technical. Exploring batch correction methods like {% tool \"harmony\" %} can help reduce technical biases in data integration. Biological Annotation: Use known marker genes or reference-based annotation to assign cell types or states to clusters. A database of known cell markers (like {% tool \"cellmarker\" %}) can be helpful. Each of these elements needs to be provided with a comprehensive description. Including details on the normalisation techniques applied, outlier removal strategies, and batch correction methods employed to enhance data quality and reliability. Data integration and analysis across experiments\nDescription\nThe analysis of single-cell sequencing data frequently requires the integration and comparative examination of data stemming from various experiments.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":7,
        "total_chunks":20,
        "content":"ntly requires the integration and comparative examination of data stemming from various experiments. Combining datasets to gain a broader perspective or comparing results from distinct experiments, navigating the intricacies of data integration, harmonisation, and interpretation is essential for extracting meaningful insights from single-cell sequencing data. This section addresses these considerations and provides solutions to facilitate the effective analysis and interpretation of integrated data, allowing researchers to draw comprehensive conclusions from diverse experimental sources. Considerations\n\nData Integration:  How to integrate data from different experiments while accounting for differences in experimental conditions? (e.g. sample control vs tested conditions with several time points)\nData Comparison: What approaches can be used to identify shared cell types and biological signals across datasets?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":8,
        "total_chunks":20,
        "content":"n: What approaches can be used to identify shared cell types and biological signals across datasets? (eg. sample WT vs KO comparison scATAC- and scRNA-seq)\nAnnotation Consistency: How should we manage metadata and annotations to ensure a consistent interpretation across experiments?\n\nSolutions\n\nData Integration and Data Comparison: Use a built-in method for data integration and comparison (such as {% tool \"seurat\" %} or {% tool \"scanpy\" %}), including normalisation, batch correction method and dimensionality reduction techniques to see their effect. Here the difficulty is to make sure the integration\/comparison is reliable, meaning being careful that the cell type annotations are consistent with previous knowledge and that the cell repartition is relevant. Annotation Consistency: Consistent metadata and annotation practices are needed, including standardised naming and format usage. Re-using terms from {% tool \"uniprot\" %} or {% tool \"gene-ontology\" %} should be considered.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":9,
        "total_chunks":20,
        "content":" usage. Re-using terms from {% tool \"uniprot\" %} or {% tool \"gene-ontology\" %} should be considered. Datatype consistency and interoperability across formats\nDescription\nSingle-cell sequencing data is encoded into many different competing formats, with  {% tool \"hierarchical-data-format\" %} (HDF5)-compatible formats such as {% tool \"anndata\" %} and {% tool \"loom\" %}, as well as other commonly-used formats such as {% tool \"seurat\" %}, {% tool \"celldataset\" %} (CDS) and {% tool \"singlecellexperiment\" %} (SCE). Each of these formats is favoured by their respective analysis suites; {% tool \"scanpy\" %}, {% tool \"seurat\" %}, {% tool \"monocle\" %} and {% tool \"scater\" %}. {% include image.html file=\"single_cell_img.png\" caption=\"Figure 1: Conversion routes for different datatypes from sceasy\" alt=\"Conversion routes for different datatypes from sceasy\" %}\nFigure 1 depicts the conversion routes of a popular conversion tool {% tool \"sceasy\" %}, which demonstrates the limited conversion potential between the different formats.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":10,
        "total_chunks":20,
        "content":"tool \"sceasy\" %}, which demonstrates the limited conversion potential between the different formats. Indeed, data are stored in a matrix composed of different layers, converting the format may lead to the loss of some of them as described in the image. Some of these formats use different programming languages to perform the conversion, such as the Loom format which requires a Python component. Considerations\n\nDatatype Preferences: Which datatypes should be actively maintained and supported, and which ones should be discouraged? Due to, for example, popularity level in the community, complexity of format, stability between versions? Datatype Support: Which datatypes do we actively support via bioinformatic cloud pipelines and tutorials?\n\nSolutions\n\nDatatype Preferences: The most common formats are AnnData from {% tool \"scanpy\" %} and SeuratObject from {% tool \"seurat\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":11,
        "total_chunks":20,
        "content":" most common formats are AnnData from {% tool \"scanpy\" %} and SeuratObject from {% tool \"seurat\" %}. There is waning support for {% tool \"loom\" %}, {% tool \"celldataset\" %} and {% tool \"singlecellexperiment\" %}, though {% tool \"singlecellexperiment\" %} is a common datatype for sharing single-cell experiments in publications. Datatype Support: {% tool \"seurat\" %} and {% tool \"scanpy\" %} are popular analysis workflows in {% tool \"galaxy\" %}, and it might be important to ensure that there is consistent and stable conversion potential between the two format (to allow the use of external tool that require the other format). Long-term data storage and accessibility\nDescription\nEnsuring the long-term storage and accessibility of single-cell sequencing data pose distinct challenges that demand attention. This section delves into the critical considerations for effectively storing and making single-cell sequencing data accessible over an extended period of time.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":12,
        "total_chunks":20,
        "content":"fectively storing and making single-cell sequencing data accessible over an extended period of time. Considerations\n\nEffective Archiving: What are the best practices for archiving and safeguarding extensive single-cell sequencing datasets to ensure their long-term preservation? Ethical Data Handling: How can we guarantee data privacy and adhere to ethical guidelines when sharing confidential single-cell data with the research community?\nCollaborative Platforms: Which platforms or repositories are suitable for simplifying data sharing and encouraging collaboration among researchers? Enhancing Reproducibility: What specific steps and formats should be employed to enable reproducibility in single-cell sequencing experiments?\n\nSolutions\n\n\nEffective Archiving: Use established data repositories such as {% tool \"gene-expression-omnibus\" %} (GEO) or {% tool \"arrayexpress\" %} for storage of experimental descriptive metadata and processed data such as count matrices.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":13,
        "total_chunks":20,
        "content":"ress\" %} for storage of experimental descriptive metadata and processed data such as count matrices. The corresponding raw sequencing data can be optimally archived at {% tool \"sequence-read-archive\" %} or {% tool \"european-nucleotide-archive\" %}. {% tool \"annotare\" %} can be used to facilitate deposition of data to the {% tool \"arrayexpress\" %} collection in {% tool \"biostudies\" %}. This tool offers support for various metadata standards; in the case of single-cell experiments it is recommended to follow the {% tool \"minsce\" %} guidelines. Ethical Data Handling: Emphasise the importance of informed consent and ethical considerations in data-sharing agreements. Following the privacy and ethical regulation of the hosting country or institution, using the data sharing infrastructure corresponding to the level of privacy required by the data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":14,
        "total_chunks":20,
        "content":"n, using the data sharing infrastructure corresponding to the level of privacy required by the data. Collaboration Platforms: Explore version control systems (e.g. {% tool \"git\" %}), data sharing platforms (e.g. {% tool \"zenodo\" %}), data analysis platforms (e.g. {% tool \"galaxy\" %}), and domain-specific repositories (e.g. {% tool \"single-cell-portal\" %}) to facilitate efficient data sharing, analysis, and collaboration. Enhancing Reproducibility: Guide on enhancing reproducibility, including the use of containerisation technologies such as {% tool \"docker\" %} to encapsulate analysis environments and to ensure analysis can be reproduced with the exact same tool version. Particularly, {% tool \"biocontainers\" %} comes in handy when dealing with bioinformatics tools. Prioritise the documentation for analysis workflows, code, and metadata using standardised formats and sharing them in version-controlled repositories. {% tool \"galaxy\" %} provides a solution for containerisation, versioning, workflow management and reproducibility for novice users.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":15,
        "total_chunks":20,
        "content":"solution for containerisation, versioning, workflow management and reproducibility for novice users. Data analysis steps and related format for single-cell sequencing\n\n\nRaw Sequencing Data:\n\nData Type: Raw FASTQ files for sequencing reads. Format: Compressed FASTQ format (*.fastq.gz). Explanation: Raw sequencing data is typically stored in compressed FASTQ format (*.fastq.gz). This format retains the original sequencing reads and is space-efficient. Compressed files reduce storage requirements while preserving data integrity. Cell-Gene Assignment:\n\nData Type: Cell-gene assignment matrix indicating gene expression levels per cell. Additionally, gene and cell annotations (e.g. gene symbols or batches, time points, genotypes) should be saved. Format: Standardised data matrix format, such as {% tool \"hierarchical-data-format\" %} (h5), h5ad from {% tool \"anndata\" %} or CSV.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":16,
        "total_chunks":20,
        "content":"x format, such as {% tool \"hierarchical-data-format\" %} (h5), h5ad from {% tool \"anndata\" %} or CSV. Explanation: The cell-gene assignment matrix, representing gene expression per cell, is best stored in a standardised format like {% tool \"hierarchical-data-format\" %} (h5), h5ad from {% tool \"anndata\" %} or CSV as it will allow the modification needed for the next step while being readable by most single-cell tools. Dimensionality Reduction and Clustering:\n\nData Type: Reduced-dimension representations (e.g. PCA, t-SNE) and cell clusters. Format: Include plots and files in common data visualisation formats (e.g. PDF, PNG). Explanation: Visual formats like PDF and PNG allow easy sharing and visualisation. Annotation and Biological Interpretation:\n\nData Type: Annotated cell types, differential gene expression results, and any other biologically meaningful annotations. Format: Structured and standardised annotation files, such as Excel spreadsheets, CSV or JSON, alongside visualisations like heatmaps or volcano plots in common visualisation formats.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":17,
        "total_chunks":20,
        "content":"SV or JSON, alongside visualisations like heatmaps or volcano plots in common visualisation formats. Explanation: Biologically meaningful annotations, including cell types and differential gene expression results, should be stored in structured formats. Visualisations like heatmaps or volcano plots should be included in standard visual formats for easy interpretation. Analysis Code and Environment:\n\nData Type: All code and scripts used for data preprocessing, analysis, and visualisation. Format: Version-controlled repositories using Git, or container files to capture analysis environments should be used. Detailed documentation for code execution should be provided. Explanation: Analysis code and scripts should be version-controlled using Git repositories. Additionally, capturing the analysis environment using Docker or Singularity container files helps to ensure reproducibility. Detailed documentation of code execution is essential for transparency and re-usability.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_18",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":18,
        "total_chunks":20,
        "content":"ducibility. Detailed documentation of code execution is essential for transparency and re-usability. Metadata:\n\nData Type: Comprehensive metadata describing experimental conditions, sample information, and data processing steps. Format: Structured metadata files in widely accepted formats like JSON, CSV or Excel spreadsheets, following community-specific metadata standards if available. Explanation: Following community-specific metadata standards, if available, ensures consistency and compatibility with other datasets. By preserving these steps and data in standardised and accessible formats, researchers can enhance the reproducibility of single-cell sequencing experiments, facilitate collaboration, and ensure that others can validate and build upon their work effectively. Other additional files can be kept if useful for the interpretation (e.g. for scATAC-seq, the results files containing sequence fragments or mapping can be important, they should be kept in standardised format: tsv, bam, bed or bigwig).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_content_single_cell_sequencing_md_19",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/single_cell_sequencing.md",
        "file_name":"single_cell_sequencing.md",
        "chunk_index":19,
        "total_chunks":20,
        "content":"s or mapping can be important, they should be kept in standardised format: tsv, bam, bed or bigwig). An overview of the best practice can be found following the {% tool \"single-cell-best-pratices\" %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"single_cell_sequencing.md",
            "language":"en",
            "frontmatter":{
                "title":"Single-cell sequencing",
                "description":"Managing data generated from single-cell sequencing experiments.",
                "contributors":[
                    "Johan Rollin",
                    "Pavankumar Videm",
                    "Mehmet Tekman"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "galaxy",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Single-cell training on the Galaxy Training Network",
                        "url":"https:\/\/usegalaxy.eu\/training-material\/topics\/single-cell\/"
                    }
                ],
                "page_id":"single_cell_sequencing"
            }
        }
    },
    {
        "id":"md_fm_epitranscriptome_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/epitranscriptome_data.md",
        "file_name":"epitranscriptome_data.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Ernesto Picardi\n- Laura Portell Silva\ndescription: Data management solutions for epitranscriptome data. page_id: epitrans\nrelated_pages:\n  tool_assembly: []\n  your_tasks: []\ntitle: Epitranscriptome data",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"epitranscriptome_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_epitranscriptome_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/epitranscriptome_data.md",
        "file_name":"epitranscriptome_data.md",
        "chunk_index":0,
        "total_chunks":7,
        "content":"Introduction\nEpitranscriptome modifications are emerging as important factors to fine tune gene expression and regulation in a variety of organisms and experimental conditions. To date more than 100 distinct chemical modifications to RNA have been characterized, including transient (i.e. m6A or m1A or m5C) and not-transient (A-to-I or C-to-U RNA editing) nucleotide variants. In the last few years, several methods based on deep sequencing technologies (RNAseq or MeRIPseq or miCLIP or direct RNA sequencing) have been optimized to profile the epitranscriptome in humans and various model organisms. The detection of RNA modifications requires ad hoc bioinformatics pipelines as well as the use of computing intensive tools to handle the huge amount of available deep transcriptome sequencing experiments.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"epitranscriptome_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Epitranscriptome data",
                "description":"Data management solutions for epitranscriptome data.",
                "contributors":[
                    "Ernesto Picardi",
                    "Laura Portell Silva"
                ],
                "page_id":"epitrans",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_epitranscriptome_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/epitranscriptome_data.md",
        "file_name":"epitranscriptome_data.md",
        "chunk_index":1,
        "total_chunks":7,
        "content":"ng intensive tools to handle the huge amount of available deep transcriptome sequencing experiments. A fruitful organization of data and computational workflows is therefore important to make data in the epitranscriptome domain interoperable and resuable in line with the FAIR (Findable, Accessible, Interoperable and Reusable) principles. Collection of research data\nDescription\nSeveral high-throughput experimental approaches have been developed for profiling the transcriptome-wide distribution of RNA modifications. While not-transient changes (RNA editing) can be detected using standard RNAseq data, RNA modifications like m6A or m1A or m5C can be identified by a variety of antibody based methods such as MeRIPseq or miCLIP and by means of the RNA directed sequencing. In order to make the data understandable and reusable, it is important to define the sequencing protocol adopted to produce data as well as related metadata. Considerations\n\nAre you planning to profile transient or not-transient RNA modifications? Is the method based on the RNA directed sequencing?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"epitranscriptome_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Epitranscriptome data",
                "description":"Data management solutions for epitranscriptome data.",
                "contributors":[
                    "Ernesto Picardi",
                    "Laura Portell Silva"
                ],
                "page_id":"epitrans",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_epitranscriptome_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/epitranscriptome_data.md",
        "file_name":"epitranscriptome_data.md",
        "chunk_index":2,
        "total_chunks":7,
        "content":"le transient or not-transient RNA modifications? Is the method based on the RNA directed sequencing? Do you collect your own data or reuse them from public databases? Solutions\n\nDefine the sequencing protocol depending on the target RNA modification (transient or not-transient). In case of using data from public databases, carefully look at the method used to generate them. Prefer profiling methods allowing the detection of RNA modifications at single nucleotide level. Epitranscriptome data is generally reused from literature or public and established databases, such as {% tool \"rediportal\" %}. All data must have an identifier from the original database that it comes from. The source database is used also to retrieve metadata. Processing and analysis of epitranscriptome data\nDescription\nEpitranscriptome is a novel field and in rapid expansion. Since a variety of transcriptome-wide sequencing methods exist, several computational tools have been developed. It is important here to decide which pipeline to adopt.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"epitranscriptome_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Epitranscriptome data",
                "description":"Data management solutions for epitranscriptome data.",
                "contributors":[
                    "Ernesto Picardi",
                    "Laura Portell Silva"
                ],
                "page_id":"epitrans",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_epitranscriptome_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/epitranscriptome_data.md",
        "file_name":"epitranscriptome_data.md",
        "chunk_index":3,
        "total_chunks":7,
        "content":"ral computational tools have been developed. It is important here to decide which pipeline to adopt. Considerations\n\nWhat are the compute resources you need to analyse your data? Do you have data storage problems due to the size of the data?\nAre you using RNAseq data? Are you profiling or transient not-transient RNA modifications? Solutions\n\nThe current pipeline for RNA editing ({% tool \"reditools\" %}) requires the use of time intensive computational resources to browse position by position all genomic sites covered by RNAseq reads. In order to overcome that, a novel tool ({% tool \"reditools2\" %}) able to employ HPC resources and reduce the computing time has been developed. However, for transient modifications identified by direct RNA sequencing, compute intensive tools are still required. The computational speed up could be obtained by using GPU graphical cards. In general, for standard RNAseq experiments, each sample requires 8-10 CPUs and at least 8-10 GB of RAM memory. Direct RNA sequencing, instead, requires 8-10 CPUs, at least 1 GPU and 8-10 GB of RAM memory.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"epitranscriptome_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Epitranscriptome data",
                "description":"Data management solutions for epitranscriptome data.",
                "contributors":[
                    "Ernesto Picardi",
                    "Laura Portell Silva"
                ],
                "page_id":"epitrans",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_epitranscriptome_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/epitranscriptome_data.md",
        "file_name":"epitranscriptome_data.md",
        "chunk_index":4,
        "total_chunks":7,
        "content":"emory. Direct RNA sequencing, instead, requires 8-10 CPUs, at least 1 GPU and 8-10 GB of RAM memory. Once a pipeline has been adopted, it should be used for all samples. Data storage is a big issue and not all intermediate files produced during the analyses can be maintained. However, since original data are easily and always available from public sources, analysis files are stored until the end of the established computational workflow. Then, only the final table file including epitranscriptomic variants are recovered and included in {% tool \"rediportal\" %}. Although this procedure could be time consuming in case of important updates, such as the adoption of a novel genome assembly, it preserves the storage requirements. Epitranscriptome experts often provide reviews on the best tools and practices, so a good starting point is to read such publications. A good example is Investigating RNA editing in deep transcriptome datasets with REDItools and REDIportal. For RNA editing events, prefer RNAseq data from total and rRNA depleted RNA.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"epitranscriptome_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Epitranscriptome data",
                "description":"Data management solutions for epitranscriptome data.",
                "contributors":[
                    "Ernesto Picardi",
                    "Laura Portell Silva"
                ],
                "page_id":"epitrans",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_epitranscriptome_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/epitranscriptome_data.md",
        "file_name":"epitranscriptome_data.md",
        "chunk_index":5,
        "total_chunks":7,
        "content":"DItools and REDIportal. For RNA editing events, prefer RNAseq data from total and rRNA depleted RNA. Strand oriented reads will improve the read mappability, mitigating mis-mapping biases. Preservation, sharing and reuse of analysis results\nDescription\nStoring epitranscriptome data is relevant for investigating the biological properties of RNA modifications and facilitating the sharing and reuse. Considerations\n\nWhich kind of RNA modifications are you studying? Do you have data storage problems when preserving the data? Can epitranscriptome data be openly shared? Solutions\n\nFor long term storage and for preserving epitranscriptome data, raw reads have to be submitted to public databases. This is a mandatory requirement to upload epitranscriptomic annotations in specialized databases. In case of data deposited in public databases such as ENA or SRA, RNA modifications could be uploaded in dedicated databases as {% tool \"rediportal\" %}. To avoid the storage of a large amount of files, raw data is used to complete all computational steps.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"epitranscriptome_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Epitranscriptome data",
                "description":"Data management solutions for epitranscriptome data.",
                "contributors":[
                    "Ernesto Picardi",
                    "Laura Portell Silva"
                ],
                "page_id":"epitrans",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_epitranscriptome_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/epitranscriptome_data.md",
        "file_name":"epitranscriptome_data.md",
        "chunk_index":6,
        "total_chunks":7,
        "content":" avoid the storage of a large amount of files, raw data is used to complete all computational steps. Soon after, they are removed as well as intermediate files. Only final tables are preserved and stored in our portal. Data is actually preserved because raw data is always available through public and established databases. All data included in the REDIportal, including individual variants, annotations and metadata, is sharable and open. Only one database is mentioned here because there is the plan of having a unique and individual resource for epitranscriptome data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"epitranscriptome_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Epitranscriptome data",
                "description":"Data management solutions for epitranscriptome data.",
                "contributors":[
                    "Ernesto Picardi",
                    "Laura Portell Silva"
                ],
                "page_id":"epitrans",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_fm_human_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"contributors:\n- Niclas Jareborg\n- Nirupama Benis\n- Ana Portugal Melo\n- Pinar Alper\n- Laura Portell Silva\n- Wolmar Nyberg kerstrm\n- Nazeefa Fatima\n- Vilem Ded\n- Teresa D'Altri\ndescription: Data management solutions for human data.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"human_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_human_data_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"- Nazeefa Fatima\n- Vilem Ded\n- Teresa D'Altri\ndescription: Data management solutions for human data. dsw:\n- name: Will you collect any data connected to a person, \"personal data\". uuid: 49c009cb-a38c-4836-9780-8a8b3dd1cbac\n- name: Will you be allowing authenticated access to the data. uuid: 55f03a4a-034b-422a-adf6-757416b7650a\n- name: Does the collection of data involve human subjects. uuid: b464593d-fb92-4ad9-88e1-764306bb3051\n- name: Are personal data sufficiently protected. uuid: d5990471-0618-42cd-92cb-bbbfd4f61532\npage_id: human_data\nrelated_pages:\n  tool_assembly:\n  - tsd\n  - covid19_data_portal\n  - transmed\n  - fairtracks\n  your_tasks:\n  - sensitive\n  - gdpr_compliance\ntitle: Human data\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess. elixir-europe. org\/search. q=sensitive%20human%20data\n- name: A FAIR guide for data providers to maximise sharing of human genomic data\n  url: https:\/\/journals. plos. org\/ploscompbiol\/article. id=10. 1371\/journal. pcbi. 1005873\n- name: Toward better governance of human genomic data\n  url: https:\/\/tess. elixir-europe.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"human_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_human_data_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":". 1005873\n- name: Toward better governance of human genomic data\n  url: https:\/\/tess. elixir-europe. org\/search. q=sensitive%20human%20data\n- name: OMOP Common Data Model and the OHDSI analytics for observational analytics\n    of real world healthcare data courses in EHDEN academy\n  url: https:\/\/academy. ehden. eu\/.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"human_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_human_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":0,
        "total_chunks":19,
        "content":"Introduction\nWhen you do research on data derived from human individuals (hereon human data), there are additional aspects that must be considered during the data life cycle. Note, much of the topics discussed on this page will refer to the General Data Protection Regulation (GDPR) as it is a central piece of legislation that affects basically all research taking place in the European Union (EU) using human data or research with data of individuals residing in the EU. Much of the information on this page is of a general nature when it comes to working with human data, an additional focus is on human genomic data and the sharing of such information for research purposes. Planning for projects with human data\nDescription\nWhen working with human data, you must follow established research ethical guidelines and legislations.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":1,
        "total_chunks":19,
        "content":"n working with human data, you must follow established research ethical guidelines and legislations. Preferably, planning for these aspects should be done before starting to handle personal data and in some cases such as in the case of the GDPR, it is an important requirement by laws and regulations. Considerations\n\nHave you got an ethical permit for your research project? To get an ethical permit, you have to apply for an ethical review by an ethical review board. The legislation that governs this differs between countries. Do seek advice from your research institute. The Global Alliance for Genomics and Health (GA4GH) has recommendations for these issues in their GA4GH regulatory and ethical toolkit, see for instance the {% tool \"consent-clauses-for-genomic-research\" %}. The acquisition of data must be legal. Receiving data\/samples directly from data subjects requires in most cases informed consents. An informed consent is an agreement from the research subject to participate in and share personal data for a particular purpose.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":2,
        "total_chunks":19,
        "content":"eement from the research subject to participate in and share personal data for a particular purpose. It shall describe the purpose and any risks involved (along with any mitigations to minimise those risks) in such a way that the research subject can make an informed choice about participating. It should also state under what circumstances the data can be used for the initial purpose, as well as for later re-use by others. Consider adoption of formalised machine-readable description of data use conditions. This will greatly improve the possibilities to make the data FAIR later on. Informed consents should be acquired for different purposes:\nIt is a cornerstone of research ethics. Regardless of legal obligations, it is important to ask for informed consents as it is a good research ethics practice and maintains trust in research. Ethical permission legislation to perform research on human subjects demand informed consents in many cases. Personal data protection legislation might have informed consent as one legal basis for processing the personal data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":3,
        "total_chunks":19,
        "content":"tection legislation might have informed consent as one legal basis for processing the personal data. Note that the content of an informed consent, as defined by one piece of legislation, might not live up to the demands of another piece of legislation. For example, an informed consent that is good enough for an ethical permit, might not be good enough for the demands of the GDPR. Receiving data from a collaborator must be covered by a contract. Ensure detailed provisions on data use, retention, re-use and publication are included in the agreements (Data Use agreement, Consortium agreement, Data Sharing agreement, ...). This applies also to samples you receive from a collaborator. Related contract (e.g. Material Transfer Agreement - MTA) should cover use of human data generated from these samples. Incomplete legal framework for the data use can require lengthy legal amendments and can result in your in-ability to comply with requirements set out by your funder or targeted publisher. Receiving data from a repository also comes with certain use restrictions.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":4,
        "total_chunks":19,
        "content":"er or targeted publisher. Receiving data from a repository also comes with certain use restrictions. These are either defined in the license attributed to the data or defined in a dataset specific access policy and terms of service of the repository. Personal data protection legislation:\nWithin the EU. If you are performing human data research in the EU, or your data subjects are located in the EU, then you must adhere to the General Data Protection Regulation - GDPR. Requirements for research that fall under the GDPR are outlined in the RDMkit GDPR compliance page. Attributes of the data determines data sensitivity and  sensitivity affects the considerations for data handling. The RDMkit Data Sensitivity page provides guidance on determining and reducing data sensitivity. Outside the EU. For countries outside the EU, the {% tool \"international-compilation-of-human-research-standards\" %} list relevant legislations. Solutions\n\n{% tool \"tryggve-elsi-checklist\" %} is a list of Ethical, Legal, and Societal Implications (ELSI) to consider for research projects on human subjects.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":5,
        "total_chunks":19,
        "content":"thical, Legal, and Societal Implications (ELSI) to consider for research projects on human subjects. {% tool \"daisy\" %} is software tool from ELIXIR that allows the record keeping of data processing activities in research projects. {% tool \"dawid\" %} is a software tool from ELIXIR that allows generation of tailor-made data sharing agreements\n{% tool \"pia\" %} is a software tool to make Data Protection Impact Assessments. {% tool \"monarc\" %} is a risk assessment tool that can be used to do Data Protection Impact Assessments\n{% tool \"data-use-ontology\" %}\n{% tool \"informed-consent-ontology\" %}\n{% tool \"ga4gh-regulatory-and-ethics-toolkit\" %}\n{% tool \"eu-general-data-protection-regulation\" %}\n{% tool \"bbmri-eric-s-elsi-knowledge-base\" %} contains a glossary, agreement templates and guidance. Processing and analysing human data\nDescription\nFor human data, it is very important to use technical and procedural measures to ensure that the information is kept secure. There might exist legal obligations to document and implement measures to ensure an adequate level of security.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":6,
        "total_chunks":19,
        "content":" exist legal obligations to document and implement measures to ensure an adequate level of security. Considerations\n\nEstablish adequate Information security measures. This should be done for all types of research data, but is even more important for human data. Information security is usually described as containing three main aspects - Confidentiality, Integrity, and Accessibility. Confidentiality is about measures to ensure that data is kept confidential from those that do not have rights to access the data. Integrity is about measures to ensure that data is not corrupted or destroyed. Accessibility is about measures to ensure that data can be accessed by those that have a right to access it, when they need to access it. Information security measures are both procedural and technical. What information security measures that need to be established should be defined at the planning stage (see above), when doing a risk assessment, e.g. the GDPR Data Protection Impact Assessment. This should identify information security risks, and define measures to mitigate those risks.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":7,
        "total_chunks":19,
        "content":"sment. This should identify information security risks, and define measures to mitigate those risks. Contact the IT or Information security office at your institution to get guidance and support to address these issues. {% tool \"iso-iec-27001\" %} is an international information security standard adopted by data centres of some universities and research institutes. Check whether there are local\/national tools and platforms suited to handle human data. Local research infrastructures have established compute and\/or storage solutions with strong information security measures tailored for working on human data. The RDMkit national resources page lists the sensitive data support facilities available in various countries. Contact your institute or your ELIXIR node for guidance. There are also emerging alternative approaches to analyse sensitive data, such as doing distributed computation, where defined analysis workflows are used to do analysis on datasets that do not leave the place where they are stored.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":8,
        "total_chunks":19,
        "content":"sis workflows are used to do analysis on datasets that do not leave the place where they are stored. The GA4GH is developing standards for this in their GA4GH Cloud workstream\n\n\nTake data quality into account. When processing human data, data quality is a very important aspect to consider because it can influence the results of the research. Especially in the healthcare sector, some of the data that is used for research was not collected for research purposes, and therefore it is not guaranteed to have sufficient quality. Check the RDMkit Data Quality page to learn more about how to assess the quality of health data. Solutions\n\n{% tool \"eupid\" %} is a tool that allows researchers to generate unique pseudonyms for patients that participate in rare disease studies. {% tool \"rd-connect-genome-phenome-analysis-platform\" %} is a platform to improve the study and analysis of Rare Diseases. {% tool \"disgenet\" %} is a platform containing collections of genes and variants associated to human diseases.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":9,
        "total_chunks":19,
        "content":"isgenet\" %} is a platform containing collections of genes and variants associated to human diseases. {% tool \"pymut\" %} is a Python3 module that helps in the prediction of pathology in protein mutations. {% tool \"intogen\" %} collects and analyses somatic mutations in thousands of tumor genomes to identify cancer driver genes. {% tool \"boostdm\" %} is a method to score all possible point mutations in cancer genes for their potential to be involved in tumorigenesis. {% tool \"cancer-genome-interpreter\" %} is designed to identify tumor alterations that drive the disease and detect those that may be therapeutically actionable. GA4GH's Data Security, and {% tool \"ga4gh-genomic-data-toolkit\" %} provide policies, standards for the secure transfer and processing of human genomics data. GA4GH standards are often implemented into multiple tools. For example, the Crypt4GH data encryption standard is implemented both in SAMTools and also provided as a utility from the EGA Archive, {% tool \"crypt4gh\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":10,
        "total_chunks":19,
        "content":"emented both in SAMTools and also provided as a utility from the EGA Archive, {% tool \"crypt4gh\" %}. GA4GH's Cloud Workstream is a more recent initiative and focuses on keeping data in secure cloud environments and meanwhile bringing computational analysis to the data. The {% tool \"erpa\" %} is a Web-based tool allowing users to create and manage a register of personal data processing activities (ROPA). {% tool \"otp\" %} is a data management platform for running bioinformatics pipelines in a high-throughput setting, and for organising the resulting data and metadata. Preserving human data\nDescription\nIt is a good ethical practice to ensure that data underlying research is preserved, preferably in a way that adheres to the FAIR principles. There might also exist legal obligations to preserve the data. With human data, you have to take extra precautions into account when doing this.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":11,
        "total_chunks":19,
        "content":"preserve the data. With human data, you have to take extra precautions into account when doing this. Considerations\n\nDepositing data in an international repository\nTo make the data as accessible as possible according to the FAIR principles, do deposit the data in an international repository under controlled access whenever possible, see the section Sharing & Reusing of human data below\nLegal obligations for preserving research data In some countries there are legal obligations to preserve research data long-term, e.g. for ten years. Even if the data has been deposited in an international repository, this might not live up to the requirements of the law. The legal responsibility for preserving the data would in most cases lie with the research institution where you perform your research. You should consult the Research Data and\/or IT support functions of your institution. Information security\nThe solutions you use need to provide information security measures that are appropriate for storing personal data, see the section Processing and Analysing human data above.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":12,
        "total_chunks":19,
        "content":"re appropriate for storing personal data, see the section Processing and Analysing human data above. Note that the providers of the solutions must be made aware that there are probably extra information security measures needed for long-term storage of this type of data. Regardless of where your data is preserved long-term, do ensure that it is associated with proper metadata according to community standards, to promote FAIR sharing of the data. Planning for long-term storage\nDo address these issues of long-term preservation and data publication as early as possible, preferably already at the planning stage. If you are relying on your research institution to provide a solution, it might need time to plan for this. Solutions\n\n{% tool \"ga4gh-data-security-toolkit\" %}\n{% tool \"iso-iec-27001\" %} is an international information security standard adopted by data centres of some universities and research institutes.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":13,
        "total_chunks":19,
        "content":" information security standard adopted by data centres of some universities and research institutes. {% tool \"the-european-genome-phenome-archive\" %} is an international service for secure archiving and sharing of all types of personally identifiable genetic and phenotypic data resulting from biomedical studies and healthcare centres. All services are free of charge. The EGA stores the data and metadata long-term, without ending date of the service. The data is backed-up in two separate geographical locations. The storing is GDPR-compliant, thanks to the use of Ga4GH encryption standard and continuously kept up-to-date. National repositories working as Federated EGA nodes are available in some countries like Sweden, Norway, Finland, Germany and Spain. Those may address specific additional national legal needs, not included in European regulation. {% tool \"dpia-knowledge-model\" %} is a DSW knowledge model guiding users through a set of questions to collect information necessary for a research project Data Protection Impact Assessment (DPIA).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":14,
        "total_chunks":19,
        "content":"ns to collect information necessary for a research project Data Protection Impact Assessment (DPIA). Sharing and reusing of human data\nDescription\nTo make human data reusable for others, it must be discoverable, stored in a safe way, and it must be clear under what circumstances it can be reused. Considerations\n\nSelecting suitable access modes for sharing human data:\n\nHuman data often carries restrictions to its use and it would need to be shared in a manner that obeys such restrictions. There are three access modes for sharing research data:\n\nOpen access: Data is shared publicly. Open-access is a rarely used access mode for the sharing of human data. To use open-access researchers need to ensure that the shared data cannot be traced back to individual study participants. In other words the data needs to be anonymised, which is difficult in practice. Registered access: Data is shared with researchers, whose researcher status has been vouched for by their institution and who agree to abide by data usage policies of repositories that serve the shared data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":15,
        "total_chunks":19,
        "content":"nstitution and who agree to abide by data usage policies of repositories that serve the shared data. Datasets that are shared via registered-access would typically have no restrictions besides the condition that data is to be used for research. Controlled access: Data can only be shared with researchers, whose research is reviewed and approved by a Data Access Committee (DAC) - typically,  researchers who are\/were involved in the primary collection of data will form the DAC. Use conditions for controlled-access could be a multitude and includes allowed research topics, allowed geographical regions, allowed recipients e.g. non-profit organisations. Publishing human data: It is highly recommended that human data is shared under controlled access. There are emerging models of sharing data through repositories under federated models. Transferring human data:\nTransferring human data has to be done in a secure way in order to avoid breaches of privacy.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":16,
        "total_chunks":19,
        "content":" data:\nTransferring human data has to be done in a secure way in order to avoid breaches of privacy. Encrypting of human data whilst it is being transferred provides successful protection if the data is intercepted by an external party while the transfer is being done. Solutions\n\nThe {% tool \"the-european-genome-phenome-archive\" %} is an international service for secure archiving and sharing of all types of personally identifiable genetic and phenotypic data resulting from biomedical studies and healthcare centres. All services are free of charge. The EGA platform offers secure and European law-compliant data sharing. Data treatment is FAIR-compliant, thus data is discoverable in the EGA website and shareable with other researchers through authorisation and authentication protocols. The right to allow access to any dataset belongs to the Data controllers (and not to the EGA), who are responsible to sign a Data Access Agreement (DAA) with researchers requesting access to their data. Templates of the legal documents are provided.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":17,
        "total_chunks":19,
        "content":"AA) with researchers requesting access to their data. Templates of the legal documents are provided. The EGA hosts data from all around the world and distributes it where and when the data controllers permit. {% tool \"dbgap\" %} and {% tool \"jga\" %} are other international data repositories, based in the USA and Japan respectively, that adopt a controlled-access model based on their national regulations. Due to European GDPR specific requirements, it may not be possible to deposit EU subjects data to these repositories. The {% tool \"beacon\" %} project is a GA4GH initiative that enables genomic and clinical data sharing across federated networks. A Beacon is defined as a web-accessible service that can be queried for information about a specific allele with no reference to a specific sample or patient, thereby reducing privacy risks. The {% tool \"data-use-ontology\" %} is an international standard, which provides codes to represent data use restrictions for controlled access datasets.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_human_data_md_18",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_data.md",
        "file_name":"human_data.md",
        "chunk_index":18,
        "total_chunks":19,
        "content":"al standard, which provides codes to represent data use restrictions for controlled access datasets. {% tool \"crypt4gh\" %} is a Python tool to encrypt, decrypt or re-encrypt files, according to the GA4GH encryption file format. {% tool \"humanmine\" %} is an integrative database of Homo sapiens genomic data, that integrates many types of human data and provides a powerful query engine, export for results, analysis for lists of data and FAIR access via web services.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Human data",
                "description":"Data management solutions for human data.",
                "contributors":[
                    "Niclas Jareborg",
                    "Nirupama Benis",
                    "Ana Portugal Melo",
                    "Pinar Alper",
                    "Laura Portell Silva",
                    "Wolmar Nyberg kerstrm",
                    "Nazeefa Fatima",
                    "Vilem Ded",
                    "Teresa D'Altri"
                ],
                "page_id":"human_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"A FAIR guide for data providers to maximise sharing of human genomic data",
                        "url":"https:\/\/journals.plos.org\/ploscompbiol\/article?id=10.1371\/journal.pcbi.1005873"
                    },
                    {
                        "name":"Toward better governance of human genomic data",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=sensitive%20human%20data"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Will you be allowing authenticated access to the data?",
                        "uuid":"55f03a4a-034b-422a-adf6-757416b7650a"
                    },
                    {
                        "name":"Does the collection of data involve human subjects?",
                        "uuid":"b464593d-fb92-4ad9-88e1-764306bb3051"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_human_pathogen_genomics_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Diana Pilvar\n- Espen berg\n- Wolmar Nyberg kerstrm\n- Rafael Andrade Buono\ndescription: Data management solutions for Human pathogen genomics\npage_id: human_pathogen_genomics\nrelated_pages:\n  tool_assembly:\n  - covid-19\n  your_tasks:\n  - data_brokering\n  - metadata\n  - transfer\n  - data_security\n  - data_quality\ntitle: Human pathogen genomics",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"human_pathogen_genomics.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":0,
        "total_chunks":16,
        "content":"Introduction\nThe human pathogen genomics domain focuses on studying the genetic code of organisms that cause disease in humans. Studies to identify and understand pathogens are conducted across different types of organisations ranging from research institutes to regional public health authorities. The aims can include urgent outbreak response, prevention measures, and developing remedies such as treatments and vaccines. Data management challenges in this domain include the potential urgency of data sharing and secondary use of data across initiatives emerging from research, public health and policymakers. While pathogenic organisms are the object of interest, there are many considerations to take into account when dealing with samples collected from patients, pathogen surveillance, and human research subjects.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":1,
        "total_chunks":16,
        "content":"en dealing with samples collected from patients, pathogen surveillance, and human research subjects. The genomic data can represent anything from the genetic sequence of a single pathogen isolate to various fragments of genetic materials from a flora of pathogens in a larger population. Other data can represent a wide range of contextual information about the human host, the disease, and various environmental factors. Planning a study with pathogen genomic data\nDescription\nWhile the objects of interest in this domain are pathogens, the data is usually derived from samples originating from human research subjects. This means that you must plan to either remove or handle human data during your study. Considerations\n\nWhat legal and ethical aspects do you need to consider? Can you separate pathogen and human host material and data? What data protection measures should be implemented in contracts and procedures dealing with suppliers and collaborators? What is the appropriate scope for the legal and ethical agreements necessary for the study?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":2,
        "total_chunks":16,
        "content":"orators? What is the appropriate scope for the legal and ethical agreements necessary for the study? How should statements related to data processing be phrased to allow timely and efficient data sharing? How much time would be required to negotiate access to the samples and data for the study? What public health and research initiatives should you consider aligning with? What data could be shared with or reused from other initiatives during the project? How will you align your practices with these initiatives to maximise the impact of the data and insight generated by the project? How will you share data with your collaborators and other initiatives? What conventions will you adopt when planning your study? What existing protocols should you consider adopting for sample preparation, sequencing, variant calling and other operations? What conventions should you adopt for documenting your research? Solutions\nWorking with human data\n\nEnsure that the projects procedures conform with good practices for handling human data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":3,
        "total_chunks":16,
        "content":"uman data\n\nEnsure that the projects procedures conform with good practices for handling human data. In particular, the following sections of the RDMkit:\nPlanning for projects with human data\nProcessing and analysing human data\nYou can also check the practices included in the {% tool \"idtk\" %} related to the management of human and pathogen data in the context of infectious diseases. Isolate pathogen from host information\n\nDepending on the pathogen and how it interacts with the host or the methods applied, it can be possible to generate clean isolates that do not contain host-related material. Data produced from a clean isolate could potentially be handled with fewer restrictions, while other data will be considered to be sensitive and will need protection. Public health initiatives\n\nNational and international recommendations from public health authorities, epidemic surveillance programs and research data communities should be considered when planning a new study or surveillance programme.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":4,
        "total_chunks":16,
        "content":" research data communities should be considered when planning a new study or surveillance programme. In particular, you could consult conventions for relevant surveillance programs while considering widely adopted guidelines for research documentation, and instructions from the data-sharing platforms. European Centre for Disease Prevention and Control (ECDC) coordinates Disease and laboratory networks and also issues Surveillance and reporting protocols and other Technical guidance on sequencing. WHO issued genomic surveillance strategy and guidance on implementation for maximum impact on public health and there are published reports that advise on Implementing Quality Management Systems in Public Health Laboratories. Refer to National resources for information on regional authorities and national considerations.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":5,
        "total_chunks":16,
        "content":"es. Refer to National resources for information on regional authorities and national considerations. Sequencing experiments\n\nGood practices for genome experiments suggest that the documentation, at a minimum, should describe the design of the study or surveillance program, the collected specimens and how the samples were prepared, the experimental setup and protocols, and the analysis workflow. Adopt specific genomics and pathogen genomics recommendations such as those outlined in Stevens2020{%cite \"stevens2020Ten\" %}. Refer to the general guidance on providing documentation and metadata during your project. Adopt standards, conventions and robust protocols to maximise the reuse potential of the data in parallel initiatives and your future projects. The Genomic Standards Consortium (GSC) develops and maintains the {% tool \"mixs\" %} and the {% tool \"migs-mims\" %} set of core and extended descriptors for genomes and metagenomes with associated samples and their environment to guide scientists on how to capture the metadata essential for high-quality research.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":6,
        "total_chunks":16,
        "content":" environment to guide scientists on how to capture the metadata essential for high-quality research. The GenEpiO Consortium develops and maintains the {% tool \"genepio\" %} to support data sharing and integration specifically for foodborne infectious disease surveillance and outbreak investigations. The Public Health Alliance for Genomic Epidemiology (PHA4GE) supports openness and interoperability in public health bioinformatics. The Data Structures working group develops, adapts and standardises data models for microbial sequence data, contextual metadata, results and workflow metrics, such as the SARS-CoV-2 contextual data specification.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":7,
        "total_chunks":16,
        "content":"extual metadata, results and workflow metrics, such as the SARS-CoV-2 contextual data specification. The International Organization for Standardization (ISO) has issued standards that can be referenced when designing or commissioning genomic sequencing and informatics services, such as \nISO 20397-1:2022 Biotechnology  Massively parallel sequencing  Part 1: Nucleic acid and library preparation\nISO 20397-2:2021 Biotechnology  Massively parallel sequencing  Part 2: Quality evaluation of sequencing data\nISO\/TS 20428:2017 Health informatics  Data elements and their metadata for describing structured clinical genomic sequence information in electronic health records\nISO\/TS 22692:2020 Genomics informatics  Quality control metrics for DNA sequencing\nISO 23418:2022 Microbiology of the food chain  Whole genome sequencing for typing and genomic characterization of bacteria  General requirements and guidance\n\n\n\nCollecting and processing pathogen genomic data\nConsiderations\n\nWhat information should you consider recording when collecting data?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":8,
        "total_chunks":16,
        "content":"en genomic data\nConsiderations\n\nWhat information should you consider recording when collecting data? What should you note when collecting, storing, and preparing the samples? How will you capture information about the configuration and quality of the sequencing results? How will you ensure that the captured information is complete and correct? What data and file formats should you consider for your project? What are the de-facto standards used for the experiment type and downstream analysis pipelines? Where are the instrument-specific aspects of the data and file formats documented? What existing data will you integrate or use as a reference in your project? What reference genome(s) will you need access to?\nWhat is the recommended citation for the data and their versions?\n\nSolutions\nFiltering genomic reads corresponding to human DNA fragments\n\nData files with reads produced by sequencing experiments sometimes contain fragments of the host organisms DNA.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":9,
        "total_chunks":16,
        "content":"ith reads produced by sequencing experiments sometimes contain fragments of the host organisms DNA. When the host is a human research subject, these fragments can be masked or removed to produce files that could potentially be handled with fewer restrictions. The approach chosen to mask the host-associated reads leads to different trade-offs. Make sure to include this as a factor in your risk assessment. Mapping to (human) host reference genomes can inadvertently leave some host-associated reads unmasked {% cite \"bush2020Evaluation\" %}. Mapping to pathogens reference genomes can inadvertently mask some pathogen-associated reads and still leave some host-associated reads unmasked\nRemoval of human reads from SARS-CoV-2 sequencing data | Galaxy training\n\nContextual information about the sample\n\nInformation about the host phenotype, context, and disease is often necessary to answer questions in a research study or policy perspective.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":10,
        "total_chunks":16,
        "content":"ntext, and disease is often necessary to answer questions in a research study or policy perspective. Other contextual information can include non-host-related environmental factors, such as interactions with other pathogens, drugs and geographic proliferation. It can also include information about the sampled material and how it was processed for sequencing. Adopt common reporting checklists, data dictionaries, terms and vocabularies to simplify data sharing across initiatives. {% tool \"european-nucleotide-archive\" %} hosts a selection of sample checklists that can be used to annotate sequencing experiments, including checklists derived from {% tool \"mixs\" %}. The ENA virus pathogen reporting standard checklist has been widely used for SARS-CoV-2 genomic studies. Reuse terms and definitions from existing vocabularies, such as the {% tool \"pato\" %}, {% tool \"ncbi-taxonomy\" %}, {% tool \"doid\" %}, {% tool \"chebi\" %}, and {% tool \"uberon\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":11,
        "total_chunks":16,
        "content":"ato\" %}, {% tool \"ncbi-taxonomy\" %}, {% tool \"doid\" %}, {% tool \"chebi\" %}, and {% tool \"uberon\" %}. The PHA4GE SARS-CoV-2 contextual data specification is a comprehensive example including a reporting checklist, related protocols, and mappings to relevant vocabularies and data sharing platforms. Generating genomic data\n\nEstablish protocols and document the steps taken in the lab to process the sample and in the computational workflow to prepare the resulting data. Make sure to keep information from quality assurance procedures and strive to make your labwork and computational process as reproducible as possible. High-Throughput Sequencing | LifeScienceRDMLookUp. The Beyond 1 Million genomes project provides guidelines that cover the minimum quality requirements {% cite \"gut2021B1MG\" %} for the generation of genome sequencing data. Data repositories generally have information about recommended data file formats and metadata. The {% tool \"fair-cookbook\" %} provides instructions on validation of file formats.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":12,
        "total_chunks":16,
        "content":"ts and metadata. The {% tool \"fair-cookbook\" %} provides instructions on validation of file formats. A good place to look for scientific and technical information about data quality validation software tools for pathogenomics is {% tool \"bio-tools\" %}. The {% tool \"idtk\" %} has a showcase on An automated SARS-CoV-2 genome surveillance system built around Galaxy. The Galaxy Training Network provides free online training materials on quality control. Sharing and preserving pathogen genomic data\nConsiderations\n\nWhat data needs to be preserved by the project and for how long? What is preserved by others and how would someone find and access the data? What databases should I use to share human pathogen genomics data? What other research information (such as protocols, computational tools, and samples) can the project share? Solutions\nSharing host-related and other contextual information\n\nSome host-related information can be personal and\/or sensitive and care should be taken when storing and sharing it.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":13,
        "total_chunks":16,
        "content":"d information can be personal and\/or sensitive and care should be taken when storing and sharing it. Apply data masking and aggregation techniques to pseudonymise or anonymise the contextual information and take measures to separate personal and sensitive information from the pathogen data when possible. Adopt solutions for federated analysis to support distributed analyses on information that could otherwise not be shared, such as establishing contractual agreements with suitable regional or international data infrastructures. GA4GH is a global organisation that frames policy and builds standards to meet the real-world needs of the genomics and health community. Its GDPR & International Health Data Sharing Forum shares GDPR Briefs that represent a consensus position among its Forum Members (not legal advice) regarding the current understanding of the GDPR and its implications for genomic and health-related research, such as \nGDPR Brief: data protection implications of publishing metadata to enable discovery;\nGDPR Brief: federated analysis for responsible data sharing under the GDPR.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":14,
        "total_chunks":16,
        "content":"ata to enable discovery;\nGDPR Brief: federated analysis for responsible data sharing under the GDPR. Sharing pathogen genomic data\n\nYou should adopt good practices for data sharing and identify which data sharing platforms to use to reach the relevant stakeholders. You can use more than one platform but care should be taken to make sure that data is interconnected where possible to enable deduplication in downstream analyses. European healthcare surveillance systems are administered and used by public health authorities such as ECDCs TESSy\/EpiPulse. International research data exchanges such as {% tool \"european-nucleotide-archive\" %} for non-sensitive genomic data. There are also pathogen specific initiatives, such as {% tool \"pathogens-portal\" %} and {% tool \"pathogen-detection\" %}. And initiatives focusing specifically on viruses, certain pathogens or certain data types, such as {% tool \"gisaid\"%} for observations and assembled consensus sequences on a selection of pathogens.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_human_pathogen_genomics_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/human_pathogen_genomics.md",
        "file_name":"human_pathogen_genomics.md",
        "chunk_index":15,
        "total_chunks":16,
        "content":"s {% tool \"gisaid\"%} for observations and assembled consensus sequences on a selection of pathogens. Investigate if there are national resources or a data brokering organisation available to facilitate data sharing. {% tool \"pathogens-portal\" %} Data Hubs network for sensitive data. {% tool \"covid-19-data-portal\" %}. Bibliography\n{% bibliography --cited %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"human_pathogen_genomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Human pathogen genomics",
                "description":"Data management solutions for Human pathogen genomics",
                "contributors":[
                    "Diana Pilvar",
                    "Espen berg",
                    "Wolmar Nyberg kerstrm",
                    "Rafael Andrade Buono"
                ],
                "page_id":"human_pathogen_genomics",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "metadata",
                        "transfer",
                        "data_security",
                        "data_quality"
                    ],
                    "tool_assembly":[
                        "covid-19"
                    ]
                }
            }
        }
    },
    {
        "id":"md_fm_rare_disease_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Philip van Damme\n- Nirupama Benis\n- Csar Bernab\n- Shuxin Zhang\n- Alberto Camara Ballesteros\n- Bruna Dos Santos Vieira\n- Munazah Andrabi\ndescription: Data management solutions for rare disease data. page_id: rare_disease\nrelated_pages:\n  tool_assembly:\n  - fairtracks\n  your_domain:\n  - human_data\n  your_tasks:\n  - dmp\n  - data_publication\n  - machine_actionability\ntitle: Rare disease data",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"rare_disease_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_rare_disease_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":0,
        "total_chunks":11,
        "content":"Introduction\nThe rare disease (RD) domain brings some unique challenges when it comes to data management. Rare disease research is often scarce and scattered among many institutions in different countries  due to the, per definition, low prevalence of RDs. This makes rare diseases a prime example of a research area that can strongly profit from coordination on an international scale, including data management. RD research should be improved to overcome fragmentation, leading to efficacious use of data and resources, faster scientific progress and competitiveness, and most importantly to decrease unnecessary hardship and prolonged suffering of RD patients. Considering the introduction of omics into care practice and the structuration of RD care centers in {% tool \"european-reference-networks\" %}, data management is key to ensure data reuse and interpretation. The go-to guidelines for efficient data management are the FAIR Principles for research data management and stewardship.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":1,
        "total_chunks":11,
        "content":" for efficient data management are the FAIR Principles for research data management and stewardship. These principles provide guidance for making (meta)data more Findable, Accessible, Interoperable, and Reusable. Research data on RDs can be found in patient registries, biobanks, genomics & multi-omics repositories, knowledge bases, resources (such as animal models and cell lines libraries), omics deposition & analysis platforms, and translational & clinical research supporting materials and services. This page provides an overview of what steps one should take to make data from those sources FAIR, with an emphasis on patient registries. It is written by people affiliated with the {% tool \"european-joint-programme-on-rare-diseases\" %} and, therefore, reflects the vision of this project. Information is grouped into six topics: administrative aspects of rare disease data, creating and collecting data, processing data, interpreting data, describing data, and giving access to data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":2,
        "total_chunks":11,
        "content":"and collecting data, processing data, interpreting data, describing data, and giving access to data. Teams for managing rare disease data\nDescription\nData management is done by people; it pays off to spend some time building a team with the right people and expertise before embarking on data management activities. Considerations\nFirst, data managers and\/or policy makers should define why they want to improve their data management activities (or lack thereof). Data management goals should be captured in a data management plan. The European Rare Disease Registry Infrastructure (ERDRI) provides components to ensure that rare disease registries are searchable, findable, and interoperable. It does so with the {% tool \"european-rare-disease-registry-infrastructure-directory-of-registries\" %}; and the {% tool \"european-rare-disease-registry-infrastructure-metadata-repository\" %}. ERDRI.dor provides an overview of registries that have been registered by their owners and includes their main characteristics and description.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":3,
        "total_chunks":11,
        "content":"s that have been registered by their owners and includes their main characteristics and description. ERDRI.mdr stores all metadata of the included registries, which eases the integration of data from different rare disease registries. Registry owners should add the relevant information of their registry to ERDRI.dor and ERDRI.mdr. When going through the process of making a rare disease registry more FAIR, and building a team of people to do so, it is considered good practice to follow the so called three-party collaboration setup for interdisciplinary teams. Essential roles include:\n\nFAIRification steward (embedded in a group that has experience with making data FAIR and semantic data modelling). Note: this role relates to the Research Software Engineer (RSE) role. Local steward (expert of local data management). Note: this role relates to the data steward role. Software engineer responsible for the software that manages the data (it is recommended to avoid vendor lock-in as much as possible). Recommended additional roles:\n*   Project manager (highly recommended organizer role).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":4,
        "total_chunks":11,
        "content":"as possible). Recommended additional roles:\n*   Project manager (highly recommended organizer role). *   Part-time advisors for expertise on (i) the domain (e.g., a medical doctor), (ii) international FAIR standards (e.g., a senior FAIR expert), and (iii) implementation of FAIR software. *   Data scientist dedicated to exploiting the added value of FAIR, machine readable data. Solutions\n\nEuropean Rare Disease Registry Infrastructure (ERDRI) \n\nCreating and collecting rare disease data\nDescription\nThis section covers ways of creating and collecting data in a FAIR way focusing on how to use your electronic data capture system to make you data FAIR as you collect it. Considerations\nData collection for clinical research is often done through (electronic) Case Report Forms (CRFs) using an Electronic Data Capture (EDC) system. When collecting rare disease data, one should ensure that they collect the minimal set of data elements for rare disease registration.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":5,
        "total_chunks":11,
        "content":" one should ensure that they collect the minimal set of data elements for rare disease registration. The Common Data Elements (CDEs) are a list of core data elements to be collected by rare disease registries, especially the ERN registries, to ensure a certain level of interoperability. The full list of CDEs for rare disease registries can be found in the {% tool \"set-of-common-data-elements-for-rare-diseases-registration\" %}. When choosing an EDC system, it is important to check if the system is open to and supports an implementation of FAIR. Two aspects to take into consideration are, for example: \n\nDoes the EDC system support the implementation of a {% tool \"fair-data-point\" %}? A FAIR Data Point stores the metadata of the data that has been collected. It makes metadata findable and reusable for others on the internet and offers a uniform way for accessing the data for those who are authorized. Does the EDC system support semantic data models? Mapping the eCRFs to the elements of a semantic data model helps making the data being collected interoperable and reusable.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":6,
        "total_chunks":11,
        "content":" elements of a semantic data model helps making the data being collected interoperable and reusable. The EJP RD developed and published a {% tool \"semantic-data-model-of-the-set-of-common-data-elements-for-rare-diseases-registration\" %}. Solutions\n\n{% tool \"set-of-common-data-elements-for-rare-diseases-registration\" %}\n{% tool \"semantic-data-model-of-the-set-of-common-data-elements-for-rare-diseases-registration\" %}\n\nProcessing rare disease data\nDescription\nThis section covers the processing of data as it is being collected. It covers the different pseudonymisation tools that could be used for registry data. Considerations\nFor data pseudonymization, it is recommended to use the {% tool \"spider-pseudonymisation-tool\" %} offered by the European Platform on Rare Disease Registration. When making data FAIR retrospectively, it is recommended to follow the retrospective FAIRification workflow.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":7,
        "total_chunks":11,
        "content":"ing data FAIR retrospectively, it is recommended to follow the retrospective FAIRification workflow. On the other hand, when registry data must be FAIR right from when it is being collected by an EDC system, it is recommended to read two papers (here and here), to learn more about the denovo FAIRification process. Solutions\n\n{% tool \"spider-pseudonymisation-tool\" %}\n\nInterpreting rare disease data\nDescription\nThis section deals with the modeling of your data, so it can be annotated with unambiguous terms and the different ways it can be queried. Considerations\nEJP RDs CDE semantic model comes with a data transformation tool called CDE in a box, which transforms data in CSV format to linked data according to the model. The {% tool \"common-data-elements-in-a-box\" %} tool works independently from any EDC system.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":8,
        "total_chunks":11,
        "content":" model. The {% tool \"common-data-elements-in-a-box\" %} tool works independently from any EDC system. Additionally, the EJP RD will provide mappings to other data models such as the Observational Health Data Sciences and Informatics (OMOP) Common Data Model, the Clinical Data Interchange Standards Consortium (CDISC) Operational Data Model, and Health Level 7s Fast Healthcare Interoperability Resources (FHIR). To enable data discovery and querying, the EJP RD is developing a Virtual Platform for rare disease resources. This Virtual Platform is a federated ecosystem in which resources are enhanced to be amenable for rare disease research. Data stays at its source but can be queried remotely through an EJP RD query endpoint. As an ecosystem, multiple query endpoints will be present, allowing for sending interrogations from one resource to another. Thus, federated discovery, querying, and analysis are made possible. All while preserving patient privacy and respecting the access conditions of individual resources.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":9,
        "total_chunks":11,
        "content":". All while preserving patient privacy and respecting the access conditions of individual resources. Solutions\n\n{% tool \"common-data-elements-in-a-box\" %}\n{% tool \"european-joint-programme-on-rare-diseases-virtual-platform\" %}\n\nDescribing rare disease data\nDescription\nThis section deals with the information needed to properly describe your data, so users can reuse it. It covers the use of FAIR Data Points and database technologies to store data. Considerations\nWhen describing rare disease data (i.e., describing the metadata), one could make use of the FAIR Data Point specification as mentioned earlier. This specification offers an extended metadata model based on the {% tool \"data-catalog-vocabulary\" %}, a World Wide Web Consortium (W3C) recommendation. Once the FAIR Data Point has been set up properly it should be visible in the list of active {% tool \"fair-data-points\" %}. Note: make sure that the registrys Data Access Policy allows for sharing of metadata.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_rare_disease_data_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/rare_disease_data.md",
        "file_name":"rare_disease_data.md",
        "chunk_index":10,
        "total_chunks":11,
        "content":"a-points\" %}. Note: make sure that the registrys Data Access Policy allows for sharing of metadata. Solutions\n\n{% tool \"european-joint-programme-on-rare-diseases-metadata-model\" %}\n{% tool \"fair-data-points\" %}\n\nGiving access to rare disease data\nDescription\nThis section deals with the information needed by people who will re-use your data, and with the access conditions they will need to follow. Considerations\nTwo main topics can be addressed when dealing with data access. First, the collection of informed consent through an informed consent form. Second, specifying who is allowed access to which data using an Authentication and Authorization Infrastructure (AAI). The informed consent form should use existing standards for informed consent. The EJP RD has developed a {% tool \"ern-registries-generic-informed-consent-forms\" %}. Solutions\n\n{% tool \"european-joint-programme-on-rare-diseases-metadata-model\" %}\n{% tool \"ern-registries-generic-informed-consent-forms\" %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"rare_disease_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Rare disease data",
                "description":"Data management solutions for rare disease data.",
                "contributors":[
                    "Philip van Damme",
                    "Nirupama Benis",
                    "Csar Bernab",
                    "Shuxin Zhang",
                    "Alberto Camara Ballesteros",
                    "Bruna Dos Santos Vieira",
                    "Munazah Andrabi"
                ],
                "page_id":"rare_disease",
                "related_pages":{
                    "your_domain":[
                        "human_data"
                    ],
                    "tool_assembly":[
                        "fairtracks"
                    ],
                    "your_tasks":[
                        "dmp",
                        "data_publication",
                        "machine_actionability"
                    ]
                }
            }
        }
    },
    {
        "id":"md_fm_proteomics_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Michael Turewicz\n- Martin Eisenacher\n- Anika Frericks-Zipper\n- Ulrike Wittig\n- Dirk Winkelhardt\ndescription: Data management solutions for proteomics data. page_id: proteomics\nrelated_pages:\n  tool_assembly: []\n  your_tasks:\n  - metadata\ntitle: Proteomics\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=proteomics",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"proteomics.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_proteomics_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":0,
        "total_chunks":8,
        "content":"Introduction\nThe proteomics domain deals with standard data formats, software tools and data repositories for mass spectrometry-based proteomics data. In proteomics, the relatively wide range of mass spectrometry technologies, devices, protocols, study designs and data analysis approaches poses a particular challenge for the standardized description and storage of data and associated metadata. This circumstance forced the proteomics community to deal with the complex definition of suitable standard data formats relatively early in its history. This encouraged, among other things, the development of software tools that can import and export results in standardized formats, and of data repositories in which proteomics data can be stored in a standardized way. The particular challenge for the proteomics community now is to evolve its achievements in data management to date towards a more complete fulfillment of FAIR research data management and to close the remaining gaps in this regard.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"proteomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Proteomics",
                "description":"Data management solutions for proteomics data.",
                "contributors":[
                    "Michael Turewicz",
                    "Martin Eisenacher",
                    "Anika Frericks-Zipper",
                    "Ulrike Wittig",
                    "Dirk Winkelhardt"
                ],
                "page_id":"proteomics",
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=proteomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_proteomics_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":1,
        "total_chunks":8,
        "content":"omplete fulfillment of FAIR research data management and to close the remaining gaps in this regard. Standard data formats\nDescription\nTo make proteomics data interoperable and reproducible from the first to the last mile of proteomics data analysis pipelines, comprehensive metadata accompanying the data is needed. The crucial metadata includes information on study design, proteomics technology, lab protocol, device, device settings and software settings. All of them have an enormous impact on the resulting data. Thus, to enable data reusability in proteomics appropriate standard data formats are needed. Considerations\nFor different proteomics experiments and different steps of the respective data analysis pipelines there are different kinds of data and metadata that should be recorded.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"proteomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Proteomics",
                "description":"Data management solutions for proteomics data.",
                "contributors":[
                    "Michael Turewicz",
                    "Martin Eisenacher",
                    "Anika Frericks-Zipper",
                    "Ulrike Wittig",
                    "Dirk Winkelhardt"
                ],
                "page_id":"proteomics",
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=proteomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_proteomics_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":2,
        "total_chunks":8,
        "content":"tive data analysis pipelines there are different kinds of data and metadata that should be recorded. Consequently, the main challenges for data and metadata standardization include:\n- What are the definitions of proteomics-specific terms that are needed to describe proteomics experiments?\n- Which is the minimal information that is needed to describe a proteomics experiment?\n- How should the data and metadata of proteomics raw data and peak lists be stored?\n- How should the data and metadata of proteomics identification results be stored?\n- How should the data and metadata of proteomics quantification results be stored?\n- How can proteomics data and metadata be stored in a simple and human-readable way? Solutions\nThe Human Proteome Organisation (HUPO) Proteomics Standards Initiative ({% tool \"proteomics-standards-initiative\" %}), a proteomics community-driven organization, provides several different controlled vocabularies, standard data formats, converter and validator software tools.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"proteomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Proteomics",
                "description":"Data management solutions for proteomics data.",
                "contributors":[
                    "Michael Turewicz",
                    "Martin Eisenacher",
                    "Anika Frericks-Zipper",
                    "Ulrike Wittig",
                    "Dirk Winkelhardt"
                ],
                "page_id":"proteomics",
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=proteomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_proteomics_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":3,
        "total_chunks":8,
        "content":"al different controlled vocabularies, standard data formats, converter and validator software tools. The most important include:\n- Controlled vocabularies: PSI-MS, PSI-MI, XLMOD and sepCV, which are provided as OBO files.\n- The Minimum Information About a Proteomics Experiment (MIAPE) guidelines document.\n- mzML  - a standard format for encoding raw mass spectrometer output. - mzIdentML - a standard exchange format for peptides and proteins identified from mass spectra.\n- mzQuantML - a standard format that is intended to store the systematic description of workflows quantifying molecules (principally peptides and proteins) by mass spectrometry. - mzTab - a tab delimited text file format to report proteomics and metabolomics results. Processing and analysis of proteomics data\nDescription\nFor all steps within a FAIR proteomics data analysis pipeline software is needed that imports standard data formats and exports standard data formats including all needed results and metadata. Considerations\n\nCan your proteomics raw data recorded by a mass spectrometer be stored as an mzML file?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"proteomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Proteomics",
                "description":"Data management solutions for proteomics data.",
                "contributors":[
                    "Michael Turewicz",
                    "Martin Eisenacher",
                    "Anika Frericks-Zipper",
                    "Ulrike Wittig",
                    "Dirk Winkelhardt"
                ],
                "page_id":"proteomics",
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=proteomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_proteomics_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":4,
        "total_chunks":8,
        "content":"siderations\n\nCan your proteomics raw data recorded by a mass spectrometer be stored as an mzML file? Is it possible to convert your raw data to mzML?\nDoes your search engine support mzML and\/or mzIdentML? Does your quantification software support mzQuantML or mzTab?\n\nSolutions\n\nWithin the proteomics community various converter software tools such as {% tool \"msconvert\" %} were implemented, which support the conversion of mass spectrometer output formats to the mzML standard data format as well as other conversions to standard data formats. Information on software tools that support HUPO-PSI data formats can be found on the standard format-specific web pages of the HUPO-PSI (e.g., mzML , mzIdentML and mzTab ).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"proteomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Proteomics",
                "description":"Data management solutions for proteomics data.",
                "contributors":[
                    "Michael Turewicz",
                    "Martin Eisenacher",
                    "Anika Frericks-Zipper",
                    "Ulrike Wittig",
                    "Dirk Winkelhardt"
                ],
                "page_id":"proteomics",
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=proteomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_proteomics_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":5,
        "total_chunks":8,
        "content":"found on the standard format-specific web pages of the HUPO-PSI (e.g., mzML , mzIdentML and mzTab ). The following list shows just a few tools using standard data formats as input and\/or output: \n{% tool \"comet\" %}\n{% tool \"mascot\" %}\n{% tool \"openms\" %}\n{% tool \"pia-protein-inference-algorithms\" %}\n{% tool \"skyline\" %}\n{% tool \"paa\" %}\n{% tool \"apid-interactomes\" %}\n\nPreserving and sharing proteomics data\nDescription\nIn order to make proteomics data and results worldwide findable and accessible for other researchers and software, FAIR public data repositories are needed. Consideration\n\nHow can I find an appropriate proteomics data repository? How can I upload my proteomics data into a specific proteomics data repository? What are the requirements for my data to be uploaded into a proteomics data repository? What are the advantages of uploading data into proteomics data repositories? How can public proteomics data be used by other researchers? How can I increase transparency and reproducibility of my shared data?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"proteomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Proteomics",
                "description":"Data management solutions for proteomics data.",
                "contributors":[
                    "Michael Turewicz",
                    "Martin Eisenacher",
                    "Anika Frericks-Zipper",
                    "Ulrike Wittig",
                    "Dirk Winkelhardt"
                ],
                "page_id":"proteomics",
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=proteomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_proteomics_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":6,
        "total_chunks":8,
        "content":"be used by other researchers? How can I increase transparency and reproducibility of my shared data? Solution\n\nYou can find an appropriate data repository via the website of the {% tool \"proteomexchange\" %} Consortium. ProteomeXchange was established to provide globally coordinated standard data submission and dissemination pipelines involving the main proteomics repositories, and to encourage open data policies in the field. Currently, member repositories include {% tool \"pride\" %}, {% tool \"peptideatlas\" %}, {% tool \"massive\" %}, jPOST, iProx and PanoramaPublic. Information on data uploads can be found on ProteomeXchange submissions or on the websites of the particular data repositories. E.g. PRIDE uploads are conducted via the {% tool \"pride-submission-tool\" %}. There are data repository-specific requirements.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"proteomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Proteomics",
                "description":"Data management solutions for proteomics data.",
                "contributors":[
                    "Michael Turewicz",
                    "Martin Eisenacher",
                    "Anika Frericks-Zipper",
                    "Ulrike Wittig",
                    "Dirk Winkelhardt"
                ],
                "page_id":"proteomics",
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=proteomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_proteomics_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/proteomics.md",
        "file_name":"proteomics.md",
        "chunk_index":7,
        "total_chunks":8,
        "content":"nducted via the {% tool \"pride-submission-tool\" %}. There are data repository-specific requirements. Advantages of data publication: fulfillment of journal requirements, higher visibility of research, free storage, worldwide accessibility, basic re-analysis by repository-associated tools and possible integration in more specialized knowledgebases like: {% tool \"human-protein-atlas\" %}, {% tool \"macpepdb\" %}, {% tool \"string\" %}, {% tool \"unimod\" %}, {% tool \"interpro\" %}, {% tool \"uniprot\" %} or {% tool \"cath\" %}\nYou can increase transparency and reproducibility of the mass spectrometry-based proteomics data by providing sample and data relationship file ({% tool \"sdrf\" %}) along with submission to data repository (e.g. ProteomeXchange).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"proteomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Proteomics",
                "description":"Data management solutions for proteomics data.",
                "contributors":[
                    "Michael Turewicz",
                    "Martin Eisenacher",
                    "Anika Frericks-Zipper",
                    "Ulrike Wittig",
                    "Dirk Winkelhardt"
                ],
                "page_id":"proteomics",
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=proteomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_biomolecular_simulation_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Karel Berka\n- Adam Hospital\ndescription: Data management solutions for biomolecular simulation data. page_id: biomol_sim\nrelated_pages:\n  tool_assembly: []\n  your_tasks:\n  - data_publication\n  - metadata\n  - storage\ntitle: Biomolecular simulation data\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation\n- name: BioExcel Knowledge Resource Center\n  url: https:\/\/krc.bioexcel.eu\/training",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":0,
        "total_chunks":10,
        "content":"Introduction\nBiomolecular simulations are important technique for our understanding and design of biological molecules and their interactions. Simulation methods are demonstrating rapidly growing impact in areas as diverse as biocatalysis, drug delivery, biomaterials, biotechnology, and drug or protein design. Simulations offer the potential of uniquely detailed, atomiclevel insight into mechanisms, dynamics, and processes, as well as increasingly accurate predictions of molecular properties. Yet the field only relatively recently started to store and share (bio)simulation data to be reused for new, unexpected projects, and started discussions about their biomolecular simulation data FAIRification (i.e. to make them Findable, Accessible, Interoperable and Reusable).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":1,
        "total_chunks":10,
        "content":" simulation data FAIRification (i.e. to make them Findable, Accessible, Interoperable and Reusable). Here we show several current possibilities moving in this direction, but we should stress that these guidelines are not carved to stone and the biomolecular simulation community still needs to address challenges to FAIRify their data. Storing and sharing the data from biomolecular simulations\nDescription\nThe biomolecular simulation data comes in several forms and multiple formats, which unfortunately are not completely interoperable. Different methods also require slightly different metadata description. Considerations\n\nWhat type of data do you have? Molecular dynamics data - by far the most typical and largest biomolecular simulation data. Each molecular dynamics simulation is driven by the used engine, force-field, and multiple other and often hidden simulation parameters to produce trajectories that are further analysed. Molecular docking data - docking provides the structures of the complex (e.g. ligand-protein, protein-protein, protein-nucleic acid, etc.) and its score\/energy.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":2,
        "total_chunks":10,
        "content":"the complex (e.g. ligand-protein, protein-protein, protein-nucleic acid, etc.) and its score\/energy. Virtual screening data - virtual screening is used for selection of active compounds from the pool of others and is usually in the form of ID and its score\/energy. Free energies and other analysis data - data calculable from the analysis of the simulations. Where should you store this data? Since there is no common community repository that would be able to gather the often spacious simulation data, the field did not systematically store them. Recently, theres multiple possibilities where the data can be stored. The repositories can be divided in two main branches:\nGeneric:  Repositories that can be used to store any kind of data. Specific:  Repositories designed to store specific data (e.g. MD data). Are you looking for a long-term or short-term storage? Repositories have different options (and sometimes prices) for the storage time of your data. Do you need a static reference for your data? A code (identifier) that can uniquely identify and refer to your data?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":3,
        "total_chunks":10,
        "content":"atic reference for your data? A code (identifier) that can uniquely identify and refer to your data? What data should you store? What type of data should you store from the whole bunch of data generated in our project. Again, the type of data might vary depending on the biomolecular simulation field. Consider what is essential (absolutely needed to reproduce the simulated experiment) versus what can be extracted from this data (analyses). How do you want your data to be shared? You should consider the terms in which other scientists can use your data for other projects, access, modify, or redistribute them. Solutions\n\nDeposit your data to a suitable repository for sharing. Theres a long (and incomplete) list of repositories available for data sharing. Repositories are divided into two main categories, general-purpose and discipline-specific, and both categories are utilised in the domain of biomolecular modeling and simulation. For a general introduction to repositories, you are advised to read the data publication page.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":4,
        "total_chunks":10,
        "content":"tion. For a general introduction to repositories, you are advised to read the data publication page. General-purpose repositories such as {% tool \"zenodo\" %}, {% tool \"figshare\" %}, {% tool \"mendeley-data\" %}, {% tool \"dryad\" %}, and {% tool \"openscienceframework\" %} can be used. Discipline-specific repositories can be used when the repository supports the type of data to be shared e.g. molecular dynamics data. Repositories for various data types and models are listed below:\n\nMolecular Dynamics repositories\n{% tool \"gpcrmd\" %} - for GPCR protein simulations, with submission process. {% tool \"model\" %} - (https:\/\/bio.tools\/model) specific database for protein MD simulations. {% tool \"bignasim\" %} - (https:\/\/bio.tools\/bignasim) specific database for Nucleic Acids MD simulations, with submission process. {% tool \"model-cns\" %} - specific database for Central Nervous System-related, mainly membrane protein, MD simulations.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":5,
        "total_chunks":10,
        "content":" %} - specific database for Central Nervous System-related, mainly membrane protein, MD simulations. {% tool \"nmrlipids\" %} - project to validate lipid force fields with NMR data with submission process\n\n{% tool \"molssi\" %} - database with COVID-19 related simulations, with submission process. Molecular Dynamics databases - allow access to precalculated data\n\n{% tool \"dynameomics\" %} - database of folding\/unfolding pathways\n\n{% tool \"memprotmd\" %} - database of automatically generated membrane proteins from PDB inserted into simulated lipid bilayers\n\n\nDocking respositories\n\n{% tool \"molssi\" %} - database with COVID-19 related simulations, with submission process. {% tool \"pdb-dev\" %} - prototype archiving system for structural models using integrative or hybrid modeling, with submission process. {% tool \"modelarchive\" %} - theoretical models of macromolecular structures, with submission process. Virtual Screening repositories:\n\n{% tool \"bioactive-conformational-ensemble\" %} - small molecule conformations, with submission process.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":6,
        "total_chunks":10,
        "content":"tool \"bioactive-conformational-ensemble\" %} - small molecule conformations, with submission process. {% tool \"bindingdb\" %} - database of measured binding affinities, focusing chiefly on the interactions of protein considered to be drug-targets with small, drug-like molecules, with submission process. Repositories for the analyzed data from simulations:\n\n{% tool \"molmedb\" %} - for molecule-membrane interactions and free energy profiles, with submission process. {% tool \"channelsdb\" %} - resource of channels, pores and tunnels found in biomacromolecules, with submission process. Based on the type of data to be shared, pay attention to what should be included and the data and metadata that will be deposited to repositories. Below listed are some suggested examples of types of essential and optional data describing the biomolecular simulation data:\n\nMolecular Dynamics:\nEssentials:\nMetadata (Temperature, pressure, program, version, ) Complete set of input files that were used in the simulations\nTrajectory(ies)\nTopology(ies)\n\n\nOptionals:",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":7,
        "total_chunks":10,
        "content":"lete set of input files that were used in the simulations\nTrajectory(ies)\nTopology(ies)\n\n\nOptionals: Analysis data (Free energy, snapshots, clusterization) Docking poses:\nEssentials:\nThe complete set of molecules tested as well as the scoring functions used and the high-ranking, final poses (3D-structures)\nMetadata (Identifiers (SMILES, InChI-Key), target (PDBID), energies\/scores, program, version, box definition)\n\n\nOptionals: Complete ensemble of poses\n\n\nVirtual Screening:\nEssentials:\nList of molecules sorted\nMetadata (identifiers of ligands and decoy molecules, target, program+version, type of VS (QSAR, ML, Docking,...)) Optionals:\nDetails of the method, scores, ...\n\n\nFree energies and other analyses:\nEssentials:\nMetadata (model, method, program, version, force field(s), etc.) Values (Free energy values, channels, etc.)\n\n\nOptionals:\nLink to Trajectory (Dynamic PDB?)\n\n\n\n\nAssociate a license with the data and\/or source code e.g. models.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":8,
        "total_chunks":10,
        "content":"k to Trajectory (Dynamic PDB?)\n\n\n\n\nAssociate a license with the data and\/or source code e.g. models. Licenses mainly differ on openness vs restrictiveness, and it is crucial to understand the differences among licenses before sharing your research outputs. The RDMkit licensing page lists resources that can help you understand licensing and choose an appropriate license. Related problems\n\n\nFile formats\nBiomolecular simulation field has a tendency to produce a multitude of input\/output formats, each of them mainly related to one software package. That makes interoperability and reproducibility really difficult. You can share your data but this data will only be useful if the scientist interested in it has access to the tool that has generated it. The field is working on possible standards (e.g. TNG trajectory). Metadata standards\nThere is no existing standard defining the type and format of the metadata needed to describe a particular project and its associated data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_biomolecular_simulation_data_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/biomolecular_simulation_data.md",
        "file_name":"biomolecular_simulation_data.md",
        "chunk_index":9,
        "total_chunks":10,
        "content":"the type and format of the metadata needed to describe a particular project and its associated data. How to store the program, version, parameters used, input files, etc., is still an open question, which has been addressed in many ways and using many formats (json, xml, txt, etc.). Again, different initiatives exist trying to address this issue (see further references). Data size\nData generated in the biomolecular simulation field is growing at an alarming pace. Making this data available to the scientific community sometimes means transferring them to a long-term storage, and even this a priori straightforward process can be cumbersome because of the large data size.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"biomolecular_simulation_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Biomolecular simulation data",
                "page_id":"biomol_sim",
                "description":"Data management solutions for biomolecular simulation data.",
                "contributors":[
                    "Karel Berka",
                    "Adam Hospital"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=biomolecular%20simulation"
                    },
                    {
                        "name":"BioExcel Knowledge Resource Center",
                        "url":"https:\/\/krc.bioexcel.eu\/training"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_virology_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Niels Geudens\n- Flora D'Anna\n- Romain David\n- Philippe Lieutaud\ndescription: Data management solutions for virology data. page_id: virology\nrelated_pages:\n  tool_assembly:\n  - covid19_data_portal\n  your_tasks:\n  - data_brokering\n  - gdpr_compliance\n  - ethics\n  - compliance\n  - sensitive\n  - data_security\n  - data_discoverability\n  - identifiers\ntitle: Virology\ntraining:\n- name: null\n  registry: null\n  url: null",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"virology.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_virology_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":0,
        "total_chunks":13,
        "content":"Introduction\nVirology is a rapidly evolving field that generates diverse and complex datasets, from genomic sequences to clinical trial results and epidemiological data. Effective research data management (RDM) is essential to ensure that these valuable datasets are organised, shared, and preserved in a manner that enables long-term impact. Data Heterogeneity\nDescription\nOutbreak surveillance in virology requires the integration of multiple data types, including sequencing, clinical, and epidemiological data. These data types originate from diverse sources, such as hospitals, research laboratories, and public health agencies, making their harmonisation and interoperability critical. Without standardised data management approaches, inconsistencies in metadata, sampling protocols, and data formats can hinder effective outbreak response, cross-study comparisons, and reproducibility of findings.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":1,
        "total_chunks":13,
        "content":"ts can hinder effective outbreak response, cross-study comparisons, and reproducibility of findings. Considerations\nKey challenges in managing data heterogeneity include:\n* Standardising sample collection protocols across clinical and environmental settings to ensure comparability. * Integrating epidemiological and genomic data to enhance outbreak detection and integrative and global responses. Solutions\nTo effectively manage data heterogeneity in virology outbreak surveillance, several domain-specific solutions are recommended:\n* The Data Provenance page provides comprehensive guidance on capturing metadata, documenting data origins, and maintaining transparent records, ensuring data traceability and reproducibility. * Use standardised protocols for sample collection by identifying and reviewing existing guidelines from organisations such as World Health Organisation, ECDC, and ISO standards to ensure alignment with best practices. * Implement metadata standards for data interoperability\n  *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":2,
        "total_chunks":13,
        "content":"o ensure alignment with best practices. * Implement metadata standards for data interoperability\n  * The Documentation and metadata page offers practical recommendations and standards for accurately describing data, ensuring consistent interpretation, interoperability, and long-term usability. * Apply {% tool \"mixs\" %} and the derived {% tool \"miuvig\" %} for annotating viral sequence data with necessary metadata fields. Visit the NCBI submission portal for an overview. * Adapt generic dataset descriptions (e.g. {% tool \"data-catalog-vocabulary\" %}, {% tool \"dublincore\" %}, {% tool \"bioschemas\" %}) for basic dataset descriptions. * Follow {% tool \"biosamples\" %} Metadata Schema from EBI for structured viral sample metadata. * Ensure metadata compliance with international repositories\n  * The Data Brokering page describes strategies and tools for integrating, harmonising, and translating data across diverse formats and sources. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":3,
        "total_chunks":13,
        "content":"s and tools for integrating, harmonising, and translating data across diverse formats and sources. * Format metadata to meet the submission requirements of repositories like {% tool \"gisaid\" %} and {% tool \"european-nucleotide-archive\" %} to ensure smooth data deposition and retrieval. For instance, search for a virology-related checklists in the ENA sample checklists. * Utilise validation tools and checklists to ensure completeness and accuracy before data submission. * FAIRsharing resources for metadata selection\n  * Refer to the EVORA collection of FAIRsharing-referenced metadata standards for pandemic preparedness and response. * Consult {% tool \"fairsharing\" %} registries to identify suitable standards for different types of virology datasets. * Integrate epidemiological and genomic data for outbreak analysis, by utilising phylodynamic workflows (e.g. BEAST, {% tool \"nextstrain\" %}, or TreeTime), enabling real-time outbreak tracking. * Implement structured pipelines for linking viral genome sequences with patient and outbreak metadata.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":4,
        "total_chunks":13,
        "content":"mplement structured pipelines for linking viral genome sequences with patient and outbreak metadata. * Apply domain-specific vocabularies for consistent annotation\n  * Utilise the {% tool \"evora-ontology\" %} and {% tool \"ictv\" %} to ensure that virus-related metadata terms are standardised and interoperable. * Monitor updates in virology-specific ontologies to maintain alignment with evolving standards. By implementing these best practices, outbreak surveillance data can be better structured, more interoperable, and more effectively shared, ultimately improving global response efforts to viral outbreaks. Data Sensitivity & Ethics\nDescription\nHandling sensitive data in virology outbreak surveillance involves managing patient data, ensuring proper anonymisation, and complying with regulations such as the General Data Protection Regulation (GDPR). The ethical and legal aspects of handling such data are crucial to maintaining patient privacy while allowing researchers and public health authorities to analyse and respond to viral threats effectively.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":5,
        "total_chunks":13,
        "content":"owing researchers and public health authorities to analyse and respond to viral threats effectively. Proper data governance strategies must balance the need for data accessibility and data security, ensuring that only authorised personnel can access identifiable information. Secure storage, controlled access mechanisms, and appropriate anonymisation techniques must be implemented to meet legal and ethical standards. Considerations\nKey challenges in managing data sensitivity and ethics include:\n* Ensuring compliance with GDPR and other legal frameworks when collecting, processing, and sharing sensitive patient data. * Anonymising and pseudonymising patient data to reduce privacy risks while preserving data utility for research. * Implementing secure and scalable storage solutions that support controlled data access, encryption, and long-term preservation. Solutions\nOrganisations must implement robust governance policies, encryption techniques, and controlled data access mechanisms to maintain patient privacy while enabling scientific advancements.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":6,
        "total_chunks":13,
        "content":"ontrolled data access mechanisms to maintain patient privacy while enabling scientific advancements. The following strategies outline best practices for secure data management and ethical compliance. * Ensure GDPR and regulatory compliance\n  * For guidance on managing sensitive data ethically and in compliance with regulations, the pages on GDPR compliance, Ethical aspects, and Compliance monitoring & measurement provide detailed recommendations on protecting personal data, navigating ethical responsibilities, and implementing effective compliance monitoring practices. * Identify and mitigate privacy risks associated with human and health-related data (see Human data and Health data domain pages). * Establish clear data governance policies defining roles and responsibilities regarding data processing and sharing. * Ensure contractual coverage for data exchanges through appropriate agreements (e.g. Data Use Agreements, Consortium Agreements, Data Sharing Agreements), explicitly outlining data usage, retention, reuse, and publication policies.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":7,
        "total_chunks":13,
        "content":"ta Sharing Agreements), explicitly outlining data usage, retention, reuse, and publication policies. Material Transfer Agreements (MTAs) should similarly address the handling of human data derived from received samples. * You can also check the practices included in the {% tool \"idtk\" %} related to the management of human and pathogen data in the context of infectious diseases. * Implement effective data anonymisation and pseudonymisation strategies to reduce data sensitivity and protect privacy, following best practices detailed on the Data Sensitivity page. * Adopt secure and scalable data storage solutions to ensure long-term data integrity, controlled access, and compliance with relevant standards and best practices, as described on the Data Storage page. * Store sensitive data in repositories designed for controlled access (e.g. {% tool \"the-european-genome-phenome-archive\" %}) * Use encryption for data at rest and in transit to prevent unauthorised access. * Establish strict access control policies, using role-based access and multi-factor authentication where appropriate.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":8,
        "total_chunks":13,
        "content":" access control policies, using role-based access and multi-factor authentication where appropriate. * Implement best practices for data versioning and backup to maintain clear data histories, prevent loss, and enhance reproducibility, following guidelines provided on the Data Organisation page. Data sharing and access\nDescription\nEffective data sharing and access enable timely surveillance of viral genome evolution, facilitating early detection of mutations and emerging variants. This rapid exchange of outbreak information supports swift global responses while simultaneously addressing critical concerns around data security and patient privacy. Researchers have a responsibility to share outbreak-related data ethically, legally, and efficiently, allowing authorised users appropriate access to sensitive materials, such as patient records and genomic sequences, in alignment with national and EU regulatory frameworks.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":9,
        "total_chunks":13,
        "content":"h as patient records and genomic sequences, in alignment with national and EU regulatory frameworks. Furthermore, assigning persistent identifiers and utilising structured data repositories enhance the long-term usability, traceability, and discoverability of outbreak data, significantly improving preparedness and response strategies. Considerations\nKey challenges in data sharing and access include:\n* Balancing accesibility with security, ensuring that sensitive data is accessible to authorised users without compromising privacy. * Adhering to national and international regulations to ensure ethical data sharing. * Ensuring proper data deposition in repositories that align with domain-specific standards. * Maintaining dataset integrity and discoverability using persistent identifiers like DOIs and accession numbers.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":10,
        "total_chunks":13,
        "content":" dataset integrity and discoverability using persistent identifiers like DOIs and accession numbers. Solutions\nTo ensure secure and effective data sharing in virology outbreak surveillance, researchers and institutions should implement structured strategies:\n* Balance accessibility with security in data sharing by implementing measures that protect sensitive data while ensuring it remains discoverable and accessible, following the guidelines provided on the pages for Data Security and Data Discoverability\n  * Use controlled-access repositories, findable via VODAN - GO FAIR to manage and access sensitive patient or outbreak data securely. * Implement data access governance models that allow tiered access based on user credentials and need. * Utilise {% tool \"pathoplexus\" %} for managing metadata and access rights in a structured manner. It is an open-source database dedicated to the efficient sharing of human viral pathogen genomic data, fostering global collaboration and public health response. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":11,
        "total_chunks":13,
        "content":"g of human viral pathogen genomic data, fostering global collaboration and public health response. * Ensure proper deposition of outbreak data into trusted repositories to facilitate data sharing, citation, and reuse, following best practices outlined on the Data Publication page. * Submit viral genomic sequences and epidemiological data to {% tool \"gisaid\" %}, NCBI {% tool \"genbank\" %}, and {% tool \"european-nucleotide-archive\" %} for public accessibility. * Use standard submission pipelines to ensure compliance with repository-specific metadata and formatting guidelines. * Assign persistent identifiers to datasets to enhance discoverability, citation, and long-term accessibility, following recommendations on the Identifiers page. * Register DOIs or accession numbers for datasets to facilitate long-term accessibility and proper citation. * Ensure metadata linking persistent identifiers is properly formatted and recorded. * Comply with national and EU data-sharing regulations by consulting country-specific guidelines and legal frameworks available on the National Resources page.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_virology_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/virology.md",
        "file_name":"virology.md",
        "chunk_index":12,
        "total_chunks":13,
        "content":"onsulting country-specific guidelines and legal frameworks available on the National Resources page. * Align data-sharing practices with GDPR, national laws, and institutional ethical guidelines. * Implement data-sharing agreements between collaborating institutions to formalise responsibilities.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"virology.md",
            "language":"en",
            "frontmatter":{
                "title":"Virology",
                "description":"Data management solutions for virology data.",
                "contributors":[
                    "Niels Geudens",
                    "Flora D'Anna",
                    "Romain David",
                    "Philippe Lieutaud"
                ],
                "page_id":"virology",
                "related_pages":{
                    "your_tasks":[
                        "data_brokering",
                        "gdpr_compliance",
                        "ethics",
                        "compliance",
                        "sensitive",
                        "data_security",
                        "data_discoverability",
                        "identifiers"
                    ],
                    "tool_assembly":[
                        "covid19_data_portal"
                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_bioimaging_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Sbastien Besson\n- Jean-Marie Burel\n- Susanne Kunis\n- Josh Moore\n- Stefanie Weidtkamp-Peters\ndescription: Data management solutions for bioimaging data. faircookbook:\n- name: Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive\n  url: https:\/\/w3id.org\/faircookbook\/FCB067\n- name: Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive\n  url: https:\/\/w3id.org\/faircookbook\/FCB086\npage_id: bioimaging_data\nrelated_pages:\n  tool_assembly:\n  - ome\n  - xnat_pic\n  your_tasks:\n  - dmp\n  - data_organisation\n  - data_publication\n  - existing_data\n  - transfer\n  - licensing\n  - metadata\n  - storage\ntitle: Bioimaging data\ntraining:\n- name: RDMbites for using REMBI\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"bioimaging_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_bioimaging_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":0,
        "total_chunks":14,
        "content":"Introduction\nBioimaging specialists are acquiring an ever growing amount of data: images, associated metadata, etc. However, image data management often does not receive the attention it requires or is avoided altogether since it is considered a burdensome task. At the same time, storing images on personal computers or USB keys is no longer an option, assuming it ever was! Data volume is exponentially increasing, and not just the acquired images need storing but potentially processed images will be generated and will need to be kept alongside the original images. It is critical to proactively identify where the data will be stored, for how long, who will cover the cost of the hardware, and who will cover the cost of managing the infrastructure. All the stakeholders need to be involved in the preliminary discussions: biologists, facility managers, data analysis, IT support, etc., to ensure that the requirements are understood and met.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":1,
        "total_chunks":14,
        "content":"y managers, data analysis, IT support, etc., to ensure that the requirements are understood and met. What constitutes bioimage data\nAn image is much more than a collection of zeros and ones. The image will contain the binary representing the pixels on screen but it is usually packed with useful metadata. You will find the obvious keys indicating how to interpret the zeros and ones, you can also find a lot of acquisition metadata e.g. hardware\/instrument used, settings used, etc. The number of image proprietary formats is very large and keeps increasing. It is challenging to support so many proprietary file formats i.e. read\/extract metadata. The {% tool \"bio-formats\" %} library currently supports over 150 different file formats. The Dataset Structure Table shows the extension of the files to read and indicates the structure of the image itself e.g. single file, multiple files, one image file and a companion file, etc.\nData management challenges\nThe number of files and their size could be extremely large.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":2,
        "total_chunks":14,
        "content":"n file, etc.\nData management challenges\nThe number of files and their size could be extremely large. Deleting\/misplacing a file could invalidate the study itself, preventing its reuse. Managing images immediately becomes a larger problem, not only the binary files need to be handled, but also the associated metadata. Several efforts have been made and still ongoing to capture those metadata. Understanding and capturing the metadata are critical for many reasons, just to mention a few: analysis, detection of possible faults in acquisition systems. It is important to decide how much details will be recorded since this could dramatically increase the metadata volume and therefore the effort required to capture the metadata. The collection of images could be: \n - data acquired within a facility;\n - data acquired in other facility (commissioned work or external guest user) and \"transported\" by the users to their facility;\n - slides scanned. After acquisition, data are usually moved to more permanent storages with different level of permissions.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":3,
        "total_chunks":14,
        "content":" acquisition, data are usually moved to more permanent storages with different level of permissions. This depends on the facility policies and could prevent collaborative work. Users will also adopt their own \"organisation\" conventions, this could potentially make it very difficult to find or understand the data when, for example, the data are migrated to a new location or when the researcher who acquired the data leaves the lab. Standard (meta)data formats\nDescription\nUnlike other domains, the bioimaging community has not yet agreed on a single standard data format which is generated by all acquisition systems. Instead, the images described above are most frequently collected in proprietary file formats (PFFs) defined by hardware vendors. Currently, there are several hundred such formats that the researchers may encounter. These formats combine critical acquisition metadata with the multidimensional binary data but are often optimized for quickly writing the data to disk. Tools and strategies are outlined below to ease working with this data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":4,
        "total_chunks":14,
        "content":"ly writing the data to disk. Tools and strategies are outlined below to ease working with this data. Considerations\n\nWhen purchasing a microscope, consider carefully how the resulting files will be processed. If open source tools will be used, proprietary file formats may require a time-consuming conversion. Discuss with your vendor if an open format is available. If data from multiple vendors is to be combined, similar a conversion may be necessary to make the data comparable. Imaging data brings special considerations due to the large, often continuous nature of the data. Single terabyte-scale files are not uncommon. Sharing these can require special infrastructure, like a data management server (described below) or a cloud-native format (described below). One goal of such infrastructure is to enable the selective (i.e. interactive) zooming of your image data without the need to download the entire volume, thereby reducing your internet bandwidth and costs. Importantly, most acquisition systems produce proprietary file formats.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":5,
        "total_chunks":14,
        "content":"nternet bandwidth and costs. Importantly, most acquisition systems produce proprietary file formats. Understanding how well they are supported by the imaging community could be a key factor of a successful study. Will it be possible to analyse or view the image using open-source software? Will it be possible to deposit the images to public repositories when published? The choice of proprietary file formats could prevent from using any other tools that are not related to the acquisition systems. Solutions\nVendor libraries: Some vendors provide open source libraries for parsing their proprietary file formats. See libCZI from Zeiss. Open source translators: Members of the community have developed multi-format translators that can be used to access your data on-the-fly i.e. the original format is preserved, no file written on disk. This implies that you will need to perform this translation each time you access your data and, depending on the size of the image(s), you could run out of memory.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":6,
        "total_chunks":14,
        "content":"h time you access your data and, depending on the size of the image(s), you could run out of memory. Translation libraries include, \n\n{% tool \"bio-formats\" %} (Java) - supports over 150 file formats\n{% tool \"openslide\" %} (C++) - primarily for whole-slide imaging (WSI) formats\n{% tool \"aicsimageio\" %} (Python) - wraps vendor libraries and Bio-Formats to support a wide-range of formats in Python\n\nPermanent conversion: An alternative is to permanently convert your data to\n\nOME-Files - The Open Microscopy Consortium (OME) has developed an open format, \"OME-TIFF\", to which you can convert your data. The Bio-Formats (above) library comes with a command line to tool {% tool \"bfconvert\" %} that can be used to convert to files to OME-TIFF\nThe {% tool \"bioformats2raw\" %} and {% tool \"raw2ometiff\" %} toolchain provided by Glencoe Software allows the more performant conversion of your data, but requires an extra intermediate copy of the data. If you have available space, the toolchain could also be an option to consider.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":7,
        "total_chunks":14,
        "content":"te copy of the data. If you have available space, the toolchain could also be an option to consider. Cloud (or \"object\") storage: If you are storing your data in the cloud, you will likely need a different file format since most current image file formats are not suitable for cloud storage. OME is currently developing a next-generation file format (NGFF) that you can use. Metadata: If metadata are stored separately from the image data, the format of the metadata should follow the subject-specific standards regarding the schema, vocabulary or ontologies and storage format used such as:\n\nOME model XML-based representation of microscopy data. {% tool \"4dn-bina-ome-quarep\" %}.\nREMBI. (Meta)Data collection\nDescription\nThe acquisition of bioimaging data takes place in various environments. The (usually) light or electron microscope may be in a core facility, in a research lab or even remotely in a different institution.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":8,
        "total_chunks":14,
        "content":"microscope may be in a core facility, in a research lab or even remotely in a different institution. Regardless of where the instrument is located, the acquired imaging data is likely to be stored, at least temporarily, in a local, vendor specific systems PC next to the acquisition system due to their complexity and size. This is often unavoidable in order to securely store the data as quickly as the acquisition process itself. Due to the scale of data, keeping track of the image data and the associated data and metadata is essential, particularly in life sciences and medical fields. Organising, storing, sharing, publishing image data and metadata can be very challenging. Considerations\n\nConsider using an image management software platform. Image management software platforms offer a way to centralize, organize, view, distribute and track all of their digital images and photos. It allows you to take control over how your images are managed, used and shared within research groups.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":11,
        "total_chunks":14,
        "content":"tology-lookup-service\" %} - Ontology lookup service. {% tool \"bioportal\" %} - Biomedical ontologies. Existing data can be found by using the following resources:\nLINCS. Research Data repositories Registry. Find software tools, image databases for benchmarking, and training materials for bioimage analysis in the {% tool \"biii\" %} registry\n\nData publication and archiving\nDescription\nPublic data archives are an essential component of biological research. However, publishing image data and metadata can be very challenging for multiple reasons, just to mention a few: limited infrastructure for some domains, data support, sparse data. Bioimaging tools and resources are behind compared to what is available in sequencing for example. mainly due to limited infrastructures capable of hosting the data. There are a few ongoing efforts to breach that gap.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":12,
        "total_chunks":14,
        "content":"ted infrastructures capable of hosting the data. There are a few ongoing efforts to breach that gap. Two distinct types of resources should be considered: \n - Data archives (\"storage\") as a long-lasting storage for data and metadata and making those data easily accessible to the community.\n - Added-values archives: store enhanced curated data, typically aiming at a scientific community. Considerations\n\nIf you only need to make your data available online and have limited metadata associated, consider publishing in a Data archive. If your data should be considered as a reference dataset, consider an Added-values archive. Select and choose the repositories based on the following characteristics: Storage vs Added-value resources. Images format support. Supported licenses e.g. CC0 or CC-BY license. For example the {% tool \"image-data-resource\" %} uses Creative Commons Licenses for submitted datasets and encourages submitting authors to choose. Which types of access are required for the users e.g. download only, browse search and view data and metadata, API access.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_bioimaging_data_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/bioimaging_data.md",
        "file_name":"bioimaging_data.md",
        "chunk_index":13,
        "total_chunks":14,
        "content":"are required for the users e.g. download only, browse search and view data and metadata, API access. Does an entry have an access e.g. idr-xxx, EMPIAR-#####?\nDoes an entry have a DOI (Digital Object Identifier)?\n\n\n\nSolutions\nComparative table of some repositories that can be used to deposit imaging data: Repository\nType\nData Restrictions\nData Upload Restrictions\nDOI\nCost\n\n\n\n\n{% tool \"bioimagearchive\" %}\nArchive\nNo PIH data\n2TB\nYes\nFree\n\n\n{% tool \"dryad\" %}\nArchive\nNo PIH data\n300GB\nYes\nover 50GB (*)\n\n\n{% tool \"empiar\" %}\nAdded-value\nElectron microscopy imaging data\nNone\nYes\nFree\n\n\n{% tool \"image-data-resource\" %}\nAdded-value\nCell\/Tissue imaging data, no PIH data\nNone\nYes\nFree\n\n\n{% tool \"ssbd-database\" %}\nAdded-value\nBiological dynamics imaging data\nNone\n---\nFree\n\n\n{% tool \"ssbd-repository\" %}\nArchive\nBiological dynamics imaging data\nNone\n---\nFree\n\n\n{% tool \"zenodo\" %}\nArchive\nNone\n50GB per dataset\nYes\nFree\n\n\n\n\nPIH: Protected health information. (*) unless submitter is based at member institution.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"bioimaging_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Bioimaging data",
                "description":"Data management solutions for bioimaging data.",
                "contributors":[
                    "Sbastien Besson",
                    "Jean-Marie Burel",
                    "Susanne Kunis",
                    "Josh Moore",
                    "Stefanie Weidtkamp-Peters"
                ],
                "page_id":"bioimaging_data",
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "data_publication",
                        "existing_data",
                        "transfer",
                        "licensing",
                        "metadata",
                        "storage"
                    ],
                    "tool_assembly":[
                        "ome",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"RDMbites for using REMBI",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-data-sharing-collection"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Depositing IMI EUBOPEN High-Content Screening data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB067"
                    },
                    {
                        "name":"Depositing epifluorescence and confocal microscopy data to EBI BioImage Archive",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB086"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_toxicology_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Manuel Pastor\n- Janet Piero Gonzalez\n- Juan Manuel Ramrez-Anguita\n- Ferran Sanz\n- Miguel Angel Mayer\n- Laura Portell Silva\ndescription: Data management solutions for toxicology data. dsw:\n- name: Will you need existing data for toxicology research\n  uuid: a781badf-f7ee-4588-9478-d31470f00c38\nfaircookbook:\n- name: Creating InChIKeys for IUPAC names\n  url: https:\/\/w3id.org\/faircookbook\/FCB080\npage_id: toxicology_data\nrelated_pages:\n  tool_assembly: []\n  your_tasks:\n  - data_analysis\ntitle: Toxicology data",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"toxicology_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_toxicology_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":0,
        "total_chunks":21,
        "content":"Introduction\nToxicology is focused on the study of the adverse effects that occur in living organisms due to their interaction with chemicals. These chemicals range from substances found in nature to those made in the laboratory for many purposes (drugs, agrochemicals, pesticides, dyes, food additives, cosmetics, household products, etc.). A part of the toxicological research is devoted to the study of the adverse effects generated by chemicals in humans, while another part is devoted to the study of the noxious effects of the chemicals in the environment. The adversity is observed for a compound at a certain concentration. Consequently, hazard characterization should always consider exposure data. Toxicology was traditionally an observational science that obtained an important part of its data by means of experiments carried out on animals.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":1,
        "total_chunks":21,
        "content":" science that obtained an important part of its data by means of experiments carried out on animals. However, the limitations of animal models to produce human-relevant data, as well as the implementation of the 3R policies (reduction, replacement, and refinement of the animal experimentation) have motivated a change of paradigm towards a more mechanistic view. Many international initiatives are promoting this change. In this page, the relevant toxicological data management issues from in vitro, animal and human assays and ecotoxicology studies are explained, as well as the appropriate solutions for them. It has to be pointed out that most of the toxicology data is generated in a regulatory context, following guidelines for obtaining marketing approval and it constitutes an extremely valuable resource that should be made available to the scientific community. For that reason, efforts are being made for the systematic collection and storage of this data, as well as its standardization, which enables its integration and joint analysis.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":2,
        "total_chunks":21,
        "content":"rage of this data, as well as its standardization, which enables its integration and joint analysis. Data from in vitro assays - Data analysis and modelling\nDescription\nIn vitro cell culture technologies are commonly used in toxicology. They provide an alternative to animal testing and allow to assess the response of the cells to toxicant exposure. They also provide unique access to biochemical, and morphological changes that can not be observed in vivo. The most commonly used systems are immortalized cell lines and primary cell cultures. Although two-dimensional cell cultures are very popular, it has been shown that they do not represent the in vivo situation, as they are still far from the tissue organization and the cellular connections seen in an organism. Recent advances in three-dimensional cell culture technologies have allowed the widespread use of organoids. Organoids have been used for in vitro modelling of drug adverse effects, specifically in organs commonly susceptible to drug-induced toxicities (i.e. gastrointestinal tract, liver, kidney).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":3,
        "total_chunks":21,
        "content":"organs commonly susceptible to drug-induced toxicities (i.e. gastrointestinal tract, liver, kidney). In vitro tests in toxicology typically consist of exposing in vitro cell cultures to growing concentrations of the substance under study and recording changes using a wide variety of techniques, from high-content imaging to cell death. Among the diverse sources of toxicological in vitro data it is worth mentioning the results of the Toxicology in the 21st Century program, or {% tool \"tox21-toolbox\" %}. The results of this project (data and tools) are publicly available. Gene expression changes that occur in biological systems in response to exposure to xenobiotics may represent mechanistically relevant cellular events contributing to the onset and progression of xenobiotic-induced adverse health outcomes. Transcriptomics data can be used to identify changes to gene expression profiles that occur in response to drug treatment which might provide predictive and mechanistic insight into the mode of action of a drug, as well as the molecular clues linked to possible toxicity.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":4,
        "total_chunks":21,
        "content":"sight into the mode of action of a drug, as well as the molecular clues linked to possible toxicity. Considerations\nResults of in vitro assays are typically collected as dose-response curves. These results should be processed to obtain indexes indicating the concentration at which relevant effects are observed like LC50, IC50, benchmark concentration (BMC). This procedure can involve non-linear curve fitting and outlier removal. It is advisable to report the details of the data processing in order to obtain reproducible results and standarization. Solutions\n\n{% tool \"toxcast-data\" %} has published an R-package with the tools used to process the high throughput chemical screening data. Benchmark concentrations (and doses) can be computed with free software as {% tool \"proast\" %} and {% tool \"bmds\" %}. For experiments where gene expression has been measured in response to a toxicant, R packages such as {% tool \"deseq2\" %} for RNA-Seq data, and {% tool \"limma\" %} for microarray data are used to find genes that are differentially expressed.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":5,
        "total_chunks":21,
        "content":"and {% tool \"limma\" %} for microarray data are used to find genes that are differentially expressed. In silico prediction models can be developed starting from a series of compounds annotated with the results on in vitro methods. The quality of the predictions provided by these methods are often comparable with those obtained by experimental methods, particularly when the models are used within their applicability domain. {% tool \"flame\" %} is an open-source modelling framework developed specifically for this purpose. {% tool \"edkb\" %} is a platform designed to foster the development of computational predictive toxicology. This platform allows direct access to ten libraries containing the following resources: a biological activity database, QSAR training sets, in vitro and in vivo experimental data for more than 3,000 chemicals, literature citations, chemical-structure search capabilities. The {% tool \"t3db\" %} is a bioinformatics resource that combines exhaustive toxin data with toxin target information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":6,
        "total_chunks":21,
        "content":"\" %} is a bioinformatics resource that combines exhaustive toxin data with toxin target information. Currently it presents more than 42,000 toxin-target associations extracted from other databases, government documents, books and scientific literature. Each toxin record includes data on chemical properties and descriptors, toxicity values and medical information. The {% tool \"tox21-toolbox\" %} is a unique collaboration between several federal agencies to develop new ways to rapidly test whether substances adversely affect human health. The Tox21 Toolbox contains data-analysis tools for accessing and visualizing Tox21 quantitative high-throughput screening (qHTS) 10K library data, as well as integrating with other publicly available data. Data from animal assays - Existing data and vocabularies\nDescription\nAssays are expensive. Most animal data come from compiling normative studies which are compulsory for obtaining the approval of diverse regulatory agencies prior to commercialization.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":7,
        "total_chunks":21,
        "content":"are compulsory for obtaining the approval of diverse regulatory agencies prior to commercialization. The choice of the species and strains was determined by their representability for the studied endpoints, and often defined in this legislation and comprises from invertebrate (e.g., daphnia is commonly used to study aquatic toxicity) and fish (e.g., zebrafish), to rodents (mice, rats, rabbits, guinea pigs) and mammals (dogs, primates). The representability of animal data to predict human toxicity is questionable and a precautionary approach or the use of extrapolation factors is recommended. In spite of their inconveniences (high costs, time consumption, requirements of significant amounts of the substance being tested, limited translatability of the observed results), in many cases, there is no suitable replacement for in vivo tests. The replacement of in vivo data for alternative approaches (often called NAM, New Approach methodologies) is an active research field. Two important toxicogenomics resources containing animal data are {% tool \"tg-gates\" %}, and {% tool \"drug-matrix\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":8,
        "total_chunks":21,
        "content":"cogenomics resources containing animal data are {% tool \"tg-gates\" %}, and {% tool \"drug-matrix\" %}. These resources contain gene expression data in several rat tissues for a large number of compounds, in several doses and exposure times. They also include histopathology annotations and chemistry measurements. Considerations\nData generated in normative studies were obtained under Good Laboratory Practices (GLP) conditions, and therefore the quality of the data is high. However, these studies were oriented to characterize a single compound, and not to carry out comparative analyses. Also, the doses used in the studies were designed to detect adversity and could be not representative of the exposure reached by consumers or patients of the marketed substances. Most of the time, data is not modelled using standards, for example, drugs are annotated using common names, and histopathology annotations are not coded in a controlled vocabulary.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":9,
        "total_chunks":21,
        "content":"notated using common names, and histopathology annotations are not coded in a controlled vocabulary. Solutions\n\nUse information about genes, and variants associated with human adverse effects, from platforms such as {% tool \"disgenet\" %}, {% tool \"ctd\" %}, and {% tool \"pharmgkb\" %}. Histopathology data requires the use of a controlled vocabulary like {% tool \"cdisc-send\" %}. The extension and curation of ontologies like CDISC\/SEND to specific domains is facilitated by tools like {% tool \"ontobrowser\" %}. In order to reduce the number of animals used in toxicological studies, it has been suggested to replace control groups with historically collected data from studies carried out in comparable conditions (so-called Virtual Control Groups). VCGs are being developed by eTRANSAFE project. Data from human assays - Existing data and vocabularies\nDescription\nHuman response to toxic agents is generally excluded from toxicity assays as it entails major ethical issues.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":10,
        "total_chunks":21,
        "content":"ponse to toxic agents is generally excluded from toxicity assays as it entails major ethical issues. Although relevant information on potential adverse effects is available from animal and in vitro assays, human data is crucial for accurate calibration of toxicity models based on these studies. Traditionally, it was frequent that exposure to an unknown or unexpected toxic agent was eventually identified as the trigger factor of a health problem for which an evident reason did not apparently exist. Thereby, unintentional human exposure to toxic agents yielded toxicological data. Two main types of sources exist in this regard:\n- Individual or group case reports are a fundamental source of information when no previously reported human toxicity information exists.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":11,
        "total_chunks":21,
        "content":"e a fundamental source of information when no previously reported human toxicity information exists. They include exhaustive medical information on a single patient or a set of patients with similar symptomatology which is gathered from health care facilities to identify etiology.\n- Epidemiologic studies (ESs) are focused on the possible association between the exposure to a substance and the potential adverse reactions observed in a given human population. ESs are classified as occupational (individuals are exposed in the workplace), or environmental (individuals are exposed through daily living). In the pharmaceutical context though, intentional human exposure to drug candidates is a necessary step in the development of medications. During the clinical trial stage, human exposure to substances is required to characterize efficacy and safety. This process consists of several phases which are exhaustively controlled and subjected to strict regulations and ethical review.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":12,
        "total_chunks":21,
        "content":"ral phases which are exhaustively controlled and subjected to strict regulations and ethical review. Adverse-event monitoring and reporting is a key issue in the assessment of the risk-benefit balance associated with the medication which is established from the clinical trials data. After the medication is released to the market it is subjected to an exhaustive pharmacovigilance process focused on the identification of safety concerns. Serious and non-serious adverse effects reporting from several sources are collected during a period and medication risk-benefit balance is re-evaluated. Considerations\nData from human assays are highly heterogeneous and integration with in vitro and animal data is a challenging task. There is a broad range of resources containing human data publicly available, but sometimes data access is limited. The nature of toxicological data has evolved in recent times and available resources and repositories comprise a variety of different types of data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":13,
        "total_chunks":21,
        "content":"recent times and available resources and repositories comprise a variety of different types of data. On one hand, many data sources are nicely structured but, on the other hand, some others provide detailed information in an unstructured format. Data should be harmonized before integration. Disparate data sources are organized differently and also use different terminologies:\n- Resources providing access to occupational epidemiologic studies report health risks by using condition-centred vocabularies like (ICD9-CM and ICD10-CM) or just uncoded terms whereas databases reporting possible links between observed adverse reactions and medications are usually expressed according to the MedDRA ontology. - Different chemical identifiers are used depending on the toxic agent.\n- Similarly, medication identifiers are not always consistent among different sources.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":14,
        "total_chunks":21,
        "content":" toxic agent.\n- Similarly, medication identifiers are not always consistent among different sources. This is a challenging issue as many medicinal products have different denominations and available commercial presentations depending on the country\/region where the product is commercialized.\n- Usually, structured resources present metadata explaining how the data is organized, thus enabling an easy data transformation process. Conversely, non-structured resources are not easy to harmonize as data organization is not consistent among the available documents. Databases containing clinical toxicological data of drugs can contain the results of clinical studies {% tool \"clinicaltrials-gov\" %}, frequent adversities (Medline), or collect pharmacovigilance data {% tool \"faers\" %} depending on the data being incorporated, the interpretation is different.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":15,
        "total_chunks":21,
        "content":"e data {% tool \"faers\" %} depending on the data being incorporated, the interpretation is different. For example, in the case of spontaneous reporting systems, the frequency with which an adverse event is reported should be considered relative to the time the compound has been in the market and the frequency of these adverse events in the population treated. Solutions\nExamples of databases containing drug toxicological data:\n- {% tool \"clinicaltrials-gov\" %} is a resource depending on the National Library of medicine which makes available private and public-funded clinical trials.\n- The FDA Adverse Event Reporting System {% tool \"faers\" %} contains adverse event reports, medication error reports and product quality complaints submitted by healthcare professionals, consumers, and manufacturers. - The {% tool \"eudravigilance\" %} is the European database of suspected adverse drug reaction reports is a public resource aimed to provide access to reported suspected side-effects of drugs. Side-effects are defined according to the MedDRA ontology.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":16,
        "total_chunks":21,
        "content":"reported suspected side-effects of drugs. Side-effects are defined according to the MedDRA ontology. - The {% tool \"txg-mapr\" %} is a tool that contains weighted gene co-expression networks obtained from the Primary Human Hepatocytes, rat kidney, and liver TG-GATEs datasets. Harmonization of terminologies can be achieved by using different resources:\n\nThe Unified Medical Language System {% tool \"umls\" %} provides mappings between different medical vocabularies. It includes common ontologies within the condition\/diagnosis domain like SNOMED, ICD9CM, ICD10CM, and also the MedDRA ontology. The {% tool \"ohdsi\" %} initiative for health data harmonization is an alternative solution for the mapping of vocabularies needed for the harmonization of different resources. This initiative maintains the ATHENA set of vocabularies which is in constant evolution and covers relevant domains in the realm of health care.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":17,
        "total_chunks":21,
        "content":"vocabularies which is in constant evolution and covers relevant domains in the realm of health care. The OHDSI community is paying special attention to the mappings between medication identifiers coming from national regulatory agencies of the countries of provenance of the institutions involved in the initiative, and the {% tool \"rxnorm\" %} identifier which is the standard vocabulary used by OHDSI.\nResources in the context of environmental ({% tool \"iter\" %}, {% tool \"iris\" %}) or occupational ({% tool \"haz-map\" %}) toxicity using {% tool \"cas-registry\" %} Number identifiers can be connected with those in the pharmaceutical field prone to use {% tool \"chembl\" %} identifiers via molecular identifiers available in both resources like the standard InChI or standard InChI Key representations. Services like EBIs {% tool \"unichem\" %} can help to translate between different chemical identifiers. The {% tool \"ghs-classification\" %} was developed by the United Nations in an attempt to align standards and chemical regulations in different countries.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_18",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":18,
        "total_chunks":21,
        "content":"the United Nations in an attempt to align standards and chemical regulations in different countries. GHS includes criteria for the classification of health, physical and environmental hazards, and what information should be included on labels of hazardous chemicals and safety data sheets. To import unstructured data sources into structured schemas is a really challenging task as it involves the application of natural language processing technologies. The development of these tools in the field of toxicology is still at the embryonic stage but several initiatives exist:\n\nThe {% tool \"limtox\" %} system is a text mining approach devoted to the extraction of associations between chemical agents and hepatotoxicity. The {% tool \"aop4eupest\" %} webserver is a resource for the identification of annotated pesticides-biological events involved in Adverse Outcome Pathways (AOPs) via text mining approaches. Ecotoxicology data - Existing data\nDescription\nSubstances can also be characterized according to their potential to affect the environment.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_19",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":19,
        "total_chunks":21,
        "content":"ription\nSubstances can also be characterized according to their potential to affect the environment. This data is collected by national and international regulatory agencies (e.g., ECHA in EU and, EPA in the USA) aiming to control the production, distribution, and use of potentially hazardous substances. Data collection is largely guided by legislation, which defines the test that should be carried out and the data that should be collected. Considerations\nWhen considering the effect of a substance on the environment, in addition to its hazard characterization, it is important to consider its environmental fate in terrestrial and aqueous environments, and its properties with respect to degradation by diverse routes (chemical, biodegradation, photodegradation). Solutions\n\nThe ECOTOXicology Knowledgebase ({% tool \"ecotox\" %}) is a comprehensive, publicly available Knowledgebase providing single chemical environmental toxicity data on aquatic life, terrestrial plants, and wildlife.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_toxicology_data_md_20",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/toxicology_data.md",
        "file_name":"toxicology_data.md",
        "chunk_index":20,
        "total_chunks":21,
        "content":"iding single chemical environmental toxicity data on aquatic life, terrestrial plants, and wildlife. The {% tool \"comptox\" %} provides toxicological information for over 800.000 chemical compounds, including experimental and predicted fate information. The {% tool \"nbp\" %} is a public resource that offers an assessment of nutritional status and the exposure of the U.S. population to environmental chemicals and toxic substances. The {% tool \"npds\" %} is a resource that provides poisson exposure occurring in the US and some freely associated states. {% tool \"pharos\" %} provides hazard, use, and exposure information on 140,872 chemicals and 180 different kinds of building products. The {% tool \"reach-registered-substances\" %} is a portal with public data submitted to ECHA in REACH registration dossiers by substance manufacturers, importers, or their representatives, as laid out by the REACH Regulation (see Understanding REACH regulation).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"toxicology_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Toxicology data",
                "description":"Data management solutions for toxicology data.",
                "contributors":[
                    "Manuel Pastor",
                    "Janet Piero Gonzalez",
                    "Juan Manuel Ramrez-Anguita",
                    "Ferran Sanz",
                    "Miguel Angel Mayer",
                    "Laura Portell Silva"
                ],
                "page_id":"toxicology_data",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis"
                    ],
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you need existing data for toxicology research",
                        "uuid":"a781badf-f7ee-4588-9478-d31470f00c38"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating InChIKeys for IUPAC names",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB080"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_cancer_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Ftima Al-Shahrour\n- Erika Schirghuber\n- Robin Navest\n- Eva Budinska\n- Gonzalo Gmez\n- Mara Gonzlez\n- Fotis Psomopoulos\n- Sarah Morgan\n- Sophie Huiskes Berends\ndescription: Data management solutions for human cancer data\npage_id: cancer_data\nrelated_pages:\n  your_tasks:\n  - sensitive\n  - gdpr_compliance\n  - data_security\ntitle: Cancer data\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection\n- name: OMOP Common Data Model and the OHDSI analytics for observational analytics\n    of real world healthcare data courses in EHDEN academy\n  url: https:\/\/academy.ehden.eu\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"cancer_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_cancer_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":0,
        "total_chunks":27,
        "content":"Introduction\nCancer is a heterogeneous disease that affects almost everyone: as a patient, survivor, relative or friend. This page focuses on the key data management challenges, considerations and solutions that are relevant across all stages of the patients journey from cancer prevention, diagnosis and treatment to assessment of patient outcomes and monitoring those at follow-up visits. Each stage of the patient journey has different associated data types,  a number of  technical, ethical, legal and organisational challenges. In this page we focus on the management of human health data generated from patients diagnosed with both solid and liquid tumors (oncology or hematology). Data might be collected by a number of different means, e.g. from clinical trials and non-interventional studies (NIS) or real-world data (RWD) from observational studies (e.g. registries) or captured in electronic health record (EHR) hospital systems during primary care.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":1,
        "total_chunks":27,
        "content":"e.g. registries) or captured in electronic health record (EHR) hospital systems during primary care. Efficient data management and interoperability are essential for ensuring timely and accurate diagnoses and treatment while maintaining compliance with ethical and regulatory standards. In the following sections we will address data management best practices, considerations and possible solutions for effective management of data in each stage (Figure1)  of the individual patient's journey. {% include image.html file=\"cancer_dm_stages.png\" caption=\"Figure 1. Cancer data management challenges at different stages of patient journey.\" %}\nCancer prevention\nDescription\nPrimary prevention data\nPrimary prevention in cancer care refers to strategies aimed at reducing the risk of developing cancer.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":2,
        "total_chunks":27,
        "content":"mary prevention in cancer care refers to strategies aimed at reducing the risk of developing cancer. Data from cancer registries (which includes spatial patterns of cancer incidence, as well as stage, survival and mortality) in combination with genetic predisposition and\/or exposome data (including exposure to environmental factors and socio-economic characteristics) can be used to identify risk factors for developing cancer. These cancer registries are information systems designed for the collection, storage, and management of data on persons with cancer and play a critical role in cancer research, surveillance, cancer prevention and control interventions. Key challenges include heterogeneity in data collection and integrating diverse datasets from different sources, e.g. linkage of exposome data to the health data from cancer registries. Secondary prevention data\nSecondary prevention in cancer care focuses on early detection and intervention to identify cancer at an early stage when it is more treatable and potentially curable.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":3,
        "total_chunks":27,
        "content":"intervention to identify cancer at an early stage when it is more treatable and potentially curable. Survival rate improvement in most major tumour types depends on early detection, which has prompted screening programs in many European countries. These programs produce highly relevant data sets for further (data-driven) research on early cancer diagnostics. This data typically consists of health and bioimaging data, such as mammograms, colonoscopies, or blood tests. Most of this data contains personal health information and must be managed in compliance with privacy regulations such as GDPR. Key challenges include integrating diverse datasets and ensuring data accuracy since the screening programs could be organised on national or regional level. Additionally, the risks and benefits of screening programs must be balanced. Considerations\nPrimary prevention data\n\nConsider local cancer registries in the different European countries as they can be organised locally, regionally or nationally. Think about the health data access procedures which could be different for each cancer registry.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":4,
        "total_chunks":27,
        "content":"ly. Think about the health data access procedures which could be different for each cancer registry. Bear in mind the interoperability of variables from the exposome data could be suboptimal due to heterogeneous data collection between different sources. Linkage between different data types, e.g. exposome and health data, could be non-trivial. Think about the following:\nDoes the geographical grid match? Does the timestamp of the data correlate? Exposome data is considered non-personal data, but once linked to personal data the linked dataset becomes personal data and privacy has to be ensured in compliance with applicable legislation (e.g. GDPR). Secondary prevention data\n\nThe data access procedure could be different for different data sources. Be mindful to contact the relevant data creators and managers for the relevant access rights. Interoperability of data originating from multiple screening programs is not guaranteed. For general health data considerations, see Health data page. For general bioimaging data considerations, see BioImaging data page.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":5,
        "total_chunks":27,
        "content":"rations, see Health data page. For general bioimaging data considerations, see BioImaging data page. Solutions\nPrimary prevention data\n\nFor data management considerations and solutions of Patient-generated health data and Electronic Health Record (EHR) data see the Health data page. Cancer registry data common rules and definitions used within Europe defined by the European Network of Cancer Registries (ENCR). Exposome data management recommendations under development by Environmental Exposure Assessment Research Infrastructure (EIRENE-RI). Exposome (meta)data definitions used within Europe defined by Eurostat, Euro SDMX Registry. Secondary prevention data As there are no commonly accepted data collection standards currently, EOSC4Cancer developed a harmonised codebook for colorectal cancer screening (based on Dutch, Catalan, Italian and Czech screening codebooks), which could be used as a common basis to be extended to other cancer types.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":6,
        "total_chunks":27,
        "content":"ch screening codebooks), which could be used as a common basis to be extended to other cancer types. Cancer diagnosis\nDescription\nA cancer patient's journey starts with a confirmed diagnosis, which involves clinical evaluation, imaging, laboratory tests, and testing of molecular biomarkers by different methods (e.g. immunohistochemistry, next-generation sequencing, in situ hybridisation) in biopsies (e.g. tissue or liquid biopsies) to confirm malignancy and assess tumour characteristics. Cancer diagnosis is a multi-step process that begins with a patient's clinical presentation, such as symptoms or incidental findings during routine check-ups or specialized screening programs (e.g. mammography for breast cancer, FIT tests and consequent colonoscopy for colorectal cancer, Pap smears and HPV PCR for cervical cancer). If cancer is suspected, the diagnostic journey typically involves a combination of medical imaging (CT, MRI, PET scans, ultrasound), laboratory tests, and biopsy procedures to confirm malignancy, each step producing a different data type.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":7,
        "total_chunks":27,
        "content":"atory tests, and biopsy procedures to confirm malignancy, each step producing a different data type. Integrating diverse data sources, including clinical history, imaging, pathology, and genomic data, allows for a more comprehensive understanding of the disease and personalized treatment strategies.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":8,
        "total_chunks":27,
        "content":" allows for a more comprehensive understanding of the disease and personalized treatment strategies. Cancer diagnosis relies on data from multiple sources that are also often used at other stages of the cancer patient's journey (prevention, treatment, follow-up):\n\nImaging (MRI, CT, PET scans) provides tumor size, location, and spread\nPathology (biopsy analysis) confirms tumor type and molecular characteristics\nGenetic\/Genomic profiling can identify tumor genomic alterations relevant for molecularly matched therapies, pharmacogenomic biomarkers relevant for drug metabolism, germline alterations\nClinical data (patient history, symptoms, lab tests) provide context on overall health and treatment history\n\nManaging cancer data for diagnosing and determining the best treatment for localized tumors presents several challenges, as it requires working with a wide range of sensitive patient data, coming from different departments\/sources, including clinical records, radiological images (radiology), histopathological evaluation (pathology) and genomic profiles (pathology or other specialized laboratory).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":9,
        "total_chunks":27,
        "content":"athological evaluation (pathology) and genomic profiles (pathology or other specialized laboratory). This makes interoperability and data integration essential to enable a holistic approach to cancer care. Consequently,  data management must be precise to ensure that healthcare professionals have accurate and comprehensive information for tumour identification and treatment decisions. Data security and compliance with ethical guidelines (such as GDPR) are critical to protecting patient privacy when dealing with personal health records and sensitive tumour data. Furthermore, the need for data to be accessible across different healthcare providers and research institutions adds complexity to the management process. Considerations\n\nAre all clinically relevant variables collected using standard vocabularies across data domains including socio-demographics, risk factors, and tumor-specific metadata (e.g. Tumour- Nodes-Metastases (TNM) stage, histology, genomic alterations)?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":10,
        "total_chunks":27,
        "content":"tumor-specific metadata (e.g. Tumour- Nodes-Metastases (TNM) stage, histology, genomic alterations)? Are diagnostic data and images stored in standardized formats (e.g. {% tool \"dicom\" %} for imaging, {% tool \"vcf\" %} for genomics) to allow long-term usability and reanalysis? Is there a data management system in place to ensure interoperability between different data types (e.g. imaging, molecular, and health records)? Are there AI-based tools or decision-support systems integrated into the workflow to assist oncologists in making diagnostic decisions? Solutions\n\nUtilize structured clinical data models and interoperability frameworks (e.g. {% tool \"hl7-fhir\" %}, {% tool \"omop-cdm\" %}, {% tool \"dicom\" %} and {% tool \"xnat\" %} for imaging) to facilitate the integration of multi-modal diagnostic data such as clinical, imaging, and molecular data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":11,
        "total_chunks":27,
        "content":"litate the integration of multi-modal diagnostic data such as clinical, imaging, and molecular data. Implement version-controlled patient records using EHR systems that support updates based on evolving classification standards and cancer-specific coding dictionaries for diagnosis (e.g. {% tool \"icd-o-3\" %} or {% tool \"snomed-ct\" %} for cancer diagnosis and topography, {% tool \"uicc-tnm\" %} staging system, {% tool \"who-tc\" %}). Utilize secure repositories and specialized cancer clinical data management systems (e.g. {% tool \"redcap\" %}, {% tool \"i2b2\" %}, {% tool \"cbioportal\" %}) that comply with GDPR, HIPAA, and other regulatory frameworks. Implement standardized consent forms and patient data governance frameworks, such as GA4GH's {% tool \"data-use-ontology\" %}, to allow data sharing while maintaining privacy.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":12,
        "total_chunks":27,
        "content":"ks, such as GA4GH's {% tool \"data-use-ontology\" %}, to allow data sharing while maintaining privacy. Store raw sequencing and imaging data in cloud-based or institutional repositories (e.g. {% tool \"the-european-genome-phenome-archive\" %}, {% tool \"dbgap\" %}, {% tool \"sequence-read-archive\" %}, {% tool \"tcia\" %} for imaging) to allow reanalysis when new prognostic markers emerge. Adopt federated learning approaches (e.g. {% tool \"fega\" %}, Federated EHR Learning Models) to enable collaborative research without transferring sensitive patient data. Integrate AI-based imaging tools (e.g. {% tool \"path-ai\" %}, {% tool \"qure-ai\" %}, {% tool \"paige-ai\" %}) for radiology and pathology analysis to assist in detecting subtle cancer features and ensure adherence to standards (e.g. {% tool \"dome\" %}, {% tool \"tripod\" %}), avoiding biases in cancer diagnosis. Cancer treatment\nDescription\nCancer treatment varies depending on the type and stage of cancer (e.g. locally advanced, metastatic disease), as well as the overall health and preferences of the patient.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":13,
        "total_chunks":27,
        "content":"locally advanced, metastatic disease), as well as the overall health and preferences of the patient. The use of advanced diagnostic techniques such as PET-CT\/MRI, molecular profiling (e.g. next-generation sequencing, comprehensive genomic profiling (CGP), whole genome sequencing (WGS) and liquid biopsies (e.g. ctDNA) has tremendously increased the data density and complexity to be dealt with at this stage of disease. Cancer treatment employs a wide range of data types, such as patients' therapeutic regimens, including surgery techniques, stem cell transplantation, radiotherapy, systemic therapies (e.g. hormone, chemotherapy, immunotherapy and targeted therapies) as well as  imaging data, biomarker assessments, responses to therapies data, clinical trial outcomes, drug efficacy, and adverse reactions. Cancer treatment data is commonly associated with further clinical data and patients' information. Due to their sensitive nature, the data must be managed following ethical guidelines, data protection laws, and FAIR (Findable, Accessible, Interoperable, and Reusable) principles.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":14,
        "total_chunks":27,
        "content":"ines, data protection laws, and FAIR (Findable, Accessible, Interoperable, and Reusable) principles. Although cancer treatment data is crucial for developing personalized medicine approaches, improving patient outcomes and advancing research, comprehensive documentation of cancer treatment data remains limited in cancer registries and public datasets. This challenge is often due to data privacy regulations, ethical concerns, and varying reporting standards, which highlight disparities arising from resource limitations, national database structures, and language barriers. In addition, while cancer treatment data publication has increased, it remains inconsistent due to the lack of data standardization along with sparse ontologies. The increasing use of electronic health records across western countries, along with standardized cancer classification systems (e.g. WHO, ICD, CAP), staging systems (e.g. {% tool \"uicc-tnm\" %} ), and pioneering drug (e.g. DRON PDRO) and side effects (e.g. OAE) ontologies, facilitates data collection.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":15,
        "total_chunks":27,
        "content":"ioneering drug (e.g. DRON PDRO) and side effects (e.g. OAE) ontologies, facilitates data collection. However, clear guidelines for cancer treatment data collection and tools for unified analysis still need to be developed. Considerations\n\nDo you use human data? You can find more information on the Human data page. Are the required clinical variables related to the treatment available? How will clinical variables be integrated with molecular or imaging data? Which resources are available for downloading and analysing cancer treatment data? Where can you access standard-of-care cancer clinical guidelines?\nHow to access cancer treatment data from clinical trials or side effect registries? How to propose cancer treatments based on cancer multi-omics data?\n\nSolutions In order to obtain information about oncological clinical practice guidelines several medical societies provide guidance:\n\nEuropean Society of Medical Oncology (ESMO)\nAmerican Society of Clinical Oncology (ASCO) General treatment types\nClinical guidelines\nNational Comprehensive Cancer Network (NCCN)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":16,
        "total_chunks":27,
        "content":"logy (ASCO) General treatment types\nClinical guidelines\nNational Comprehensive Cancer Network (NCCN) A more unified approach to cancer treatment data collection is crucial for improving outcome analysis and supporting all stakeholders. To support this aim, several consortia and institutions provide annotated reference datasets with cancer treatment data: Reference databases and platforms:\n\n{% tool \"the-european-genome-phenome-archive\" %} : Service for permanent archiving and sharing of personally identifiable genetic, phenotypic, and clinical data. {% tool \"cbioportal\" %}: Multidimensional genomics data with treatment annotations. {% tool \"icgc-argo\" %}: Comprehensive clinical and genomic data for >100,000 patients. {% tool \"aacr-genie\" %}: Cancer genomic dataset. {% tool \"msk-chord\" %}: Molecular and clinical data for cancer treatment analysis. {% tool \"hmf\" %}: Multi-omic data for >7000 patients. {% tool \"wayfind-r\" %}: Real-world clinical\/genomic data from patients diagnosed with solid tumours across geographies. {% tool \"eucaim\" %}: Federated platform for Cancer image data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":17,
        "total_chunks":27,
        "content":"ith solid tumours across geographies. {% tool \"eucaim\" %}: Federated platform for Cancer image data. {% tool \"all-of-us\" %}: US-based patient health data. {% tool \"uk-biobank\" %}: UK-based longitudinal study of 500,000 UK individuals; multi-level data across a range of diseases. {% tool \"tcia\" %}: Imaging data with metadata. {% tool \"gdsc\" %}): Drug sensitivity data from 1000 cancer cell lines. {% tool \"ctrp\" %}: Genetic and drug sensitivity relationships. Drug and trial public repositories:\n\n{% tool \"nci-drug-database\" %}\n{% tool \"ema-medicine-finder\" %}\n{% tool \"clinicaltrials-gov\" %}\n{% tool \"drugbank\" %}\n{% tool \"dgidb\" %}\n{% tool \"drugmap\" %}\n{% tool \"ttd\" %} \n{% tool \"pharmgkb-cancer-pgx\" %}\n{% tool \"oncokb\" %}\n{% tool \"sider\" %}\n\nGenomics & multi-omics resources:\n\n{% tool \"mtb-portal\" %}: provides a general framework to interpret the functional and predictive relevance of a given list of gene variants in interactive reports. {% tool \"pandrugs\" %}: a platform to prioritize cancer drug treatments according to individual multi-omics data (SNVs, CNVs and gene expression).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_18",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":18,
        "total_chunks":27,
        "content":"ze cancer drug treatments according to individual multi-omics data (SNVs, CNVs and gene expression). {% tool \"cancer-genome-interpreter\" %}: flags genomic biomarkers of drug response with clinical relevance. {% tool \"civic\" %}: a free resource to identify the best cancer treatment options based on DNA alterations. Topograph: Therapy-Oriented Precision Oncology Guidelines for Recommending Anti-cancer Pharmaceuticals. Monitoring of outcomes during follow-up visits\nDescription\nThe follow-up phase in cancer care is a critical component of comprehensive patient management, ensuring long-term monitoring and well-being of cancer survivors. This stage focuses on assessing treatment outcomes, detecting potential recurrences, managing long-term side effects, and enhancing the overall quality of life. Effective follow-up strategies integrate not only systematic clinical evaluations, which include routine medical visits, imaging exams (e.g. MRI, CT, PET), and biomarker testing (e.g. CEA, PSA, ctDNA), but also patient-reported outcomes (PROs).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_19",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":19,
        "total_chunks":27,
        "content":", CT, PET), and biomarker testing (e.g. CEA, PSA, ctDNA), but also patient-reported outcomes (PROs). In this context, the increasing adoption of digital health technologies, including wearable devices and mobile health applications, as well as Artificial Intelligence and predictive analytics, has transformed post-treatment monitoring. On one hand, it has enabled real-time remote tracking of health metrics (e.g. physical activity, heart rate, sleep patterns etc), facilitating early detection of potential complications and on the other hand help anticipate complications and tailor follow-up schedules to individual patients' needs. Both scenarios lead to generation of diverse data types. Additionally, cancer registries (CRs) and clinical trial databases play a fundamental role in storing longitudinal data on disease progression, survival rates, and treatment efficacy, allowing researchers to analyze trends, identify recurrence risk factors, and refine personalized follow-up guidelines.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_20",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":20,
        "total_chunks":27,
        "content":"s to analyze trends, identify recurrence risk factors, and refine personalized follow-up guidelines. However, due to the wide heterogeneity of data types, sources, and healthcare systems achieving seamless interoperability and standardisation of follow-up data, to support individualized patient management and optimize data reuse in cancer research remains a major challenge. In addition, data collection and management at this stage presents other challenges, including: (i) the sensitive nature of the data, requiring strict adherence to regulatory and ethical frameworks, (ii) the lack of consistency and\/or quality of patient follow-up information, and (iii) the lack of standardization and inherent subjectivity in survivorship quality-of-life data, influenced by patient perception, reporting methods, and assessment tools.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_21",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":21,
        "total_chunks":27,
        "content":"hip quality-of-life data, influenced by patient perception, reporting methods, and assessment tools. Considerations\nDifferent considerations should be taken into account depending on the type of data being managed:\n\nUse specific standards and methods to extract and transform data included in the Electronic Health Record (clinical data, diagnoses, demographics, procedures, medications, vital signs, laboratory results). For Considerations towards improved reuse of EHR refer to the section in the Health data page. Considerations for managing  imaging data (and histopathological data), binary files,as well as the associated metadata can be found in the Bioimaging data page. For human genomic data, established research ethical guidelines and legislations must be followed as described in the Human data page. Since health data falls under the \"special category of data\" as defined by the GDPR, strict guidelines and considerations must be followed when handling this information covered in the GDPR compliance and Data Sensitivity pages of the RDMkit.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_22",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":22,
        "total_chunks":27,
        "content":"n handling this information covered in the GDPR compliance and Data Sensitivity pages of the RDMkit. For PROs, to collect data directly from cancer patients and\/or survivors, follow the considerations listed on the health data page. Additionally, since these PROs focus on quality-of-life and are inherently subjective, additional considerations must be addressed:\n\n\nAre questionnaires designed to minimize ambiguity and ensure that all patients interpret questions in a similar way?\n\nAre there methods in place to differentiate between true changes in quality of life and variations due to individual perception or recall bias? Have statistical or methodological approaches been considered to adjust for subjectivity in self-reported data? How is the potential discrepancy between patient-reported outcomes and clinician assessments addressed? For data collected from wearable devices and mobile applications, the follow considerations should be taken into account:\n\n\nAre the wearable devices and mobile applications validated to provide accurate real-time measurements?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_23",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":23,
        "total_chunks":27,
        "content":"e the wearable devices and mobile applications validated to provide accurate real-time measurements? How is the data quality ensured, considering potential sensor calibration issues, environmental factors, or user error? Are there mechanisms in place to handle missing or incomplete data, such as when the device is not worn or battery levels are low? How are transient fluctuations in health metrics differentiated from clinically significant changes? Are patient-specific factors incorporated into the analysis to improve data interpretation? Is there a system for aggregating data from multiple devices or platforms to create a comprehensive view of the patients health metrics over time? To address the potential lack of consistency and\/or quality in patient follow-up information, particularly over the long term, the following considerations should be taken into account: How will data consistency be maintained if patients change healthcare providers, devices, or platforms over time?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_24",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":24,
        "total_chunks":27,
        "content":" consistency be maintained if patients change healthcare providers, devices, or platforms over time? Are there standardized processes in place to ensure that follow-up data from different sources can be seamlessly integrated and compared? Is there a plan to handle potential gaps in data, such as missed follow-up appointments or missing reports? What strategies are in place to encourage continuous patient engagement and adherence to follow-up protocols? Are there periodic checks or audits in place to validate data quality and identify potential discrepancies or inconsistencies? Solutions\n\nTo address the challenges associated with the monitoring of outcomes during follow-up visits, the following solutions are proposed: Adopt common data models and standards to ensure consistency and interoperability of clinical data across institutions. Regarding data included in the EHR, for standards that are likely to be present as part of such systems, common data models that can facilitate data sharing, and tools for data integration, refer to the section in the Health data page.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_25",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":25,
        "total_chunks":27,
        "content":"cilitate data sharing, and tools for data integration, refer to the section in the Health data page. Regarding imaging data, for standard (meta)data formats, management platforms, ontologies resources, and image repositories, refer to the Bioimaging page. Use cancer-specific standard terminologies, ontologies, and reference databases for coding diagnosis related data (e.g. {% tool \"icd-o-3\" %}, {% tool \"who-tc\" %}, {% tool \"uicc-tnm\" %}), treatment related data (e.g. {% tool \"ctrp\" %}, {% tool \"civic\" %}, {% tool \"ttd\" %}) and follow-up related data (e.g. {% tool \"meddra\" %}, {% tool \"ecog\" %}, {% tool \"percist\" %}). Utilise GDPR compliant EDC systems that support capture of PROs (refer to the Health data page and structured formats (e.g. FHIR QuestionnaireResponse). Employ validated and standardised instruments for quality-of-life assessment (e.g. {% tool \"eortc-qlq\" %}, {% tool \"promis\" %}) to reduce variability in interpretation and improve comparability.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_cancer_data_md_26",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/cancer_data.md",
        "file_name":"cancer_data.md",
        "chunk_index":26,
        "total_chunks":27,
        "content":"rtc-qlq\" %}, {% tool \"promis\" %}) to reduce variability in interpretation and improve comparability. Use certified, clinically validated devices and apps to ensure data reliability and regulatory compliance (e.g. CE-marked, {% tool \"fda-approved-tools\" %}). Employ data aggregation platforms (e.g. {% tool \"apple-health-kit\" %}, {% tool \"google-fit\" %}, {% tool \"open-mhealth\" %}) that support cross-device integration and longitudinal monitoring. Define clear data governance policies for longitudinal data capture and ensure data traceability. Establish patient engagement protocols to support consistent reporting and minimise data loss over time. Define standardised follow-up templates to optimise data completeness.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cancer_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Cancer data",
                "description":"Data management solutions for human cancer data",
                "contributors":[
                    "Ftima Al-Shahrour",
                    "Erika Schirghuber",
                    "Robin Navest",
                    "Eva Budinska",
                    "Gonzalo Gmez",
                    "Mara Gonzlez",
                    "Fotis Psomopoulos",
                    "Sarah Morgan",
                    "Sophie Huiskes Berends"
                ],
                "page_id":"cancer_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance",
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/collections\/rdmbites-redcap-collection"
                    },
                    {
                        "name":"OMOP Common Data Model and the OHDSI analytics for observational analytics of real world healthcare data courses in EHDEN academy",
                        "url":"https:\/\/academy.ehden.eu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_structural_bioinformatics_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Gerardo Tauriello\n- Ian Sillitoe\n- Nicola Bordin\n- Christine Orengo\n- Mihaly Varadi\n- Sameer Velankar\n- Ji ern\n- Carolina Simn Guerrero\ndescription: Data management solutions for structural bioinformatics data. page_id: struct_bioinfo\nrelated_pages:\n  tool_assembly: []\n  your_tasks: []\ntitle: Structural Bioinformatics\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"structural_bioinformatics.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":0,
        "total_chunks":12,
        "content":"Introduction\nStructural bioinformatics provides scientific methods to analyse, predict, and validate the three-dimensional structure of biological macromolecules such as proteins, RNA, DNA, or carbohydrates including small molecules bound to them. It also provides an important link with the genomics and structural biology communities. One objective of structural bioinformatics is the creation of new methods of analysis and manipulation of biological macromolecular data in order to predict their structures, function and interactions. Currently, atomic structures of macromolecules can be obtained both based on experimental and computational methods. This document describes guidelines to deposit computationally or experimentally solved structure models together with relevant metadata according to FAIR principles.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":1,
        "total_chunks":12,
        "content":"experimentally solved structure models together with relevant metadata according to FAIR principles. While we describe guidelines for the deposition process, predictors are usually required to collect the relevant metadata already while doing the predictions so that the data is available during deposition. Storing and sharing structure predictions\nDescription\nResearchers in the field should be able to find predictions of macromolecular structures, access their coordinates, understand how and why they were produced, and have estimates of model quality to assess the applicability of the model for specific applications. The considerations and solutions described below are written from the perspective of protein structure predictions but they also apply to other types of macromolecular structures. Considerations\n\nIs your prediction based on experimental data (i.e. integrative or hybrid modelling) or purely in silico? This is important to define the appropriate deposition system. What is the purpose of the structure prediction?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":2,
        "total_chunks":12,
        "content":"ortant to define the appropriate deposition system. What is the purpose of the structure prediction? Is it a large-scale modelling effort using automated prediction methods to (for instance) generally increase structural coverage of known proteins or a single modelling effort performed, possibly with manual intervention, for a specific application? This is important to define the appropriate deposition system. What is the source for the sequences of the modelled proteins? This is important to cross-link with existing databases such as UniProtKB. What modelling steps were performed? Descriptions here can vary widely among modelling methods but should be detailed enough to enable reproducibility and include references to methods described in manuscripts and publicly available software or web services. What input data were used for the modelling steps? For protein structure predictions, this commonly includes the identification of homologous proteins from sequence databases with or without coverage by experimental structures.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":3,
        "total_chunks":12,
        "content":" of homologous proteins from sequence databases with or without coverage by experimental structures. Knowing the input data greatly facilitates further analysis and reproducibility of the structure prediction. What is the expected accuracy of the structure prediction? This is commonly referred to as \"model quality\" or \"model confidence\" and is of major relevance to determine whether a given model can be used for downstream analysis. Quality estimates should enable users to judge the expected accuracy of the prediction both globally and locally. Under which licence terms can others use your models? Depending on the deposition system, there will be predefined and commonly permissive terms of use, but if this is to be restricted or if models are made available in a self-hosted system, an appropriate usage policy must be defined. Solutions\n\nThere are three main options to make your models available:\nDeposit in {% tool \"modelarchive\" %} for theoretical models of macromolecular structures.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":4,
        "total_chunks":12,
        "content":"available:\nDeposit in {% tool \"modelarchive\" %} for theoretical models of macromolecular structures. Models deposited in the ModelArchive are made available under the CC BY-SA 4.0 licence (see here for details). Deposit in {% tool \"pdb-dev\" %} for models using integrative or hybrid modelling. Models deposited in PDB-Dev are made available under the CC0 1.0 licence (see here for details). If theoretical models were used as part of the modelling, they can either be included in the PDB-Dev deposition or, if they are expected to be useful by themselves, deposited in ModelArchive and referenced to. Make available using a dedicated web service for large-scale modelling efforts which are updated on a regular basis using automated prediction methods. The solution for rapidly building such a service is to deploy the {% tool \"mineprot\" %} application, which is able to curate data from most AlphaFold-like systems (see here for details). Unified access to these services can be provided with the {% tool \"3d-beacons\" %} which is being developed by the ELIXIR 3D-BioInfo Community.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":5,
        "total_chunks":12,
        "content":"ovided with the {% tool \"3d-beacons\" %} which is being developed by the ELIXIR 3D-BioInfo Community. The data providers currently connected in the network are listed in the 3D-Beacons documentation. An appropriate licence must be associated with the models (check the licensing page for guidance on this) and must be compatible with CC-BY 4.0 if the models are to be distributed in the 3D-Beacons network. Model coordinates are preferably stored in the standard PDB archive format {% tool \"pdbx-mmcif-format-and-tools\" %}. While, for many purposes, the legacy PDB format may suffice to store model coordinates and is still widely used, the format is no longer being modified or extended. Model quality estimates can be computed globally, per-residue, and per-residue-pair. The estimates should be computed using a relatively recent and well benchmarked tool or by the structure prediction method itself. Please check {% tool \"cameo\" %}, {% tool \"casp\" %}, and {% tool \"capri\" %} to find suitable quality estimators.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":6,
        "total_chunks":12,
        "content":"k {% tool \"cameo\" %}, {% tool \"casp\" %}, and {% tool \"capri\" %} to find suitable quality estimators. The 3D-BioInfo Community is also currently working to further improve benchmarking for protein complexes, protein-ligand interactions, and nucleic acid structures. By convention, the main per-residue quality estimates are stored in place of B-factors in model coordinate files. In mmCIF files any number of quality estimates can be properly described and stored in the ma_qa_metric category of the PDBx\/mmCIF ModelArchive Extension Dictionary described below. Metadata for theoretical models of macromolecular structures should preferably be stored using the {% tool \"pdbx-mmcif-modelcif-extension-dictionary\" %} independently of the deposition process. The extension is being developed by the ModelCIF working group with input from the community. Feedback and change requests are welcome and can be given on github.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":7,
        "total_chunks":12,
        "content":" with input from the community. Feedback and change requests are welcome and can be given on github. The same information can also be provided manually during the deposition in ModelArchive and there is additional documentation on how to provide metadata and minimal requirements for it. Generally, the metadata must include:\na short description of the study for which the model was generated;\nif available, a citation to the manuscript referring to the models;\nthe source for the sequences of modelled proteins with references to databases such as {% tool \"uniprot\" %};\nmodelling steps with references to available software or web services used and to manuscripts describing the method;\ninput data needed for the modelling steps. For instance in homology modelling this could include the {% tool \"pdb\" %} identifiers for the template structures used for modelling and their alignments to the target protein;\nmodel quality estimates. If necessary, accompanying data can be provided in separate files using different file formats.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":8,
        "total_chunks":12,
        "content":"tes. If necessary, accompanying data can be provided in separate files using different file formats. The files can be added to ModelArchive depositions and referred to in the PDBx\/mmCIF ModelArchive extension format. Storing and sharing experimentally solved structures\nDescription\nExperimentally solved atomic structures of molecules can be obtained by several methods, such as X-ray crystallography,  Nuclear Magnetic Resonance (NMR) spectroscopy, and 3D Electron Microscopy. Here you can find useful tools and guides for storing and sharing structure models based on these methods. * Structure models resulting from experimental methods are broadly available in the {% tool \"pdb\" %} under the CC0 1.0 Universal (CC0 1.0) Public Domain Dedication. * Additionally, raw and intermediate data associated with the structure model can be also published in different curated data archives depending on the methods used. Raw EM data and processed 3D volumes and tomograms can be stored in {% tool \"empiar\" %} and {% tool \"emdb\" %}, respectively.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":9,
        "total_chunks":12,
        "content":"d 3D volumes and tomograms can be stored in {% tool \"empiar\" %} and {% tool \"emdb\" %}, respectively. Raw data from NMR studies can be stored in {% tool \"bmrb\" %}. For X-ray diffraction experiments raw data can be stored in {% tool \"irrmc\" %} and {% tool \"sbgrid-data-bank\" %}. Data submitted to these repositories can be cross-referenced to related PDB entries. * To extend molecular context, structure models can be visualised and analysed along with respective volume maps and {% tool \"uniprot\" %} sequences using data aggregators such as {% tool \"3dbionotes\" %}. This can be done independently of whether they have been published in PDB and EMDB. A collection of biochemical, biomedical and validation annotations would be mapped on the structure model coordinates and sequence to let the user better understand macromolecular function and interactions. Users can also use the {% tool \"covid-19-structural-hub\" %}, a dedicated summary view for all published SARS-CoV-2 structure models.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":10,
        "total_chunks":12,
        "content":"covid-19-structural-hub\" %}, a dedicated summary view for all published SARS-CoV-2 structure models. * As well as for computationally solved structures, model coordinates and metadata for experimentally solved structures are also preferably stored using the standard PDB archive format {% tool \"pdbx-mmcif-format-and-tools\" %} and the {% tool \"pdbx-mmcif-modelcif-extension-dictionary\" %}, respectively. * Data model and metadata standards for submitting data underpinning macromolecular models depend on the experimental method used. EMDB map distribution format description has broadly followed CCP4 map format and MRC map format. Metadata is contained in a header file, an XML file that follows the XSD data model. EMPIAR data model schema consists of the main empiar.xsd XML schema file and additional requirements in empiar.sch in Schematron format (see here for more details). BMRB (meta)data distribution format is based on NMR-STAR, an extension of the Self-defining Text Archive and Retrieval (STAR) file format. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_structural_bioinformatics_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/structural_bioinformatics.md",
        "file_name":"structural_bioinformatics.md",
        "chunk_index":11,
        "total_chunks":12,
        "content":"ased on NMR-STAR, an extension of the Self-defining Text Archive and Retrieval (STAR) file format. * As image processing framework, users can operate with workflow managers FAIR compliant such as {% tool \"scipion\" %} to obtain macromolecular models using Electron Microscopy (3DEM). It integrates several software packages while taking care of formats and conversions and data submissions to public repositories such as EMDB and EMPIAR. It is also possible to deploy a cloud-compatible version of Scipion either in a single server or in a cluster with {% tool \"scipioncloud\" %}. * {% tool \"aria\" %} is a platform that projects and infrastructures can use to manage access, from proposal submission to reporting. It provides tools for facilities within a distributed infrastructure to manage their equipment. ARIA will soon allow linking of output data and metadata with proposals, publications and other outputs.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"structural_bioinformatics.md",
            "language":"en",
            "frontmatter":{
                "title":"Structural Bioinformatics",
                "description":"Data management solutions for structural bioinformatics data.",
                "contributors":[
                    "Gerardo Tauriello",
                    "Ian Sillitoe",
                    "Nicola Bordin",
                    "Christine Orengo",
                    "Mihaly Varadi",
                    "Sameer Velankar",
                    "Ji ern",
                    "Carolina Simn Guerrero"
                ],
                "page_id":"struct_bioinfo",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?utf8=%E2%9C%93&q=Structural+Bioinformatics#workflows"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_enzymology_and_biocatalysis_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Carsten Kettner\n- Jrgen Pleiss\n- Johann Rohwer\n- Hans V. Westerhoff\n- Ulrike Wittig\ndescription: Data management solutions for enzymology and biocatalysis data. page_id: enzym_biocat\nrelated_pages:\n  tool_assembly: []\n  your_tasks:\n  - data_publication\n  - data_quality\n  - metadata\ntitle: Enzymology and biocatalysis",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":0,
        "total_chunks":24,
        "content":"Introduction\nThe enzymology and biocatalysis domain is concerned with collecting experimental data that characterises biocatalysts with regards to their activity, specificity, selectivity, and catalytic mechanism in a chemical reaction. Biocatalysts are macromolecules of biological origin (or synthetic equivalents thereof) that are directly involved in, and enhance the rates of, chemical reactions without themselves being produced or consumed in them. They are mostly proteins (called enzymes) or RNA molecules (ribozymes), but can also be entire networks of enzymes and in living organisms. The complete characterisation of a biocatalyst comprises both structural and functional properties.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":1,
        "total_chunks":24,
        "content":" The complete characterisation of a biocatalyst comprises both structural and functional properties. Amino acid sequence, covalent modification, 3-dimensional structure, formulation, and functional properties constitute the former, whereas the kinetics, reaction stoichiometries (as given by the complete chemical equation of the reaction(s) catalysed), selectivity and specificity are parameters that contribute to the latter, functional aspects. The dynamic properties are often referred to as enzyme activity data. They are ultimately determined by the structural properties of the biocatalysts and their reactants, but the computation of the former from the latter is still much less accurate than inference from direct experimental measurement, which is what the domain Enzymology and Biocatalysis focuses on.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":2,
        "total_chunks":24,
        "content":" direct experimental measurement, which is what the domain Enzymology and Biocatalysis focuses on. Thermodynamic parameters such as the equilibrium constant and standard Gibbs or metabolic energy of the reaction are properties only of the complete chemical reaction catalysed, yet worth mentioning in biocatalyst characterisation because they can limit reaction rate, yield and efficiency. Similarly, the process conditions have a major effect on the kinetic and thermodynamic parameters. The parameters are calculated from a series of experimental raw data. Enzyme activity data are widely distributed in the literature and databases and are used when inferring and comparing reaction specificity and mechanisms, when comparing enzymes from various organisms, when trying to understand the physiological function of an enzyme and when making dynamic pathway models to understand genome function. Biochemical parameter values vary with the conditions around the biocatalyst.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":3,
        "total_chunks":24,
        "content":"stand genome function. Biochemical parameter values vary with the conditions around the biocatalyst. Neither the comparison nor corroboration, analysis or interpretation of this data is possible without specifying those conditions in the assessments. A complete description of the experiment including the materials and methods is therefore necessary for the data to be interoperable and FAIR, i.e. useful for the scientific community at large. Standards for reporting data, definitions of metadata and frameworks for structuring the data for the publication in databases and repositories and for the data exchange greatly assist researchers in carrying out the above tasks by sharing data, reproducing recent findings and collaborating in distributed projects. Adherence to standards comes with extra requirements in terms of equipment, expense, training, assay conditions and assay time and is not always of immediate benefit of the study at hand. Yet, the utility of the data that comes out is greatly enhanced by the standardisation as is the impact of the work done.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":4,
        "total_chunks":24,
        "content":"he data that comes out is greatly enhanced by the standardisation as is the impact of the work done. The increased impact and citation rate as well as the quality stamp obtained, should motivate the adoption of the standards by the community in order to generate complete and robust datasets (manually written or in electronic notebooks) and to apply tools that allow interchangeability of data and to make these datasets publicly findable, available, interoperable and reusable in high quality. Standards-compliant data collection\nDescription\nThe determination of functional parameters of biocatalysts does not always require catalytic turnover; equilibrium binding constants are functionally important too. Collections and reports of biocatalyst function data must contain a description of the experimental setup.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":5,
        "total_chunks":24,
        "content":"tions and reports of biocatalyst function data must contain a description of the experimental setup. In order to be complete, this should include the identity of the catalytic or binding entity (enzyme, protein, nucleic acid or other molecule), the biological origin or source of the molecule, its amino acid sequence, its purity (also in terms of the fraction that is in the native rather than a denatured state), its formulation, and other characteristics such as post-translational modifications, prosthetic groups, mutations, any modifications made to facilitate expression or purification, and oligomeric state if the biocatalysts forms complexes with itself.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":6,
        "total_chunks":24,
        "content":"te expression or purification, and oligomeric state if the biocatalysts forms complexes with itself. The methods and technologies used as well as the experimental conditions (temperature, pH, pressure, additives and solvents, pMg, ionic strength, medium osmolarity (If >0.3 M) and approximate macromolecule concentration) of the assay must be described, certainly if it is a new assay, but also if the assay has been published before (all too often minor modifications of experimental conditions are not reported, leading to irreproducibility and inutility; referencing publications with the original assay description is still recommended). Specific information regarding the operation mode, type of reaction vessel and mixing, and the environment of the reaction needs to be provided in the reports. The manner in which the concentration of the added substrates was determined should be described. In instances where catalytic activity or binding cannot be detected, an estimate of the limit of detection based on the sensitivity and error analysis of the assay should be provided.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":7,
        "total_chunks":24,
        "content":" the limit of detection based on the sensitivity and error analysis of the assay should be provided. In such cases, a positive control should be assayed, and this should be described. In case activity is observed, a negative control (e.g. with denatured biocatalyst) should be included and described. In end point essays, the way the reaction was brought to a halt should be described. The analytical equipment (e.g. spectrophotometer, mass spectrometer), relevant metadata (e.g. wavelength), and the measured raw data should be reported, including the ways the measurements were calibrated (e.g. proton release by acid titration). By reporting the measured data (e.g. absorption) and the data used for calibration, the evaluation of concentrations becomes reproducible. Ambiguous terms such as not detectable should be avoided or extended by at a detection limit of .",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":8,
        "total_chunks":24,
        "content":"biguous terms such as not detectable should be avoided or extended by at a detection limit of . A description of the software used for data analysis should be included along with calculated errors for all parameters and the biochemical model of the biocatalyst used by the analysis, inclusive of the mathematical equations used. Additional information is required for both the investigation and reporting of the apparent equilibrium constants of reactions. Both the equilibrium constants and the standard states\/conditions need to be clearly defined. When calculating and reporting the value of an equilibrium constant, the units of concentrations, the direction of the reaction as well as the procedure of the calculation of the equilibrium constant itself must be specified. Control experiments should always be performed to detect systematic failures or external effects to exclude interferences from the enzyme or the solution. The chemical equilibrium needs to be defined when the forward and reverse reactions proceed at the same rate (reaction quotient Q does not change with time).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":9,
        "total_chunks":24,
        "content":"ward and reverse reactions proceed at the same rate (reaction quotient Q does not change with time). It should be demonstrated (e.g. by addition of more substrate) that the reaction did not stop because the biocatalyst lost activity. It should be demonstrated that the position of the measured equilibrium constant does not depend on the amount of added enzyme nor on the initial amount of substrate or product added. Considerations\nPrerequisite for the reproducibility of enzyme activity datasets is the reporting in a complete way, without omissions and without the lack of essential information that allows other researchers to corroborate, interpret and reuse the data. Therefore, the major questions to fulfill these aspects include:\n* Which data are required to provide complete data sets? * What is the minimal data accepted to be considered complete? * What is the minimal data set required to make the data useful for studies of metabolic pathways? * Which metadata describe both the materials and methods data and results data most appropriately? * From where can I obtain the metadata?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":10,
        "total_chunks":24,
        "content":"erials and methods data and results data most appropriately? * From where can I obtain the metadata? * What should be the best way to define the metabolic energy of reactions, substrates and metabolites? * How can I address thermodynamic issues in my experiments? * How can I ensure that my datasets are reproducible? Solutions\nThe Commission of {% tool \"standards-for-reporting-enzyme-data\" %}, a community driven initiative {% cite strenda2014standards %} has developed reporting standards that are unique for this domain and include:\n*",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":11,
        "total_chunks":24,
        "content":"nda2014standards %} has developed reporting standards that are unique for this domain and include:\n* STRENDA Guidelines List Level 1a - Data required for a complete description of an experiment\n* STRENDA Guidelines List Level 1b - Description of enzyme activity data\n* Recommendations on the design and execution of experiments to obtain the apparent equilibrium constants of enzyme catalyzed reactions\n* Recommendations on the reporting of the results to determine the equilibrium constant\n* STRENDA Biocatalysis Guidelines and Metadata catalogue, an extension of the STRENDA Guidelines towards some specialities in biocatalysis\nThe STRENDA Guidelines, which initially propose reporting fundamental enzymology data, have been extended by additional parameters for the description of biocatalysis experiments, such as for reactors and vessels, mixing conditions and the formulation of the biocatalyst, which can be studied in a solved or immobilised form.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":12,
        "total_chunks":24,
        "content":"itions and the formulation of the biocatalyst, which can be studied in a solved or immobilised form. Not only have parameters been defined, but also the corresponding metadata, which assist researchers in describing both the biocatalyst and the reaction conditions in more detail. The nomenclature of an enzyme should follow the systematic classification and numbering recommended by the Enzyme Commission (EC) of the International Union of Biochemistry and Molecular Biology (IUBMB). The EC number classifies enzymes based on the catalyzing reaction. If a new enzyme is discovered or the classification changes an EC number can be proposed for reviewing at https:\/\/www.enzyme-database.org\/newform.php. Data structure and exchange\nDescription When sampling and collecting data for deposition, sharing, and exchanging, the data needs to be structured in a way that both the sender and the recipient of the data are enabled to directly integrate these into their workflow.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":13,
        "total_chunks":24,
        "content":"he sender and the recipient of the data are enabled to directly integrate these into their workflow. When structuring data, usually ontologies and metadata catalogs provide a valuable means for the integration of controlled vocabularies, ontologies and additional information that enriches the experimental data. Structured data is required that follows community-based principles to increase the findability of the data on the web. Considerations\nBefore data can be sampled in a structured way, frameworks and tools are required to assist the researcher in compiling complete and high-quality datasets. Therefore, the major questions that address the requirement of standardised and structured data include:\n* How to assist with the implementation of repositories, databases and electronic lab notebooks? * How to structure the data? * Which ontologies to use? * How to include ontologies in the definition of data fields? * How to define metadata so as to enrich experimental data optimally? * How to increase the findability of datasets?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":14,
        "total_chunks":24,
        "content":"metadata so as to enrich experimental data optimally? * How to increase the findability of datasets? * How to enhance the utility of data for users?\nSolutions\n{% tool \"enzymeml\" %} is a data exchange format enabling the transfer of enzyme function data between instruments, electronic lab notebooks, modelling tools, and databases. It includes experimental raw data as well as metadata compliant with the {% tool \"standards-for-reporting-enzyme-data\" %} and {% tool \"systems-biology-markup-language\" %}. {% tool \"systems-biology-markup-language\" %} is a data exchange format for computational systems biology to describe biological models including enzyme networks, their reactions and kinetic properties. The model repositories {% tool \"jws-online\" %} and {% tool \"biomodels\" %} are home to a large variety of detailed kinetic models of cell biochemistry that are exchangeable through {% tool \"systems-biology-markup-language\" %}. The models are populated with curated parameter values based on experimental data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":15,
        "total_chunks":24,
        "content":"kup-language\" %}. The models are populated with curated parameter values based on experimental data. As such they serve to structure the data concerning enzymological parameters in a way that shows the implications of the parameter values for physiological functions. This makes models and data immediately useful for the non-modelling expert. {% tool \"bioschemas\" %} is a framework that adds bio-related properties and types to {% tool \"schema-org\" %} which aims at increasing the findability of datasets in the web. {% tool \"schema-org\" %} is a general framework that enriches any webpage with additional metadata. However, as {% tool \"schema-org\" %} is a general framework, Bioschemas introduces a domain-specific controlled vocabulary. The {% tool \"ontology-lookup-service\" %} provides more than 260 ontologies in the various fields. For the biocatalysis and enzymology domain, the following ontologies may be of interest:",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":16,
        "total_chunks":24,
        "content":"ous fields. For the biocatalysis and enzymology domain, the following ontologies may be of interest: * {% tool \"bioassay-ontology\" %}\n* {% tool \"chebi\" %}\n* {% tool \"cell-ontology\" %} for cell types\n* {% tool \"brenda-tissue-ontology\" %}, source of an enzyme comprising tissues, cell lines, cell types and cell cultures\n* {% tool \"protein-modification-ontology\" %}\n* {% tool \"protein-ontology\" %}\nDeposition, sharing and reusing of data\nDescription\nBecause of their usefulness for comparative enzymology, as well as for understanding the functioning of biochemical pathways and networks through systems biology, data and results should be made available worldwide in the sense of FAIR data. This means that this data needs to be findable and accessible to allow other researchers and software to reuse and reproduce this data as well as to generate new knowledge through comparison and integration. Various databases cover different aspects of enzymology data including enzyme occurrence, catalyzed reactions, binding mechanisms, or kinetic properties.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":17,
        "total_chunks":24,
        "content":"gy data including enzyme occurrence, catalyzed reactions, binding mechanisms, or kinetic properties. Most of the databases contain manually curated data from literature, while only few also support direct data submission of experimental data. Considerations\n\nHow to find appropriate resources for the deposition and reuse of enzymology data? How to upload enzymology and biocatalysis data? What is the prerequisite for the upload of data? What are the requirements for the publication of data in databases and repositories?\nAre there any tools that support researchers in uploading their data? Are the suggested databases and repositories open (freely accessible by the researchers)?\nHow to meet the requirements of journals and funding agencies to provide a meaningful data availability statement? Is there an indicator of the quality of the data (e.g. in the senses of accuracy and proven reproducibility)?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_18",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":18,
        "total_chunks":24,
        "content":"an indicator of the quality of the data (e.g. in the senses of accuracy and proven reproducibility)? Solutions\n\nFor the collection of experimental data in the laboratory electronic lab notebooks (e.g. {% tool \"chemotion\" %}, {% tool \"openbis\" %}) should be used to store raw and processed data along with metadata and corresponding protocols. Enzyme-related repositories which enable the direct submission of enzyme function data and experimental conditions are {% tool \"strenda-db\" %} and {% tool \"sabiork\" %} via the data exchange formats {% tool \"enzymeml\" %} and {% tool \"systems-biology-markup-language\" %}. {% tool \"strenda-db\" %} is a storage and search platform for authors who are preparing a manuscript containing functional enzymology data. Data sets entered in {% tool \"strenda-db\" %} are automatically checked for compliance with the {% tool \"standards-for-reporting-enzyme-data\" %} and prepared for publication after the journals reviewing process together with the corresponding paper.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_19",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":19,
        "total_chunks":24,
        "content":"repared for publication after the journals reviewing process together with the corresponding paper. The direct deposition of experimental data in {% tool \"strenda-db\" %} by the authors not only ensures the completeness of information but also simplifies the integration of the data into other enzyme databases. Information about the effects of chemical compounds on enzyme protein targets can be uploaded to the {% tool \"chembl\" %} database. Most of the databases containing enzymology data are based on information manually extracted from literature. The structured format of the literature data in such databases allows the export and reuse of enzyme data (e.g. kinetic parameters) as well as the automatic integration in processing tools for modelling or visualisation. Manually curated databases containing enzyme function data are: {% tool \"uniprot\" %}, {% tool \"brenda\" %}, {% tool \"sabiork\" %}, {% tool \"m-csa\" %}, {% tool \"ezcatdb\" %}, {% tool \"metacyc\" %}. An overview of general and more specialised enzyme databases was published 2023 {% cite presern2023enzymedatabases %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_20",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":20,
        "total_chunks":24,
        "content":"eral and more specialised enzyme databases was published 2023 {% cite presern2023enzymedatabases %}. Besides literature-based information, there are databases such as {% tool \"gotenzymes\" %} containing predicted kinetic parameters for enzymes or {% tool \"topenzyme\" %} containing predicted enzyme structure models. Further repositories which are neither domain specific nor store data in a structured way are {% tool \"zenodo\" %}, {% tool \"figshare\" %} and {% tool \"dataverse\" %}. These repositories are often suggested by journals and funding agencies that may be unaware of awareness of the structured repositories mentioned above. Data processing\nDescription\nThe primary data that emerge directly from experimental analysis are mostly extensive tables of observations (e.g. measured concentrations) as a function of time or of variations in conditions such as substrate concentrations.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_21",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":21,
        "total_chunks":24,
        "content":"ncentrations) as a function of time or of variations in conditions such as substrate concentrations. The functional data of enzyme kinetics and biocatalysis is a much-reduced set, typically comprising kinetic and thermodynamic parameters such as equilibrium dissociation constants and Michaelis-Menten and catalytic constants. These parameters completely pin down mathematical models for the biocatalysts. These models then enable the calculation of the rate of the reaction catalysed by the enzyme for a wide range of concentrations of substrates, products, modifiers, pH values and temperatures. A frequent example of such a model is the reversible Michaelis-Menten equation. The appropriateness of this model for the description of the biocatalyst function is often uncertain or an approximation. It is important that the model used is validated for the biocatalyst under consideration. Considerations\n\nHow to find the most appropriate model for my data?\nHow to infer the kinetic and thermodynamic parameters from the primary data?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_22",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":22,
        "total_chunks":24,
        "content":"iate model for my data?\nHow to infer the kinetic and thermodynamic parameters from the primary data? How to assess the accuracy and reliability of the kinetic and thermodynamic parameters? How and to what extent are experimental tests required for the validity of these kinetic models for the particular biocatalysts? Solutions\n\nMany examples of kinetic models for enzymes are available in standard enzyme kinetics textbooks. Moreover, simulation tools such as {% tool \"copasi\" %} and {% tool \"jws-online\" %} provide a predefined list of reference kinetic models from which the user can choose when entering a new enzyme reaction. {% tool \"enzymeml\" %} provides a standard format and data model for capturing the raw data, the metadata of the kinetic experiment, the kinetic model used for fitting and the final kinetic and thermodynamic parameters. The {% tool \"pyenzyme\" %} library facilitates the processing of data by providing a programmatic interface to {% tool \"enzymeml\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_enzymology_and_biocatalysis_md_23",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/enzymology_and_biocatalysis.md",
        "file_name":"enzymology_and_biocatalysis.md",
        "chunk_index":23,
        "total_chunks":24,
        "content":"y facilitates the processing of data by providing a programmatic interface to {% tool \"enzymeml\" %}. {% tool \"pyenzyme\" %} also interfaces with computational systems biology tools such as {% tool \"pysces\" %} and {% tool \"copasi\" %} to assist with numerically solving the kinetic models for parameter estimation. Fitting statistics such as the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC), which are commonly reported by fitting libraries, can be used to select the most appropriate model from different alternatives. Bibliography\n{% bibliography --cited %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"enzymology_and_biocatalysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Enzymology and biocatalysis",
                "description":"Data management solutions for enzymology and biocatalysis data.",
                "contributors":[
                    "Carsten Kettner",
                    "Jrgen Pleiss",
                    "Johann Rohwer",
                    "Hans V. Westerhoff",
                    "Ulrike Wittig"
                ],
                "page_id":"enzym_biocat",
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_quality",
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_fm_marine_metagenomics_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/marine_metagenomics.md",
        "file_name":"marine_metagenomics.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Nils Peder Willassen\n- Anastasis Oulas\n- Evangelos Pafilis\n- Nazeefa Fatima\ndescription: Data management solutions for marine metagenomics data. page_id: marine\nrelated_pages:\n  tool_assembly:\n  - marine_assembly\n  your_tasks:\n  - metadata\ntitle: Marine metagenomics\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=marine%20metagenomics",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"marine_metagenomics.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_marine_metagenomics_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/marine_metagenomics.md",
        "file_name":"marine_metagenomics.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"Introduction\nThe marine metagenomics domain is characterized by large datasets that require access to substantial storage and High-Performance Computing (HPC) for running complex and memory-intensive analysis pipelines, and therefore are difficult to handle for typical end-users and beyond the resources of many service providers. With respect to sharing metagenomics datasets in compliance with the FAIR principles, so that they can be reused, it hinges entirely on recording rich metadata about all the steps from sampling to data analysis. Managing marine metagenomic metadata\nDescription\nMetagenomics is a highly complex process the encompasses several steps including: sampling, isolation of DNA, generation of sequencing libraries, sequencing, pre-processing of raw data, taxonomic and functional profiling using reads, assembly, binning, refinement of bins, generation of MAGs, taxonomic classification of MAGs, and archiving of raw or processed data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine metagenomics",
                "description":"Data management solutions for marine metagenomics data.",
                "contributors":[
                    "Nils Peder Willassen",
                    "Anastasis Oulas",
                    "Evangelos Pafilis",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "marine_assembly"
                    ]
                },
                "page_id":"marine",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine%20metagenomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/marine_metagenomics.md",
        "file_name":"marine_metagenomics.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":" bins, generation of MAGs, taxonomic classification of MAGs, and archiving of raw or processed data. To comply with the FAIR principles, you need to collect metadata about all these steps. Moreover, in marine metagenomics, it is also necessary to characterize the marine environment of the sample, including geolocation, and the physico-chemical properties of the water. Considerations\n\nAs a starting point to get acquainted with the intricacies of reporting marine metagenomics experiments, the following publications are recommended reading: \nThe metagenomic data life-cycle: standards and best practices which describes the metagenomics data life-cycle in detail. Marine microbial biodiversity, bioinformatics and biotechnology (M2B3) data reporting and service standards, guided by marine microbial research, and providing clear examples and colour-coded illustrations.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine metagenomics",
                "description":"Data management solutions for marine metagenomics data.",
                "contributors":[
                    "Nils Peder Willassen",
                    "Anastasis Oulas",
                    "Evangelos Pafilis",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "marine_assembly"
                    ]
                },
                "page_id":"marine",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine%20metagenomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/marine_metagenomics.md",
        "file_name":"marine_metagenomics.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"s, guided by marine microbial research, and providing clear examples and colour-coded illustrations. Metadata standards that apply to marine metagenomics data are the {% tool \"genomic-standards-consortium\" %} family of minimum information standards, including the core standard {% tool \"mixs\" %}, the derived {% tool \"migs-mims\" %}, and the also derived Minimum Information About a Metagenome-Assembled Genome (MIMAG) that is presently only available as a scientific publication. Tools and resources for analyzing metagenomics datasets\nDescription\nThe field of marine metagenomics has been in rapid expansion, with many statistical\/computational tools and databases developed to explore the huge influx of data. You need to be able to choose between the multiple bioinformatics techniques, tools, and methodologies available for performing each step of a typical metagenomics  analysis, while ensuring that your choice conforms to the best practices for the domain.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine metagenomics",
                "description":"Data management solutions for marine metagenomics data.",
                "contributors":[
                    "Nils Peder Willassen",
                    "Anastasis Oulas",
                    "Evangelos Pafilis",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "marine_assembly"
                    ]
                },
                "page_id":"marine",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine%20metagenomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/marine_metagenomics.md",
        "file_name":"marine_metagenomics.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"tagenomics  analysis, while ensuring that your choice conforms to the best practices for the domain. Moreover, you need access to HPC facilities with capacity to execute the data analysis and store the resulting data, and therefore should be aware of what computing infrastructures are available to you (and at what cost). Considerations\n\nAre there particular characteristics of your dataset that would restrict the choice of applicable tools? Are the recommended tools freely available? If not, can you afford the software licensing cost? If not, are there freely available alternatives? Does your institution have its own HPC facilities, and what are the access conditions? Does your country have a research HPC infrastructure, and what are the access conditions?\n\nSolutions\n\nExperts in the field often provide reviews on the best tools and practices, so a good starting point is to look up such publications. A good example is Metagenomics: tools and insights for analyzing next-generation sequencing data derived from biodiversity studies.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine metagenomics",
                "description":"Data management solutions for marine metagenomics data.",
                "contributors":[
                    "Nils Peder Willassen",
                    "Anastasis Oulas",
                    "Evangelos Pafilis",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "marine_assembly"
                    ]
                },
                "page_id":"marine",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine%20metagenomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/marine_metagenomics.md",
        "file_name":"marine_metagenomics.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":" tools and insights for analyzing next-generation sequencing data derived from biodiversity studies. Freely available software and pipelines, such as those listed below, can be an option compared to commercial analysis packages. To get access to compute and storage you may contact your local IT department or national ELIXIR node which can guide you to the right facilities.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine metagenomics",
                "description":"Data management solutions for marine metagenomics data.",
                "contributors":[
                    "Nils Peder Willassen",
                    "Anastasis Oulas",
                    "Evangelos Pafilis",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "marine_assembly"
                    ]
                },
                "page_id":"marine",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine%20metagenomics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_microbial_biotechnology_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Anil Wipat\n- David Markham\n- Christian Atallah\n- Bradley Brown\n- Munazah Andrabi\ndescription: Data management solutions for microbial biotechnology data. page_id: micro_biotech\nrelated_pages:\n  tool_assembly: []\n  your_tasks: []\ntitle: Microbial biotechnology",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"microbial_biotechnology.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":0,
        "total_chunks":24,
        "content":"Introduction\nMicrobial biotechnology and DBTL cycle\nThe microbial biotechnology domain is a very broad field that encompasses the application of microorganisms to the development of useful products and processes. As such, there are a very wide variety of experimental tools, approaches, and ultimately data, that arise in this field. A convenient representation of microbial biotechnology for organisational purposes is the stages of the engineering life cycle drawn from the related field of synthetic biology. The Design-Build-Test-Learn (DBTL) cycle represents experimental design and analysis steps in synthetic biology. Current data management best practices and guidelines that should be applied throughout the DBTL cycle will be described and discussed here.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":1,
        "total_chunks":24,
        "content":"nd guidelines that should be applied throughout the DBTL cycle will be described and discussed here. Design\nThe design for a system in microbial biotechnology essentially involves two, interrelated exercises: (i) Identification of the biological entities\/hosts that will be used to develop the product in question and (ii) Identification of the genetic modifications\/circuitry\/constructs necessary to modify the host if appropriate. The design stage may also include optional approaches: (iii) Metabolic engineering of biosynthetic pathways and (iv) Using mathematical modelling to aid the design of the system. Data management best practices and guidelines should be applied for each exercise and approach. The components of the design stage can be summarised as:\n* Biological host or organism. * Synthetic parts. * Metabolomic pathways and enzymes. * Mathematical model for system design.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":2,
        "total_chunks":24,
        "content":"nism. * Synthetic parts. * Metabolomic pathways and enzymes. * Mathematical model for system design. Build\nThe build stage in the microbial biotechnology and\/or synthetic biology life cycle is about the building of the microbial systems and involves the application of any number of a range of experimental techniques. At this stage, the synthetic parts are assembled and transformed into the biological host. The main aspects of the build stage are:\n* methods, protocols and procedures used to build the modified organism. Test\nThe test stage of a biotechnological study is the most variable in terms of the types of data produced. This stage is mostly about:\n* testing the outcome or output variables and analyse the modified organism. * Characterising the synthetic parts using experimental data. Learn\nThe learning stage consists of interpreting the obtained results, sharing the acquired knowledge and reusing it in combination with other existing data to improve the creation of the modified organism. * Publish and share data and results. * Reuse existing data and combine it with new data. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":3,
        "total_chunks":24,
        "content":"rganism. * Publish and share data and results. * Reuse existing data and combine it with new data. * Feed data back into model(s) to inform the next iteration. Here, we adopt the stages of design, build and test, and their components or aspects, to categorise the various approaches available for the management of data in microbial biotechnology. Data management challenges\nUltimately, the ideal scenario is that data is captured in a standard format and then uploaded to a repository to ensure that it is Findable, Accessible, Interoperable and Reusable (FAIR). However, for the biotechnology field, data standards are still under development or missing completely and there are still gaps in database provision for some data types. Due to the interdisciplinary nature of the field, data arising from studies in microbial biotechnology relate to both computational studies, such as modelling and simulation, and the results of wet lab-based studies used for the construction and experimental characterisation of microbial systems.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":4,
        "total_chunks":24,
        "content":" lab-based studies used for the construction and experimental characterisation of microbial systems. Given the breadth, scope and rapid development of the field of microbial biotechnology, this guide is by no means exhaustive. This guide is by no means comprehensive. Please get in touch with further suggestions for relevant standards and data-sharing tools that can make it more complete. Sites such as {% tool \"fairsharing\" %} can provide a wealth of information about standards that may be appropriate for a given data type and not mentioned in this brief guide. Design: Biological hosts - metadata, ontologies and (meta)data publication\nDescription\nMetadata standards and ontologies to capture the taxonomic and phenotypic data about the biological hosts or organism are still evolving, therefore finding and using a correct standard to describe the biological host can be challenging. It is recommended to publish and share information about biological hosts in dedicated public data repositories and databases.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":5,
        "total_chunks":24,
        "content":"sh and share information about biological hosts in dedicated public data repositories and databases. Considerations\n\nThe recording of taxonomic and genetic data must be considered carefully as part of the design stage. Metadata surrounding the host is essential, such as where it was isolated, growth conditions, recommended protocols, etc. Genetic information relating to strains and any modifications needs to be kept track of as modifications are made. Note that capturing the metadata describing a genome sequence and its host is vitally important to facilitate further studies in comparative genomics and phenotypic analysis. To choose what are the appropriate repositories for your (meta)data, you should consider what kind of information about the host you are going to share since each type of information could be published in a different repository. Species, taxonomy, strain. Phenotypic information. Genomic or nucleotide information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":6,
        "total_chunks":24,
        "content":"nt repository. Species, taxonomy, strain. Phenotypic information. Genomic or nucleotide information. Solutions\nMetadata schemas and ontologies\n\nThe current data standards to capture the  taxonomic and phenotypic data are still evolving, with notable work on the {% tool \"access-to-biological-collection-data-schema\" %} and the activities of the {% tool \"biodiversity-information-standards\" %}. The Darwin Core standard from the {% tool \"biodiversity-information-standards\" %} is an appropriate standard to provide metadata about the taxonomic properties of a particular microorganism. The {% tool \"ncbi-taxonomy\" %}homepage can also provide appropriate taxon IDs for recording taxonomic information. Information about proposed standardised nomenclature for prokaryotes can be found at the {% tool \"list-of-prokaryotic-names-with-standing-in-nomenclature\" %} {% cite parte2020lpsn %}. Data standards for recording the information about where a microorganism was isolated from do exist and this topic is covered in other RDMkit pages such as the marine metagenomics domain.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":7,
        "total_chunks":24,
        "content":"rom do exist and this topic is covered in other RDMkit pages such as the marine metagenomics domain. Information can also be found in a publication by Ten Hoopen and colleagues {% cite tenhoopen2015m2b3 %}. {% tool \"the-environment-ontology\" %} is also relevant here to describe environmental entities of all kinds, from microscopic to intergalactic scales. A set of genetic nomenclature standards have been established by microbiologists and have been used for many years. These are still a useful way of communicating data about the genotype of a strain {% cite maloy2007strain %}. Minimal information standards have been established to specify this metadata, such as the MIGS standard {% cite field2008migs %}. (Meta)data publication and sharing\n\nFor sharing host information, you  can use databases such as the {% tool \"bacdive\" %}. You  can also deposit strains and associated information in a strain repository such as the {% tool \"ncimb\" %} or the {% tool \"atcc\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":8,
        "total_chunks":24,
        "content":"sociated information in a strain repository such as the {% tool \"ncimb\" %} or the {% tool \"atcc\" %}. There are also many organisations established for individual species of microorganisms, the {% tool \"bacillus-genetic-stock-center\" %} being one example. Databases such as {% tool \"cellrepo\" %} allow strains that have been barcoded to be tracked using a version control type system {% cite tellechealuzardo2020linking %}. Genomic information can be captured at the nucleotide level using the well-known {% tool \"european-nucleotide-archive\" %} and submitted to the ENA database to allow the information to be shared. The database collection from the {% tool \"international-nucleotide-sequence-database-collaboration\" %} provides an umbrella for gathering and sharing a variety of sequence data from different sequence databases internationally. Other databases such as {% tool \"genbank\" %} and the {% tool \"dna-data-bank-of-japan\" %} also cater for sequence information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":9,
        "total_chunks":24,
        "content":"% tool \"genbank\" %} and the {% tool \"dna-data-bank-of-japan\" %} also cater for sequence information. Design: Synthetic parts - existing data, metadata collection and publication\nDescription\nAppropriate and detailed description of the synthetic parts design is critical for reproducibility. It is important to consider how to record metadata at each point in the design process in a standard way, so that it can be reproducible. Considerations\n\nFormat of designs may vary depending on the application, whether this be at the sequence level or an entire system. Consider existing management tools that can help visualise and modify genetic designs. Think about how the information about the characterisation of genetic constructs assist in the selection of parts and modelling designs. At this stage, it may be desirable to assert which host the designed device is intended to express in and also the intended method of replication in the host - for example, cloned on a particular plasmid or integrated in the host chromosome.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":10,
        "total_chunks":24,
        "content":"tion in the host - for example, cloned on a particular plasmid or integrated in the host chromosome. Solutions\nExisting data\n\nSequences are characterised as parts which can be found with the assistance of various repositories such as: \n{% tool \"igem-parts-registry\" %}\n{% tool \"jbei-ice\" %} {% cite ham2012jbeiice %}\n{% tool \"synbiohub\" %}\n{% tool \"freegenes\" %} - Repository of IP-free synthetic biological parts\nSequences can be isolated from standard genetic databases such as {% tool \"european-nucleotide-archive\" %} and {% tool \"genbank\" %}. Tools for metadata collection\n\nYou can manage the design stage using genetic computer-aided design tools, such as {% tool \"benchling\" %} for example, where information can be shared within small teams. {% tool \"benchling\" %} supports a number of different data standards including FASTA, GenBank and SBOL1. Sometimes FASTA will be the most relevant format, for example when sending for DNA synthesis.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":11,
        "total_chunks":24,
        "content":"SBOL1. Sometimes FASTA will be the most relevant format, for example when sending for DNA synthesis. Formats like GenBank, DICOM-SB {% cite sainzdemurieta2016toward %} or SBOL may be more applicable for instances where more information, such as functional annotation, would be useful to be shared. SBOL 2.0 and higher allows more than just the genetics of a system to be captured and shared. Using SBOL allows interactions between components in the design to be specified, information about RNA and proteins can be included and the provenance of a design can also be captured. Experimental information relating to the test and build of a system can also be captured and shared. SBOL data can be made using tools such as {% tool \"benchling\" %} (SBOL1 only), {% tool \"sboldesigner\" %} {% cite zhang2017sboldesigner %} and {% tool \"shortbol\" %} to name but a few. A more comprehensive list of SBOL tools can be found on the {% tool \"synthetic-biology-open-language\" %} website.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":12,
        "total_chunks":24,
        "content":"hensive list of SBOL tools can be found on the {% tool \"synthetic-biology-open-language\" %} website. More generally, the Investigation\/Study\/Assay (ISA) model can be used in systems biology, life sciences, environmental and biomedical domains to structure research outputs. The ISA-Tab format provides a framework for capturing these data in CSV files. {% tool \"rightfield\" %} provides a mechanism for capturing metadata using easy to use spreadsheets. (Meta)data publication and sharing\n\nOnce the design is complete, you can share this information via a repository such as: \n{% tool \"igem-parts-registry\" %}\n{% tool \"synbiohub\" %}\n{% tool \"jbei-ice\" %}\n{% tool \"addgene\" %}\nMuch information about its performance can be included, varying from experimental results such as fluorescence curves to predicted performance based on modelling. It would be recommended to use standard figures that can be easily understood.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":13,
        "total_chunks":24,
        "content":"e based on modelling. It would be recommended to use standard figures that can be easily understood. {% tool \"sbol-visual\" %} is a good example of a graphical standard; it utilises standard shapes to represent different genetic parts which can help clarify a complex synthetic construct. {% tool \"sbol-visual\" %} can be crafted using tools such as {% tool \"visbol\" %}. Platforms such as {% tool \"fairdom-seek\" %}, built on technologies such as ISA, support a large range of systems and synthetic biology projects. {% tool \"fairdom-seek\" %} provides a web-based resource for sharing scientific research datasets, models or simulations, and processes. {% tool \"fairdom-seek\" %} can be installed locally or {% tool \"fairdomhub\" %}, a version of {% tool \"fairdom-seek\" %} is available for general community use.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":14,
        "total_chunks":24,
        "content":"tool \"fairdomhub\" %}, a version of {% tool \"fairdom-seek\" %} is available for general community use. Information about biological sources and other data not fitting elsewhere can be shared via the {% tool \"biostudies\" %} database,\n\nDesign: Metabolomic pathways and enzymes - metadata, ontologies and (meta)data publication\nDescription\nHere we describe some of the available options to accurately represent and store information about the designs of metabolic pathways and functional information about assays. Considerations\n\nEnzymes have specific data standards that should be considered when accessing and recording their data. Solutions\nMetadata and ontologies\n\nSBOL allows information about the enzymes and the metabolic pathways to be captured in the design document and so this is a viable approach for sharing more than just the genetics of the system.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":15,
        "total_chunks":24,
        "content":"ign document and so this is a viable approach for sharing more than just the genetics of the system. Enzymes can be assigned EC numbers, according to the guidance from the {% tool \"iupac-iubmb-joint-commission-on-biochemical-nomenclature\" %} (IUPAC and {% tool \"international-union-of-biochemistry-and-molecular-biology\" %}), to indicate their function and an entry made in the {% tool \"brenda\" %} (BRENDA). More generally, the {% tool \"iupac-iubmb-joint-commission-on-biochemical-nomenclature\" %} encourages the communication of biochemical information using generally understood terminology. (Meta)data publication\n\nDatabases such as SBOLME {% cite kuwahara2017sbolme %} or {% tool \"synbiohub\" %} can be used to share the data. Metabolite information can also be submitted to, or referred to in, {% tool \"chebi\" %}. {% tool \"brenda\" %} (BRENDA). Design: mathematical model - standards and (meta)data publication\nDescription\nWhat tools and standards need to be considered when building mathematical models to aid the design of genetic systems?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":16,
        "total_chunks":24,
        "content":"ndards need to be considered when building mathematical models to aid the design of genetic systems? How can the models be shared via repositories and made  available in a way that makes results reproducible? Considerations\n\nA variety of standards and tools are available for model building. It is important to associate the genetic design with its corresponding model. Solutions\n\n{% tool \"systems-biology-markup-language\" %} is a popular standardised format for sharing mathematical models for which a variety of tools are available for model building. More generally, the {% tool \"computational-modeling-in-biology-network\" %}, provides a platform for coordinating the standardisation of models in biology. SBOL can also be used to associate a genetic design with its corresponding model. Models can be shared in model repositories such as {% tool \"biomodels\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":17,
        "total_chunks":24,
        "content":" its corresponding model. Models can be shared in model repositories such as {% tool \"biomodels\" %}. Build: methods - documentation and (meta)data publication\nDescription\nThe build stage in the microbial biotechnology and\/or synthetic biology life cycle involves the application of any number of a range of experimental techniques and, since these techniques are so varied, the domain is therefore very difficult to standardise in terms of the data and metadata to be shared. The current method of sharing information about the building of microbial systems is to write a detailed free text in the materials and methods section of a scientific paper. Considerations:\n\nCapturing the information about the build process involves collecting the information arising from DNA amplification, DNA preparation and purification, primer design, restriction enzyme analysis, gel electrophoresis and DNA sequencing to name but a few techniques. If using a protein expression device, the intended vector for its replication in a given host will need to be named.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_18",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":18,
        "total_chunks":24,
        "content":"in expression device, the intended vector for its replication in a given host will need to be named. The cloning strategy used to assemble the protein expression device and the vector will also need to be specified and shared. The information about how the final system was built is highly variable, depending on the DNA synthesis and\/or assembly approach used. Consider ways to share this information. Solutions\nDocumentation\n\nTo the authors knowledge, there are no proposed standards that exist that are able to capture this diverse set of data. Currently, from a pragmatic point of view, the best a data manager can do is to make sure data is captured in some form from the lab scientist and grouped together with as much metadata as possible. The metadata standards for a build exercise are still to be defined and so at the discretion of the data manager. * SBOL versions 2.0 and above provides a data standard that allows build data that has been grouped to be associated with design data for a part, device or system along with a minimal amount of metadata. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_19",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":19,
        "total_chunks":24,
        "content":" associated with design data for a part, device or system along with a minimal amount of metadata. * Similarly, research object bundles, and more recently {% tool \"research-object-crate\" %}, can be used to gather together build data and test data with information about the overall study. (Meta)data publication and sharing\n\nThe design information about the vector DNA or RNA sequence should be shared via public databases  such as ENA or Genbank. Various DNA synthesis companies build DNA from a computer specification of the sequence and also a variety of experimental approaches for assembling DNA molecules. This information can be shared as free text attached to a design in SBOL format and uploaded to a repository that supports SBOL2 format and above such as {% tool \"synbiohub\" %}. Once grouped together in a free form, the data can be archived along with the metadata, collecting the data together in an archived form using a file compression format. The combine archive format may also be useful.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_20",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":20,
        "total_chunks":24,
        "content":" in an archived form using a file compression format. The combine archive format may also be useful. Test: outcome tests - metadata standards and (meta)data publication\nDescription\nThe test stage of a biotechnological study is the most variable in terms of the types of data produced. The types of experiments carried out to test a microbial system are highly dependent on the intended function of the system under construction. Some common approaches include at the simplest level, characterising the growth of an organism at various scales in different growth regimes and assaying the production of desired product. The data arising from assays for product development is highly variable and beyond the scope of this short guide, however, we propose some recommended resources. Considerations\n\n\nWhat types of experiments, e.g.  organism growth, organism characterisation, will you undertake to test your microbial system? What types of data result from those experiments? Will you combine multi-omics assays in your study? Is there a reporting guideline for the type of you are generating?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_21",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":21,
        "total_chunks":24,
        "content":"multi-omics assays in your study? Is there a reporting guideline for the type of you are generating? Will you reuse existing testing protocols or generate and share your own protocols? Since (meta)data repositories often require compliance to their metadata standards, ontologies and file formats, it is recommended to be aware of those requirements when describing the test stage. Solutions\nMetadata standards\n\n\nMinimum Information Standard for Engineered Organism Experiments (MIEO). Minimal information necessary to record the growth of an organism in culture, has been described by Hect and colleagues {% cite hecht2018bacterial %}. Enzyme. If your product is a protein such as an enzyme then some standards developed by the {% tool \"standards-for-reporting-enzyme-data\" %} may be helpful {% cite strenda2014standards %}. Microscopy. Microscopy is often also used to characterise the behaviour of engineered microorganisms. Standards such as the Open Microscopy Environment Ontology and the {% tool \"cellular-microscopy-phenotype-ontology\" %} can help provide standardised metadata terms.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_22",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":22,
        "total_chunks":24,
        "content":"he {% tool \"cellular-microscopy-phenotype-ontology\" %} can help provide standardised metadata terms. Flow Cytometry data. The {% tool \"international-society-for-the-advancement-of-cytometry\" %} provides information on a variety of appropriate data standards for capturing Flow Cytometry data (used to characterise microbial populations at a single cell level) {% cite spidlen2021data %}. Nucleic acids information. The {% tool \"european-nucleotide-archive\" %}, amongst others, provides guidance on the metadata for RNAseq datasets.\n\n\nProteomics. {% tool \"proteomics-standards-initiative\" %} provides a range of guidance for capturing and sharing proteomics data. (Meta)data publication and sharing\n\nProtocols. Protocols used for testing can be shared using platforms such as: \n{% tool \"protocols-io\" %}. iGEM engineering hub, which also provides some guidance for a variety of data capture protocols and standardised units.\nImages. Images can be shared with the community by repositories such as the {% tool \"image-data-resource\" %}. Nucleic acids information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_content_microbial_biotechnology_md_23",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/microbial_biotechnology.md",
        "file_name":"microbial_biotechnology.md",
        "chunk_index":23,
        "total_chunks":24,
        "content":"e community by repositories such as the {% tool \"image-data-resource\" %}. Nucleic acids information. Information about nucleic acids can be shared via\n{% tool \"european-nucleotide-archive\" %}\n{% tool \"gene-expression-omnibus\" %}\n{% tool \"arrayexpress\" %} \nProteomics. Proteomics data can be shared via {% tool \"proteomics-standards-initiative\" %}. Metabolic studies. Metabolomic studies can be shared through the {% tool \"metabolomexchange\" %}, which provides a resource for sharing data from metabolic studies and guidance for the submission of metabolome data. Biological sources. Information about biological sources can be shared via the {% tool \"biostudies\" %} database, which has been set up to capture and share information about multi-omics and other biological studies {% cite sarkans2018biostudies %}. Bibliography\n{% bibliography --cited %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"microbial_biotechnology.md",
            "language":"en",
            "frontmatter":{
                "title":"Microbial biotechnology",
                "description":"Data management solutions for microbial biotechnology data.",
                "contributors":[
                    "Anil Wipat",
                    "David Markham",
                    "Christian Atallah",
                    "Bradley Brown",
                    "Munazah Andrabi"
                ],
                "page_id":"micro_biotech",
                "related_pages":{
                    "your_tasks":[

                    ],
                    "tool_assembly":[

                    ]
                }
            }
        }
    },
    {
        "id":"md_fm_machine_learning_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Styliani-Christina Fragkouli\n- Uladzislau Vadadokhau\n- Adriano Fonzino\n- Fotis Psomopoulos\n- Mihaly Varadi\n- Edward Parkinson\n- Federico Bianchini\n- Munazah Andrabi\ndescription: This page is about setting best practices for data towards enabling FAIR\n  ML.\npage_id: machine_learning\nrelated_pages:\n  your_tasks:\n  - data_quality\n  - sensitive\ntitle: Machine learning\ntraining:\n- name: Machine learning events and materials on TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"machine_learning.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_machine_learning_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":0,
        "total_chunks":17,
        "content":"What is machine learning (on this page)? Description\nThe definition of Machine Learning (ML) can become so vague that it can reach the point of becoming a philosophical question. There are two main approaches; the first one considers the model as the centre of the definition. In this perspective, ML is defined mainly by the characteristics and capabilities of the model employed. This approach focuses on the technical aspects of ML, by emphasising factors such as algorithms, data processing and model performance {% cite ravi2022 %}. In contrast, the second approach places the entire ML process at the centre of the definition of ML. In this form, the entire process is seen as a single entity, which includes all internal aspects\/steps  such as data collection, preprocessing, feature engineering, model training, evaluation and deployment. This approach acknowledges that all these stages are interconnected.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":1,
        "total_chunks":17,
        "content":"ing, evaluation and deployment. This approach acknowledges that all these stages are interconnected. For the purposes of this page, we will be using the first definition, i.e. the model-centred approach. The reasons behind this choice mainly include the technical focus with a strong emphasis on the technical aspects of ML and the performance evaluation because it provides a clear framework for comparing against other models. What is FAIR in machine learning? Description\nAs global standards for good data stewardship , the FAIR principles have become instrumental in ML, impacting policies and practices across sectors {% cite psomopoulos2023Roadmap %}. Embraced by policymakers and research institutes, implementing FAIR in ML enhances technical performance and proves economically advantageous. FAIR is an aspirational guideline, not a stringent standard, propelling better data utilisation in ML.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":2,
        "total_chunks":17,
        "content":"IR is an aspirational guideline, not a stringent standard, propelling better data utilisation in ML. Applying the FAIR principles in ML involves creating easily discoverable models with comprehensive metadata, openly accessible with clear licensing, compatible with other systems via standardised formats, and designed for reuse with meticulous documentation, licensing and versioning {% cite huerta2023FAIR %}. Actualising these principles necessitates infrastructural adjustments and stakeholder education {% cite castro2021Working %}. FAIR ML holds immense potential in life sciences, from accelerating drug discovery processes to driving innovative bioinformatics applications through data interoperability from various sources. The transformative power of FAIR extends to enhancing predictive modelling, genetic research, disease diagnosis, and much more, demonstrating the criticality of its adoption for the future of life sciences {% cite ravi2022FAIR %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":3,
        "total_chunks":17,
        "content":"monstrating the criticality of its adoption for the future of life sciences {% cite ravi2022FAIR %}. Considerations\nThere are several key considerations in applying the FAIR principles in ML and the life sciences:\n- Findability: How can an ML model be easily identified? What metadata is necessary to make a model easily searchable?\n- Accessibility: What measures must be in place to ensure the ML model is easily accessible? How does licensing impact the accessibility and usage of the model? \n- Interoperability: How can an ML model effectively work with other systems or models? What role does data standardisation play in this regard? What documentation is needed to ensure seamless interoperability? What is the community-backed metadata schema used for annotating the model?\n- Reusability: How can an ML model be designed for optimal reuse?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":4,
        "total_chunks":17,
        "content":"ema used for annotating the model?\n- Reusability: How can an ML model be designed for optimal reuse? What is the role of version control and comprehensive documentation in ensuring others can easily understand and build upon the model?\n- Ethics and Privacy: What ethical considerations and privacy protections must be implemented when dealing with data, especially in sensitive areas like healthcare? How might these considerations impact the FAIRness of ML models?\n- Quality Assurance: How can the data quality used for ML models be controlled? How does data quality impact the robustness and reliability of ML models?\n- Sustainability: What are the strategies for maintaining models and their dependencies?\n- Evaluation: How can FAIR models be transparently evaluated? What role does documentation of performance metrics, validation procedures, and evaluation results play in providing users with an understanding of a models capabilities and limitations?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":5,
        "total_chunks":17,
        "content":"ion results play in providing users with an understanding of a models capabilities and limitations? Solutions\nApplying the FAIR principles in ML is the focal point of initiatives such as the ELIXIR {% tool \"dome\" %} {% cite walsh2021Author %} recommendations and the ELIXIR ML Focus Group. The following solutions apply to the above-mentioned considerations at a high level:\n- Use community-backed and standardised metadata that includes details about the model's authors, creation date, model type, training data, intended tasks, and performance metrics (such as {% tool \"bioimage\" %}, {% tool \"schema-org\" %}, {% tool \"dome\" %}, and {% tool \"onnx\" %}). - Assign a unique and persistent identifier to each model. This identifier should be linked to the model's metadata to improve searchability. - Ensure that models are open-sourced and shared on public platforms (e.g. {% tool \"github\" %}  or {% tool \"huggingface\" %}) to improve accessibility.\n- Specify the terms of use in the licensing information, or link to standard licenses. This must include what users are allowed to do with the model.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":6,
        "total_chunks":17,
        "content":"mation, or link to standard licenses. This must include what users are allowed to do with the model. The most commonly used license on {% tool \"github\" %} is the MIT License, other options can be explored here. - Implement Application Programming Interfaces (APIs) to allow easy interaction with the model. - Use standardised formats for sharing models, making them compatible with different platforms and languages ({% tool \"onnx\" %} for neural networks, for example). - Provide clear documentation about the model's requirements, design, usage, and output formats. This will ensure the model can interact with other systems more easily.\n- Implement version control for the models. This allows for tracking changes, resolving conflicts, and supporting reusability. - Provide comprehensive documentation about the model's training data, architecture, hyperparameters, and performance. This allows other researchers to reproduce the original work or build upon it.\n- Design models modularly, separating data pre-processing, the model itself, and post-processing.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":7,
        "total_chunks":17,
        "content":"t.\n- Design models modularly, separating data pre-processing, the model itself, and post-processing. This makes each component reusable in different contexts.\n- Ensure that models and their dependencies (like libraries or data sources) are maintained regularly or provide versioned snapshots of your library and all its dependencies, e.g. by offering dockerised containers. - Implement anonymisation techniques for sensitive data and always gain consent before using data, especially in sensitive areas like healthcare. Note that privacy considerations can affect the FAIRness of the data, but models can be trustworthy even when they compromise on specific FAIRness aspects. See also the Data sensitivity page for more information. Data readiness for the ML models\nDescription\nThe success of an ML model depends on the input data. Finding an appropriate dataset can be a challenge. The data has to be cleaned, explored, and evaluated before ML model training. Data preparation is often the most time-consuming step in the AI lifecycle.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":8,
        "total_chunks":17,
        "content":"efore ML model training. Data preparation is often the most time-consuming step in the AI lifecycle. The Garbage in, Garbage out principle (GIGO) has to be kept in mind at this stage: models trained on unreliable data will produce unreliable predictions {% cite sansone2023FAIR %}. To prepare data for ML models, several steps need to be followed. Firstly, data should be collected from reliable and diverse resources, ensuring it represents the problem domain accurately. Then, data cleaning techniques such as removing duplicates, handling missing values, and addressing outliers should be applied to enhance data quality. A commonly used practice for this task is the implementation of {% tool \"scikit-learn\" %}. Regarding features, on one hand there is the selection or extraction that can be performed to identify the most relevant and informative attributes for the model {% cite comess2020Bringing %}. On the other hand, there is the problem of the number of features which exceeds that of observations due to the nature of data in life sciences {% cite berisha2021Digital %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":9,
        "total_chunks":17,
        "content":"ceeds that of observations due to the nature of data in life sciences {% cite berisha2021Digital %}. Furthermore, data normalisation and standardisation might be necessary to scale features appropriately. Also, over or under-sampling can be used to handle an imbalanced dataset {% cite williamson2023Data %}. Considerations\n\nThe type of the data (text, images, time series, and others). Is there a curse of the data (more features than observations)? Are all variables converted to numeric type (data encoding)? Does the data need preprocessing? Are there outliers in the data? How are missing values treated (drop vs impute, random and non-random missing values)? Are there duplicates in the data?\nDoes every subset (train, validation, and test) of the data represent the overall population, if data has been split? Data provenance: The source of the data, and whether it is recognised by the community.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":10,
        "total_chunks":17,
        "content":" been split? Data provenance: The source of the data, and whether it is recognised by the community. (source of data, involved points and more)\nDataset size: Ensure the data set captures the full complexity of the underlying distribution, for example, the biological heterogeneity in the sample population. Balanced dataset: a dataset where all classes are properly and equally represented (i.e. same number of cases in each class and more). Availability of data\/License associated with data\nAre the data  processed and AI-ready? One of the possible ways to achieve this would be through a curation effort. Solutions\n\nClassical ML algorithms have to be applied with caution to the high-dimensional data. For example, in a high-dimensional space distances between points have little difference meaning that algorithms based on distance measurement would fail. Additionally, the term blind spots can be defined here as a particular combination(s) of variables not covered by a given set of observations. Therefore, cursed data often represents a distorted picture of a real-world concept.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":11,
        "total_chunks":17,
        "content":"observations. Therefore, cursed data often represents a distorted picture of a real-world concept. One of the most direct solutions is to reduce the dimensional space. For instance, the theory of the domain can be applied to get a subset of features that are proven to be related to the target variable. Principal components analysis (PCA) and likewise methods do not result in domain-specific features but increase the model's general ability by reducing its variance. ML models take only numeric values as input with some exceptions (e.g. {% tool \"catboost\" %}). Categorical data has to be encoded into numbers via various strategies. The simplest is one-hot encoding. Namely, a new feature per every level of a categorical variable is created and the relation of that level to a particular observation is encoded with 1 (observation has this level of a variable) or 0. The drawback of this method is that the feature number is increased if the categorical variable has many levels.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":12,
        "total_chunks":17,
        "content":" of this method is that the feature number is increased if the categorical variable has many levels. Other methods include label\/ordinal encoding, target encoding, frequency encoding, and vectorisation (for text data). It is always a good idea to encode a variable in a way where encoding has a meaning which can help a model to recognise patterns in the data. For example, a variable storing temperature values with levels cold, warm, and hot can be encoded with 1 (cold), 2 (warm), and 3 (hot). However, the context of the task has to be considered in this case. Before dropping anomalies from the data, it is required to determine their nature and whether it is possible to convert them to regular values with a high level of confidence. Augmentation allows artificially increasing the diversity of the data by realistic data points to improve performance (decreasing overfitting, resolving class imbalance, rare events prediction) of the ML model or reducing the cost of data collection. Images can be augmented by random rotations, re-scaling, cropping, zooming, and noise addition.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":13,
        "total_chunks":17,
        "content":"ion. Images can be augmented by random rotations, re-scaling, cropping, zooming, and noise addition. Several neural networks for this purpose are used (GANs, adversarial ML, neural style transfer). For NLP purposes word(s) deletion\/insertion\/swap and synonym replacement are used. For the regular table data, synthetic observations can be generated by drawing values from a distribution, utilising agent-based and deep-learning models. However, this process has to be planned carefully and performed with the assistance of an expert in the domain and with the utilisation of suitable tools like {% tool \"keras\" %}, {% tool \"tensorflow\" %} and {% tool \"cuda\" %}. For some ML algorithms, variables have to be put on the same scale. It is a crucial rule for unsupervised algorithms based on distance evaluation between data points (e.g. K-Means) and algorithms for dimensionality reduction (e.g. PCA). On the other hand, linear regression, tree-based algorithms, and neural networks can handle non-normalised data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":14,
        "total_chunks":17,
        "content":" hand, linear regression, tree-based algorithms, and neural networks can handle non-normalised data. The most popular technique is mean scaling, where each data point is converted to a z-score with a mean equal to 0 and a standard deviation equal to 1. In addition, data can be rescaled to a range [0, 1] by the min-max scaling technique. Source Verification: Establish robust mechanisms to verify the source of data and ensure its authenticity. Use cryptographic techniques or digital signatures to validate data integrity and origin. Metadata and Documentation: Maintain comprehensive metadata and documentation for each dataset, including information about data collection methodologies, ethical considerations, and any potential biases. This helps establish transparency and assists in community recognition. Depending on the type of data, certain preprocessing and transformation techniques can be followed: Text Data: Implement text preprocessing techniques such as tokenisation, stemming, and stop-word removal to prepare textual data for analysis.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":15,
        "total_chunks":17,
        "content":"chniques such as tokenisation, stemming, and stop-word removal to prepare textual data for analysis. Apply techniques like term frequency-inverse document frequency (TF-IDF) or word embeddings to represent text data in a numerical format. Image Data: Utilise image preprocessing techniques such as resizing, cropping, and normalisation to standardise image sizes and enhance model performance. Apply image augmentation techniques like rotation, flipping, and colour jittering to increase dataset diversity. Time-Series Data: Perform time-series preprocessing techniques such as resampling, interpolation, and feature engineering to extract relevant temporal patterns. Apply sliding windows or lagged variables to capture temporal dependencies. License: It is of pivotal importance to work in agreement and compliance with the license of data especially if you are planning to share them or a part of those also if those have been preprocessed. Data Balance: The dataset must be balanced. For data in labelled classes, ensure each class is sufficiently represented in the dataset.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_learning_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/machine_learning.md",
        "file_name":"machine_learning.md",
        "chunk_index":16,
        "total_chunks":17,
        "content":"alanced. For data in labelled classes, ensure each class is sufficiently represented in the dataset. For data with continuous labels, like in regression tasks, evaluate how well the range of outputs is covered. Curation: If you are sharing a dataset there is the need to provide information about the curation process performed or if the dataset has to be curated before its usage. Bibliography\n{% bibliography --cited %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_learning.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine learning",
                "description":"This page is about setting best practices for data towards enabling FAIR ML.",
                "contributors":[
                    "Styliani-Christina Fragkouli",
                    "Uladzislau Vadadokhau",
                    "Adriano Fonzino",
                    "Fotis Psomopoulos",
                    "Mihaly Varadi",
                    "Edward Parkinson",
                    "Federico Bianchini",
                    "Munazah Andrabi"
                ],
                "page_id":"machine_learning",
                "related_pages":{
                    "your_tasks":[
                        "data_quality",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Machine learning events and materials on TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=machine+learning#events"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_intrinsically_disordered_proteins_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/intrinsically_disordered_proteins.md",
        "file_name":"intrinsically_disordered_proteins.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Ivan Mieti\ndescription: Data management solutions for intrinsically disordered proteins data. page_id: idp\nrelated_pages:\n  tool_assembly: []\n  your_tasks:\n  - metadata\ntitle: Intrinsically disordered proteins",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"intrinsically_disordered_proteins.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_intrinsically_disordered_proteins_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/intrinsically_disordered_proteins.md",
        "file_name":"intrinsically_disordered_proteins.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"Introduction\nIntrinsically disordered proteins (IDP) domain brings together databases and tools needed to organize IDP data and knowledge in a Findable, Accessible, Interoperable and Reusable (FAIR) manner. Experimental data created by users must be complemented by metadata in order to be deposited in an IDP resource. This document describes what community standards must be followed and where to find information needed to complete the metadata of an IDP experiment or study. Annotating or curating data from an IDP related experiment or study\nDescription\nAs a researcher in the field of Intrinsically Disordered Proteins (IDPs), you want to know how to process an experimental result in a FAIR way. As a final aim, you want to deposit the data in a community database or registry for wider adoption. Considerations\nYou can split the experimental process in several steps:\n* How should you properly describe an IDP experiment? Are there any community standards that you should follow? *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"intrinsically_disordered_proteins.md",
            "language":"en",
            "frontmatter":{
                "title":"Intrinsically disordered proteins",
                "description":"Data management solutions for intrinsically disordered proteins data.",
                "contributors":[
                    "Ivan Mieti"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "page_id":"idp"
            }
        }
    },
    {
        "id":"md_content_intrinsically_disordered_proteins_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/intrinsically_disordered_proteins.md",
        "file_name":"intrinsically_disordered_proteins.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"you properly describe an IDP experiment? Are there any community standards that you should follow? * How do you add metadata in order to make IDP data more machine readable? * How should you publish IDP data to a wider audience? Solutions\n\n\nThe IDP community developed a {% tool \"miade\" %} standard under a PSI-ID workgroup. The standard specifies the minimum information required to comprehend the result of a disorder experiment. The standard is available in XML and TAB format. You can check example annotation in XML and TAB format and adapt it to your data. * The IDP community developed the Intrinsically Disordered Proteins Ontology ({% tool \"idpo\" %}). The ontology is an agreed consensus of terms used in the community, organised in a structured way. The ontology is available in OWL and OBO format. * You should deposit primary data into relevant community databases ({% tool \"bmrb\" %}, {% tool \"pcddb\" %}, {% tool \"sasbdb\" %}). You should deposit literature data to the manually curated database {% tool \"disprot\" %}. DisProt is built on MIADE standard and IDPO ontology.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"intrinsically_disordered_proteins.md",
            "language":"en",
            "frontmatter":{
                "title":"Intrinsically disordered proteins",
                "description":"Data management solutions for intrinsically disordered proteins data.",
                "contributors":[
                    "Ivan Mieti"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "page_id":"idp"
            }
        }
    },
    {
        "id":"md_content_intrinsically_disordered_proteins_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/intrinsically_disordered_proteins.md",
        "file_name":"intrinsically_disordered_proteins.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"anually curated database {% tool \"disprot\" %}. DisProt is built on MIADE standard and IDPO ontology. As such, DisProt requires curators to annotate all new data according to community standards. IDP data from primary databases, together with curated experimental annotations and software predictions, is integrated in the comprehensive {% tool \"mobidb\" %} database. DisProt and MobiDB add and expose {% tool \"bioschemas\" %} markup to all data records increasing data findability and interoperability. Issues annotating or describing an IDP related term or study\nDescription\nIDP field is actively evolving. It integrates newly published experimental evidence of protein disorder and translates it in a machine readable way in an IDP database. This mapping process relies on accurate knowledge of protein identifiers, protein regions under study and disorder region functional annotation.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"intrinsically_disordered_proteins.md",
            "language":"en",
            "frontmatter":{
                "title":"Intrinsically disordered proteins",
                "description":"Data management solutions for intrinsically disordered proteins data.",
                "contributors":[
                    "Ivan Mieti"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "page_id":"idp"
            }
        }
    },
    {
        "id":"md_content_intrinsically_disordered_proteins_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/intrinsically_disordered_proteins.md",
        "file_name":"intrinsically_disordered_proteins.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"ledge of protein identifiers, protein regions under study and disorder region functional annotation. Considerations\nMost common issues that you as a researcher can encounter during the mapping process are:\n* how to properly and uniquely identify the protein (or fragment) under study?\n* how to deal with missing terms in IDPO? Solutions In order to uniquely identify the protein under study, you should identify the protein on {% tool \"uniprot\" %} reference protein database. The protein identifier must be complemented with an isoform identifier (if needed) in order to completely match the experimental protein sequence. Use the {% tool \"sifts\" %} database to precisely map the experimental protein fragment (deposited at {% tool \"pdb\" %}) to a reference protein database ({% tool \"uniprot\" %}) at an amino acid level. * Experimental evidence from literature must be mapped to relevant IDPO terms.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"intrinsically_disordered_proteins.md",
            "language":"en",
            "frontmatter":{
                "title":"Intrinsically disordered proteins",
                "description":"Data management solutions for intrinsically disordered proteins data.",
                "contributors":[
                    "Ivan Mieti"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "page_id":"idp"
            }
        }
    },
    {
        "id":"md_content_intrinsically_disordered_proteins_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/intrinsically_disordered_proteins.md",
        "file_name":"intrinsically_disordered_proteins.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":" an amino acid level. * Experimental evidence from literature must be mapped to relevant IDPO terms. If no suitable term could be found in IDPO, try with following resources:\n  * Evidence & Conclusion Ontology (ECO) for experimental methods\n  * Molecular Interactions Controlled Vocabulary for molecular interactions\n  * Gene Ontology for functional terms\nIf there isn't an appropriate term in ontologies or vocabularies, you can submit a new proposal for community review at DisProt feedback.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"intrinsically_disordered_proteins.md",
            "language":"en",
            "frontmatter":{
                "title":"Intrinsically disordered proteins",
                "description":"Data management solutions for intrinsically disordered proteins data.",
                "contributors":[
                    "Ivan Mieti"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[

                    ]
                },
                "page_id":"idp"
            }
        }
    },
    {
        "id":"md_fm_plant_sciences_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Anne-Franoise Adam-Blondon\n- Sebastian Beier\n- Cyril Pommier\n- Erwan Le Floch\n- Daniel Faria\ndescription: Data management solutions for plant sciences data. faircookbook:\n- name: Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases\n  url: https:\/\/w3id.org\/faircookbook\/FCB061\n- name: Publishing plant phenotypic data\n  url: https:\/\/w3id.org\/faircookbook\/FCB083\npage_id: plants\nrelated_pages:\n  tool_assembly:\n  - plant_geno_assembly\n  - plant_pheno_assembly\n  - fairtracks\n  your_tasks:\n  - metadata\ntitle: Plant sciences\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"plant_sciences.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_plant_sciences_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":0,
        "total_chunks":18,
        "content":"Introduction\nData management challenges in plant sciences\nThe plant science domain includes studying the adaptation of plants to their environment, with applications ranging from improving crop yield or resistance to environmental conditions to managing forest ecosystems. Data integration and reuse are facilitators for understanding the play between genotype and environment to produce a phenotype, which requires integrating phenotyping experiments and genomic assays made on the same plant material with geo-climatic data. Moreover, cross-species comparisons are often necessary to understand the mechanisms behind phenotypic traits, especially at the genotypic level, due to the gap in genomic knowledge between well-studied plant species (namely Arabidopsis) and newly sequenced ones. The challenges to data integration stem from the multiple levels of heterogeneity in this domain.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":1,
        "total_chunks":18,
        "content":"s. The challenges to data integration stem from the multiple levels of heterogeneity in this domain. It encompasses a variety of species, ranging from model organisms to crop species to wild plants such as forest trees. These often need to be detailed at infra-specific levels (e.g. subspecies, variety), but naming at these levels sometimes lacks consensus. Studies can take place in a diversity of settings, including indoor (e.g. growth chamber, greenhouse) and outdoor settings (e.g. cultivated field, forest) which differ fundamentally on the requirements and manner of characterizing the environment. Phenotypic data can be collected manually or automatically (by sensors and drones), and be very diverse in nature, spanning physical measurements, the results of biochemical assays, and images. Some omics data can be considered as well as molecular phenotypes (e.g. transcriptome, metabolomes). Thus, the extension and depth of metadata required to describe a plant experiment in a FAIR-compliant way is very demanding for researchers.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":2,
        "total_chunks":18,
        "content":"a required to describe a plant experiment in a FAIR-compliant way is very demanding for researchers. Another particularity of this domain is the absence of central deposition databases for certain important data types, in particular data deriving from plant phenotyping experiments. Whereas datasets from plant omics experiments are typically deposited in global deposition databases for that type of experiment, those from phenotyping experiments remain in institutional or, at best, national repositories. This makes it difficult to find, access and interconnect plant phenotyping data. Data management planning\nDescription \nThe general principles for data management planning are described in the Planning page of the Data life cycle section, while generic but more practical aspects of writing a DMP can be found on the Data Management Plan page. Considerations \n\nImportant general considerations about data management planning can be found on the Planning page. Phenotyping data must be described following the {% tool \"miappe\" %} data standard.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":3,
        "total_chunks":18,
        "content":"e Planning page. Phenotyping data must be described following the {% tool \"miappe\" %} data standard. Make sure to identify and describe the biological material and the observation variables in your research. Solutions\nThe knowledge model of the data management planning application {% tool \"data-stewardship-wizard\" %} was reviewed for compliance with the needs of the Plant Sciences community. Machine-actionable DMP\n\nThe DSW Plant Sciences project template, available on ELIXIR's DSW instance for researchers can be used for any plant sciences project. When creating the DMP Project, choose the option \"From Project Template\" and search for the \"Plant Sciences\" template. DMP as a text document\n\n{% tool \"dataplan\" %} is a Data Management Plan generator for plant science. It supports DMPs for Horizon 2020, Horizon Europe and the German BMBF and DFG. The main focus during development was to be able to be used with German funding agencies but was also extended to include other European funders.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":4,
        "total_chunks":18,
        "content":"ble to be used with German funding agencies but was also extended to include other European funders. Depending on the country, there might also be other tools to take into consideration: for example, DMP OPIDoR in France or {% tool \"dmponline\" %} for the UK. Visit the RDMkit national resources section for details. Plant biological materials: (meta)data collection and sharing\nDescription\nPlant genetic studies, such as the genomic-based prediction of phenotypes, require the integration of genomic and phenotypic data with data about their environment. While phenotypic and environmental data are typically stored together in phenotyping databases, genomic and other types of molecular data are typically deposited in international deposition databases, for example, those of the {% tool \"international-nucleotide-sequence-database-collaboration\" %}. It can be challenging to integrate phenotypic and molecular data even within a single project, particularly if the project involves studying a panel of genetic resources in different conditions.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":5,
        "total_chunks":18,
        "content":" particularly if the project involves studying a panel of genetic resources in different conditions. It is paramount to maintain the link between the plant material in the field, the samples extracted from them (e.g. at different development stages), and the results of omics experiments (e.g. transcriptomics, metabolomics) performed on those samples, across all datasets that will be generated and published. Integrating phenotyping and molecular data, both within and between studies, hinges entirely on precise identification of the plant material under study (down to the variety or even the seed lot), as well as of the samples that are collected from these plants. Considerations\n\nAre you working with established plant varieties, namely crop plants? Can you trace their provenance to a genebank accession? Are they identified in a germplasm database with an accession number? Are you working with crosses of established plant varieties?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":6,
        "total_chunks":18,
        "content":"lasm database with an accession number? Are you working with crosses of established plant varieties? Can you trace the genealogy of the crosses to plant varieties from a genebank or identified in a germplasm database?\nAre you working with experimental material? Can you trace a genealogy to other material? How do you unambiguously identify your material?\n\nSolutions\nIdentification of plant biological materials\n\nDetailed metadata needs to be captured on the biological materials used in the studythe accession in the genebank or the experimental identification and, when applicable, the seed lots or the parent plants as well as the possible samples taken from the plantas they are the key to integrating omics and phenotyping datasets. Checklists and metadata standard\n\nThe identification and description of plant materials should comply with the standard for the identification of plant genetic resources, The {% tool \"multi-crop-passport-descriptor\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":7,
        "total_chunks":18,
        "content":" for the identification of plant genetic resources, The {% tool \"multi-crop-passport-descriptor\" %}. If you are studying experimental plant materials that cannot be traced to an existing genebank or germplasm database, you should describe them in accordance with the MCPD in as much detail as possible. If your plant materials can be traced to an existing genebank or germplasm database, you need only to cross reference to the MCPD information already published in the genebank or germplasm database. The minimal fields from MCPD are listed in the Biological Material section of the Minimum Information About Plant Phenotyping Experiments (MIAPPE) metadata standard. For wild plants and accessions from tree collections, precise identification often requires the GPS coordinates of the tree. MIAPPE provides the necessary fields.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":8,
        "total_chunks":18,
        "content":"identification often requires the GPS coordinates of the tree. MIAPPE provides the necessary fields. Tools for (meta)data collection\n\nFor identifying your plant material in a plant genetic resource repository (genebank or germplasm database), you can consult the European Cooperative Programme for Plant Genetic Resources {% tool \"ecpgr\" %}, which includes a {% tool \"ecpgr-central-crop-databases\" %} and a catalogue of relevant {% tool \"international-multicrop-databases\" %}. Other key databases for identifying plant material are \nthe European Search Catalogue for Plant Genetic Resources {% tool \"eurisco\" %}, which provides information about more than 2 million accessions of crop plants and their wild relatives from hundreds of European institutes in 43 member countries. {% tool \"genesys\" %}, an online platform with a search engine for Plant Genetic Resources for Food and Agriculture (PGRFA) conserved in genebanks worldwide. The Biological Material section of the {% tool \"miappe-checklist-data-model\" %} checklist deals with sample description.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":9,
        "total_chunks":18,
        "content":"al section of the {% tool \"miappe-checklist-data-model\" %} checklist deals with sample description. (Meta)Data sharing and publication\n\nFor identifying samples from which molecular data was produced, the {% tool \"biosamples\" %} database is recommended as a provider of international unique identifiers. The {% tool \"plant-miappe-json\" %} model provided by BioSamples is aligned with all recommendations provided above for plant identification and is therefore recommended for your sample submission. It is also recommended that you provide permanent access to a description of the project or study, that contains links to all the data, molecular or phenotypic. Several databases are recommended for this purpose, including:\n{% tool \"recherche-data-gouv\" %}\n{% tool \"e-dal\" %}\n{% tool \"zenodo\" %}\n{% tool \"biostudies\" %}\n{% tool \"fairdomhub\" %}\n\nPhenotyping: (meta)data collection and publication\nDescription\nArchiving, sharing, and publication of plant phenotyping data can be challenging, given that there is no global centralized archive for this type of data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":10,
        "total_chunks":18,
        "content":"ng data can be challenging, given that there is no global centralized archive for this type of data. Research projects often involve multiple partners, some of which collate data into their own (institutional) data management platforms, whereas others collate data into Excel spreadsheets. For researchers, it is highly desirable that the datasets collected in different media by the partners in a research project (or across different collaborative projects) can be shared in a way that enables their integration for collective analysis and for facilitating deposition into a dedicated repository. For managers of plant phenotyping data repositories that support a project or institution, it is essential to ensure that the uptake of data is easy and includes a step of metadata validation upon intake. It is recommended that metadata collection is contemplated from the start of the experiment and that the working environment facilitates (meta)data collection, storage, and validation throughout the project.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":11,
        "total_chunks":18,
        "content":"rking environment facilitates (meta)data collection, storage, and validation throughout the project. In field studies, it is critical to record the geographical coordinates and time of the experiment for linkage with geo-climatic data. For all study types (fields, growth chamber or greenhouse), the environmental conditions that were measured should be described in detail. Considerations\n\nDid you collect the metadata for the identification of your plant material according to the recommendation provided in the above section? Have you documented your phenotyping and environment assays (i.e. measurement or computation methodology based on the trait, method, scale triplet) both for direct measures (data collection) and computed data (after data processing or analysis)? Is there an existing {% tool \"crop-ontology\" %} for the species you experiment and does it describe your assay? If not, have you described your data following the trait, method, and scale triplet? Do you have your own system to collect data? Is it compliant with the {% tool \"miappe\" %} standard?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":12,
        "total_chunks":18,
        "content":" Do you have your own system to collect data? Is it compliant with the {% tool \"miappe\" %} standard? Are you exchanging data with individual researchers? In what media is data being collected?\nIs the data described in a {% tool \"miappe\" %}-compliant manner? Are you exchanging data across different data management platforms? Do these platforms implement the Breeding API {% tool \"brapi\" %} specification? If not, are they MIAPPE-compliant? Do they enable automated data exchange?\n\nSolutions\nChecklists and ontologies\n\nThe metadata standard applicable to plant phenotyping experiments is {% tool \"miappe\" %}. There is a section dedicated to the identification of plant biological materials that follows {% tool \"multi-crop-passport-descriptor\" %} described above. There is a section to describe the phenotyping assays based on the {% tool \"crop-ontology\" %} recommendations. There is a section describing the type of experiment (greenhouse, field, etc.) and it is advisable to collect the location (geographical coordinates) and time where it was performed for linkage with geo-climatic data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":13,
        "total_chunks":18,
        "content":"ation (geographical coordinates) and time where it was performed for linkage with geo-climatic data. Other sections include a description of investigations, studies, people involved, data files, environmental parameters, experimental factors, events, observed variables. Tools and resources for data collection and management:\n{% tool \"fairdom-seek\" %} is a free data management platform for which MIAPPE templates are in development. {% tool \"dataverse\" %} is a free data management platform for which MIAPPE templates are in development. It is used in several repositories such as {% tool \"recherche-data-gouv\" %}. {% tool \"e-dal\" %} is a free data management platform for which MIAPPE templates are in development. The {% tool \"isa-tools\" %} also include a configuration for MIAPPE and can be used both for filling in metadata and for validating. Collaborative Open Plant Omics {% tool \"copo\" %} is a data management platform specific to the plant sciences.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":14,
        "total_chunks":18,
        "content":"ive Open Plant Omics {% tool \"copo\" %} is a data management platform specific to the plant sciences. {% tool \"fairsharing\" %} is a manually curated registry of reporting guidelines, vocabularies, identifier schemes, models, formats, repositories, knowledge bases, and data policies that includes many resources relevant for managing plant phenotyping data. Validation of MIAPPE compliance can be done via {% tool \"isa-tools\" %} or upon data deposition in a Breeding API ({% tool \"brapi\" %}) {% tool \"brapi-compatible-server\" %}. If you or your partners collect data manually, it is critical to adopt a spreadsheet template that is compatible with the structure of the database that will be used for data deposition. If the database is MIAPPE compliant, you can use the {% tool \"miappe-compliant-spreadsheet-template\" %}. This template could make use of tools for handling ontology annotations in a spreadsheet, such as {% tool \"rightfield\" %} or {% tool \"onotomaton\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":15,
        "total_chunks":18,
        "content":"g ontology annotations in a spreadsheet, such as {% tool \"rightfield\" %} or {% tool \"onotomaton\" %}. If you or your partners collect data into data management platforms:\nIf it implements BrAPI, you can exchange data using BrAPI calls. If it doesnt implement BrAPI, the simplest solution would be to export data into the MIAPPE spreadsheet template, or another formally defined data template. For data deposition, it is highly recommended that you opt for one of the many repositories that implement {% tool \"brapi-compatible-server\" %}, as they enhance findability through the ELIXIR plant data discovery service, FAIR Data-finder for Agronomic Research ({% tool \"faidare\" %}), enable machine actionable access to MIAPPE compliant data and validation of that compliance.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":16,
        "total_chunks":18,
        "content":"e\" %}), enable machine actionable access to MIAPPE compliant data and validation of that compliance. Genotyping: (meta)data collection and publication\nDescription\nHere are described the mandatory, recommended and optional metadata fields for data interoperability and re-use, as well as for data deposition in EVA (European Variation Archive), the EMBL-EBI's open-access genetic variation archive connected to {% tool \"biosamples\" %}, described above. Considerations\n\nDid you collect the metadata for the identification of your plant samples according to the recommendations provided in the above section? Is the reference genome assembly available in an {% tool \"international-nucleotide-sequence-database-collaboration\" %} archive and has a Genome Collections Accession number, either GCA or GCF? Is the analytic approach used for creating the VCF file available in a publication and has a Digital Object Identifier (DOI)? Solutions\nChecklists, ontologies and file formats\n\nSharing plant genotyping data files involves the use of the Variant Call Format (VCF) standard.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_sciences_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/plant_sciences.md",
        "file_name":"plant_sciences.md",
        "chunk_index":17,
        "total_chunks":18,
        "content":"ats\n\nSharing plant genotyping data files involves the use of the Variant Call Format (VCF) standard. Findability and reusability of VCF files depend on the supplied metadata and, in particular, with MIAPPE-compliant biological material description: the plant genomic and genetic variation data submission recipe helps you on that topic. Data sharing and publication\n\nOnce the VCF file is ready with all necessary metadata, it can be submitted to {% tool \"european-variation-archive\" %}. You will find all necessary information on the submission steps on the EVA submission page.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_sciences.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant sciences",
                "description":"Data management solutions for plant sciences data.",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Sebastian Beier",
                    "Cyril Pommier",
                    "Erwan Le Floch",
                    "Daniel Faria"
                ],
                "related_pages":{
                    "your_tasks":[
                        "metadata"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly",
                        "plant_pheno_assembly",
                        "fairtracks"
                    ]
                },
                "page_id":"plants",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=plant%20data%20management"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    },
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_health_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Marcus Buchwald\n- Tim Beck\n- Saskia Lawson-Tovey\n- Gerhard Mayer\n- Soumyabrata Ghosh\n- Philip Quinlan\n- Venkata Satagopam\n- Jan Willem Boiten\n- Patrick Ruch\n- Hindrik Kerstens\n- Carlos Lus Parra Caldern\n- Salvador Capella-Gutierrez\n- Magda Chegkazi\n- Arshiya Merchant\ndescription: Data management solutions for human health data. faircookbook:\n- name: Creating a metadata profile for clinical trial protocols\n  url: https:\/\/w3id.org\/faircookbook\/FCB084\n- name: Mapping IMI APPROACH datasets to CDISC-SDTM standard\n  url: https:\/\/w3id.org\/faircookbook\/FCB078\npage_id: health_data\nrelated_pages:\n  your_domain:\n  - human data\n  your_tasks:\n  - sensitive\n  - gdpr_compliance\ntitle: Health data",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"health_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_health_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":0,
        "total_chunks":19,
        "content":"Introduction\nHuman health data is a broad concept encapsulating diverse data types and modalities, including omics and clinical data. Clinical data (routinely collected or originating from clinical studies) includes but is not limited to images, healthcare administrative data (e.g. demographics), free text and patient-generated data from questionnaires or real-world wearables\/mobile devices. This page describes data management considerations and solutions for two widely collected data types used in health data research studies: data about the patient from questionnaires and electronic health records (EHRs) generated from interactions with the healthcare system. Future versions of this page will include additional health data types. All scientific research involving data processing concerning identifiable people in the European Union is subject to the General Data Protection Regulation (GDPR) and may require ethics approval.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":1,
        "total_chunks":19,
        "content":"n Union is subject to the General Data Protection Regulation (GDPR) and may require ethics approval. This page will not repeat the GDPR, ethics and data anonymization information given elsewhere in RDMkit, namely on the GDPR compliance, Ethical aspects, Data sensitivity and Human data pages, which should be familiar to scientists working with health data. The content on this page is also distinct from the Rare disease data page, which considers collecting and processing data specific to rare diseases. Country-specific RDM resources, including existing national solutions or RDM advice specific to national policies\/funders\/infrastructures are on the National Resources pages. The information presented on this page is disease and country-agnostic. Patient-generated health data from questionnaires\nDescription\nParticipants health data which can be collected via surveys, interviews, and monitoring, are called Clinical Outcome Measures (COMs). In surveys, the questionnaire is either completed by the participants or their representative (e.g. family member or caregiver).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":2,
        "total_chunks":19,
        "content":"e is either completed by the participants or their representative (e.g. family member or caregiver). In interviews, a healthcare professional asks\/explains the questionnaire to the participants and records their responses. Monitoring includes measuring a participants behaviour or activity in both a clinical and non-clinical setup. Based on this, COMs can be classified into four broad categories:\nPatient Reported Outcome Measure (PROM) is a measurement that comes directly from the patient (i.e. study participant) about the status of a patients health condition without amendment or interpretation of the patients response by a clinician or anyone else. Observer-Reported Outcome Measure (ObsROM) is a measurement based on a report of observable signs, events or behaviours related to a patients health condition by someone (e.g. family member or caregiver) other than the patient or a health professional. Clinician-Reported Outcome Measure (ClinROM) is a measurement based on a report from a trained healthcare professional after observing a patients health condition.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":3,
        "total_chunks":19,
        "content":"sed on a report from a trained healthcare professional after observing a patients health condition. Performance Outcome Measure (PefOM) is a measurement based on standardised task(s) actively undertaken by a patient according to a set of instructions and administered by trained professionals or completed by the patient independently. Usually, COMs are inherently time-point specific, necessitating the inclusion of corresponding date-time information alongside the measured values. When COMs from a participant are gathered across multiple time points, the study is categorised as a longitudinal study. Within the clinical study\/trial domain, these time points are referred to as Events, and a cohesive set of COM questions presented in a singular questionnaire is denoted as an Instrument or Battery. Considerations\nTo collect health data directly from participants, an efficient data collection strategy will consider the following components:\n* Consider the impact of the digital divide when digital collection methods are utilised. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":4,
        "total_chunks":19,
        "content":"ponents:\n* Consider the impact of the digital divide when digital collection methods are utilised. * Define key scientific objectives with patients and stakeholders from clinical, social-sciences and data analysis domains. * In the case of a longitudinal study, define time points for the data collection (consult doctors on typical visit schedules to minimise the burden on participants and a calendar for holidays and other events). * Any personally identifiable information (PII), including communication details like name, address, email, or telephone number, needs to be separated from data and stored in a separate system with additional security measures like Two-Factor Authentication and encryption at rest. * Design the privacy policy for the survey according to relevant local guidelines with the information governance\/data protection officer and IT team\n* Design the questionnaires with consideration given to interoperability (e.g. mapping questions\/answers to concepts in clinical terminologies) and avoiding ambiguity in the questions.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":5,
        "total_chunks":19,
        "content":"ng questions\/answers to concepts in clinical terminologies) and avoiding ambiguity in the questions. * Guidelines: \n     * EC Guidelines for the development and criteria for the adoption of Health Survey instruments\n     * EC Selection of a Coherent Set of Health Indicators for the European Union Phase II\n  * Check the readability and accessibility of the questionnaires. * Use validated, standardised questionnaires where possible, for example REDCap has a library of data collection instruments\n  * Use a collaborative editing platform with versioning \n  *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":6,
        "total_chunks":19,
        "content":"library of data collection instruments\n  * Use a collaborative editing platform with versioning \n  * Finalise the questionnaires in the required template (if any) for ethical approval\n\nDevelopment of the machine-readable data dictionary for all languages:   \nUse a table format file such as CSV or TSV for the data dictionary\nREDCap has an example data dictionary template\nIt is highly recommended to use standard ontology terms as field names and value options where applicable\n\nMap the data dictionary to applicable standards in your disease\/research area to improve interoperability in future data use\n\n\nOnce the data collection workflow is finalised, design a diagram of the workflow with tools like draw.io or Miro. This will help to understand the bottlenecks of the flow better. Keep the workflow diagram updated if there are any changes to the workflow. Use or deploy GDPR-compliant Electronic Data Capture (EDC) systems (see Solutions section)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":7,
        "total_chunks":19,
        "content":"workflow. Use or deploy GDPR-compliant Electronic Data Capture (EDC) systems (see Solutions section) Import\/build the questionnaire\/data dictionary into the chosen EDC systems to generate the collection instrument(s) or forms\nDesign the survey frontend (user interface) of the collection instrument(s) considering the participants perspective. Responsive design and co-development with patient partners are highly recommended. Test and retest the data collection forms and UI If patients\/parents\/public are involved in any part of the project, including data system development, make sure their time\/expenses are costed into the grant. Solutions\nGDPR compliant EDC systems that support the capture of COMs:\n* {% tool \"redcap\" %} - Academic licence\n  * Check the licence terms carefully, as some uses in commercial research may not be allowed. * REDCap  online training videos\n* {% tool \"redcap-cloud\" %} - Commercial licence\n  * A fully managed REDCap system based in the cloud, provided by nPhase.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":8,
        "total_chunks":19,
        "content":"d\" %} - Commercial licence\n  * A fully managed REDCap system based in the cloud, provided by nPhase. * {% tool \"castor\" %} - Academic\/commercial licence\n* {% tool \"eu-survey\" %} - SaaS provided by the EU Commission\n* {% tool \"limesurvey\" %} Open source, \n* {% tool \"alchemer\" %}  Commercial\n* {% tool \"jotform\" %}  Commercial \n* Data Integration System  Commercial\nPII separation and storage systems:\n* {% tool \"smasch\" %} - Open source\n* Mosaic Project - Open source \nImproving the FAIRness of health data:\n* {% tool \"fairsharing\" %}\n* {% tool \"fair-cookbook\" %}\nElectronic Health Record (EHR) data\nDescription\nElectronic Health Record (EHR) data includes patient identifiers, diagnoses, demographics, procedures, medications, vital signs, laboratory results, and utilisation events as well as financial records or administrative information. Converting these different data types to a usable structured format is critical to improving EHR-originated data management. Considerations\nThe structure of EHRs varies widely within and between countries.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":9,
        "total_chunks":19,
        "content":"ed data management. Considerations\nThe structure of EHRs varies widely within and between countries. Even within a single care provider, there may be multiple EHRs. National and international efforts are underway to drive EHR standardisation and interoperability. It is useful to keep in mind that EHRs are healthcare-oriented electronic tools with a data model design and functionalities intended for critical healthcare operations and not for research. Therefore, specific standards and methods to extract and transform this information are required to allow such use ethically and legally. This section presents some of the transnational projects working towards improved reuse of EHR data, and the next section introduces key technical standards for storing, integrating, and exchanging EHR and clinical data. For member states within the EU, the European Commission published a proposed regulation for establishing the European Health Data Space (or EHDS). The proposed regulation establishes a common space for health data where:\n*",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":10,
        "total_chunks":19,
        "content":" Data Space (or EHDS). The proposed regulation establishes a common space for health data where:\n* Individuals are empowered through increased digital access to and control of their electronic personal health data\n* Researchers, innovators and policymakers can request access to these electronic health data in a trusted and secure way that preserves the individuals personal data\nThe EHDS will also regulate the interoperability of EHRs to a certain extent, in particular to facilitate the exchange of the patient summary data. EHDS places a significant emphasis on promoting the secondary use of health data, to serve research, innovation, policy-making and regulatory purposes. To achieve this, several European initiatives have been launched to establish its foundation and define guiding principles. Among these endeavors, two signification projects stand out:\n* TEHDAS, the joint action Towards the European Health Data Space, helped develop and promote concepts for the secondary use of health data to benefit public health and health research and innovation in Europe.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":11,
        "total_chunks":19,
        "content":" secondary use of health data to benefit public health and health research and innovation in Europe. TEHDAS produced a set of recommendations for the European Commission and member states to enable secondary use of health data. * HealthData@EU Pilot is a project designed to build a pilot version of the EHDS infrastructure for the secondary use of health data HealthData@EU. The project establishes connections between data platforms within a network infrastructure and develops services that facilitate the user journey for research projects using health data. It also offers guidelines for data standards, data quality, data security and data transfer to support this cross-border infrastructure. The EU published an overview of the national laws on electronic health records in 2016. Under US law, EHR data is classified as protected health information (PHI) and must comply with security laws and encrypt data properly when sending or retrieving such information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":12,
        "total_chunks":19,
        "content":"ust comply with security laws and encrypt data properly when sending or retrieving such information. Examples of protected health data include patient names, phone numbers, addresses, dates of birth, social security numbers, and insurance information. * Regulations: Health Insurance Portability and Accountability Act (HIPAA) and Health Information Technology for Economic and Clinical Health (HITECH) The International Patient Summary (IPS) is a standardised set of basic patient-related physiological and clinical data that includes the most important health and care related facts required to ensure safe and secure healthcare. It comprises data about medications, allergies\/intolerances, problems, immunizations, results and procedures for a specified patient. It is a joint standard of five standard development organisations (CEN, HL7, IHE, ISO and SNOMED) and is actively supported by the Global Digital Health Partnership and the World Health Organisation.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":13,
        "total_chunks":19,
        "content":"nd is actively supported by the Global Digital Health Partnership and the World Health Organisation. Solutions\nIt is likely that the use of one of the following standards will not be a choice, but something imposed by the software providers of the EHR systems. These interchange formats are the standards that are likely to be present as part of the EHR and include:\n* {% tool \"hl7-fhir\" %} is a standard used for health care data exchange and\/or storage of semantically annotated clinical or administrative health data that is useful for data integration and data interoperability. Within the FHIR ecosystem there are specific implementation guides for its use in research:",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":14,
        "total_chunks":19,
        "content":"ability. Within the FHIR ecosystem there are specific implementation guides for its use in research: * {% tool \"vulcan\" %} defines a minimal set of clinical research FHIR resources and elements in an EHR that can be utilised in an interoperable and consistent manner for clinical research\n  * {% tool \"fhir4fair\" %} provides guidance on how FHIR can be used for supporting FAIR health data\n* {% tool \"iso13606\" %} is a standard designed by the European Committee for Standardization to define a rigorous and stable information architecture for communicating part or all of the EHR of a single patient between EHR systems or between EHR systems and a centralised EHR data repository. It may also be used for EHR communication between an EHR system and clinical applications or middleware components, or for representing EHR data within a federated record system\n* The {% tool \"eehrxf\" %} is recommended by the European Commission to be used for the exchange of EHR data for cross-border healthcare\n* The {% tool \"isodis-14199\" %} standard Biomedical Research Integrated Domain Group (BRIDG)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":15,
        "total_chunks":19,
        "content":"lthcare\n* The {% tool \"isodis-14199\" %} standard Biomedical Research Integrated Domain Group (BRIDG) Model is a domain model for data interchange that enables semantic interoperability and intends to integrate biomedical, clinical research and routine healthcare data\n* {% tool \"openehr\" %} - a nonprofit organisation that publishes technical standards for an EHR platform along with domaindeveloped clinical models to define content. It is an open health interoperability standard and an alternative to FHIR.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":16,
        "total_chunks":19,
        "content":"models to define content. It is an open health interoperability standard and an alternative to FHIR. The data are patient-centric, i.e., all health data for a person are stored in a lifetime, vendor-independent EHR for that patient\nThese common data models are less likely to be directly supported by the EHR, but can facilitate sharing and analysis of data, however, EHR data are likely to require curation to these standards:\n* {% tool \"cdisc\" %} is a consortium, which defines several open standards for regulatory approval and case report forms in particular in the context of clinical trials meant for submission to FDA and EMA, e.g.\n  * {% tool \"adam\" %}\n  * {% tool \"ctr-xml\" %}\n  * {% tool \"odm-xml\" %}\n  * {% tool \"sdtm\" %}   for clinical study data in a tabular format\n* The {% tool \"cdm\" %} is an open community standard for observational health care data obtained from health records. It uses the OHDSI (Observational Health Data Sciences and Informatics) standard vocabularies.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":17,
        "total_chunks":19,
        "content":"cords. It uses the OHDSI (Observational Health Data Sciences and Informatics) standard vocabularies. It has quickly gained traction over recent years, amongst others, through the support received from several large EU projects. * {% tool \"fhim\" %} is a UML-based logical health information model defined by the Open Group, intended to achieve interoperability between multiple healthcare standards and protocols\n* Detailed clinical model (DCM) is the {% tool \"iso139722022\" %} standard. It defines data elements, the relationships between such data elements and terminologies for detailed small, reusable clinical models\nAdditionally, {% tool \"fairsharing\" %} can be used to search for more domain\/disease-specific standards (if applicable).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_health_data_md_18",
        "source":"markdown_content",
        "file_path":"pages\/your_domain\/health_data.md",
        "file_name":"health_data.md",
        "chunk_index":18,
        "total_chunks":19,
        "content":"l \"fairsharing\" %} can be used to search for more domain\/disease-specific standards (if applicable). Data integration tooling, from EHR to a common data model:\n* REDCap has an existing feature, {% tool \"cdis\" %}, which allows a REDCap project to interact with an EHR system and pull EHR data into REDCap\n* Tools to map datasets to the OMOP CDM\n  * OHDSI software\n  * {% tool \"carrot-mapper\" %}\nComprehensive lists of clinical terminologies are available from the {% tool \"ontology-lookup-service\" %} and {% tool \"bioportal\" %} ontology catalogues. Ontologies for use with the OMOP CDM are available from {% tool \"ohdsi-athena\" %}. Some examples of widely used clinical terminologies in health data research include:\n* International Classification of Diseases ({% tool \"icd10\" %}, {% tool \"icd11\" %}) * {% tool \"loinc\" %} for reporting laboratory test results\n* {% tool \"snomed-ct\" %}\n* {% tool \"hpo\" %}\n* Normalised names for clinical drugs {% tool \"rxnorm\" %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"health_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Health data",
                "description":"Data management solutions for human health data.",
                "contributors":[
                    "Marcus Buchwald",
                    "Tim Beck",
                    "Saskia Lawson-Tovey",
                    "Gerhard Mayer",
                    "Soumyabrata Ghosh",
                    "Philip Quinlan",
                    "Venkata Satagopam",
                    "Jan Willem Boiten",
                    "Patrick Ruch",
                    "Hindrik Kerstens",
                    "Carlos Lus Parra Caldern",
                    "Salvador Capella-Gutierrez",
                    "Magda Chegkazi",
                    "Arshiya Merchant"
                ],
                "page_id":"health_data",
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "gdpr_compliance"
                    ],
                    "your_domain":[
                        "human data"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a metadata profile for clinical trial protocols",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB084"
                    },
                    {
                        "name":"Mapping IMI APPROACH datasets to CDISC-SDTM standard",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB078"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_planning_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/data_life_cycle\/planning.md",
        "file_name":"planning.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Siiri Fuchs\n- Korbinian Bsl\n- Minna Ahokas\n- Federico Bianchini\n- Flora D'Anna\ndescription: Introduction to data management planning. page_id: plan\nrelated_pages:\n  your_tasks:\n  - compliance\n  - costs\n  - dmp\n  - data_security\n  - dm_coordination\n  - machine_actionability\n  - creating_dataflow_diagram\ntitle: Planning\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+management+planning%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"planning.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_planning_md_0",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/planning.md",
        "file_name":"planning.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"What is data management planning? Data management planning consists of defining the strategy that you plan to use for managing data and documentation generated within the project. It is about thinking upfront what's the best way to avoid problems or unexpected costs related to data management, and set the conditions for your research data to achieve the highest possible impact in science, even after the end of the project. Solutions regarding the handling of the data generated within a project is usually formalised in a Data Management Plan (DMP). A DMP is a document describing several aspects of the data management process which occur before, during and after the end of a project (see the Data Management Plan page). Why is data management planning important? It is good research practice to take care of your research data and have a DMP. It will make your work more efficient, facilitate team work and use of services and tools.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"planning.md",
            "language":"en",
            "frontmatter":{
                "title":"Planning",
                "page_id":"plan",
                "description":"Introduction to data management planning.",
                "contributors":[
                    "Siiri Fuchs",
                    "Korbinian Bsl",
                    "Minna Ahokas",
                    "Federico Bianchini",
                    "Flora D'Anna"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "costs",
                        "dmp",
                        "data_security",
                        "dm_coordination",
                        "machine_actionability",
                        "creating_dataflow_diagram"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+planning%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_planning_md_1",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/planning.md",
        "file_name":"planning.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ve a DMP. It will make your work more efficient, facilitate team work and use of services and tools. Moreover, a detailed DMP would help in making your research data more FAIR. Advantages of making a DMP:\n* it is often a requirement of research organisations and funders;\n* it helps to plan and budget necessary resources and equipment;\n* it defines roles and responsibilities in data management among the project team; * it helps to identify risks in data handling and apply solutions at early stage;\n* it facilitates data sharing, reuse and preservation. What should be considered for data management planning? Several aspects should be taken into account when making a data management plan. Research organisation and funders often require a DMP as part of the application for grants or later when the project is funded. Therefore, consider guidelines, policies and tools for data management planning required by your funder. Data management should be planned in the early stages of a research project. Preferably, the DMP should be filled in before starting data collection.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"planning.md",
            "language":"en",
            "frontmatter":{
                "title":"Planning",
                "page_id":"plan",
                "description":"Introduction to data management planning.",
                "contributors":[
                    "Siiri Fuchs",
                    "Korbinian Bsl",
                    "Minna Ahokas",
                    "Federico Bianchini",
                    "Flora D'Anna"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "costs",
                        "dmp",
                        "data_security",
                        "dm_coordination",
                        "machine_actionability",
                        "creating_dataflow_diagram"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+planning%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_planning_md_2",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/planning.md",
        "file_name":"planning.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"ages of a research project. Preferably, the DMP should be filled in before starting data collection. However, the DMP is a living document and should be updated as the research project progresses to match e.g. an update of the infrastructures, research softwares or a novel collaboration. Consider standards or best practices required by facilities and infrastructures that you plan to use. Due to the variety of aspects that need to be addressed in a DMP, it is better to find recommendations and obtain help from your institution support services, such as IT department, library, data managers or data stewards, legal or tech transfer team and data protection officer. Explore best practices, guidelines, tools and resources for research data management described in this website.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"planning.md",
            "language":"en",
            "frontmatter":{
                "title":"Planning",
                "page_id":"plan",
                "description":"Introduction to data management planning.",
                "contributors":[
                    "Siiri Fuchs",
                    "Korbinian Bsl",
                    "Minna Ahokas",
                    "Federico Bianchini",
                    "Flora D'Anna"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "costs",
                        "dmp",
                        "data_security",
                        "dm_coordination",
                        "machine_actionability",
                        "creating_dataflow_diagram"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+planning%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_reusing_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/data_life_cycle\/reusing.md",
        "file_name":"reusing.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Korbinian Bsl\n- Daniel Faria\n- Markus Englund\ndescription: Introduction to data reuse. dsw:\n- name: Is there any pre-existing data?\n  uuid: efc80cc8-8318-4f8c-acb7-dc1c60e491c1\npage_id: reuse\nrelated_pages:\n  your_tasks:\n  - data_analysis\n  - transfer\n  - existing_data\n  - identifiers\n  - licensing\n  - data_provenance\n  - data_quality\ntitle: Reusing\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+reuse%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"reusing.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_reusing_md_0",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/reusing.md",
        "file_name":"reusing.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"What is data reuse? Data reuse means using data for other purposes than it was originally collected for. Reuse of data is particularly important in science, as it allows different researchers to analyse and publish findings based on the same data independently of one another. Reusability is one key component of the FAIR principles. Data that is well-described, curated and shared under clear terms and conditions is more likely to be reused. Integration with other data sources is also important, since that can enable new, yet unanticipated, uses for the data. Why is data reuse important? By reusing existing data you can:\n\nobtain reference data for your research;\navoid doing new, unnecessary experiments;\nrun analyses to verify that reported findings are correct, and thereby making subsequent findings more robust;\nmake research more robust by aggregating results obtained from different methods or samples;\ngain novel insights by connecting and meta-analysing datasets.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"reusing.md",
            "language":"en",
            "frontmatter":{
                "title":"Reusing",
                "page_id":"reuse",
                "description":"Introduction to data reuse.",
                "contributors":[
                    "Korbinian Bsl",
                    "Daniel Faria",
                    "Markus Englund"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "transfer",
                        "existing_data",
                        "identifiers",
                        "licensing",
                        "data_provenance",
                        "data_quality"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+reuse%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_reusing_md_1",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/reusing.md",
        "file_name":"reusing.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ed from different methods or samples;\ngain novel insights by connecting and meta-analysing datasets. What should be considered for data reuse? Reusing existing data implies checking the necessary conditions for reuse are met. Explore different sources for reusable data. A starting point can be to look for value added databases with curated content. Other possibilities include searching data deposition repositories for suitable datasets based on their annotation, or obtaining data directly from the author of a scientific article. Check under which terms and conditions the data is shared. Make sure that there is a licence, and that the licence gives you permission to do what you intend to. Check whether there is sufficient metadata to enable data reuse. Some types of data can be straightforward to reuse (e.g. genome data), while other may require extensive metadata to interpret and reuse (e.g. gene expression experiment data). Assess the quality of the data. Evaluate if the data comes from a trusted source and if it is curated. Check if the data adheres to a standard.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"reusing.md",
            "language":"en",
            "frontmatter":{
                "title":"Reusing",
                "page_id":"reuse",
                "description":"Introduction to data reuse.",
                "contributors":[
                    "Korbinian Bsl",
                    "Daniel Faria",
                    "Markus Englund"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "transfer",
                        "existing_data",
                        "identifiers",
                        "licensing",
                        "data_provenance",
                        "data_quality"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+reuse%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_reusing_md_2",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/reusing.md",
        "file_name":"reusing.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":" the data comes from a trusted source and if it is curated. Check if the data adheres to a standard. Verify that the data has been ethically collected and that your reuse of the data conforms with policies and regulations you are expected to follow. For personal (sensitive) data, there are usually legal and technical requirements that have to be met before data can be accessed. Getting access to personal (sensitive) data will therefore involve additional steps. If the data you are reusing has been updated, make sure to document which version of the data you are using. Also consider what impact the changes may have on your results. Cite the data properly by include a persistent identifier (such as a DOI) in the citation, if there is one.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"reusing.md",
            "language":"en",
            "frontmatter":{
                "title":"Reusing",
                "page_id":"reuse",
                "description":"Introduction to data reuse.",
                "contributors":[
                    "Korbinian Bsl",
                    "Daniel Faria",
                    "Markus Englund"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "transfer",
                        "existing_data",
                        "identifiers",
                        "licensing",
                        "data_provenance",
                        "data_quality"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+reuse%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_collecting_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/data_life_cycle\/collecting.md",
        "file_name":"collecting.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Korbinian Bsl\n- Siiri Fuchs\n- Anastasia Chasapi\n- Ulrike Wittig\ndescription: Introduction to data collection. dsw:\n- name: Specify a list of data sets you will be producing\n  uuid: 4e0c1edf-660c-4ebf-81f5-9fa959dead30\npage_id: collect\nrelated_pages:\n  your_tasks:\n  - data_organisation\n  - data_quality\n  - existing_data\n  - identifiers\n  - metadata\n  - sensitive\n  - storage\n  - data_provenance\ntitle: Collecting\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+collection%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"collecting.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_collecting_md_0",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/collecting.md",
        "file_name":"collecting.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"What is data collection? Data collection is the process where information is gathered about specific variables of interest either using instrumentation or other methods (e.g. questionnaires, patient records). While data collection methods depend on the field and research subject, it is important to ensure data quality. You can also reuse existing data in your project. This can either be individual earlier collected datasets, reference data from curated resources or consensus data like reference genomes. For more information see Reuse in the data life cycle. Why is data collection important? Apart from being the source of information to build your findings on, the collection phase lays the foundation for the quality of both the data and its documentation. It is important that the decisions made regarding quality measures are implemented, and that the collect procedures are appropriately recorded. What should be considered for data collection?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"collecting.md",
            "language":"en",
            "frontmatter":{
                "title":"Collecting",
                "page_id":"collect",
                "description":"Introduction to data collection.",
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "data_quality",
                        "existing_data",
                        "identifiers",
                        "metadata",
                        "sensitive",
                        "storage",
                        "data_provenance"
                    ]
                },
                "contributors":[
                    "Korbinian Bsl",
                    "Siiri Fuchs",
                    "Anastasia Chasapi",
                    "Ulrike Wittig"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+collection%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Specify a list of data sets you will be producing",
                        "uuid":"4e0c1edf-660c-4ebf-81f5-9fa959dead30"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_collecting_md_1",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/collecting.md",
        "file_name":"collecting.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"at the collect procedures are appropriately recorded. What should be considered for data collection? Appropriate tools or integration of multiple tools (also called tool assembly or ecosystem) can help you with data management and documentation during data collection. Suitable tools for data management and documentation during data collection are Electronic Lab Notebooks (ELNs), Electronic Data Capture (EDC) systems, Laboratory Information Management Systems (LIMS). Moreover, online platforms for collaborative research and file sharing services could also be used as ELN or data management systems. Independently of the tools you will use, consider the following, while collecting data. Capture the provenance e.g. of samples, researchers and instruments. Ensure data quality, since data can either be generated by yourself, or by another infrastructure or facility with this specialisation. Check options for reusing data instead of generating new data. Define the experimental design including a collection plan (e.g. repetitions, controls, randomisation) in advance.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"collecting.md",
            "language":"en",
            "frontmatter":{
                "title":"Collecting",
                "page_id":"collect",
                "description":"Introduction to data collection.",
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "data_quality",
                        "existing_data",
                        "identifiers",
                        "metadata",
                        "sensitive",
                        "storage",
                        "data_provenance"
                    ]
                },
                "contributors":[
                    "Korbinian Bsl",
                    "Siiri Fuchs",
                    "Anastasia Chasapi",
                    "Ulrike Wittig"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+collection%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Specify a list of data sets you will be producing",
                        "uuid":"4e0c1edf-660c-4ebf-81f5-9fa959dead30"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_collecting_md_2",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/collecting.md",
        "file_name":"collecting.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"erimental design including a collection plan (e.g. repetitions, controls, randomisation) in advance. Calibrate the instruments. Check data protection and security issues if you work with sensitive or confidential data. Check permissions or consent if you work with human-related data. Define how to store the data e.g. format and volume. Find suitable repository to store the data. Identify suitable metadata standards.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"collecting.md",
            "language":"en",
            "frontmatter":{
                "title":"Collecting",
                "page_id":"collect",
                "description":"Introduction to data collection.",
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "data_quality",
                        "existing_data",
                        "identifiers",
                        "metadata",
                        "sensitive",
                        "storage",
                        "data_provenance"
                    ]
                },
                "contributors":[
                    "Korbinian Bsl",
                    "Siiri Fuchs",
                    "Anastasia Chasapi",
                    "Ulrike Wittig"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+collection%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Specify a list of data sets you will be producing",
                        "uuid":"4e0c1edf-660c-4ebf-81f5-9fa959dead30"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_preserving_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/data_life_cycle\/preserving.md",
        "file_name":"preserving.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Siiri Fuchs\n- Korbinian Bsl\n- Anastasia Chasapi\n- Flora D'Anna\ndescription: Introduction to data preservation. dsw:\n- name: Specify a list of data sets you will be producing\n  uuid: 4e0c1edf-660c-4ebf-81f5-9fa959dead30\n- name: Will this data set be published?\n  uuid: a063da1c-aaea-4e18-85ec-f560d833f292\npage_id: preserve\nrelated_pages:\n  your_tasks:\n  - data_organisation\n  - data_security\n  - data_publication\n  - metadata\n  - storage\n  - identifiers\n  - licensing\ntitle: Preserving\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+preserve%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"preserving.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_preserving_md_0",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/preserving.md",
        "file_name":"preserving.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"What is data preservation? Data preservation consists of a series of activities necessary to ensure safety, integrity and accessibility of data for as long as necessary, even decades. Data preservation is indeed more than just data storage and backup, since data can be stored and backed up without being preserved. Data preservation prevents data from becoming unavailable and unusable over time through appropriate steps. * Ensure data safety and integrity. * Change the file format (format migration) and update software to make sure that they do not become outdated or obsolete. * Change hardware and other storage media (such as paper, magnetic tape, etc.) to avoid degradation. * Ensure that data is organised and described with appropriate metadata and documentation to be always understandable and reusable. Why is data preservation important? There are several important reasons to preserve research data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"preserving.md",
            "language":"en",
            "frontmatter":{
                "title":"Preserving",
                "page_id":"preserve",
                "description":"Introduction to data preservation.",
                "contributors":[
                    "Siiri Fuchs",
                    "Korbinian Bsl",
                    "Anastasia Chasapi",
                    "Flora D'Anna"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "data_security",
                        "data_publication",
                        "metadata",
                        "storage",
                        "identifiers",
                        "licensing"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+preserve%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Specify a list of data sets you will be producing",
                        "uuid":"4e0c1edf-660c-4ebf-81f5-9fa959dead30"
                    },
                    {
                        "name":"Will this data set be published?",
                        "uuid":"a063da1c-aaea-4e18-85ec-f560d833f292"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_preserving_md_1",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/preserving.md",
        "file_name":"preserving.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":". Why is data preservation important? There are several important reasons to preserve research data. * Guarantee that your data can be verified and reproduced for several years after the end of the project. * Allow the reuse of the data in the future for different purposes, such as teaching or further research. * Funders, publishers, institutions and organisations could require a specific period for preservation of certain data for a specific purpose. * Preserve data that have significant value for an organisation, a Nation, the environment or  for the entire society. What should be considered for preserving data? Not all data should be preserved. Preservation should be applied to an appropriate selection of data, since it takes relevant effort and costs.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"preserving.md",
            "language":"en",
            "frontmatter":{
                "title":"Preserving",
                "page_id":"preserve",
                "description":"Introduction to data preservation.",
                "contributors":[
                    "Siiri Fuchs",
                    "Korbinian Bsl",
                    "Anastasia Chasapi",
                    "Flora D'Anna"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "data_security",
                        "data_publication",
                        "metadata",
                        "storage",
                        "identifiers",
                        "licensing"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+preserve%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Specify a list of data sets you will be producing",
                        "uuid":"4e0c1edf-660c-4ebf-81f5-9fa959dead30"
                    },
                    {
                        "name":"Will this data set be published?",
                        "uuid":"a063da1c-aaea-4e18-85ec-f560d833f292"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_preserving_md_2",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/preserving.md",
        "file_name":"preserving.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"ion should be applied to an appropriate selection of data, since it takes relevant effort and costs. Common criteria to select the data to preserve for a certain amount of time are:\n* data requared to be preserved by funder, publisher and institution policies (usually, data should be preserved for at least 5 or 10 years after the end of the project);\n* data preservation of which is needed by legal or ethical requirements (e.g. clinical trial data);\n* unique data or that cannot be easily re-generated (e.g. raw data, analysis workflow);\n* data that will probably being reused in the future;\n* data of great value for society (scientifically, historically or culturally). Data preservation must be done by experts and dedicated services. Preservation of digital information requires planning, policies, resources (time, funds, people) as well as the right technology to ensure that the data stays functional and that it can be accessed (see ISO Standards for quality, preservation and integrity of information).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"preserving.md",
            "language":"en",
            "frontmatter":{
                "title":"Preserving",
                "page_id":"preserve",
                "description":"Introduction to data preservation.",
                "contributors":[
                    "Siiri Fuchs",
                    "Korbinian Bsl",
                    "Anastasia Chasapi",
                    "Flora D'Anna"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "data_security",
                        "data_publication",
                        "metadata",
                        "storage",
                        "identifiers",
                        "licensing"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+preserve%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Specify a list of data sets you will be producing",
                        "uuid":"4e0c1edf-660c-4ebf-81f5-9fa959dead30"
                    },
                    {
                        "name":"Will this data set be published?",
                        "uuid":"a063da1c-aaea-4e18-85ec-f560d833f292"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_preserving_md_3",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/preserving.md",
        "file_name":"preserving.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":" that it can be accessed (see ISO Standards for quality, preservation and integrity of information). Hence, special long term data repositories should be used for digital preservation, where the data is actively maintained and information integrity is monitored. Therefore, it is best to consider different options. * Contact the IT department or the library or the data center of your institution. * Check if national services are available. * Choose trustworthy research data repositories or deposition databases, based on your data type. Repositories could be publicly accessible and allow you to also publish your data. When preparing data for preservation several requirements need to be fulfilled. * Do not include data that are temporary or mutable. * Ensure well described and self-explanatory documentation. * Include information about provenance. * Include sufficient licensing information. * Ensure that data is well organised. * Ensure that a consistent naming convention is used. * Use standard, open source, file formats instead of proprietary ones.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"preserving.md",
            "language":"en",
            "frontmatter":{
                "title":"Preserving",
                "page_id":"preserve",
                "description":"Introduction to data preservation.",
                "contributors":[
                    "Siiri Fuchs",
                    "Korbinian Bsl",
                    "Anastasia Chasapi",
                    "Flora D'Anna"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "data_security",
                        "data_publication",
                        "metadata",
                        "storage",
                        "identifiers",
                        "licensing"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+preserve%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Specify a list of data sets you will be producing",
                        "uuid":"4e0c1edf-660c-4ebf-81f5-9fa959dead30"
                    },
                    {
                        "name":"Will this data set be published?",
                        "uuid":"a063da1c-aaea-4e18-85ec-f560d833f292"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_preserving_md_4",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/preserving.md",
        "file_name":"preserving.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"nt naming convention is used. * Use standard, open source, file formats instead of proprietary ones. If you need to preserve non-digital data (e.g. paper), consider whether digitalising the data is feasible or consult with data management support services in your institution. If you need to preserve materials, such as micro-organisms, biomaterials or biomolecules, consult with data management support services in your institution to find appropriate centers or biobanks.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"preserving.md",
            "language":"en",
            "frontmatter":{
                "title":"Preserving",
                "page_id":"preserve",
                "description":"Introduction to data preservation.",
                "contributors":[
                    "Siiri Fuchs",
                    "Korbinian Bsl",
                    "Anastasia Chasapi",
                    "Flora D'Anna"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "data_security",
                        "data_publication",
                        "metadata",
                        "storage",
                        "identifiers",
                        "licensing"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+preserve%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Specify a list of data sets you will be producing",
                        "uuid":"4e0c1edf-660c-4ebf-81f5-9fa959dead30"
                    },
                    {
                        "name":"Will this data set be published?",
                        "uuid":"a063da1c-aaea-4e18-85ec-f560d833f292"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_processing_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/data_life_cycle\/processing.md",
        "file_name":"processing.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Rob Hooft\n- Munazah Andrabi\ndescription: Introduction to data processing. dsw:\n- name: List the data formats you will be using for interpretation and describe their\n    structure\n  uuid: a797cab9-0829-4787-a096-1b5cedc9147f\n- name: How will you work with your data?\n  uuid: df36fb68-131c-4f31-a42b-684abf523bbc\npage_id: process\nrelated_pages:\n  your_tasks:\n  - data_analysis\n  - data_organisation\n  - data_quality\n  - data_provenance\ntitle: Processing\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+process%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"processing.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_processing_md_0",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/processing.md",
        "file_name":"processing.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"What is data processing? Data processing is the phase in the project where data is converted into a desired format and prepared for analysis. When data has been freshly collected, data processing includes some automated steps in a workflow that perform format conversion, quality check and preprocessing following a standardised protocol. The main aim of processing is to:\n * convert data into readable format giving it the shape and form necessary for downstream analysis;\n * discard bad or low quality data in order to create clean, high-quality dataset for reliable results. When data is imported from existing sources, e.g. data to be reused from another project, processing can also include manual steps to make it suitable for analysis.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"processing.md",
            "language":"en",
            "frontmatter":{
                "title":"Processing",
                "page_id":"process",
                "description":"Introduction to data processing.",
                "contributors":[
                    "Rob Hooft",
                    "Munazah Andrabi"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "data_quality",
                        "data_provenance"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+process%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_processing_md_1",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/processing.md",
        "file_name":"processing.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"sed from another project, processing can also include manual steps to make it suitable for analysis. These steps include but are not limited to:\n * making changes to data formats such that different datasets will be compatible for integration with each other;\n * changing coding systems or ontologies for the data to bring everything to the same level;\n * filtering data such that only data suitable for the project is retained. After data processing, clean data is ready for analysis and should therefore be available to the members of the project team that need to perform the next steps. Why is data processing important?\nData processing is important to ensure good quality of the collected data and to prepare it for meaningful data analysis. Accurate data processing is also essential for combining two or more datasets into a single dataset. An accurate documentation of every step done during data processing is key for the reproducibility of your result. Processing data correctly makes it easy to arrange, analyse and also saves a lot of space. What should be considered for data processing?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"processing.md",
            "language":"en",
            "frontmatter":{
                "title":"Processing",
                "page_id":"process",
                "description":"Introduction to data processing.",
                "contributors":[
                    "Rob Hooft",
                    "Munazah Andrabi"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "data_quality",
                        "data_provenance"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+process%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_processing_md_2",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/processing.md",
        "file_name":"processing.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"sy to arrange, analyse and also saves a lot of space. What should be considered for data processing? The following considerations are important for data processing:\n\nsensitive data should be pseudonymised\/anonymised. Not only should you remove the directly identifying data, but also be attentive to other sources e.g. names written on images;\nappropriate standards for encoding different data fields should be used;\nall steps of encoding and anonymisation should be properly documented. E.g. consider recording:\nencoding formats used for data fields;\nsignificance of empty fields and meaning of any special value;\nall relationships between data fields (e.g. if a dataset contains \"medication\" and \"disease\", is that medication actually used to treat the disease? Or is it a medication that the patient is using for other reasons?).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"processing.md",
            "language":"en",
            "frontmatter":{
                "title":"Processing",
                "page_id":"process",
                "description":"Introduction to data processing.",
                "contributors":[
                    "Rob Hooft",
                    "Munazah Andrabi"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "data_quality",
                        "data_provenance"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+process%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_sharing_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Flora D'Anna\n- Bert Droesbeke\n- Niclas Jareborg\n- Ulrike Wittig\ndescription: Introduction to data sharing. dsw:\n- name: When will the data set be published?\n  uuid: 5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6\n- name: Is there a collaboration agreement in the project that describes who can have\n    access to what data?\n  uuid: a5dbea23-b7d6-4e31-a1a5-ec5007ec7848\npage_id: share\nrelated_pages:\n  your_tasks:\n  - gdpr_compliance\n  - data_security\n  - data_brokering\n  - data_publication\n  - transfer\n  - identifiers\n  - licensing\n  - metadata\n  - sensitive\ntitle: Sharing\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"sharing.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_sharing_md_0",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":0,
        "total_chunks":8,
        "content":"What is data sharing? Sharing data means making your data known to other people. You can share your data with collaboration partners in the context of a collaborative research project, or you can publish your data to share it with the global research community and society at large. Its important to know that data sharing doesnt mean open data or public data. You can choose to share your data with restricted access or even closed access. Moreover, sharing or publishing data is different from publishing a paper or a manuscript in a journal. Here we focused on data (i.e. raw observations and measurements, analysis workflows, code, etc.), not on papers or articles. Data sharing can be done at any time during the research data life cycle but, at the latest, data should be made available at the time of publication of articles that use the data to make scientific conclusions. Why is data sharing important?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"sharing.md",
            "language":"en",
            "frontmatter":{
                "title":"Sharing",
                "page_id":"share",
                "description":"Introduction to data sharing.",
                "contributors":[
                    "Flora D'Anna",
                    "Bert Droesbeke",
                    "Niclas Jareborg",
                    "Ulrike Wittig"
                ],
                "related_pages":{
                    "your_tasks":[
                        "gdpr_compliance",
                        "data_security",
                        "data_brokering",
                        "data_publication",
                        "transfer",
                        "identifiers",
                        "licensing",
                        "metadata",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"When will the data set be published?",
                        "uuid":"5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6"
                    },
                    {
                        "name":"Is there a collaboration agreement in the project that describes who can have access to what data?",
                        "uuid":"a5dbea23-b7d6-4e31-a1a5-ec5007ec7848"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_sharing_md_1",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":1,
        "total_chunks":8,
        "content":"ication of articles that use the data to make scientific conclusions. Why is data sharing important? In a collaborative project, being able to easily share data makes research more efficient. Sharing of data is a cornerstone of good science. It is a good research practice to ensure that data underlying research is preserved and made available to the research community and society at large. Sharing data is a prerequisite for making your research reproducible. To be useful for others, you should strive to make the shared data adhere to the FAIR principles. In the European Union, the 'Open Data Directive' (Directive (EU) 2019\/1024) states that \"Member States shall support the availability of research data by adopting national policies and relevant actions aiming at making publicly funded research data openly available (open access policies), following the principle of open by default and compatible with the FAIR principles.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"sharing.md",
            "language":"en",
            "frontmatter":{
                "title":"Sharing",
                "page_id":"share",
                "description":"Introduction to data sharing.",
                "contributors":[
                    "Flora D'Anna",
                    "Bert Droesbeke",
                    "Niclas Jareborg",
                    "Ulrike Wittig"
                ],
                "related_pages":{
                    "your_tasks":[
                        "gdpr_compliance",
                        "data_security",
                        "data_brokering",
                        "data_publication",
                        "transfer",
                        "identifiers",
                        "licensing",
                        "metadata",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"When will the data set be published?",
                        "uuid":"5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6"
                    },
                    {
                        "name":"Is there a collaboration agreement in the project that describes who can have access to what data?",
                        "uuid":"a5dbea23-b7d6-4e31-a1a5-ec5007ec7848"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_sharing_md_2",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":2,
        "total_chunks":8,
        "content":"ss policies), following the principle of open by default and compatible with the FAIR principles. \"\nMany research funders, institutions and reputable journals\/publishers now have data sharing mandates, from which you normally cannot opt out of unless there are legitimate reasons (ethical or legal reasons). There are additional reasons to share your datasets. * Ten reasons to share your data. * Ask not what you can do for open data; ask what open data can do for you. Even though it may not be possible to openly share all data because of ethical, legal, contractual, or intellectual property reasons, do strive to make data \"as open as possible, as closed as necessary\" as advised in The European Code of Conduct for\nResearch Integrity. Making the data as FAIR as possible will ensure that maximum value can be obtained out of it in future. What should be considered for data sharing? If you are part of a collaborative research project, it is recommended to plan and establish the following in advance. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"sharing.md",
            "language":"en",
            "frontmatter":{
                "title":"Sharing",
                "page_id":"share",
                "description":"Introduction to data sharing.",
                "contributors":[
                    "Flora D'Anna",
                    "Bert Droesbeke",
                    "Niclas Jareborg",
                    "Ulrike Wittig"
                ],
                "related_pages":{
                    "your_tasks":[
                        "gdpr_compliance",
                        "data_security",
                        "data_brokering",
                        "data_publication",
                        "transfer",
                        "identifiers",
                        "licensing",
                        "metadata",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"When will the data set be published?",
                        "uuid":"5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6"
                    },
                    {
                        "name":"Is there a collaboration agreement in the project that describes who can have access to what data?",
                        "uuid":"a5dbea23-b7d6-4e31-a1a5-ec5007ec7848"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_sharing_md_3",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":3,
        "total_chunks":8,
        "content":" collaborative research project, it is recommended to plan and establish the following in advance. * The use of repositories and sharing services that allow controlled access to share your preliminary data with project partners. * The use of storage solutions that guarantee shared, controlled and secure access to the data and appropriate data transfer. * The deposition of your data to a public repository as early as possible. This saves a lot of trouble later on. Data can be put under embargo until you want to release it, e.g. at the time of article publication. * The use of common data organisation, data formats, standards, data documentation and metadata.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"sharing.md",
            "language":"en",
            "frontmatter":{
                "title":"Sharing",
                "page_id":"share",
                "description":"Introduction to data sharing.",
                "contributors":[
                    "Flora D'Anna",
                    "Bert Droesbeke",
                    "Niclas Jareborg",
                    "Ulrike Wittig"
                ],
                "related_pages":{
                    "your_tasks":[
                        "gdpr_compliance",
                        "data_security",
                        "data_brokering",
                        "data_publication",
                        "transfer",
                        "identifiers",
                        "licensing",
                        "metadata",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"When will the data set be published?",
                        "uuid":"5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6"
                    },
                    {
                        "name":"Is there a collaboration agreement in the project that describes who can have access to what data?",
                        "uuid":"a5dbea23-b7d6-4e31-a1a5-ec5007ec7848"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_sharing_md_4",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":4,
        "total_chunks":8,
        "content":"on. * The use of common data organisation, data formats, standards, data documentation and metadata. If you want to share or publish your data, you should:\n  * make sure you have the rights to do so (i.e., are you the creator of the data?);\n  * consider all possible ethical, legal, contractual, or intellectual property restrictions related to your data (GDPR, consent, patent, etc.);\n  * check funders and institutional requirements about data sharing policy and data availability;\n  * establish if you need to limit reusability of your data for legitimate reasons (consider applying a specific licence);\n  * make the data citable so that you can receive credit (use identifiers). Based on the considerations listed above, you should be able to determine the right type of access for you data. Even if the access to the data is restricted, it is good practice to openly and publicly share the metadata of your data. * Open access: data is shared publicly. Anyone can access the data freely.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"sharing.md",
            "language":"en",
            "frontmatter":{
                "title":"Sharing",
                "page_id":"share",
                "description":"Introduction to data sharing.",
                "contributors":[
                    "Flora D'Anna",
                    "Bert Droesbeke",
                    "Niclas Jareborg",
                    "Ulrike Wittig"
                ],
                "related_pages":{
                    "your_tasks":[
                        "gdpr_compliance",
                        "data_security",
                        "data_brokering",
                        "data_publication",
                        "transfer",
                        "identifiers",
                        "licensing",
                        "metadata",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"When will the data set be published?",
                        "uuid":"5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6"
                    },
                    {
                        "name":"Is there a collaboration agreement in the project that describes who can have access to what data?",
                        "uuid":"a5dbea23-b7d6-4e31-a1a5-ec5007ec7848"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_sharing_md_5",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":5,
        "total_chunks":8,
        "content":"he metadata of your data. * Open access: data is shared publicly. Anyone can access the data freely. * Registered access or authentication procedure: potential users must register before they are able to access the data. The researcher status is guaranteed by the institution and the user agrees to abide by data usage policies of repositories that serve the shared data. Datasets shared via registered-access would typically have no restrictions besides the condition that data is to be used for research. Registered access allows the data archive to monitor who can access data, enabling reminders about conditions of use to be issued. * Controlled access or Data Access Committees (DACs): data can only be shared with researchers, whose research is reviewed and approved by a Data Access Committee (DAC). DAC is an organization of one or more named individuals responsible for data release to external requestors based on specific criteria (research topics, allowed geographical regions, allowed recipients, etc.).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"sharing.md",
            "language":"en",
            "frontmatter":{
                "title":"Sharing",
                "page_id":"share",
                "description":"Introduction to data sharing.",
                "contributors":[
                    "Flora D'Anna",
                    "Bert Droesbeke",
                    "Niclas Jareborg",
                    "Ulrike Wittig"
                ],
                "related_pages":{
                    "your_tasks":[
                        "gdpr_compliance",
                        "data_security",
                        "data_brokering",
                        "data_publication",
                        "transfer",
                        "identifiers",
                        "licensing",
                        "metadata",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"When will the data set be published?",
                        "uuid":"5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6"
                    },
                    {
                        "name":"Is there a collaboration agreement in the project that describes who can have access to what data?",
                        "uuid":"a5dbea23-b7d6-4e31-a1a5-ec5007ec7848"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_sharing_md_6",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":6,
        "total_chunks":8,
        "content":"ased on specific criteria (research topics, allowed geographical regions, allowed recipients, etc.). Criteria established by DAC for data access are usually described on the website of the organization. * Access upon request (not recommended): in order to manage this type of access a named contact is required for the dataset who would be responsible for making decisions about whether access is granted. The owner of the data must provide his\/her contact in the documentation associated with the datasets (metadata). Metadata about the datasets must be open. Share and publish your data in professional deposition databases that provide the appropriate access type and licence. * If there are discipline-specific repositories available for you data, this should be your primary choice. They will work towards a high level of FAIRness by recommending appropriate community standards for describing the data. * If there are no suitable discipline-specific repositories for your data consider other options. * Deposit the data in an Institutional repository, if there is one.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"sharing.md",
            "language":"en",
            "frontmatter":{
                "title":"Sharing",
                "page_id":"share",
                "description":"Introduction to data sharing.",
                "contributors":[
                    "Flora D'Anna",
                    "Bert Droesbeke",
                    "Niclas Jareborg",
                    "Ulrike Wittig"
                ],
                "related_pages":{
                    "your_tasks":[
                        "gdpr_compliance",
                        "data_security",
                        "data_brokering",
                        "data_publication",
                        "transfer",
                        "identifiers",
                        "licensing",
                        "metadata",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"When will the data set be published?",
                        "uuid":"5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6"
                    },
                    {
                        "name":"Is there a collaboration agreement in the project that describes who can have access to what data?",
                        "uuid":"a5dbea23-b7d6-4e31-a1a5-ec5007ec7848"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_sharing_md_7",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/sharing.md",
        "file_name":"sharing.md",
        "chunk_index":7,
        "total_chunks":8,
        "content":"our data consider other options. * Deposit the data in an Institutional repository, if there is one. These often provide stewardship and curation, helping to ensure that your dataset is preserved and accessible. Contact the Research Data Office function at your institution, if there is one. * Deposit the data in a General purpose repository. * If there isn't any suitable repository that can harbour your controlled access data, it is recommended that you at least create a metadata record for the data in an Institutional or General purpose repository.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"sharing.md",
            "language":"en",
            "frontmatter":{
                "title":"Sharing",
                "page_id":"share",
                "description":"Introduction to data sharing.",
                "contributors":[
                    "Flora D'Anna",
                    "Bert Droesbeke",
                    "Niclas Jareborg",
                    "Ulrike Wittig"
                ],
                "related_pages":{
                    "your_tasks":[
                        "gdpr_compliance",
                        "data_security",
                        "data_brokering",
                        "data_publication",
                        "transfer",
                        "identifiers",
                        "licensing",
                        "metadata",
                        "sensitive"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+share%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"When will the data set be published?",
                        "uuid":"5f5cc5b6-a17c-4cf5-b6fc-ecfd655c0fe6"
                    },
                    {
                        "name":"Is there a collaboration agreement in the project that describes who can have access to what data?",
                        "uuid":"a5dbea23-b7d6-4e31-a1a5-ec5007ec7848"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_analysing_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/data_life_cycle\/analysing.md",
        "file_name":"analysing.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Rob Hooft\n- Olivier Collin\n- Munazah Andrabi\n- Flora D'Anna\ndescription: Introduction to data analysis. page_id: analyse\nrelated_pages:\n  your_tasks:\n  - data_analysis\n  - data_organisation\n  - storage\n  - data_provenance\ntitle: Analysing\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"analysing.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_analysing_md_0",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/analysing.md",
        "file_name":"analysing.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"What is data analysis? Data analysis consists in exploring the collected data to begin understanding the messages contained in a dataset and\/or in applying mathematical formula (or models) to identify relationships between variables. The steps of the workflow in the analysis phase will often be repeated several times to explore the data as well as to optimize the workflow itself. According to the different types of data (quantitative or qualitative) the data analysis methods will differ. Data analysis follows the (often automated, batch) data processing stage. Why is data analysis important?\nSince data analysis is the stage where new knowledge and information are generated, it can be considered as central in the research process. Because of the relevance of the data analysis stage in research findings, it is essential that the analysis workflow applied to a dataset complies with the FAIR principles.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"analysing.md",
            "language":"en",
            "frontmatter":{
                "title":"Analysing",
                "page_id":"analyse",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "storage",
                        "data_provenance"
                    ]
                },
                "contributors":[
                    "Rob Hooft",
                    "Olivier Collin",
                    "Munazah Andrabi",
                    "Flora D'Anna"
                ],
                "description":"Introduction to data analysis.",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_analysing_md_1",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/analysing.md",
        "file_name":"analysing.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":", it is essential that the analysis workflow applied to a dataset complies with the FAIR principles. Moreover, it is extremely important that the analysis workflow is reproducible by other researchers and scientists. With many disciplines becoming data-oriented, more data intensive projects will arise which will require experts from dedicated fields. What should be considered for data analysis? Because of the diversity of domains and technologies in Life Sciences, data can be either \"small\" or \"big data\". As a consequence, the methods and technical solutions used for data analysis might differ. The characteristics of \"big data\" are often summarized by a growing list of \"V\" properties: Volume, Velocity, Variety, Variability, Veracity, Visualization and Value. The data analysis stage relies on the previous stages (collection, processing) that will lay the foundations for the generation of new knowledge by providing accurate and trustworthy data. The location of your data is important because of the need of proximity with computing resources.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"analysing.md",
            "language":"en",
            "frontmatter":{
                "title":"Analysing",
                "page_id":"analyse",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "storage",
                        "data_provenance"
                    ]
                },
                "contributors":[
                    "Rob Hooft",
                    "Olivier Collin",
                    "Munazah Andrabi",
                    "Flora D'Anna"
                ],
                "description":"Introduction to data analysis.",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_analysing_md_2",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/analysing.md",
        "file_name":"analysing.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"a. The location of your data is important because of the need of proximity with computing resources. This can impact data transfer across the different infrastructures. It is worthwhile to compare the cost of the transfer of massive amounts of data compared to the transfer of virtual images of machines for the analysis. For the analysis of data, you will first have to consider the computing environment and choose between several computing infrastructure types, e.g. cluster, cloud. You will also need to select the appropriate work environment according to your needs and expertise (command line, web portal). You will have to select the tools best suited for the analysis of your data. It is important to document the exact steps used for data analysis. This includes the version of the software used, as well as the parameters used, as well as the computing environment. Manual \"manipulation\" of the data may complicate this documentation process. In the case of collaborative data analysis, you will have to ensure access to the data and tools for all collaborators.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"analysing.md",
            "language":"en",
            "frontmatter":{
                "title":"Analysing",
                "page_id":"analyse",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "storage",
                        "data_provenance"
                    ]
                },
                "contributors":[
                    "Rob Hooft",
                    "Olivier Collin",
                    "Munazah Andrabi",
                    "Flora D'Anna"
                ],
                "description":"Introduction to data analysis.",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_analysing_md_3",
        "source":"markdown_content",
        "file_path":"pages\/data_life_cycle\/analysing.md",
        "file_name":"analysing.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"aborative data analysis, you will have to ensure access to the data and tools for all collaborators. This can be achieved by setting up virtual research environments. Consider publishing your analysis workflow according to the FAIR principles as well as your datasets.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"analysing.md",
            "language":"en",
            "frontmatter":{
                "title":"Analysing",
                "page_id":"analyse",
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "storage",
                        "data_provenance"
                    ]
                },
                "contributors":[
                    "Rob Hooft",
                    "Olivier Collin",
                    "Munazah Andrabi",
                    "Flora D'Anna"
                ],
                "description":"Introduction to data analysis.",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_steward_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_role\/data_steward.md",
        "file_name":"data_steward.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Mijke Jetten\n- Martin Cook\n- Siiri Fuchs\n- Ulrike Wittig\n- Daniel Wibberg\n- Helena Schnitzer\n- Xnia Prez Sitj\n- Nazeefa Fatima\n- Gregoire Rossier\n- Federico Bianchini\n- Erik Hjerde\n- Minna Ahokas\n- Priit Adler\n- Alexander Botzki\n- Robert Andrews\n- Celia van Gelder\n- Graham Hughes\n- Marko Vidak\n- Pedro Fernandes\n- Pinar Alper\n- Victoria Dominguez D. Angel\n- Wolmar Nyberg kerstrm\n- Alexia Cardona\ndescription: Data management guidance for data stewards.\npage_id: data_steward\nredirect_from:\n- data_steward_infrastructure\n- data_steward_policy\n- data_steward_research\ntitle: Data Steward",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_steward.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_steward_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/data_steward.md",
        "file_name":"data_steward.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"Introduction\nData stewardship is a relatively new profession and a catch-all term for numerous support functions, roles and activities. It implies professional and careful treatment of data throughout all stages of a research process. The core responsibilities and tasks vary, from policy advising and consultancy, to operational and technical support and IT related tasks. Responsibilities also vary between and among the different research-performing organisations, and data stewards (DS) often have different job titles.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_steward.md",
            "language":"en",
            "frontmatter":{
                "title":"Data Steward",
                "description":"Data management guidance for data stewards.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona"
                ],
                "page_id":"data_steward",
                "redirect_from":[
                    "data_steward_infrastructure",
                    "data_steward_policy",
                    "data_steward_research"
                ]
            }
        }
    },
    {
        "id":"md_content_data_steward_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/data_steward.md",
        "file_name":"data_steward.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"different research-performing organisations, and data stewards (DS) often have different job titles. Data stewards can be categorised in different ways, for example according to their \n\nplace in an organisation: coordinator or generic data stewards (hired in a central library, for example), and embedded data steward (working for a research department or project), or\non their topic focus: policy oriented, research oriented and infrastructure oriented.\\\n See Mijke Jetten, Marjan Grootveld, Annemie Mordant, Mascha Jansen, Margreet Bloemers, Margriet Miedema, & Celia W.G. van Gelder. (2021). Professionalising data stewardship in the Netherlands. Competences, training and education. Dutch roadmap towards national implementation of FAIR data stewardship. Zenodo. https:\/\/doi.org\/10.5281\/zenodo.4623713. See also https:\/\/competency.ebi.ac.uk\/framework\/datasteward\/1.0 \n. Role\nDescription\n\n\n\n\nCoordinator \/ generic DS\nActs as a centralised knowledge hub and is able to advise on organisational policies, guidelines, infrastructure and tools. They may coordinate embedded data stewards.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_steward.md",
            "language":"en",
            "frontmatter":{
                "title":"Data Steward",
                "description":"Data management guidance for data stewards.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona"
                ],
                "page_id":"data_steward",
                "redirect_from":[
                    "data_steward_infrastructure",
                    "data_steward_policy",
                    "data_steward_research"
                ]
            }
        }
    },
    {
        "id":"md_content_data_steward_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/data_steward.md",
        "file_name":"data_steward.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"sational policies, guidelines, infrastructure and tools. They may coordinate embedded data stewards. Embedded DS\nWorks directly for research departments or research teams and offers support and hands on help with any RDM matter from collection of data to publishing and long-term preservation. Policy-oriented DS\nFocuses on policy development and the implementation of research data management practices in their organisation. They may coordinate other data stewards in their institutions. Research-oriented DS\nWorks directly with researchers and offers support with RDM matters. They make sure data is handled in compliance with the institutes policy and they can also perform hands-on work in a project. Infrastructure-oriented DS\nTranslates the requirements of policies and science into suitable IT solutions and tools as well as provide advice. They implement IT infrastructure solutions, give access to data and software for researchers. Data management responsibilities\nAs a data steward, you are supporting researchers in data handling before, during and after a research project.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_steward.md",
            "language":"en",
            "frontmatter":{
                "title":"Data Steward",
                "description":"Data management guidance for data stewards.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona"
                ],
                "page_id":"data_steward",
                "redirect_from":[
                    "data_steward_infrastructure",
                    "data_steward_policy",
                    "data_steward_research"
                ]
            }
        }
    },
    {
        "id":"md_content_data_steward_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/data_steward.md",
        "file_name":"data_steward.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"nsiderations to be taken into account and solutions used by the community to address the challenges. You will also find training material and links to relevant tools and resources. Your task pages are organised around regular RDM tasks and challenges. You will find best practices, guidelines, training material as well as links to tools and resources. The National resources pages point to country-specific information resources such as local funding agencies and research councils, and information on local policies for open science, national regulations on data ethics, and domain-specific infrastructures and tools. Other resources\n\nFAIR Cookbook gives you step by step recipes to complete common data management tasks. Data Stewardship Wizard (DSW) guides you through creating a data management plan. FAIRification Framework guides you through making your data FAIR. TeSS is a life science training portal, where you can search for training courses or materials on data management. FAIRsharing is a portal where you can search for databases, standards and policies.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_steward.md",
            "language":"en",
            "frontmatter":{
                "title":"Data Steward",
                "description":"Data management guidance for data stewards.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona"
                ],
                "page_id":"data_steward",
                "redirect_from":[
                    "data_steward_infrastructure",
                    "data_steward_policy",
                    "data_steward_research"
                ]
            }
        }
    },
    {
        "id":"md_fm_research_software_engineer_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_role\/research_software_engineer.md",
        "file_name":"research_software_engineer.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Mijke Jetten\n- Martin Cook\n- Siiri Fuchs\n- Ulrike Wittig\n- Daniel Wibberg\n- Helena Schnitzer\n- Xnia Prez Sitj\n- Nazeefa Fatima\n- Gregoire Rossier\n- Federico Bianchini\n- Erik Hjerde\n- Minna Ahokas\n- Priit Adler\n- Alexander Botzki\n- Robert Andrews\n- Celia van Gelder\n- Graham Hughes\n- Marko Vidak\n- Pedro Fernandes\n- Pinar Alper\n- Victoria Dominguez D. Angel\n- Wolmar Nyberg kerstrm\n- Alexia Cardona\ndescription: Data management guidance for Research Software Engineers (RSEs).\npage_id: research_software_engineer\ntitle: Research Software Engineer (RSE)",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"research_software_engineer.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_research_software_engineer_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/research_software_engineer.md",
        "file_name":"research_software_engineer.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"Introduction\nResearch software engineers (RSE) in the life sciences design, develop and maintain software systems that help researchers manage their software and data. The RSEs software tools and infrastructure are critical in enabling scientific research to be conducted effectively. In this role, it is essential that you implement software systems that meet the needs and requirements of researchers. Software needs to be reliable, scalable, secure, well-documented, and easy to use. You often work in research-intensive environments such as universities, research institutions, or government agencies. Collaboration with researchers, data scientists, data managers, and IT professionals is vital. Data management responsibilities\nAs a research software engineer, your focus is on the liaison between researchers and people involved in IT infrastructure and services. You are responsible for the implementation of IT infrastructure solutions and the access to data and software.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"research_software_engineer.md",
            "language":"en",
            "frontmatter":{
                "title":"Research Software Engineer (RSE)",
                "description":"Data management guidance for Research Software Engineers (RSEs).",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona"
                ],
                "page_id":"research_software_engineer"
            }
        }
    },
    {
        "id":"md_content_research_software_engineer_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/research_software_engineer.md",
        "file_name":"research_software_engineer.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"sponsible for the implementation of IT infrastructure solutions and the access to data and software. In your role of research software engineer, you may need to:\n\nIdentify the requirements of and provide access to data infrastructure and tool landscape for researchers according to the research data management policies;\nAdvise and assist researchers on short and long term actions for data infrastructure and tools including (meta)data standards;\nEnsure the compliance of the data infrastructure and tool landscape with codes of conduct and regulations;\nAlign the data infrastructure and tool landscape to the FAIR data principles and the principles of Open Science, and facilitate and support FAIR data;\nAlign the data infrastructure and tools management inside and outside the organisation, in close collaboration with the IT department;\nFacilitate the availability of local data-infrastructure and tools for FAIR and long term archiving of data. Data management guidance\nRDMkit pages\n\nThe data organisation page helps with file naming, versioning and folder structures.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"research_software_engineer.md",
            "language":"en",
            "frontmatter":{
                "title":"Research Software Engineer (RSE)",
                "description":"Data management guidance for Research Software Engineers (RSEs).",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona"
                ],
                "page_id":"research_software_engineer"
            }
        }
    },
    {
        "id":"md_content_research_software_engineer_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/research_software_engineer.md",
        "file_name":"research_software_engineer.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"e\nRDMkit pages\n\nThe data organisation page helps with file naming, versioning and folder structures. Data documentation, such as README files and metadata, helps to make data understandable and reusable. The identifiers page gives advice on how to create and use identifiers. Machine actionability helps to automatically access and process research data. Consider the best practices and technical solutions for data analysis. Data protection helps you to make research data GDPR-compliant. Data sensitivity helps you to identify sensitivity of different research data types. Licensing gives advice on how to assign a licence to research data. Consult the data transfer page for information about transferring large data files. The data brokering page provides information on uploading data to repositories and metadata requirements for the process. The data storage page helps to consider short and long-term storage, during and at the end of a project. Other resources\n\nFAIR Principles gives an overview of how to make data Findable, Accessible, Interoperable and Reusable (FAIR).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"research_software_engineer.md",
            "language":"en",
            "frontmatter":{
                "title":"Research Software Engineer (RSE)",
                "description":"Data management guidance for Research Software Engineers (RSEs).",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona"
                ],
                "page_id":"research_software_engineer"
            }
        }
    },
    {
        "id":"md_content_research_software_engineer_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/research_software_engineer.md",
        "file_name":"research_software_engineer.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"iples gives an overview of how to make data Findable, Accessible, Interoperable and Reusable (FAIR). FAIR Cookbook gives step by step recipes for common data management tasks, including levels and indicators of FAIRness, technologies, tools and the standards available. FAIRsharing is a portal where you can search for databases, standards and policies. Learn from experts in the field in the RDNL & DCC Delivery RDM Services course. Software Carpentry helps set up training in basic lab skills for research computing. ELN Guide is a useful resource on Electronic Laboratory Notebooks (ELN).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"research_software_engineer.md",
            "language":"en",
            "frontmatter":{
                "title":"Research Software Engineer (RSE)",
                "description":"Data management guidance for Research Software Engineers (RSEs).",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona"
                ],
                "page_id":"research_software_engineer"
            }
        }
    },
    {
        "id":"md_fm_researcher_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_role\/researcher.md",
        "file_name":"researcher.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Mijke Jetten\n- Martin Cook\n- Siiri Fuchs\n- Ulrike Wittig\n- Daniel Wibberg\n- Helena Schnitzer\n- Xnia Prez Sitj\n- Nazeefa Fatima\n- Gregoire Rossier\n- Federico Bianchini\n- Erik Hjerde\n- Siiri Fuchs\n- Minna Ahokas\n- Priit Adler\n- Alexander Botzki\n- Robert Andrews\n- Celia van Gelder\n- Graham Hughes\n- Marko Vidak\n- Pedro Fernandes\n- Pinar Alper\n- Victoria Dominguez D. Angel\n- Wolmar Nyberg kerstrm\n- Alexia Cardona\n- Munazah Andrabi\ndescription: Data management guidance for researchers, including how to make your\n  data FAIR. page_id: researcher\ntitle: Researcher",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"researcher.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_researcher_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/researcher.md",
        "file_name":"researcher.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\nYour research data is a major output from your research project, it supports your research conclusions, and guides yourself and others towards future research. Therefore, managing the data well throughout the project, and sharing it, is a crucial aspect of research. Data management responsibilities\nData management includes actions throughout all stages of the research process. In your role of researcher, you may need to:\n\nWrite a data management plan;\nEstimate the costs of data management for a grant application;\nEnsure your data complies with ethical, policy and legal requirements;\nStore your data securely, in a resource that is sustained and accessible; Use metadata standards and documentation methods for your data; Get training about data management, including the use of data management tools and data archives. Data management guidance\nRDMkit pages\n\nThe RDM life cycle pages give an overview of how to approach data management tasks.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"researcher.md",
            "language":"en",
            "frontmatter":{
                "title":"Researcher",
                "description":"Data management guidance for researchers, including how to make your data FAIR.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona",
                    "Munazah Andrabi"
                ],
                "page_id":"researcher"
            }
        }
    },
    {
        "id":"md_content_researcher_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/researcher.md",
        "file_name":"researcher.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ce\nRDMkit pages\n\nThe RDM life cycle pages give an overview of how to approach data management tasks. Data management plan guides you through writing a data management plan. Costs of data management helps you budget for your project. Compliance helps you comply with the institution policy, including the legal and ethical aspects. National resources give country-specific guidance and resources. Documentation and metadata helps you document data and choose the appropriate metadata standards. Data publication guides to find a data repository for your needs. Other resources\n\nContact the data steward in your local organisation or your national contact in the ELIXIR network. Your institution may have web pages about RDM and support services available. They may also give you in-person advice and provide training. The Turing Way handbook to reproducible, ethical and collaborative data science offers guidance to researchers in academia, industry and the public sector. FAIR Cookbook gives step by step recipes to complete common data management tasks.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"researcher.md",
            "language":"en",
            "frontmatter":{
                "title":"Researcher",
                "description":"Data management guidance for researchers, including how to make your data FAIR.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona",
                    "Munazah Andrabi"
                ],
                "page_id":"researcher"
            }
        }
    },
    {
        "id":"md_content_researcher_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/researcher.md",
        "file_name":"researcher.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"he public sector. FAIR Cookbook gives step by step recipes to complete common data management tasks. Data Stewardship Wizard (DSW) guides through creating a data management plan. FAIRification Framework guides through making your data FAIR. TeSS is a life science training portal, where you can search for training courses or materials on data management. FAIRsharing is a portal where you can search for databases, standards and policies. FAIR Principles gives an overview of how to make your data Findable, Accessible, Interoperable and Reusable (FAIR). 23 Things provides links to a range of useful resources on data management.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"researcher.md",
            "language":"en",
            "frontmatter":{
                "title":"Researcher",
                "description":"Data management guidance for researchers, including how to make your data FAIR.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier",
                    "Federico Bianchini",
                    "Erik Hjerde",
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona",
                    "Munazah Andrabi"
                ],
                "page_id":"researcher"
            }
        }
    },
    {
        "id":"md_fm_trainer_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_role\/trainer.md",
        "file_name":"trainer.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Mijke Jetten\n- Martin Cook\n- Siiri Fuchs\n- Ulrike Wittig\n- Daniel Wibberg\n- Helena Schnitzer\n- Xnia Prez Sitj\n- Nazeefa Fatima\n- Gregoire Rossier\ndescription: Data management guidance for trainers.\npage_id: trainer\ntitle: Trainer",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"trainer.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_trainer_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/trainer.md",
        "file_name":"trainer.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"Introduction\nAs a trainer, you design and deliver training courses in research data management with a focus on bioinformatics data. Your audience is mainly people in biomedical sciences: PhD students, postdocs, researchers, technicians and PIs. Your role is to emphasise the importance of applying best practices in Research Data Management, including FAIR principles, and also to provide researchers with the skills necessary to put these principles into practice throughout their projects. In addition to the usual abilities required for a trainer (communication, pedagogy, problem-solving), flexibility is key as you have to deal with an audience of several domains, skills and levels of involvement. Data management responsibilities\nAs a trainer you are responsible for encouraging and guiding researchers and scientists in effectively managing their data throughout the entire research lifecycle.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"trainer.md",
            "language":"en",
            "frontmatter":{
                "title":"Trainer",
                "description":"Data management guidance for trainers.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier"
                ],
                "page_id":"trainer"
            }
        }
    },
    {
        "id":"md_content_trainer_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/trainer.md",
        "file_name":"trainer.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"earchers and scientists in effectively managing their data throughout the entire research lifecycle. You play a critical role in assisting individuals and organisations in improving their data management skills and achieving their research goals. In your role of trainer maker, you may need to:\n\nCollaborate with Data Managers to determine precise training needs and establish a tailored schedule for training sessions. Design effective training programs to ensure the delivered training empower participants with actionable skills and knowledge. Develop educational material, such as slide decks, training manuals, and online resources. These materials should be clear and concise, enabling the trainees to understand and implement effective data management strategies. Make sure that the training material is as FAIR and open as possible. Provide comprehensive training sessions, interactive workshops, and webinars to educate researchers on data management best practices, policies, and guidelines.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"trainer.md",
            "language":"en",
            "frontmatter":{
                "title":"Trainer",
                "description":"Data management guidance for trainers.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier"
                ],
                "page_id":"trainer"
            }
        }
    },
    {
        "id":"md_content_trainer_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/trainer.md",
        "file_name":"trainer.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"ps, and webinars to educate researchers on data management best practices, policies, and guidelines. This involves explaining the importance of data management, introducing relevant resources and tools, and providing hands-on training on data management. Implement a feedback system (e.g. surveys) to enhance the quality and impact of your training programs, and to improve learning outcomes and the training effectiveness. Data management guidance\nRDMkit pages\n\nYour task pages are organised around regular RDM tasks and challenges. You will find best practices, guidelines and training materials. The National resources pages provide country-specific guidance, to help you choose the best services, tools and pipelines to manage your data. Furthermore, it links to national training pages in TeSS. You can find an overview of all training recourses on the All training resources pages.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"trainer.md",
            "language":"en",
            "frontmatter":{
                "title":"Trainer",
                "description":"Data management guidance for trainers.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier"
                ],
                "page_id":"trainer"
            }
        }
    },
    {
        "id":"md_content_trainer_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/trainer.md",
        "file_name":"trainer.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"ges in TeSS. You can find an overview of all training recourses on the All training resources pages. Other resources\n\nTeSS is a life science training portal, where you can search for training courses or materials on data management\nFAIR guiding principles gives an overview of how to make your data Findable, Accessible, Interoperable and Reusable (FAIR). The Train-the-Trainer program relies in the development of new Train-the-Trainer (TtT) courses and materials with the aim to give new instructors tools and tips for providing and enriching learning experiences to trainees and to include best-practice guidance on course and training material development\nData Stewardship Wizard (DSW) guides you through creating a data management plan. Mantra Research Data Management Training is a free, online course with guidelines to help understanding and reflecting on how to manage the digital data collected throughout your research.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"trainer.md",
            "language":"en",
            "frontmatter":{
                "title":"Trainer",
                "description":"Data management guidance for trainers.",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier"
                ],
                "page_id":"trainer"
            }
        }
    },
    {
        "id":"md_fm_principal_investigator_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_role\/principal_investigator.md",
        "file_name":"principal_investigator.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Mijke Jetten\n- Martin Cook\n- Siiri Fuchs\n- Ulrike Wittig\n- Daniel Wibberg\n- Helena Schnitzer\n- Xnia Prez Sitj\n- Nazeefa Fatima\n- Gregoire Rossier\ndescription: Data management guidance for Principal Investigator (PI). page_id: principal_investigator\ntitle: Principal Investigator (PI)",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"principal_investigator.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_principal_investigator_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/principal_investigator.md",
        "file_name":"principal_investigator.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"Introduction\nAs a Principal Investigator (PI), you may have recently acquired project funding. More and more funders require data management plans (DMP), stimulating the researcher to consider, from the beginning of a project, all relevant aspects of data management. Funders often refer to the FAIR principles. Applying these principles to your research data would greatly ease reusing and repurposing of data, either by you or others, and enable automation of processes. Data management responsibilities\nYour data reflects objective research, generating independent, high quality and reproducible results. Managing, monitoring and ensuring data integrity in collaborative research projects is thus an essential aspect of research. In your role of PI, you may need to:\n\nDefine your projects data management strategy, plan resources and budget, via a data management plan submitted to the funder. Define data responsibilities and roles, to create awareness and collaboration in your team.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"principal_investigator.md",
            "language":"en",
            "frontmatter":{
                "title":"Principal Investigator (PI)",
                "description":"Data management guidance for Principal Investigator (PI).",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier"
                ],
                "page_id":"principal_investigator"
            }
        }
    },
    {
        "id":"md_content_principal_investigator_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/principal_investigator.md",
        "file_name":"principal_investigator.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":" funder. Define data responsibilities and roles, to create awareness and collaboration in your team. Anticipate the ethical and legal aspects of your project in an early stage, like protecting human data against unauthorised access. Consider a common work environment and lab notebook, to limit the risk of information loss and unauthorised access, and start creating metadata from the beginning of a project. Ensure maximum reproducibility, such as data organisation, data documentation and providing workflows and code. Share data as it allows others to build upon your work, enables meta-analysis, increases visibility as it is a requirement for grant funding. Data management guidance\nRDMkit pages\n\nAt the heart of FAIR science lies good data management practice. The RDM life cycle pages guide you in complying with the FAIR requirements of funders. A DMP should address a broad range of data management aspects, so it is important to be aware of the current best practices in DMPs.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"principal_investigator.md",
            "language":"en",
            "frontmatter":{
                "title":"Principal Investigator (PI)",
                "description":"Data management guidance for Principal Investigator (PI).",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier"
                ],
                "page_id":"principal_investigator"
            }
        }
    },
    {
        "id":"md_content_principal_investigator_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/principal_investigator.md",
        "file_name":"principal_investigator.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"ge of data management aspects, so it is important to be aware of the current best practices in DMPs. To organise data management in collaborative projects, it will benefit from a formalised way of working via a Data Management Working Group (DMWG). The costs of data management page helps you budget for your project, including costs for data storage and preservation. The national resources pages provide country-specific guidance, to help you choose the best services, tools and pipelines to manage your data. The human data page gathers information that needs to be taken into consideration when working with human data. Make sure to protect the data in your project well and prevent unauthorised access. Consider your data storage needs in an early stage, including long-term storage at the project end. The data organisation page helps you with file naming, versioning and folder structures. Data documentation, like README files and metadata, help secondary users to understand and reuse your data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"principal_investigator.md",
            "language":"en",
            "frontmatter":{
                "title":"Principal Investigator (PI)",
                "description":"Data management guidance for Principal Investigator (PI).",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier"
                ],
                "page_id":"principal_investigator"
            }
        }
    },
    {
        "id":"md_content_principal_investigator_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/principal_investigator.md",
        "file_name":"principal_investigator.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"cumentation, like README files and metadata, help secondary users to understand and reuse your data. The data processing and data analysis pages provide useful tips, including ensuring maximum reproducibility\nThe data publication page guides you in publishing your data via a public (domain-specific) repository. To make research more robust, consider reusing existing data yourself. Other resources\n\nYour institution may have web pages about RDM. Check if there is an institutional RDM office and\/or data steward(s), and contact them for support and training available. Data Stewardship Wizard (DSW) guides you through creating a data management plan.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"principal_investigator.md",
            "language":"en",
            "frontmatter":{
                "title":"Principal Investigator (PI)",
                "description":"Data management guidance for Principal Investigator (PI).",
                "contributors":[
                    "Mijke Jetten",
                    "Martin Cook",
                    "Siiri Fuchs",
                    "Ulrike Wittig",
                    "Daniel Wibberg",
                    "Helena Schnitzer",
                    "Xnia Prez Sitj",
                    "Nazeefa Fatima",
                    "Gregoire Rossier"
                ],
                "page_id":"principal_investigator"
            }
        }
    },
    {
        "id":"md_fm_policy_maker_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_role\/policy_maker.md",
        "file_name":"policy_maker.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Mijke Jetten\n- Federico Bianchini\n- Gregoire Rossier\n- Erik Hjerde\n- Siiri Fuchs\n- Minna Ahokas\n- Priit Adler\n- Alexander Botzki\n- Robert Andrews\n- Celia van Gelder\n- Daniel Wibberg\n- Graham Hughes\n- Marko Vidak\n- Pedro Fernandes\n- Pinar Alper\n- Victoria Dominguez D. Angel\n- Wolmar Nyberg kerstrm\n- Alexia Cardona\n- Ulrike Wittig\ndescription: Data management guidance for policy makers. page_id: policy_maker\ntitle: Policy maker",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"policy_maker.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_policy_maker_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/policy_maker.md",
        "file_name":"policy_maker.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\nAs a policy maker, you are responsible for the development of a strategic data management framework and the coordination and implementation of research data management guidelines and practices. It is essential that you have knowledge of local, national and international data-related procedures and regulations. General data concepts have to be translated into practical guidelines for organisations and collaborative projects. Close collaboration with policy-related roles such as directors, project coordinators and funders is vital for this role. Data management responsibilities\nAs a policy maker you are coordinating and aligning efforts on the quality, security and management of institutional or collaborative project data. In your role of policy maker, you may need to: Advise, develop and monitor a RDM policy, institutionally or nationally;",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"policy_maker.md",
            "language":"en",
            "frontmatter":{
                "title":"Policy maker",
                "description":"Data management guidance for policy makers.",
                "contributors":[
                    "Mijke Jetten",
                    "Federico Bianchini",
                    "Gregoire Rossier",
                    "Erik Hjerde",
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Daniel Wibberg",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona",
                    "Ulrike Wittig"
                ],
                "page_id":"policy_maker"
            }
        }
    },
    {
        "id":"md_content_policy_maker_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/policy_maker.md",
        "file_name":"policy_maker.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"icy maker, you may need to: Advise, develop and monitor a RDM policy, institutionally or nationally; Ensure compliance of the RDM policy to codes of conduct and regulations, including ethical and legal compliance;\nAlign the RDM policy to the FAIR (Findable, Accessible, Interoperable, Reusable) data principles and the principles of Open Science;\nIdentify the requirements of adequate data-infrastructure for RDM to comply with the institutes RDM policy and alignment to (inter)national data-infrastructure and tools;\nDetermine the adequate level of knowledge and skills on RDM;\nMaintain a network of aligned RDM expertise inside and outside the organisation or the collaborative project. Data management guidance\nRDMkit pages\n\nThe Compliance page helps comply with the institution policy, including legal and ethical aspects. The National resources pages point to country-specific information resources such as local funding agencies and research councils, and information on local policies for open science, national regulations on data ethics, and domain-specific infrastructures and tools.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"policy_maker.md",
            "language":"en",
            "frontmatter":{
                "title":"Policy maker",
                "description":"Data management guidance for policy makers.",
                "contributors":[
                    "Mijke Jetten",
                    "Federico Bianchini",
                    "Gregoire Rossier",
                    "Erik Hjerde",
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Daniel Wibberg",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona",
                    "Ulrike Wittig"
                ],
                "page_id":"policy_maker"
            }
        }
    },
    {
        "id":"md_content_policy_maker_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_role\/policy_maker.md",
        "file_name":"policy_maker.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"or open science, national regulations on data ethics, and domain-specific infrastructures and tools. Data protection helps to make research data compliant to GDPR. Data sensitivity helps to identify sensitivity of different research data types. Licensing gives advice on how to assign a licence to research data. Data management plan guides through writing a data management plan. Project data management coordination gives support in coordination and organisation of RDM in collaborative projects. Other resources\n\nFAIR guiding principles\nPractical Guide to the International Alignment of Research Data Management",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"policy_maker.md",
            "language":"en",
            "frontmatter":{
                "title":"Policy maker",
                "description":"Data management guidance for policy makers.",
                "contributors":[
                    "Mijke Jetten",
                    "Federico Bianchini",
                    "Gregoire Rossier",
                    "Erik Hjerde",
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Priit Adler",
                    "Alexander Botzki",
                    "Robert Andrews",
                    "Celia van Gelder",
                    "Daniel Wibberg",
                    "Graham Hughes",
                    "Marko Vidak",
                    "Pedro Fernandes",
                    "Pinar Alper",
                    "Victoria Dominguez D. Angel",
                    "Wolmar Nyberg kerstrm",
                    "Alexia Cardona",
                    "Ulrike Wittig"
                ],
                "page_id":"policy_maker"
            }
        }
    },
    {
        "id":"md_fm_fairtracks_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- 'NO'\n- ES\n- EMBL-EBI\ncontributors:\n- Federico Bianchini\n- Sveinung Gundersen\ndescription: The FAIRtracks ecosystem provides technical solutions for the FAIRification\n  of genome browser track files\npage_id: fairtracks\nrelated_pages: your_domain:\n  - plants\n  - rare_disease\n  - single_cell_sequencing\n  - human_data\n  your_tasks:\n  - data_publication\n  - data_transfer\n  - metadata\ntitle: FAIRtracks\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=fairtracks",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"fairtracks_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_fairtracks_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":0,
        "total_chunks":8,
        "content":"What is the FAIRtracks tool assembly? The FAIRtracks ecosystem is a set of services associated with a minimal\nmetadata model for\ngenomic annotations\/tracks,\nimplemented as a set of JSON Schemas. The FAIRtracks model contains metadata fields particularly useful for data discovery,\nharmonised through strict adherence to a selection of ontologies available through the {%tool \"ontology-lookup-service\" %}. The usability of the model can be expanded through referencing the original records via Compact Uniform Resource Identifiers (CURIEs) \nresolvable by {% tool \"identifiers-org\" %}. In the context of the Data Life Cycle and its stages, the FAIRtracks ecosystem covers Collecting, Processing,\nAnalysing, Sharing, and Reusing. It has to be noted, however, that the FAIRtracks ecosystem is structured\naround a secondary data life cycle, as illustrated in Figure 1.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fairtracks_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"FAIRtracks",
                "contributors":[
                    "Federico Bianchini",
                    "Sveinung Gundersen"
                ],
                "description":"The FAIRtracks ecosystem provides technical solutions for the FAIRification of genome browser track files",
                "page_id":"fairtracks",
                "affiliations":[
                    "NO",
                    "ES",
                    "EMBL-EBI"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[
                        "plants",
                        "rare_disease",
                        "single_cell_sequencing",
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=fairtracks"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fairtracks_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":1,
        "total_chunks":8,
        "content":"e FAIRtracks ecosystem is structured\naround a secondary data life cycle, as illustrated in Figure 1. As part of this secondary life cycle, the annotation\/track data gets further distributed\nand its discovery is enhanced through derived metadata. The FAIRtracks ecosystem aims at harmonising this process. Primary data needs to be handled independently following domain best practices\n(see e.g. the pages on Single cell sequencing, Plant sciences, or Rare disease data). The FAIRtracks ecosystem is developed and provided as part of the national Service Delivery Plans by\nELIXIR Norway and ELIXIR Spain,\nand is supported by the Track Hub Registry group at EMBL-EBI. FAIRtracks is endorsed by ELIXIR Europe as a\nRecommended Interoperability Resource. {% include image.html file=\"fairtracks_tool-assembly.png\" caption=\"Figure 1. Illustration of the Data life cycle \nfor the FAIRtracks tool assembly. As genomic tracks\/annotations often represent condensed summaries of the raw data, \nthis ecosystem covers a secondary cycle designed around the FAIRtracks metadata model.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fairtracks_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"FAIRtracks",
                "contributors":[
                    "Federico Bianchini",
                    "Sveinung Gundersen"
                ],
                "description":"The FAIRtracks ecosystem provides technical solutions for the FAIRification of genome browser track files",
                "page_id":"fairtracks",
                "affiliations":[
                    "NO",
                    "ES",
                    "EMBL-EBI"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[
                        "plants",
                        "rare_disease",
                        "single_cell_sequencing",
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=fairtracks"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fairtracks_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":2,
        "total_chunks":8,
        "content":"he raw data, \nthis ecosystem covers a secondary cycle designed around the FAIRtracks metadata model. The grey box shows the areas of relevance for the FAIRtracks ecosystem with its integrations, \nand only a subset of the icons represents FAIRtracks services per se. Omnipy (dark grey box) is a general Python library \nfor scalable and reproducible data wrangling which can be used across several data models and research disciplines. \"\nalt=\"FAIRtracks RDMkit\" %}\nWho can use the FAIRtracks tool assembly? There is no central authentication solution for the FAIRtracks services requiring login. The entire FAIRtracks ecosystem is available to everyone. Most of the services are accessible through Application Programming Interfaces (APIs). More details are provided in the description below.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fairtracks_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"FAIRtracks",
                "contributors":[
                    "Federico Bianchini",
                    "Sveinung Gundersen"
                ],
                "description":"The FAIRtracks ecosystem provides technical solutions for the FAIRification of genome browser track files",
                "page_id":"fairtracks",
                "affiliations":[
                    "NO",
                    "ES",
                    "EMBL-EBI"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[
                        "plants",
                        "rare_disease",
                        "single_cell_sequencing",
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=fairtracks"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fairtracks_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":3,
        "total_chunks":8,
        "content":"rough Application Programming Interfaces (APIs). More details are provided in the description below. Users of the FAIRtracks ecosystem belong to different categories, which could be summarised as:\n\nResearchers and data analysts\nData providers and biocurators\nDevelopers working on tooling for\nResearch\nImplementation of the FAIR data principles\n\nEach of these categories benefits specifically from a subset of the global ecosystem. The core services can be accessed both upstream (for data providers and biocurators) and downstream (for tool developers and analytical end users). For what can you use the FAIRtracks tool assembly? The FAIRtracks tool assembly can be used for a large number of applications; we summarise the main ones below following the steps of the data life-cycle\nand focusing on particular tools. While the assembly does not include a tool for Data Management Planning,\nthe FAIRtracks metadata standard is registered in {%tool \"fairsharing\" %}\nand, thus, formally connected to several other standards and databases.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fairtracks_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"FAIRtracks",
                "contributors":[
                    "Federico Bianchini",
                    "Sveinung Gundersen"
                ],
                "description":"The FAIRtracks ecosystem provides technical solutions for the FAIRification of genome browser track files",
                "page_id":"fairtracks",
                "affiliations":[
                    "NO",
                    "ES",
                    "EMBL-EBI"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[
                        "plants",
                        "rare_disease",
                        "single_cell_sequencing",
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=fairtracks"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fairtracks_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":4,
        "total_chunks":8,
        "content":"d in {%tool \"fairsharing\" %}\nand, thus, formally connected to several other standards and databases. The FAIRtracks standard can, thus, be selected on your Data Management Plan in all the instances of {% tool \"data-stewardship-wizard\" %} through\nthe integration with {%tool \"fairsharing\" %}. {%tool \"omnipy\" %} is a high-level Python library for type-driven data wrangling and scalable data flow orchestration;\nit is a self-standing subset of the FAIRtracks ecosystem covering several steps in the data life-cicle. It can be used to extract metadata from specific portals and for Processing of metadata entries to harmonise them into a unique model. {%tool \"omnipy\" %} data flows are defined as transformations from specific input data models to specific output data models. Input and output data are validated at each iteration through parsing based on {%tool \"pydantic\" %}. Offloading of  data flows to external compute resources is provided through the integration of {%tool \"omnipy\" %} with an orchestration engine based on {%tool \"prefect\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fairtracks_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"FAIRtracks",
                "contributors":[
                    "Federico Bianchini",
                    "Sveinung Gundersen"
                ],
                "description":"The FAIRtracks ecosystem provides technical solutions for the FAIRification of genome browser track files",
                "page_id":"fairtracks",
                "affiliations":[
                    "NO",
                    "ES",
                    "EMBL-EBI"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[
                        "plants",
                        "rare_disease",
                        "single_cell_sequencing",
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=fairtracks"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fairtracks_assembly_md_5",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":5,
        "total_chunks":8,
        "content":"ugh the integration of {%tool \"omnipy\" %} with an orchestration engine based on {%tool \"prefect\" %}. There is ongoing work into adding {%tool \"prefect\" %} as one of the services available in the\nNational Infrastructure for Research Data (NIRD) service platform. This would enable running {%tool \"omnipy\" %} on data and metadata stored in the NIRD data storage. Refer also to the Norwegian national page for more details. Note that, while the usage of NIRD storage and services\nis certainly convenient for Norwegian users, this is not a central or mandatory part of the tool assembly which is born as an international\nservice and aims at maintaining this status. Data Sharing and preservation is one of the key components of the FAIRtracks ecosystem. Since genomic annotations\/tracks typically consist of secondary data files referring to primary data sources,\nthey are often deposited together with the primary data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fairtracks_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"FAIRtracks",
                "contributors":[
                    "Federico Bianchini",
                    "Sveinung Gundersen"
                ],
                "description":"The FAIRtracks ecosystem provides technical solutions for the FAIRification of genome browser track files",
                "page_id":"fairtracks",
                "affiliations":[
                    "NO",
                    "ES",
                    "EMBL-EBI"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[
                        "plants",
                        "rare_disease",
                        "single_cell_sequencing",
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=fairtracks"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fairtracks_assembly_md_6",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":6,
        "total_chunks":8,
        "content":"ta files referring to primary data sources,\nthey are often deposited together with the primary data. The aim of the minimal metadata model is to\noffer a greater level of granularity, providing each track with an identifier and enabling the possibility of analysis across datasets\nin an automatised fashion. A dedicated registry would typically be required to accomplish this. Given that such a registry does not yet exist,\nthe current recommendation is to deposit FAIRtracks-compliant metadata files to {%tool \"zenodo\" %},\nas this platform supports both Digital Object Identifier (DOI) versioning and DOI reservation before publication. The identifiers on the metadata FAIRtracks object are then cross-linked with the actual data which is hosted\ne.g. in a Track Hub and registered in\nthe {%tool \"track-hub-registry\" %}. Data and metadata organised in this fashion can be discovered for Reusing through {%tool \"trackfind\" %},\na search and curation engine for genomic tracks. {%tool \"trackfind\" %} will import FAIRtracks-compliant metadata from e.g. {%tool \"zenodo\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fairtracks_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"FAIRtracks",
                "contributors":[
                    "Federico Bianchini",
                    "Sveinung Gundersen"
                ],
                "description":"The FAIRtracks ecosystem provides technical solutions for the FAIRification of genome browser track files",
                "page_id":"fairtracks",
                "affiliations":[
                    "NO",
                    "ES",
                    "EMBL-EBI"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[
                        "plants",
                        "rare_disease",
                        "single_cell_sequencing",
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=fairtracks"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fairtracks_assembly_md_7",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/fairtracks_assembly.md",
        "file_name":"fairtracks_assembly.md",
        "chunk_index":7,
        "total_chunks":8,
        "content":"racks. {%tool \"trackfind\" %} will import FAIRtracks-compliant metadata from e.g. {%tool \"zenodo\" %}. This metadata can be accessed through hierarchical browsing or by search queries both through a web-based user interface and as a RESTful API. TrackFind supports advanced SQL-based queries that can be easily built into the user interface. Additional tools that comprise the core of the FAIRtracks ecosystem are the\nmetadata validation and the\nmetadata augmentation services. The former is REST API that extends the standard JSON Schema validation technology to\ne.g. validate ontology terms or check CURIEs against the registered entries. The FAIRtracks augmentation service\nis implemented as a REST API that expands on the information contained in a minimal FAIRtracks JSON by adding\na set of fields with human-readable values including ontology labels, versions, and summaries. This service bridges the gap between data providers, which are required to submit only minimal information, and data consumers\nwho require richer information for data discovery and retrieval.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fairtracks_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"FAIRtracks",
                "contributors":[
                    "Federico Bianchini",
                    "Sveinung Gundersen"
                ],
                "description":"The FAIRtracks ecosystem provides technical solutions for the FAIRification of genome browser track files",
                "page_id":"fairtracks",
                "affiliations":[
                    "NO",
                    "ES",
                    "EMBL-EBI"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[
                        "plants",
                        "rare_disease",
                        "single_cell_sequencing",
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=fairtracks"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_ifb_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"affiliations:\n- ELIXIR Europe\n- FR\ncontributors:\n- Olivier Collin\n- Marie-Christine Jacquemot\n- Paulette Lieby\n- Flora D'Anna\n- Anne-Franoise Adam-Blondon\ndescription: The French Bioinformatics Institute (IFB) offers IT infrastructure and\n  bioinformatics expertise to support researchers in Life Sciences. page_id: ifb\nrelated_pages:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ifb_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_ifb_assembly_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":" and\n  bioinformatics expertise to support researchers in Life Sciences. page_id: ifb\nrelated_pages: your_domain: []\n  your_tasks:\n  - dmp\n  - data_organisation\n  - storage\n  - data_publication\n  - data_transfer\n  - metadata\n  - data_analysis\ntitle: IFB\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=IFB\n- name: Data management training at the IFB\n  url: https:\/\/www.france-bioinformatique.fr\/en\/training\/\n- name: Inist and the network of regional scientific information units (Urfist)\n  url: https:\/\/doranum.fr\n- name: Documentation for the IFB core cluster\n  url: https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/\n- name: Documentation for the Biosphere cloud federation\n  url: https:\/\/ifb-elixirfr.github.io\/biosphere\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ifb_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_ifb_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":0,
        "total_chunks":8,
        "content":"What is the IFB data management tool assembly? The IFB is the French national Bioinformatics Infrastructure that supports research projects in Life Sciences by provisioning a bioinformatics environment, which consists of IT infrastructure (such as storage and computing resources), software and training, distributed across the country. The IFB federates around 20 bioinformatics platforms which make physical, operational and human resources available to researchers in a synergistic and efficient way. Each platform brings its own IT infrastructure and bioinformatics expertise to create a better support network, distributed over the country, for Life Sciences research activities. IFB data management tool assembly supports data management activities of scientists during all the phases of their projects, from planning to publication. Who can use the IFB data management tool assembly?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ifb_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"IFB",
                "contributors":[
                    "Olivier Collin",
                    "Marie-Christine Jacquemot",
                    "Paulette Lieby",
                    "Flora D'Anna",
                    "Anne-Franoise Adam-Blondon"
                ],
                "description":"The French Bioinformatics Institute (IFB) offers IT infrastructure and bioinformatics expertise to support researchers in Life Sciences.",
                "page_id":"ifb",
                "affiliations":[
                    "ELIXIR Europe",
                    "FR"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=IFB"
                    },
                    {
                        "name":"Data management training at the IFB",
                        "url":"https:\/\/www.france-bioinformatique.fr\/en\/training\/"
                    },
                    {
                        "name":"Inist and the network of regional scientific information units (Urfist)",
                        "url":"https:\/\/doranum.fr"
                    },
                    {
                        "name":"Documentation for the IFB core cluster",
                        "url":"https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/"
                    },
                    {
                        "name":"Documentation for the Biosphere cloud federation",
                        "url":"https:\/\/ifb-elixirfr.github.io\/biosphere\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ifb_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":1,
        "total_chunks":8,
        "content":" of their projects, from planning to publication. Who can use the IFB data management tool assembly? IFB and the underlying infrastructure are accessible to researchers in France and their foreign collaborators. Researchers that would like to know more about IFB services can find specific contact details at the unified IFB help desk page and get support through the dedicated help pages. Depending on the resources, fees may apply. It is therefore advisable to contact them during the planning phase of the project. The way you can access the IFB depends on the type of resources (for instance, cluster or cloud), and there will be different authentication procedures (local, national or international). For example, the Biosphere cloud federation uses the EduGAIN federation for authentication, while useGalaxy.fr uses the {% tool \"life-science-login\" %} authentication. To have additional information on how to access the IFB contact the help desk. For what can you use the IFB data management tool assembly?\n{% include image.html file=\"fr_ifb_assembly.svg\" caption=\"Figure 1.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ifb_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"IFB",
                "contributors":[
                    "Olivier Collin",
                    "Marie-Christine Jacquemot",
                    "Paulette Lieby",
                    "Flora D'Anna",
                    "Anne-Franoise Adam-Blondon"
                ],
                "description":"The French Bioinformatics Institute (IFB) offers IT infrastructure and bioinformatics expertise to support researchers in Life Sciences.",
                "page_id":"ifb",
                "affiliations":[
                    "ELIXIR Europe",
                    "FR"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=IFB"
                    },
                    {
                        "name":"Data management training at the IFB",
                        "url":"https:\/\/www.france-bioinformatique.fr\/en\/training\/"
                    },
                    {
                        "name":"Inist and the network of regional scientific information units (Urfist)",
                        "url":"https:\/\/doranum.fr"
                    },
                    {
                        "name":"Documentation for the IFB core cluster",
                        "url":"https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/"
                    },
                    {
                        "name":"Documentation for the Biosphere cloud federation",
                        "url":"https:\/\/ifb-elixirfr.github.io\/biosphere\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ifb_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":2,
        "total_chunks":8,
        "content":"B data management tool assembly?\n{% include image.html file=\"fr_ifb_assembly.svg\" caption=\"Figure 1. The French Bioinformatics Institute (IFB) tool assembly.\" alt=\"IFB RDMkit\" %}\nData management planning\nIFB recommends DMP-OPIDoR or DSW as tools for writing a Data Management Plan (DMP). DMP-OPIDoR is hosted and maintained at Inist-CNRS and is tailored to meet the needs of many French academic institutes. You will find many DMP templates, in French and\/or English, created by funders and academic institutes. A dedicated team offers training and support for DMP templates and DMPs. They can be reached via this contact form. The machine actionable version of DMP-OPIDoR allows the production of structured standardized DMP content. It enables the integration of information from funding agencies such as the French National Agency (ANR), and also integration and interactions with computing infrastructures provided by IFB and Genci, the organization in charge of the three supercomputing centres in France. DMP OPIDoR is freely accessible to anyone.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ifb_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"IFB",
                "contributors":[
                    "Olivier Collin",
                    "Marie-Christine Jacquemot",
                    "Paulette Lieby",
                    "Flora D'Anna",
                    "Anne-Franoise Adam-Blondon"
                ],
                "description":"The French Bioinformatics Institute (IFB) offers IT infrastructure and bioinformatics expertise to support researchers in Life Sciences.",
                "page_id":"ifb",
                "affiliations":[
                    "ELIXIR Europe",
                    "FR"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=IFB"
                    },
                    {
                        "name":"Data management training at the IFB",
                        "url":"https:\/\/www.france-bioinformatique.fr\/en\/training\/"
                    },
                    {
                        "name":"Inist and the network of regional scientific information units (Urfist)",
                        "url":"https:\/\/doranum.fr"
                    },
                    {
                        "name":"Documentation for the IFB core cluster",
                        "url":"https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/"
                    },
                    {
                        "name":"Documentation for the Biosphere cloud federation",
                        "url":"https:\/\/ifb-elixirfr.github.io\/biosphere\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ifb_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":3,
        "total_chunks":8,
        "content":" in charge of the three supercomputing centres in France. DMP OPIDoR is freely accessible to anyone. First, one has to create an account (login, password). Then this account can be linked to the Renater identity federation. For support about OPIDoR, you can check the cat-OPIDoR support providers page. DSW is a tool to collaboratively compose data management plans through customisable questionnaires. IFB has used DSW to develop templates for France Bioimaging (FBI data management plan) and for Hosted Scientific Service Management Plan (HSSMP). Data collection Although they are not part of IFB, other infrastructures in France can also help you generate new data. Specifically, some facilities can assist you with in vivo and in vitro experiments, synthetic biology, omics techniques, imaging, structural biology and other techniques and expertise. To find the adequate facility you may use the Ministry search engine or the IBiSA directory of french facilities in Life Sciences.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ifb_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"IFB",
                "contributors":[
                    "Olivier Collin",
                    "Marie-Christine Jacquemot",
                    "Paulette Lieby",
                    "Flora D'Anna",
                    "Anne-Franoise Adam-Blondon"
                ],
                "description":"The French Bioinformatics Institute (IFB) offers IT infrastructure and bioinformatics expertise to support researchers in Life Sciences.",
                "page_id":"ifb",
                "affiliations":[
                    "ELIXIR Europe",
                    "FR"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=IFB"
                    },
                    {
                        "name":"Data management training at the IFB",
                        "url":"https:\/\/www.france-bioinformatique.fr\/en\/training\/"
                    },
                    {
                        "name":"Inist and the network of regional scientific information units (Urfist)",
                        "url":"https:\/\/doranum.fr"
                    },
                    {
                        "name":"Documentation for the IFB core cluster",
                        "url":"https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/"
                    },
                    {
                        "name":"Documentation for the Biosphere cloud federation",
                        "url":"https:\/\/ifb-elixirfr.github.io\/biosphere\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ifb_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":4,
        "total_chunks":8,
        "content":"you may use the Ministry search engine or the IBiSA directory of french facilities in Life Sciences. Once your data have been generated by the facility, you will need to transfer it to your local system or to the IFB infrastructure, if you intend to use the IFBs compute services. In both cases it is a good practice to get in touch with IT support (local or IFB), especially if the volume of your data is large. If you have to reuse previously generated data, keep in mind that the different IFB platforms provide many specialized databases. A list of the databases is available here. These databases are, for the most, freely available. To support data collection along with standard metadata, IFB is providing SEEK instances available at URGI and GenOuest. Data processing and analysis\nIFB infrastructure gives you access to several flavours of computing resources, according to your needs and expertise:\n\nSeveral clusters hosted either at IFB-Core or on any of the member platforms. You can request accounts on any of the member clusters.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ifb_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"IFB",
                "contributors":[
                    "Olivier Collin",
                    "Marie-Christine Jacquemot",
                    "Paulette Lieby",
                    "Flora D'Anna",
                    "Anne-Franoise Adam-Blondon"
                ],
                "description":"The French Bioinformatics Institute (IFB) offers IT infrastructure and bioinformatics expertise to support researchers in Life Sciences.",
                "page_id":"ifb",
                "affiliations":[
                    "ELIXIR Europe",
                    "FR"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=IFB"
                    },
                    {
                        "name":"Data management training at the IFB",
                        "url":"https:\/\/www.france-bioinformatique.fr\/en\/training\/"
                    },
                    {
                        "name":"Inist and the network of regional scientific information units (Urfist)",
                        "url":"https:\/\/doranum.fr"
                    },
                    {
                        "name":"Documentation for the IFB core cluster",
                        "url":"https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/"
                    },
                    {
                        "name":"Documentation for the Biosphere cloud federation",
                        "url":"https:\/\/ifb-elixirfr.github.io\/biosphere\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ifb_assembly_md_5",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":5,
        "total_chunks":8,
        "content":" IFB-Core or on any of the member platforms. You can request accounts on any of the member clusters. The Galaxy France portal operated by IFB members in complement of the Galaxy Europe. The cloud federation Biosphere allows the deployment of ready-to-use appliances (virtual machines with all required software installed for analysis) for several scientific domains (Genomics, Bioimaging, Metabolomics, etc.). A list of the different appliances is available on the RainBio catalogue. You can log in here using your academic credentials. Each of the computing resources offers its own storage solution tailored for the needs of the users (fast access, capacitive). You may have to choose a resource according to what its service offers and also according to its proximity to your own location in order to benefit from better support and also better data transfer speed. IFB infrastructure can also help you with bioinformatics analysis of your data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ifb_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"IFB",
                "contributors":[
                    "Olivier Collin",
                    "Marie-Christine Jacquemot",
                    "Paulette Lieby",
                    "Flora D'Anna",
                    "Anne-Franoise Adam-Blondon"
                ],
                "description":"The French Bioinformatics Institute (IFB) offers IT infrastructure and bioinformatics expertise to support researchers in Life Sciences.",
                "page_id":"ifb",
                "affiliations":[
                    "ELIXIR Europe",
                    "FR"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=IFB"
                    },
                    {
                        "name":"Data management training at the IFB",
                        "url":"https:\/\/www.france-bioinformatique.fr\/en\/training\/"
                    },
                    {
                        "name":"Inist and the network of regional scientific information units (Urfist)",
                        "url":"https:\/\/doranum.fr"
                    },
                    {
                        "name":"Documentation for the IFB core cluster",
                        "url":"https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/"
                    },
                    {
                        "name":"Documentation for the Biosphere cloud federation",
                        "url":"https:\/\/ifb-elixirfr.github.io\/biosphere\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ifb_assembly_md_6",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":6,
        "total_chunks":8,
        "content":"data transfer speed. IFB infrastructure can also help you with bioinformatics analysis of your data. Many of the IFB member platforms can provide expertise for data analysis in many domains (genomics, metagenomics, transcriptomics) as well as software development. To check the expertise of the platforms, you can use this catalog. A list of the tools developed by all IFB members is available here. Data sharing and publishing\nIt is good practice to publish your data on repositories. IFB encourages researchers to browse the list of {% tool \"elixir-deposition-databases-for-biomolecular-data\" %} to find the appropriate repository. The french scientific community benefit from Recherche. Data. Gouv a national Dataverse repository. This repository is associated with thematic reference centres and data management clusters. IFB is the reference centre for Life Science. You can also browse cat-OPIDoR for an overview of the different services related to data management provided by IFB infrastructure and its stakeholders in France.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ifb_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"IFB",
                "contributors":[
                    "Olivier Collin",
                    "Marie-Christine Jacquemot",
                    "Paulette Lieby",
                    "Flora D'Anna",
                    "Anne-Franoise Adam-Blondon"
                ],
                "description":"The French Bioinformatics Institute (IFB) offers IT infrastructure and bioinformatics expertise to support researchers in Life Sciences.",
                "page_id":"ifb",
                "affiliations":[
                    "ELIXIR Europe",
                    "FR"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=IFB"
                    },
                    {
                        "name":"Data management training at the IFB",
                        "url":"https:\/\/www.france-bioinformatique.fr\/en\/training\/"
                    },
                    {
                        "name":"Inist and the network of regional scientific information units (Urfist)",
                        "url":"https:\/\/doranum.fr"
                    },
                    {
                        "name":"Documentation for the IFB core cluster",
                        "url":"https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/"
                    },
                    {
                        "name":"Documentation for the Biosphere cloud federation",
                        "url":"https:\/\/ifb-elixirfr.github.io\/biosphere\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ifb_assembly_md_7",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/ifb_assembly.md",
        "file_name":"ifb_assembly.md",
        "chunk_index":7,
        "total_chunks":8,
        "content":"t services related to data management provided by IFB infrastructure and its stakeholders in France. Compliance monitoring & measurement\nIFB infrastructure promotes the implementation of the FAIR principles. To this end, IFB provides and encourages the use of the FAIR-Checker, a web interface aimed at monitoring the level of FAIRification of data resources. This tool uses the FAIRMetrics APIs to provide a global assessment and recommendations. It also uses semantic technologies to help users in annotating their resources with high-quality metadata.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ifb_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"IFB",
                "contributors":[
                    "Olivier Collin",
                    "Marie-Christine Jacquemot",
                    "Paulette Lieby",
                    "Flora D'Anna",
                    "Anne-Franoise Adam-Blondon"
                ],
                "description":"The French Bioinformatics Institute (IFB) offers IT infrastructure and bioinformatics expertise to support researchers in Life Sciences.",
                "page_id":"ifb",
                "affiliations":[
                    "ELIXIR Europe",
                    "FR"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=IFB"
                    },
                    {
                        "name":"Data management training at the IFB",
                        "url":"https:\/\/www.france-bioinformatique.fr\/en\/training\/"
                    },
                    {
                        "name":"Inist and the network of regional scientific information units (Urfist)",
                        "url":"https:\/\/doranum.fr"
                    },
                    {
                        "name":"Documentation for the IFB core cluster",
                        "url":"https:\/\/ifb-elixirfr.gitlab.io\/cluster\/doc\/"
                    },
                    {
                        "name":"Documentation for the Biosphere cloud federation",
                        "url":"https:\/\/ifb-elixirfr.github.io\/biosphere\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_tsd_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/tsd_assembly.md",
        "file_name":"tsd_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- 'NO'\n- ELIXIR Europe\n- University of Oslo\ncontributors:\n- Tina Visnovska\n- Federico Bianchini\n- Korbinian Bsl\n- Nazeefa Fatima\ndescription: The Sensitive Data Service (TSD) provides a platform to store, compute\n  and analyse research sensitive data in compliance with Norwegian regulations regarding\n  individuals privacy. page_id: tsd\nrelated_pages: your_domain:\n  - human_data\n  your_tasks:\n  - dmp\n  - storage\n  - sensitive\n  - data_security\n  - gdpr_compliance\n  - transfer\ntitle: TSD\ntraining:\n- name: Documentation for the HPC cluster\n  url: https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/help\/hpc\/index.html\n- name: Courses on the usage of TSD from the University of Oslo\n  url: https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/\n- name: Recording of a previous course on Nettskjema and TSD (April 2020)\n  url: https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/tsd-nettskjema2april.html",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"tsd_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_tsd_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/tsd_assembly.md",
        "file_name":"tsd_assembly.md",
        "chunk_index":0,
        "total_chunks":7,
        "content":"What is the Norwegian TSD Data Management Tools Assembly? The Norwegian TSD tools assembly is centred around \nTSD (services for sensitive data in Norwegian); an infrastructure provided by the University of Oslo (UiO). Together with the complementary tools provided by ELIXIR, TSD is used for the management of sensitive data, including Human data. This assembly covers Data Life Cycle stages such as Planning, Processing, Analysing and Sharing and, in addition, offers Data Storage quotas and tools for transfer of sensitive data, following the requirements of the {% tool \"eu-general-data-protection-regulation\" %} and its Norwegian implementation. Who can use the TSD data management tools assembly? Resources on TSD are accessible for international users through the User Management in TSD webpage (maintained by the University of Oslo); the page provides guidance on account creation and administration procedures.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"tsd_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TSD",
                "contributors":[
                    "Tina Visnovska",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "description":"The Sensitive Data Service (TSD) provides a platform to store, compute and analyse research sensitive data in compliance with Norwegian regulations regarding individuals privacy.",
                "page_id":"tsd",
                "affiliations":[
                    "NO",
                    "ELIXIR Europe",
                    "University of Oslo"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "storage",
                        "sensitive",
                        "data_security",
                        "gdpr_compliance",
                        "transfer"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Documentation for the HPC cluster",
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/help\/hpc\/index.html"
                    },
                    {
                        "name":"Courses on the usage of TSD from the University of Oslo",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/"
                    },
                    {
                        "name":"Recording of a previous course on Nettskjema and TSD (April 2020)",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/tsd-nettskjema2april.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_tsd_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/tsd_assembly.md",
        "file_name":"tsd_assembly.md",
        "chunk_index":1,
        "total_chunks":7,
        "content":"e University of Oslo); the page provides guidance on account creation and administration procedures. Researchers in Norway can also access resources through the Sigma2 e-infrastructure program which offers additional services and support for sensitive data storage and processing. If you are affiliated with a Norwegian institution that has a data processing and\/or service agreement with TSD, you can use\/amend the agreement to account for your project. Otherwise, you can establish a data agreement for your individual project by contacting tsd-contact@usit.uio.no. International users may need to follow additional steps to comply with institutional and international data protection regulations. For example, additional authentication or approval steps may be required. Specific procedures for accessing resources from outside Norway are outlined in the TSD user documentation, and further assistance can be sought from the University of Oslo's support team or through local research infrastructure providers.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"tsd_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TSD",
                "contributors":[
                    "Tina Visnovska",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "description":"The Sensitive Data Service (TSD) provides a platform to store, compute and analyse research sensitive data in compliance with Norwegian regulations regarding individuals privacy.",
                "page_id":"tsd",
                "affiliations":[
                    "NO",
                    "ELIXIR Europe",
                    "University of Oslo"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "storage",
                        "sensitive",
                        "data_security",
                        "gdpr_compliance",
                        "transfer"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Documentation for the HPC cluster",
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/help\/hpc\/index.html"
                    },
                    {
                        "name":"Courses on the usage of TSD from the University of Oslo",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/"
                    },
                    {
                        "name":"Recording of a previous course on Nettskjema and TSD (April 2020)",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/tsd-nettskjema2april.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_tsd_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/tsd_assembly.md",
        "file_name":"tsd_assembly.md",
        "chunk_index":2,
        "total_chunks":7,
        "content":"ought from the University of Oslo's support team or through local research infrastructure providers. What can you use the TSD data management tools assembly for?\n{% include image.html file=\"TSD_tool_assembly.svg\" caption=\"Figure 1. Norwegian ELIXIR tools assembly for sensitive data - TSD\" alt=\"TSD tool assembly\" %}\nThe Norwegian Tool Assembly for sensitive data offers support with Data Management Planning through a national instance of the Data Stewardship Wizard (DSW) following the guidelines of the major national and European funding bodies. Dedicated references in DSW guide you (user) through national infrastructure, resources, and laws and regulations, and also include the {% tool \"tryggve-elsi-checklist\" %} for Ethical, Legal and Social Implications. In the future, you will be able to submit storage request forms for Data Storage in TSD with defined access permissions through the DSW. In addition to its storage services, TSD offers safe environments for data processing and analysis.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"tsd_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TSD",
                "contributors":[
                    "Tina Visnovska",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "description":"The Sensitive Data Service (TSD) provides a platform to store, compute and analyse research sensitive data in compliance with Norwegian regulations regarding individuals privacy.",
                "page_id":"tsd",
                "affiliations":[
                    "NO",
                    "ELIXIR Europe",
                    "University of Oslo"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "storage",
                        "sensitive",
                        "data_security",
                        "gdpr_compliance",
                        "transfer"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Documentation for the HPC cluster",
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/help\/hpc\/index.html"
                    },
                    {
                        "name":"Courses on the usage of TSD from the University of Oslo",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/"
                    },
                    {
                        "name":"Recording of a previous course on Nettskjema and TSD (April 2020)",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/tsd-nettskjema2april.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_tsd_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/tsd_assembly.md",
        "file_name":"tsd_assembly.md",
        "chunk_index":3,
        "total_chunks":7,
        "content":" In addition to its storage services, TSD offers safe environments for data processing and analysis. As a national user, you can access TSD by identifying yourself using the Norwegian ID-porten system. International users can get access by contacting tsd-contact@usit.uio.no. Within TSD, you can access a Windows or Linux virtual machine (VM) and, upon request, high-performance computing (HPC) resources and backup storage. You log in using two-factor authentication with Google Authenticator and a dedicated username and password. The login procedure is different for Windows and Linux VMs. As the primary design goal of TSD is data security, transfer of data by other means to and from TSD is restricted and logged. Data management planning You can access the ELIXIR-NO instance of the Data Stewardship Wizard using {% tool \"life-science-login\" %}, which can be coupled with the national solution for secure login and data sharing in the educational and research sector Feide. Data Collection",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"tsd_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TSD",
                "contributors":[
                    "Tina Visnovska",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "description":"The Sensitive Data Service (TSD) provides a platform to store, compute and analyse research sensitive data in compliance with Norwegian regulations regarding individuals privacy.",
                "page_id":"tsd",
                "affiliations":[
                    "NO",
                    "ELIXIR Europe",
                    "University of Oslo"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "storage",
                        "sensitive",
                        "data_security",
                        "gdpr_compliance",
                        "transfer"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Documentation for the HPC cluster",
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/help\/hpc\/index.html"
                    },
                    {
                        "name":"Courses on the usage of TSD from the University of Oslo",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/"
                    },
                    {
                        "name":"Recording of a previous course on Nettskjema and TSD (April 2020)",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/tsd-nettskjema2april.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_tsd_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/tsd_assembly.md",
        "file_name":"tsd_assembly.md",
        "chunk_index":4,
        "total_chunks":7,
        "content":"tion for secure login and data sharing in the educational and research sector Feide. Data Collection If you use one of the Norwegian research infrastructures, such as the Norwegian sequencing infrastructure NorSeq they can directly upload data to your TSD project for you - the process is described by ELIXIR Norway at https:\/\/elixir.no\/Services-bak\/data_produced_NorSeq\nThe sensitive data tools assembly provides Nettskjema as a solution for designing and managing data collections using online forms and surveys. This is a secure and GDPR-compliant service. It can be accessed through the UiO's web pages and it is used through a web browser. Submissions from a Nettskjema questionnaire can be delivered securely (fully encrypted) to your project area within TSD. TSD-users are granted access to Nettskjema through IDporten or Feide. When the Nettskjema form is complete, you can upload it on TSD following these instructions. After verification, the form can be used for collecting sensitive data. Note that further processing and analysis of the results should be conducted within TSD.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"tsd_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TSD",
                "contributors":[
                    "Tina Visnovska",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "description":"The Sensitive Data Service (TSD) provides a platform to store, compute and analyse research sensitive data in compliance with Norwegian regulations regarding individuals privacy.",
                "page_id":"tsd",
                "affiliations":[
                    "NO",
                    "ELIXIR Europe",
                    "University of Oslo"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "storage",
                        "sensitive",
                        "data_security",
                        "gdpr_compliance",
                        "transfer"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Documentation for the HPC cluster",
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/help\/hpc\/index.html"
                    },
                    {
                        "name":"Courses on the usage of TSD from the University of Oslo",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/"
                    },
                    {
                        "name":"Recording of a previous course on Nettskjema and TSD (April 2020)",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/tsd-nettskjema2april.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_tsd_assembly_md_5",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/tsd_assembly.md",
        "file_name":"tsd_assembly.md",
        "chunk_index":5,
        "total_chunks":7,
        "content":"itive data. Note that further processing and analysis of the results should be conducted within TSD. If exporting data is necessary, the files should be properly de-identified or anonymised. Data Processing and Analysis\nFor Processing and Analysing your data,  you can use singularity containers and individual tools on the HPC cluster. The computing services provided through TSD include an Illumina DRAGEN (Dynamic Read Analysis for GENomics) node, which can be used to speed up genomic analysis of sequencing data. Dragen is a dedicated resource and if you want to run jobs on DRAGEN, please send an email to tsd-drift@usit.uio.no. Data Sharing and Preservation\nOne solution for permanent archiving and sharing of personally identifiable genetic and phenotypic datasets resulting from biomedical research data is to deposit them to the {% tool \"the-european-genome-phenome-archive\" %}. The EGA applies a controlled access model. There can be limitations, e.g. given consents, for your datasets which prevents them from leaving your jurisdiction or being archived in general.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"tsd_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TSD",
                "contributors":[
                    "Tina Visnovska",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "description":"The Sensitive Data Service (TSD) provides a platform to store, compute and analyse research sensitive data in compliance with Norwegian regulations regarding individuals privacy.",
                "page_id":"tsd",
                "affiliations":[
                    "NO",
                    "ELIXIR Europe",
                    "University of Oslo"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "storage",
                        "sensitive",
                        "data_security",
                        "gdpr_compliance",
                        "transfer"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Documentation for the HPC cluster",
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/help\/hpc\/index.html"
                    },
                    {
                        "name":"Courses on the usage of TSD from the University of Oslo",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/"
                    },
                    {
                        "name":"Recording of a previous course on Nettskjema and TSD (April 2020)",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/tsd-nettskjema2april.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_tsd_assembly_md_6",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/tsd_assembly.md",
        "file_name":"tsd_assembly.md",
        "chunk_index":6,
        "total_chunks":7,
        "content":", for your datasets which prevents them from leaving your jurisdiction or being archived in general. This is partly addressed by federated EGA services with nodes operating from one country or institution under one specific jurisdiction. This model enables discovery of publicly shareable metadata about studies\/datasets archived at the federated EGA nodes through the Central EGA, while the remaining data is stored in a local solution. The federated EGA nodes offer the same APIs as the Central EGA and provide independent data distribution to users. The Norwegian Federated EGA is accessible through {% tool \"life-science-login\" %}, compatible with Feide.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"tsd_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TSD",
                "contributors":[
                    "Tina Visnovska",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "description":"The Sensitive Data Service (TSD) provides a platform to store, compute and analyse research sensitive data in compliance with Norwegian regulations regarding individuals privacy.",
                "page_id":"tsd",
                "affiliations":[
                    "NO",
                    "ELIXIR Europe",
                    "University of Oslo"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "storage",
                        "sensitive",
                        "data_security",
                        "gdpr_compliance",
                        "transfer"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Documentation for the HPC cluster",
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/help\/hpc\/index.html"
                    },
                    {
                        "name":"Courses on the usage of TSD from the University of Oslo",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/"
                    },
                    {
                        "name":"Recording of a previous course on Nettskjema and TSD (April 2020)",
                        "url":"https:\/\/www.uio.no\/for-ansatte\/kompetanse\/tema\/data\/nettskjema-tsd\/tsd-nettskjema2april.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_xnat_pic_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/xnat_pic_assembly.md",
        "file_name":"xnat_pic_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- Euro BioImaging\n- IT\ncontributors:\n- Sara Zullino\n- Alessandro Paglialonga\n- Walter Dastr\n- Dario Longo\n- Silvio Aime\ndescription: XNAT for Preclinical Imaging Centers (XNAT-PIC) is a of set of tools\n  to store, process and share preclinical imaging studies built on top of the XNAT\n  imaging informatics platform.\npage_id: xnat_pic\nrelated_pages:\n  your_domain: []\n  your_tasks:\n  - data_organisation\n  - storage\n  - data_analysis\ntitle: XNAT-PIC\ntraining:\n- name: EOSC-Life website\n  url: https:\/\/www.eosc-life.eu\/d5\/\n- name: Euro-Bioimaging website\n  url: https:\/\/www.eurobioimaging.eu\/news\/towards-sharing-and-reusing-of-preclinical-image-data\n- name: Data Management - Biological and Preclinical Imaging Perspective\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/watch?v=QNiAGuFk53w\n- name: XNAT-PIC - expanding XNAT for image archiving and processing to Preclinical\n    Imaging Centers\n  registry: YouTube\n  url: ttps:\/\/www.youtube.com\/cpEcfIJJqCo",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"xnat_pic_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_xnat_pic_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/xnat_pic_assembly.md",
        "file_name":"xnat_pic_assembly.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"What is XNAT-PIC? Preclinical imaging centers deal with many challenges mostly related to the variety of imaging instrumentation yielding huge volumes of raw data. The current procedures to collect, share and reuse preclinical image data are insufficient, thus revealing an urgent need of standardization in terms of data storage and image processing. {% tool \"xnat\" %} for Preclinical Imaging Centers (XNAT-PIC) has been developed to overcome this limitation by extending XNATs basic functionalities to meet the needs of preclinical imaging facilities. XNAT for Preclinical Imaging Centers (XNAT-PIC) consists of a set of tools built in Python and MATLAB to store, process and share preclinical imaging studies built on top of the {% tool \"xnat\" %} imaging informatics platform. Who is XNAT-PIC intended for?\nXNAT-PIC is inteded for scientists, researchers and data stewards working in the preclinical and biomedical imaging field to support image data management and processing.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"xnat_pic_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"XNAT-PIC",
                "contributors":[
                    "Sara Zullino",
                    "Alessandro Paglialonga",
                    "Walter Dastr",
                    "Dario Longo",
                    "Silvio Aime"
                ],
                "page_id":"xnat_pic",
                "affiliations":[
                    "Euro BioImaging",
                    "IT"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "storage",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "description":"XNAT for Preclinical Imaging Centers (XNAT-PIC) is a of set of tools to store, process and share preclinical imaging studies built on top of the XNAT imaging informatics platform.",
                "training":[
                    {
                        "name":"EOSC-Life website",
                        "url":"https:\/\/www.eosc-life.eu\/d5\/"
                    },
                    {
                        "name":"Euro-Bioimaging website",
                        "url":"https:\/\/www.eurobioimaging.eu\/news\/towards-sharing-and-reusing-of-preclinical-image-data"
                    },
                    {
                        "name":"Data Management - Biological and Preclinical Imaging Perspective",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=QNiAGuFk53w"
                    },
                    {
                        "name":"XNAT-PIC - expanding XNAT for image archiving and processing to Preclinical Imaging Centers",
                        "registry":"YouTube",
                        "url":"ttps:\/\/www.youtube.com\/cpEcfIJJqCo"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_xnat_pic_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/xnat_pic_assembly.md",
        "file_name":"xnat_pic_assembly.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ing in the preclinical and biomedical imaging field to support image data management and processing. Which task can be solved with XNAT-PIC? XNAT-PIC is a set of tools to support preclinical imaging scientists in their data management and processing needs. The Extensible Neuroimaging Archive Toolkit {% tool \"xnat\" %} is an imaging informatics platform developed by the Neuroinformatics Research Group at the Washington University for the management, storage and analysis of biomedical image data. XNAT is an open-source project that can support a wide range of imaging modalities thanks to its extensibility. {% include image.html file=\"xnat-pic.png\" caption=\"Figure 1. Schematic overview of the XNAT-PIC tool assembly.\" alt=\"Schematic overview of the XNAT-PIC tool assembly.\" %}\nXNAT-PIC consists of:\n\n{% tool \"mri2dicom\" %} to process Magnetic Resonance (MR) images and convert them from ParaVision (Bruker, Inc.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"xnat_pic_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"XNAT-PIC",
                "contributors":[
                    "Sara Zullino",
                    "Alessandro Paglialonga",
                    "Walter Dastr",
                    "Dario Longo",
                    "Silvio Aime"
                ],
                "page_id":"xnat_pic",
                "affiliations":[
                    "Euro BioImaging",
                    "IT"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "storage",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "description":"XNAT for Preclinical Imaging Centers (XNAT-PIC) is a of set of tools to store, process and share preclinical imaging studies built on top of the XNAT imaging informatics platform.",
                "training":[
                    {
                        "name":"EOSC-Life website",
                        "url":"https:\/\/www.eosc-life.eu\/d5\/"
                    },
                    {
                        "name":"Euro-Bioimaging website",
                        "url":"https:\/\/www.eurobioimaging.eu\/news\/towards-sharing-and-reusing-of-preclinical-image-data"
                    },
                    {
                        "name":"Data Management - Biological and Preclinical Imaging Perspective",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=QNiAGuFk53w"
                    },
                    {
                        "name":"XNAT-PIC - expanding XNAT for image archiving and processing to Preclinical Imaging Centers",
                        "registry":"YouTube",
                        "url":"ttps:\/\/www.youtube.com\/cpEcfIJJqCo"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_xnat_pic_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/xnat_pic_assembly.md",
        "file_name":"xnat_pic_assembly.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"2dicom\" %} to process Magnetic Resonance (MR) images and convert them from ParaVision (Bruker, Inc. Billerica, MA) file format to DICOM standard;\n{% tool \"xnat-pic-uploader\" %} to import and store multimodal DICOM image datasets to XNAT;\n{% tool \"xnat-pic-pipelines\" %} for analysing single or multiple subjects within the same project in XNAT. Citation\nIf you use XNAT-PIC please cite: \n\nS. Zullino, A. Paglialonga, W. Dastr, D. L. Longo, S. Aime. XNAT-PIC: Extending XNAT to Preclinical Imaging Centers, 2021. Pre-print: https:\/\/arxiv.org\/abs\/2103.02044",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"xnat_pic_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"XNAT-PIC",
                "contributors":[
                    "Sara Zullino",
                    "Alessandro Paglialonga",
                    "Walter Dastr",
                    "Dario Longo",
                    "Silvio Aime"
                ],
                "page_id":"xnat_pic",
                "affiliations":[
                    "Euro BioImaging",
                    "IT"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "storage",
                        "data_analysis"
                    ],
                    "your_domain":[

                    ]
                },
                "description":"XNAT for Preclinical Imaging Centers (XNAT-PIC) is a of set of tools to store, process and share preclinical imaging studies built on top of the XNAT imaging informatics platform.",
                "training":[
                    {
                        "name":"EOSC-Life website",
                        "url":"https:\/\/www.eosc-life.eu\/d5\/"
                    },
                    {
                        "name":"Euro-Bioimaging website",
                        "url":"https:\/\/www.eurobioimaging.eu\/news\/towards-sharing-and-reusing-of-preclinical-image-data"
                    },
                    {
                        "name":"Data Management - Biological and Preclinical Imaging Perspective",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=QNiAGuFk53w"
                    },
                    {
                        "name":"XNAT-PIC - expanding XNAT for image archiving and processing to Preclinical Imaging Centers",
                        "registry":"YouTube",
                        "url":"ttps:\/\/www.youtube.com\/cpEcfIJJqCo"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_marine_metagenomics_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/marine_metagenomics_assembly.md",
        "file_name":"marine_metagenomics_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- ELIXIR Europe\n- 'NO'\ncontributors:\n- Nazeefa Fatima\n- Espen berg\n- Nils Peder Willassens\ndescription: The Marine Metagenomics tool assembly aims to provide a comprehensive\n  data management toolkit of marine genomics researchers in Norway. page_id: marine_assembly\nrelated_pages: your_domain:\n  - marine\n  your_tasks:\n  - dmp\n  - existing_data\n  - data_organisation\n  - storage\n  - data_publication\n  - data_transfer\n  - metadata\n  - data_analysis\ntitle: Marine Metagenomics\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=marine+metagenomics\n- name: ELIXIR Norways training pages\n  url: https:\/\/elixir.no\/training\/material\n- name: Workshop materials on ELIXIR-SI eLearning Platform (EeLP)\n  url: https:\/\/elixir.mf.uni-lj.si\/course\/index.php?categoryid=16",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"marine_metagenomics_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_marine_metagenomics_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/marine_metagenomics_assembly.md",
        "file_name":"marine_metagenomics_assembly.md",
        "chunk_index":0,
        "total_chunks":7,
        "content":"What is the Norwegian tool assembly for marine metagenomics data management? The Norwegian tool assembly for marine metagenomics aims to provide a comprehensive toolkit for management of marine genomic research data throughout a project's data life cycle. The toolkit, developed by students and researchers in Norway, contains resources and software tools for both data management (Planning, Processing, Storing and Sharing), data analysis and training. It is built on the Norwegian e-Infrastructure for Life Sciences (NeLS) tool assembly of ELIXIR Norway and the Marine Metagenomics Platform (MMP). Who can use the marine metagenomics data management tool assembly? This tool assembly is useful for students and researchers, in Norway, who are interested in analysing marine datasets (e.g. genomes, metagenomes, and transcriptomes).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine Metagenomics",
                "contributors":[
                    "Nazeefa Fatima",
                    "Espen berg",
                    "Nils Peder Willassens"
                ],
                "description":"The Marine Metagenomics tool assembly aims to provide a comprehensive data management toolkit of marine genomics researchers in Norway.",
                "page_id":"marine_assembly",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "existing_data",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "marine"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine+metagenomics"
                    },
                    {
                        "name":"ELIXIR Norways training pages",
                        "url":"https:\/\/elixir.no\/training\/material"
                    },
                    {
                        "name":"Workshop materials on ELIXIR-SI eLearning Platform (EeLP)",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/course\/index.php?categoryid=16"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/marine_metagenomics_assembly.md",
        "file_name":"marine_metagenomics_assembly.md",
        "chunk_index":1,
        "total_chunks":7,
        "content":"ay, who are interested in analysing marine datasets (e.g. genomes, metagenomes, and transcriptomes). Parts of the assembly, such as data storage, are based on national infrastructures, laws and regulations, and consequently limited to Norwegian users, while other parts, such as data analysis tools and data repositories, are globally accessible. How can you access the marine metagenomics data management tool assembly? To be able to use resources and tools that are mentioned here, you are recommended to have a Feide account. In addition, it is important for you to have a NeLs account in order to access usegalaxy.no. In case your institution does not use the national Feide secure login service, you can apply for a NeLs IDP through the ELIXIR Norway help desk. Note, that Marine Metagenomics Platform (MMP) is an open-access platform that can be accessed without a Feide account at https:\/\/mmp2.sfb.uit.no\/. For what purpose can you use the marine metagenomics data management tool assembly? {% include image.html file=\"mmp_assembly.svg\" caption=\"Figure 1.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine Metagenomics",
                "contributors":[
                    "Nazeefa Fatima",
                    "Espen berg",
                    "Nils Peder Willassens"
                ],
                "description":"The Marine Metagenomics tool assembly aims to provide a comprehensive data management toolkit of marine genomics researchers in Norway.",
                "page_id":"marine_assembly",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "existing_data",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "marine"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine+metagenomics"
                    },
                    {
                        "name":"ELIXIR Norways training pages",
                        "url":"https:\/\/elixir.no\/training\/material"
                    },
                    {
                        "name":"Workshop materials on ELIXIR-SI eLearning Platform (EeLP)",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/course\/index.php?categoryid=16"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/marine_metagenomics_assembly.md",
        "file_name":"marine_metagenomics_assembly.md",
        "chunk_index":2,
        "total_chunks":7,
        "content":"mics data management tool assembly? {% include image.html file=\"mmp_assembly.svg\" caption=\"Figure 1. The Marine Metagenomics data management tool assembly.\" alt=\"Diagram on tools in the Data Life Cycle in the Marine Metagenomics tool assembly.\" %}\nData management planning\nThe support for data management planning and the Data Management Plan model for marine metagenomics in Norway is provided through the ELIXIR-NO instance of the Data Stewardship Wizard. To read more on standards and best practices for the metagenomics data life-cycle, we refer you to a publication for further reading. Questions regarding the DSW and data management in general can be directed to the ELIXIR Norway helpdesk. Data collection",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine Metagenomics",
                "contributors":[
                    "Nazeefa Fatima",
                    "Espen berg",
                    "Nils Peder Willassens"
                ],
                "description":"The Marine Metagenomics tool assembly aims to provide a comprehensive data management toolkit of marine genomics researchers in Norway.",
                "page_id":"marine_assembly",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "existing_data",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "marine"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine+metagenomics"
                    },
                    {
                        "name":"ELIXIR Norways training pages",
                        "url":"https:\/\/elixir.no\/training\/material"
                    },
                    {
                        "name":"Workshop materials on ELIXIR-SI eLearning Platform (EeLP)",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/course\/index.php?categoryid=16"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/marine_metagenomics_assembly.md",
        "file_name":"marine_metagenomics_assembly.md",
        "chunk_index":3,
        "total_chunks":7,
        "content":"he DSW and data management in general can be directed to the ELIXIR Norway helpdesk. Data collection If you use one of the National Norwegian research infrastructures, such as the Norwegian sequencing infrastructure NorSeq, they can directly upload data to your NeLS project for you, as described in this page\nData storage, sharing and compute\nThe solutions for data storage, sharing and computation are built on the services and infrastructure delivered by ELIXIR Norway described in the Norwegian e-Infrastructure for Life Sciences (NeLS) tool assembly. Data processing and analysis\nThe {% tool \"marine-metagenomics-portal\" %} provides a complete service for analysis of marine metagenomic data through the tool META-pipe. META-pipe is a pipeline that can assemble your high-throughput sequence data, functionally annotate the predicted genes, and taxonomically profile your marine metagenomics samples, helping you to gain insight into the phylogenetic diversity, metabolic and functional potential of environmental communities. You can read more details about META-pipe in the publication.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine Metagenomics",
                "contributors":[
                    "Nazeefa Fatima",
                    "Espen berg",
                    "Nils Peder Willassens"
                ],
                "description":"The Marine Metagenomics tool assembly aims to provide a comprehensive data management toolkit of marine genomics researchers in Norway.",
                "page_id":"marine_assembly",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "existing_data",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "marine"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine+metagenomics"
                    },
                    {
                        "name":"ELIXIR Norways training pages",
                        "url":"https:\/\/elixir.no\/training\/material"
                    },
                    {
                        "name":"Workshop materials on ELIXIR-SI eLearning Platform (EeLP)",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/course\/index.php?categoryid=16"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/marine_metagenomics_assembly.md",
        "file_name":"marine_metagenomics_assembly.md",
        "chunk_index":4,
        "total_chunks":7,
        "content":"otential of environmental communities. You can read more details about META-pipe in the publication. Norwegian users with Feide access can access the online version of META-pipe. For other users META-pipe is downloadable and can easily be run on any computing environment (e.g. any Linux workstation, SLURM cluster or Kubernetes). Usegalaxy.no is a Norwegian instance of the {% tool \"galaxy\" %} web-based platform for data intensive life science research that provides users with a unified, easy-to-use graphical interface to a host of more than 200 different analysis tools. Here, you can find tools for a wide variety of analysis for your marine metagenomic and genomic data. The tools are publicly available in the Galaxy Toolshed which serves as an \"appstore\" so you can easily transfer them to your favourite Galaxy instance anywhere. You can run the tools interactively, one by one, or combine them into multi-step workflows that can be executed as a single analysis.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine Metagenomics",
                "contributors":[
                    "Nazeefa Fatima",
                    "Espen berg",
                    "Nils Peder Willassens"
                ],
                "description":"The Marine Metagenomics tool assembly aims to provide a comprehensive data management toolkit of marine genomics researchers in Norway.",
                "page_id":"marine_assembly",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "existing_data",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "marine"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine+metagenomics"
                    },
                    {
                        "name":"ELIXIR Norways training pages",
                        "url":"https:\/\/elixir.no\/training\/material"
                    },
                    {
                        "name":"Workshop materials on ELIXIR-SI eLearning Platform (EeLP)",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/course\/index.php?categoryid=16"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_assembly_md_5",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/marine_metagenomics_assembly.md",
        "file_name":"marine_metagenomics_assembly.md",
        "chunk_index":5,
        "total_chunks":7,
        "content":"ly, one by one, or combine them into multi-step workflows that can be executed as a single analysis. Premade workflows (i.e for Taxonomic classification of metagenomic sequences) are provided, and you can request installation of your favourite tool by contacting the ELIXIR Norway help desk. Data sharing and publishing\nELIXIR Norway acts as a broker for Norwegian end-users that wish to submit data to {% tool \"elixir-deposition-databases-for-biomolecular-data\" %} (such as ENA), providing support in submitting the data on behalf of the data owners directly from the National e-infrastructure for Life Science (NeLS). If you need help with publishing or are interested in using the brokering service, please contact the ELIXIR Norway help desk. Data reuse\nThe {% tool \"marine-metagenomics-portal\" %} provides you with high-quality curated and freely accessible microbial genomics and metagenomics resources.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine Metagenomics",
                "contributors":[
                    "Nazeefa Fatima",
                    "Espen berg",
                    "Nils Peder Willassens"
                ],
                "description":"The Marine Metagenomics tool assembly aims to provide a comprehensive data management toolkit of marine genomics researchers in Norway.",
                "page_id":"marine_assembly",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "existing_data",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "marine"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine+metagenomics"
                    },
                    {
                        "name":"ELIXIR Norways training pages",
                        "url":"https:\/\/elixir.no\/training\/material"
                    },
                    {
                        "name":"Workshop materials on ELIXIR-SI eLearning Platform (EeLP)",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/course\/index.php?categoryid=16"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_marine_metagenomics_assembly_md_6",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/marine_metagenomics_assembly.md",
        "file_name":"marine_metagenomics_assembly.md",
        "chunk_index":6,
        "total_chunks":7,
        "content":"s you with high-quality curated and freely accessible microbial genomics and metagenomics resources. Through MMP you can access the The Marine reference databases ({% tool \"marref\" %}), Marine Genome Database({% tool \"mardb\" %}), database for marine fungi genomes ({% tool \"marfun\" %}), and salmon specific database of genome sequenced prokaryotes({% tool \"saldb\" %}) databases. They are built by aggregating data from a number of publicly available sequences, taxonomy and literature databases in a semi-automatic fashion. Other databases or resources such as bacterial diversity and culture collections databases, web mapping service and ontology databases are used extensively for curation of metadata. At present the {% tool \"marref\" %} contains nearly 1000 complete microbial genomes, and {% tool \"mardb\" %} hosts more than 13,000 non-complete genomes. The MAR database entries are cross-referenced with ENA and the World Register of Marine Species - you can read the publication about the Mar databases.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"marine_metagenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Marine Metagenomics",
                "contributors":[
                    "Nazeefa Fatima",
                    "Espen berg",
                    "Nils Peder Willassens"
                ],
                "description":"The Marine Metagenomics tool assembly aims to provide a comprehensive data management toolkit of marine genomics researchers in Norway.",
                "page_id":"marine_assembly",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "existing_data",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "marine"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=marine+metagenomics"
                    },
                    {
                        "name":"ELIXIR Norways training pages",
                        "url":"https:\/\/elixir.no\/training\/material"
                    },
                    {
                        "name":"Workshop materials on ELIXIR-SI eLearning Platform (EeLP)",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/course\/index.php?categoryid=16"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_galaxy_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/galaxy_assembly.md",
        "file_name":"galaxy_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- ELIXIR Europe\n- European Union\ncontributors:\n- Amandine Nunes-Jorge\n- Beatriz Serrano-Solano\ndescription: Galaxy is an open, web-based platform for accessible, reproducible, and\n  transparent computational research. page_id: galaxy\nrelated_pages:\n  your_tasks:\n  - data_analysis\n  - data_organisation\n  - data_publication\n  - data_quality\n  - data_transfer\n  - existing_data\n  - identifiers\n  - machine_actionability\n  - metadata\ntitle: Galaxy\ntraining:\n- name: Galaxy Training Network\n  url: https:\/\/training.galaxyproject.org\/\n- name: Galaxy Mentor Network\n  url: https:\/\/galaxy-mentor-network.netlify.app\/\n- name: Training in TeSS\n  registry: TeSS\n  registry_url: https:\/\/tess.elixir-europe.org\n  url: https:\/\/tess.elixir-europe.org\/search?q=galaxy",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"galaxy_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_galaxy_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/galaxy_assembly.md",
        "file_name":"galaxy_assembly.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"What is Galaxy? Galaxy is a well-known open-source platform for FAIR data analysis that enables users to:\n- access and collect data from reference databases, external repositories and other data sources;\n- use tools from various domains that can be plugged into workflows through its graphical web interface;\n- run code in interactive environments (RStudio, Jupyter...) along with other tools or workflows;\n- manage data by sharing and publishing results, workflows, and visualizations;\n- capture the metadata of data analyses, thus ensuring their reproducibility. Galaxy supports scientists to perform accessible, reproducible, and transparent computational analysis. The Galaxy Community is actively involved in helping the ecosystem improve and sharing scientific discoveries. Who can use Galaxy? Galaxy also provides open infrastructure ready to use for researchers worldwide.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"galaxy_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Galaxy",
                "contributors":[
                    "Amandine Nunes-Jorge",
                    "Beatriz Serrano-Solano"
                ],
                "description":"Galaxy is an open, web-based platform for accessible, reproducible, and transparent computational research.",
                "page_id":"galaxy",
                "affiliations":[
                    "ELIXIR Europe",
                    "European Union"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "data_publication",
                        "data_quality",
                        "data_transfer",
                        "existing_data",
                        "identifiers",
                        "machine_actionability",
                        "metadata"
                    ]
                },
                "training":[
                    {
                        "name":"Galaxy Training Network",
                        "url":"https:\/\/training.galaxyproject.org\/"
                    },
                    {
                        "name":"Galaxy Mentor Network",
                        "url":"https:\/\/galaxy-mentor-network.netlify.app\/"
                    },
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=galaxy"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_galaxy_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/galaxy_assembly.md",
        "file_name":"galaxy_assembly.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"Who can use Galaxy? Galaxy also provides open infrastructure ready to use for researchers worldwide. All what you need is a web browser and an account in a public server:\n- European Galaxy server\n- US Galaxy server\n- Australian Galaxy server\nWhat can you use Galaxy for? Galaxy can be used at different stages of the data life cycle, covering from the data collection to the reuse steps. Collect\n\n\nAccess to databases\n\n{% tool \"uniprot\" %}\nInterMine\n{% tool \"omero\" %}\n{% tool \"omicsdi\" %}\nCopernicus\nUCSC genome browser (tutorial) NCBI datasets\n{% tool \"international-nucleotide-sequence-database-collaboration\" %}\n{% tool \"european-nucleotide-archive\" %}\n{% tool \"pdb\" %}\n3rd-party databases\n\nCustomised data access\n\nData libraries\nBYOD (Posix, WebDav, Dropbox, ...)\nOn-demand reference data\nDeferred data from remote locations\n\nLIMS integration\n\nConnect to sequencing facilities\nRich API for integration with LIMS\n\n\n\n\n\n\n\n\nProcess\n\n\nData transformation\n\nData transformation tools\nQuality control\nData cleaning\nAnnotation\nInteractive Tools (OpenRefine, RStudio, Jupyter Notebook)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"galaxy_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Galaxy",
                "contributors":[
                    "Amandine Nunes-Jorge",
                    "Beatriz Serrano-Solano"
                ],
                "description":"Galaxy is an open, web-based platform for accessible, reproducible, and transparent computational research.",
                "page_id":"galaxy",
                "affiliations":[
                    "ELIXIR Europe",
                    "European Union"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "data_publication",
                        "data_quality",
                        "data_transfer",
                        "existing_data",
                        "identifiers",
                        "machine_actionability",
                        "metadata"
                    ]
                },
                "training":[
                    {
                        "name":"Galaxy Training Network",
                        "url":"https:\/\/training.galaxyproject.org\/"
                    },
                    {
                        "name":"Galaxy Mentor Network",
                        "url":"https:\/\/galaxy-mentor-network.netlify.app\/"
                    },
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=galaxy"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_galaxy_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/galaxy_assembly.md",
        "file_name":"galaxy_assembly.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"s\nQuality control\nData cleaning\nAnnotation\nInteractive Tools (OpenRefine, RStudio, Jupyter Notebook) Import workflows\n\n{% tool \"workflowhub\" %}\nDockstore\nGA4GH TRS API\n\nMetadata handling\n\nProvenance tracking\nAutomatic metadata enrichment\nBulk (meta)data manipulation\n\n\n\n\n\n\n\n\nAnalyse\n\n\n2,900 domain-specific tools\n\nCancer research\nClimate science\nComputational chemistry\nEcology\nGenomics\nImaging\nMaterial science\nMetabolomics\nMicrobiome\nMachine learning\nPlant biology\nProteomics\nSingle-cell omics\n\n\n\n\n\n\n\n\nPreserve\n\n\nExport artefacts\n\nWorkflows\nHistory\nDatasets\n\nFormats\n\nArchive file\nBioCompute Object\n{% tool \"research-object-crate\" %}\n\nExport to remote sources\n\nFTP\nDropbox\nS3 Bucket\nAWS\nGDrive\nNextcloud\nWebDav\nGoogle Cloud Storage\n\n\n\n\n\n\n\n\nShare\n\n\nShare artefacts\n\nDatasets\nHistories\nWorkflows\nVisualizations\nGA4GH Beacon (WIP)\nDRS server\n\nShareability\n\nRBAC (Role-Based Access Control)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"galaxy_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Galaxy",
                "contributors":[
                    "Amandine Nunes-Jorge",
                    "Beatriz Serrano-Solano"
                ],
                "description":"Galaxy is an open, web-based platform for accessible, reproducible, and transparent computational research.",
                "page_id":"galaxy",
                "affiliations":[
                    "ELIXIR Europe",
                    "European Union"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "data_publication",
                        "data_quality",
                        "data_transfer",
                        "existing_data",
                        "identifiers",
                        "machine_actionability",
                        "metadata"
                    ]
                },
                "training":[
                    {
                        "name":"Galaxy Training Network",
                        "url":"https:\/\/training.galaxyproject.org\/"
                    },
                    {
                        "name":"Galaxy Mentor Network",
                        "url":"https:\/\/galaxy-mentor-network.netlify.app\/"
                    },
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=galaxy"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_galaxy_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/galaxy_assembly.md",
        "file_name":"galaxy_assembly.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"rkflows\nVisualizations\nGA4GH Beacon (WIP)\nDRS server\n\nShareability\n\nRBAC (Role-Based Access Control) One user\nA group of users\nPublic\n\n\n\n\n\n\n\n\n\nReuse\n\n\nAccount cleaning\n\nStorage dashboard to manage quota\nBulk (permanent) delete\nQuota temporarily extendable\nMultiple quota per object storage (WIP)\n\nImport artefacts\n\nHistories (own, shared by others)\nWorkflows from the {% tool \"workflowhub\" %}",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"galaxy_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Galaxy",
                "contributors":[
                    "Amandine Nunes-Jorge",
                    "Beatriz Serrano-Solano"
                ],
                "description":"Galaxy is an open, web-based platform for accessible, reproducible, and transparent computational research.",
                "page_id":"galaxy",
                "affiliations":[
                    "ELIXIR Europe",
                    "European Union"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_organisation",
                        "data_publication",
                        "data_quality",
                        "data_transfer",
                        "existing_data",
                        "identifiers",
                        "machine_actionability",
                        "metadata"
                    ]
                },
                "training":[
                    {
                        "name":"Galaxy Training Network",
                        "url":"https:\/\/training.galaxyproject.org\/"
                    },
                    {
                        "name":"Galaxy Mentor Network",
                        "url":"https:\/\/galaxy-mentor-network.netlify.app\/"
                    },
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=galaxy"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_transmed_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- ELIXIR Europe\n- LU\ncontributors:\n- Wei Gu\n- Soumyabrata Ghosh\n- Muhammad Shoaib\n- Irina Balaur\n- Xinhui Wang\n- Carlos Vega\n- Pinar Alper\n- Venkata Satagopam\ndescription: TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical\n  and translational biomedicine. page_id: transmed\nrelated_pages:\n  your_domain:\n  - human_data\n  your_tasks:\n  - compliance\n  - storage\n  - metadata\n  - data_organisation\n  - data_analysis\n  - sensitive\n  - gdpr_compliance\n  - dmp\ntitle: TransMed",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"transmed_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_transmed_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":0,
        "total_chunks":8,
        "content":"What is the TransMed data and computing tool assembly? The TransMed data and computing tool assembly is an infrastructure provided by ELIXIR Luxembourg for clinical and translational projects. TransMed assembly provides the tools for managing ongoing projects that often require the management of cohort recruitment, and processing of samples, data and metadata. This entails GDPR-compliant and secure data collection, storage, curation, standardisation integration and analysis of clinical data and associated molecular, imaging and sensor\/mobile data and metadata. TransMed tool assembly is also a blueprint showing how a collection of tools can be combined to support data lifecycle management in clinical and translational projects. Who can use the TransMed data and computing tool assembly? All researchers can use tools in the TransMed assembly individually or in combination depending on their project needs. Most of the tools in the TransMed assembly are open-source and can be re-used.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"transmed_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TransMed",
                "contributors":[
                    "Wei Gu",
                    "Soumyabrata Ghosh",
                    "Muhammad Shoaib",
                    "Irina Balaur",
                    "Xinhui Wang",
                    "Carlos Vega",
                    "Pinar Alper",
                    "Venkata Satagopam"
                ],
                "description":"TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical and translational biomedicine.",
                "page_id":"transmed",
                "affiliations":[
                    "ELIXIR Europe",
                    "LU"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "storage",
                        "metadata",
                        "data_organisation",
                        "data_analysis",
                        "sensitive",
                        "gdpr_compliance",
                        "dmp"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_transmed_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":1,
        "total_chunks":8,
        "content":" their project needs. Most of the tools in the TransMed assembly are open-source and can be re-used. ELIXIR Luxembourg provides know-how transfer and training on the tool assembly upon request from researchers and data steward organisations. To make a request please contact info@elixir-luxembourg.org. Additionally, ELIXIR Luxembourg provides hosting of the TransMed assembly. Hosting of tools and data is free of charge for national users. For international users hosting of data (up to 10TB) is free on the basis that the data is shared with the wider research community with an appropriate access model such as controlled access. For international users, charges for the hosting tools and hosting of large datasets are evaluated on a case-by-case, please contact info@elixir-luxembourg.org for details. For what purpose can the TransMed assembly be used?\n{% include image.html file=\"TransMed_assembly.svg\" caption=\"Figure 1.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"transmed_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TransMed",
                "contributors":[
                    "Wei Gu",
                    "Soumyabrata Ghosh",
                    "Muhammad Shoaib",
                    "Irina Balaur",
                    "Xinhui Wang",
                    "Carlos Vega",
                    "Pinar Alper",
                    "Venkata Satagopam"
                ],
                "description":"TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical and translational biomedicine.",
                "page_id":"transmed",
                "affiliations":[
                    "ELIXIR Europe",
                    "LU"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "storage",
                        "metadata",
                        "data_organisation",
                        "data_analysis",
                        "sensitive",
                        "gdpr_compliance",
                        "dmp"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_transmed_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":2,
        "total_chunks":8,
        "content":"the TransMed assembly be used?\n{% include image.html file=\"TransMed_assembly.svg\" caption=\"Figure 1. TransMed data and computing tool assembly\" alt=\"TransMed tool assembly\" %}\nData management planning\nTranslational Biomedicine projects often deal with sensitive data from human subjects. Therefore, data management planning of this type of projects needs to take data protection and GDPR compliance into account . Typically a TransMed project involves  multiple (clinical) study sites and can contain several cohorts. During the planning phase the dataflow for the project and data\/metadata collected prospectively or retrospectively needs to be documented. Projects can use the Data Information Sheet DISH to map the project dataflow and collect metadata necessary for GDPR-compliant processing. In addition, a data protection impact assessment needs to be performed taking into account partner roles, responsibilities and the data information collected via the DISH.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"transmed_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TransMed",
                "contributors":[
                    "Wei Gu",
                    "Soumyabrata Ghosh",
                    "Muhammad Shoaib",
                    "Irina Balaur",
                    "Xinhui Wang",
                    "Carlos Vega",
                    "Pinar Alper",
                    "Venkata Satagopam"
                ],
                "description":"TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical and translational biomedicine.",
                "page_id":"transmed",
                "affiliations":[
                    "ELIXIR Europe",
                    "LU"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "storage",
                        "metadata",
                        "data_organisation",
                        "data_analysis",
                        "sensitive",
                        "gdpr_compliance",
                        "dmp"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_transmed_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":3,
        "total_chunks":8,
        "content":"taking into account partner roles, responsibilities and the data information collected via the DISH. For this purpose TransMed assembly uses the Data Information System - {% tool \"daisy\" %}, which indexes all information collected by DISH and provides a repository to accumulate GDPR-required project documentation  such as ethics approvals and consent templates and subject information sheets and ultimately the project data management plan. TransMed assembly includes the risk management tool {% tool \"monarc\" %}, which can be used to perform Data Protection Impact Assessments (DPIA). DPIAs are a requirement of the GDPR for projects dealing with sensitive human data. Data collection, transfer and storage\nFor projects involving patient recruitment the TransMed assembly provides the Smart Scheduling System, {% tool \"smasch\" %}, tracking availability of resources in clinics and manages patient visits.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"transmed_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TransMed",
                "contributors":[
                    "Wei Gu",
                    "Soumyabrata Ghosh",
                    "Muhammad Shoaib",
                    "Irina Balaur",
                    "Xinhui Wang",
                    "Carlos Vega",
                    "Pinar Alper",
                    "Venkata Satagopam"
                ],
                "description":"TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical and translational biomedicine.",
                "page_id":"transmed",
                "affiliations":[
                    "ELIXIR Europe",
                    "LU"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "storage",
                        "metadata",
                        "data_organisation",
                        "data_analysis",
                        "sensitive",
                        "gdpr_compliance",
                        "dmp"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_transmed_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":4,
        "total_chunks":8,
        "content":"stem, {% tool \"smasch\" %}, tracking availability of resources in clinics and manages patient visits. Pseudonymised clinical data and patient surveys are then collected by the state of the art electronic data capture (EDC) system {% tool \"redcap\" %} through a battery of electronic case report forms (eCRFs). Imaging data from the clinics are deposited into a dedicated imaging platform {% tool \"xnat\" %}. Omics data, both in raw and derived form can be deposited to the data provenance system {% tool \"irods\" %}. The transfer of data files can be done via various encrypted communication options as outlined in the Data transfer section of the RDMkit. The TransMed assembly most typically utilises (S)FTP, Aspera FASP and ownCloud. Data is also encrypted at rest with hard-ware and also with file-level encryption using either open-source utilities such as gpg or commercial options such as Aspera FASP. Data curation and harmonisation\nTo facilitate cross-cohort\/cross-study interoperability of data, upon collection, the data needs to be curated and harmonised.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"transmed_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TransMed",
                "contributors":[
                    "Wei Gu",
                    "Soumyabrata Ghosh",
                    "Muhammad Shoaib",
                    "Irina Balaur",
                    "Xinhui Wang",
                    "Carlos Vega",
                    "Pinar Alper",
                    "Venkata Satagopam"
                ],
                "description":"TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical and translational biomedicine.",
                "page_id":"transmed",
                "affiliations":[
                    "ELIXIR Europe",
                    "LU"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "storage",
                        "metadata",
                        "data_organisation",
                        "data_analysis",
                        "sensitive",
                        "gdpr_compliance",
                        "dmp"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_transmed_assembly_md_5",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":5,
        "total_chunks":8,
        "content":"\/cross-study interoperability of data, upon collection, the data needs to be curated and harmonised. For this purpose the TransMed assembly uses a variety of open standards and tools. For data quality and cleansing the assembly uses {% tool \"openrefine\" %}, which provides an intuitive interface to generate facets of data that support the research to identify quality issues and outliner. It also enables traceable and yet easy data correction. For data Extraction, Transformation and Loading (ETL) the assembly uses {% tool \"talend\" %} Open Studio (for complex and reusable ETLs) as well as R and Python (for ad-hoc and simple transformation). To evaluate and improve FAIRness of datasets, the assembly follows the recipes in the {% tool \"fair-cookbook\" %} developed by the FAIRplus consortium. Related to standard data models and ontologies the assembly follows the recommendations in the  FAIR Cookbook recipe for selecting terminologies and ontologies.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"transmed_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TransMed",
                "contributors":[
                    "Wei Gu",
                    "Soumyabrata Ghosh",
                    "Muhammad Shoaib",
                    "Irina Balaur",
                    "Xinhui Wang",
                    "Carlos Vega",
                    "Pinar Alper",
                    "Venkata Satagopam"
                ],
                "description":"TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical and translational biomedicine.",
                "page_id":"transmed",
                "affiliations":[
                    "ELIXIR Europe",
                    "LU"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "storage",
                        "metadata",
                        "data_organisation",
                        "data_analysis",
                        "sensitive",
                        "gdpr_compliance",
                        "dmp"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_transmed_assembly_md_6",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":6,
        "total_chunks":8,
        "content":"follows the recommendations in the  FAIR Cookbook recipe for selecting terminologies and ontologies. Data integration and analysis\nTransMed projects usually require different data types from different cohorts to be integrated into one data platform for the exploring, sub-setting and integrated analysis for hypothesis generation. The TransMed assembly consists of several such tools: {% tool \"ada-discovery-analytics\" %} is a web-based tool to provide a performant and highly configurable system for secured integration, visualization, and collaborative analysis of heterogeneous data sets, primarily targeting clinical and experimental sources. The assembly also includes other tools for specific data types, such as {% tool \"atlas\" %} that integrate features from various {% tool \"ohdsi\" %} applications for Electronic Health Record data in {% tool \"omop-cdm\" %} format into a single cohesive experience. {% tool \"transmart\" %} is a tool that provides easy integration between phenotypic\/clinical data and molecular data and a drag-and-drop fashion data exploration interface.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"transmed_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TransMed",
                "contributors":[
                    "Wei Gu",
                    "Soumyabrata Ghosh",
                    "Muhammad Shoaib",
                    "Irina Balaur",
                    "Xinhui Wang",
                    "Carlos Vega",
                    "Pinar Alper",
                    "Venkata Satagopam"
                ],
                "description":"TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical and translational biomedicine.",
                "page_id":"transmed",
                "affiliations":[
                    "ELIXIR Europe",
                    "LU"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "storage",
                        "metadata",
                        "data_organisation",
                        "data_analysis",
                        "sensitive",
                        "gdpr_compliance",
                        "dmp"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                }
            }
        }
    },
    {
        "id":"md_content_transmed_assembly_md_7",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/transmed_assembly.md",
        "file_name":"transmed_assembly.md",
        "chunk_index":7,
        "total_chunks":8,
        "content":"henotypic\/clinical data and molecular data and a drag-and-drop fashion data exploration interface. Data stewardship\nTo facilitate the findability of data the TransMed assembly provides a {% tool \"data-catalog\" %} tool that supports the indexing search and discovery of studies, data sets and samples accumulated in the context of projects from different sites and cohorts. The catalog implements a controlled-access model by integration with {% tool \"rems\" %}. Audit trailing of data access is achieved by integration of the {% tool \"daisy\" %} in the access process. The catalog tool can be integrated with various identity management systems such as {% tool \"keycloak\" %}, {% tool \"life-science-login\" %} or {% tool \"free-ipa\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"transmed_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"TransMed",
                "contributors":[
                    "Wei Gu",
                    "Soumyabrata Ghosh",
                    "Muhammad Shoaib",
                    "Irina Balaur",
                    "Xinhui Wang",
                    "Carlos Vega",
                    "Pinar Alper",
                    "Venkata Satagopam"
                ],
                "description":"TransMed tool assembly from ELIXIR Luxembourg supports projects in clinical and translational biomedicine.",
                "page_id":"transmed",
                "affiliations":[
                    "ELIXIR Europe",
                    "LU"
                ],
                "related_pages":{
                    "your_tasks":[
                        "compliance",
                        "storage",
                        "metadata",
                        "data_organisation",
                        "data_analysis",
                        "sensitive",
                        "gdpr_compliance",
                        "dmp"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                }
            }
        }
    },
    {
        "id":"md_fm_plant_phenomics_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"affiliations: null\ncontributors:\n- Anne-Franoise Adam-Blondon\n- Cyril Pommier\n- Bert Droesbeke\n- Matthias Lange\n- Daniel Arend\n- Daniel Faria\n- Isabelle Alic\n- Philippe Rocca-Serra\n- Sebastian Beier\n- Erwan Le Floch\ndescription: Tool assembly for managing plant phenomic data. faircookbook:\n- name:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_plant_phenomics_assembly_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"\n- Erwan Le Floch\ndescription: Tool assembly for managing plant phenomic data. faircookbook:\n- name: Publishing plant phenotypic data\n  url: https:\/\/w3id.org\/faircookbook\/FCB083\npage_id: plant_pheno_assembly\nrelated_pages:\n  tool_assembly:\n  - plant_geno_assembly\n  your_domain:\n  - plants\n  your_tasks:\n  - metadata\n  - data_publication\ntitle: Plant Phenomics\ntraining:\n- name: MIAPPE training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=miappe\n- name: MIAPPE templates on GitHub\n  registry: GitHub\n  url: https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates\n- name: PHIS user documentation\n  registry: null\n  url: https:\/\/opensilex.github.io\/phis-docs-community\/\n- name: PHIS developer documentation\n  registry: null\n  url: https:\/\/opensilex.github.io\/docs-community-dev\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":0,
        "total_chunks":12,
        "content":"What is the plant phenomics tool assembly and who can use it? The plant phenomics tool assembly covers the whole life cycle of experimental plant phenotyping data. It uses the concepts of the {% tool \"miappe\" %} (Minimum Information About a Plant Phenotyping Experiment) standard: (i) experiments description including organisation, objectives and location, (ii) biological material description and identification and (iii) traits (phenotypic and environmental) description including measurement methodology. A more detailed overview of the MIAPPE standard is available, as well as the full specifications. The plant phenomics tool assembly helps everyone in charge of plant phenotyping data management to enable:\n*",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":1,
        "total_chunks":12,
        "content":"t phenomics tool assembly helps everyone in charge of plant phenotyping data management to enable:\n* the integration of phenotyping data with other omics data: see the general principles on the Plant Sciences domain page;\n* the findability of their data in plant specific (e.g. {% tool \"faidare\" %}) or generic search portal (e.g. Google Data Search);\n* the long term reusability of their data. How can you access the plant phenomics tool assembly? All the components of the plant phenomics tool assembly are publicly available and listed below, but many of them require registration. {% include image.html file=\"plant_phenomics.svg\" caption=\"Figure 1. The plant phenomics tool assembly.\" alt=\"Tools and resources used in managing plant phenomics and phenotyping data.\" %}\nData management planning\nThe general principles to be considered are described in the Plant Sciences domain page. {% tool \"data-stewardship-wizard\" %} is a human-friendly tool for machine-actionable DMP collaborative editing.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":2,
        "total_chunks":12,
        "content":"ta-stewardship-wizard\" %} is a human-friendly tool for machine-actionable DMP collaborative editing. The DSW Plant Sciences project template, available on ELIXIR's DSW instance for researchers can be used for any plant sciences project. When creating the DMP Project, choose the option \"From Project Template\" and search for the \"Plant Sciences\" template. File based data collection\nThe metadata and description of your experiments should be filled using a MIAPPE template. Note that there is a readme that fully describes each field as well as their type and their optional or mandatory status. All fields should be present in the file you are using, even if you leave the optional ones empty. This will allow standard processing and validation using dedicated tools. Experimental data gathering and management\nSystems for file based data collection\n\n{% tool \"fairdom-seek\" %} is an open source web-based data sharing platform used as a repository or a catalog.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":3,
        "total_chunks":12,
        "content":"airdom-seek\" %} is an open source web-based data sharing platform used as a repository or a catalog. It is being deployed as several instances ranging from confidential project data sharing platforms (INRAE\/AGENT, VIB) to public repositories like {% tool \"fairdomhub\" %}. It is MIAPPE compliant through the integration of MIAPPE metadata at the investigation, study and assay levels. It can be used for project based early data sharing, in preparation for long term data storage, but also as a preservation tool for raw data. {% tool \"pisa-tree\" %} is a data management solution developed to contribute to the reproducibility of research and analyses. Hierarchical set of batch files is used to create standardized nested directory tree and associated files for research projects. {% tool \"copo\" %} is a data management platform specific to plant sciences. High throughput dedicated systems\n\n{% tool \"phis\" %} the open-source Phenotyping Hybrid Information System (PHIS), based on OpenSILEX, manages and collects data from Phenotyping and High Throughput Phenotyping experiments on a day to day basis.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":4,
        "total_chunks":12,
        "content":"nd collects data from Phenotyping and High Throughput Phenotyping experiments on a day to day basis. It can store, organize and manage highly heterogeneous (e.g. images, spectra, growth curves) and multi-spatial and temporal scale data (leaf to canopy level) originating from multiple sources (field, greenhouse). It unambiguously identifies all objects and traits in an experiment and establishes their relations via ontologies and semantics that apply to both field and controlled conditions. Its ontology-driven architecture is a powerful tool for integrating and managing data from multiple experiments and platforms, for creating relationships between objects and enriching datasets with knowledge and metadata. It is MIAPPE and BrAPI compliant, and naming conventions are recommended for users to declare their resources. Several experimental platforms use PHIS to manage their data, and PHIS instances dedicated to sharing resources (projects, genetic resources, variables) also exist to allow the sharing of studied concepts.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_5",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":5,
        "total_chunks":12,
        "content":"ources (projects, genetic resources, variables) also exist to allow the sharing of studied concepts. PIPPA is the PSB Interface for Plant Phenotype Analysis, is the central web interface and database that provides the tools for the management of the plant imaging robots on the one hand, and the analysis of images and data on the other hand. The database supports all MIAPPE fields which are accessible through the BrAPI endpoints. Experiment pages are marked up with {% tool \"bioschemas\" %} to improve findability on google. Data processing and analysis\nIt is important to keep in mind the difference between data processing and analysing. Processing provides the tools and procedures to transform primary data, such as imaging or observational data, to appropriate quality and processability. Analysing, on the other hand, is concerned with extracting information from the processed data for the purpose of supporting knowledge acquisition.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_6",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":6,
        "total_chunks":12,
        "content":" extracting information from the processed data for the purpose of supporting knowledge acquisition. Some analysis tools dedicated to plant phenotyping experiments are registered in bio.tools, for example: {% tool \"plant3d\" %},{% tool \"leafnet\" %}, {% tool \"plantcv\" %}, {% tool \"phenomenal-3d\" %}\n\nData sharing\nThe data collected and annotated can be shared in trustworthy repositories under clear conditions of access to the data. As no global central repository exists for phenotyping data, the Plant Science research community combines the use of scattered trustworthy repositories and of centralized search tools. Metadata management\n\n{% tool \"isa4j\" %} is a software library which can help you to programmatically generate ISA-Tab formatted metadata for your experiments. This will make your metadata machine-(and human-)readable and thereby improve the reusability of your work.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_7",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":7,
        "total_chunks":12,
        "content":"ll make your metadata machine-(and human-)readable and thereby improve the reusability of your work. It was especially designed for large datasets and\/or to be included in applications which export data regularly, but of course it can also be used for smaller, individual datasets (although you will need to know how to code). Since version 1.1 it also supports specific term completion and validation for MIAPPE, see the isa4j documentation. Repositories\n\n\n{% tool \"dataverse\" %} is an open source research data repository software used by several research institute over the globe to publicly share heterogenous dataset. In Europe, it is being used among others by the portuguese DMPortal, the german Julich data portal, and the french Recherche Data Gouv (previously Data.INRAE) research communities. Its main strength is its flexibility, as the mandatory metadata are focused on publication information such as title, abstract, authors and keywords.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_8",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":8,
        "total_chunks":12,
        "content":"atory metadata are focused on publication information such as title, abstract, authors and keywords. It can therefore host any datatype, which is both a strength and a weakness, as shared good practices are necessary to ensure the reusability and findability of published phenomic data. {% tool \"e-dal-pgp\" %} is a comprehensive research data repository, which is hosted at the Leibniz Institute of Plant Genetics and Crop Plant Research (IPK) Gatersleben and is mainly focused on sharing high valuable and large genomics and phenomics datasets. It is the first productive instance, which is based on the open source {% tool \"e-dal\" %} infrastructure software and is furthermore a part of the de.NBI\/ELIXIR Germany services. All provided datasets are FAIR compliant and citable via a persistent DOI. By using the widely established LifeScience AAI (formerly known as ELIXIR AAI) the submission procedure is open for all ELIXIR associated users. The key feature of e!DAL-PGP is its user-friendly, simple and FAIR-compliant data submission and internal review procedure.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_9",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":9,
        "total_chunks":12,
        "content":"L-PGP is its user-friendly, simple and FAIR-compliant data submission and internal review procedure. The repository has no general limit to any type of size of datasets. A comprehensive documentation including, guidelines, code snippets for technical integration and videos is available on the project website. {% tool \"gnpis\" %} is a multispecies integrative information system dedicated to plants. It allows researchers to access genetic, MIAPPE compliant phenotypic data as well as genomic data. It is used by both large international projects and the French National Research Institute for Agriculture, Food and Environment. {% tool \"zenodo\" %} is a powerful data publication service, which is supported by the European commission and focused on research data, including supplemental material like software, tables, figures or slides. Therefore the publication is usually associated with the publication of a research paper, book chapters or presentations.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_10",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":10,
        "total_chunks":12,
        "content":"tion is usually associated with the publication of a research paper, book chapters or presentations. The Zenodo data submission form allows to describe every data file with a set of technical metadata based on the DataCite metadata schema, which is necessary and assign a persistent DOI to every dataset. The Zenodo infrastructure is hosted at the CERN and can publish dataset up to a size of 50 GB for free. For larger datasets a specific support request is necessary. A further valuable feature of Zenodo is the connection to GitHub and the provided opportunity to assign a DOI to a concrete version or rather commit of a hosted software repository which allows to persist software scripts, which improves the reproducibility of research workflows and results, which is often a challenge especially for older research publications. Machine actionable data sharing\n\n{% tool \"brapi\" %}(the Breeding API) is a MIAPPE compliant web service specification available on several deposition databases.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_phenomics_assembly_md_11",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_phenomics_assembly.md",
        "file_name":"plant_phenomics_assembly.md",
        "chunk_index":11,
        "total_chunks":12,
        "content":"ding API) is a MIAPPE compliant web service specification available on several deposition databases. Those endpoints can be validated using the BrAPI validator {% tool \"brava\" %} BrAPI hosts several documentation and training material to support its usage. Data reuse\nPlant phenotyping data reuse relies on rich metadata following the MIAPPE specifications annotated with proper ontologies. Most of the important ontologies are registered on FAIRSHARING: use this search example. {% tool \"agroportal\" %} is a vocabulary and ontology repository for agronomy and related domains. {% tool \"faidare\" %}(FAIR Data-finder for Agronomic Research) is a portal facilitating discoverability of public data on plant biology from a federation of established data repositories.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_phenomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Phenomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Bert Droesbeke",
                    "Matthias Lange",
                    "Daniel Arend",
                    "Daniel Faria",
                    "Isabelle Alic",
                    "Philippe Rocca-Serra",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant phenomic data.",
                "page_id":"plant_pheno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_geno_assembly"
                    ]
                },
                "training":[
                    {
                        "name":"MIAPPE training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=miappe"
                    },
                    {
                        "name":"MIAPPE templates on GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/MIAPPE\/MIAPPE\/tree\/master\/MIAPPE_Checklist-Data-Model-v1.1\/MIAPPE_templates"
                    },
                    {
                        "name":"PHIS user documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/phis-docs-community\/"
                    },
                    {
                        "name":"PHIS developer documentation",
                        "registry":null,
                        "url":"https:\/\/opensilex.github.io\/docs-community-dev\/"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Publishing plant phenotypic data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB083"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_omero_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/omero_assembly.md",
        "file_name":"omero_assembly.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"affiliations:\n- Euro BioImaging\ncontributors:\n- Jean-Marie Burel\ndescription: OMERO is a software platform for managing, sharing and analysing images\n  data. page_id: ome\nrelated_pages:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"omero_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_omero_assembly_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/omero_assembly.md",
        "file_name":"omero_assembly.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"s a software platform for managing, sharing and analysing images\n  data. page_id: ome\nrelated_pages: your_domain:\n  - bioimaging_data\n  your_tasks:\n  - data_organisation\n  - storage\n  - data_analysis\n  - metadata\ntitle: OMERO\ntraining:\n- name: General information about the OME ecosystem\n  url: https:\/\/www. openmicroscopy. org\n- name: Collection of presentations given over the years\n  url: https:\/\/downloads. openmicroscopy. org\/presentations\/\n- name: Technical documentation for developers, system administrators\n  url: https:\/\/docs. openmicroscopy. org\/omero\/latest\/\n- name: Collection of workflow describing to how use the system, with links to scripts\n    and notebooks\n  url: https:\/\/omero-guides. readthedocs. io\/en\/latest\/\n- name: YouTube channel with tutorials and presentations\n  registry: YouTube\n  url: https:\/\/www. youtube. com\/channel\/UCyySB9ZzNi8aBGYqcxSrauQ\n- name: 'I3D:bio''s OMERO Training Videos 2023: Research Data Management for Microscopy'\n  registry: YouTube\n  url: https:\/\/www. youtube. com\/playlist.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"omero_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_omero_assembly_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/omero_assembly.md",
        "file_name":"omero_assembly.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"earch Data Management for Microscopy'\n  registry: YouTube\n  url: https:\/\/www. youtube. com\/playlist. list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU\n- name: Imaging Forum - discussions about imaging related topics\n  url: https:\/\/forum. image. sc\/.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"omero_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_omero_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/omero_assembly.md",
        "file_name":"omero_assembly.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"What is OMERO? {% tool \"omero\" %} is a software platform for managing, sharing and analysing images data. OMERO supports over proprietary 150 file formats, including all major microscopy formats, medical images, digital pathology images, high content screening, etc., using {% tool \"bioformats\" %}. Bio-Formats is a Java software tool for reading proprietary image data and metadata and writing image data using standardized open formats. OMERO handles all your images in a secure central repository. Users can view, organize, analyze and share data from anywhere via the internet. Users can work with image data and metadata from a Desktop application, from the Web or from 3rd party tools e.g. {% tool \"fiji\" %}. OMERO stores image metadata in a relational database and offers a more flexible structure based on HDF5 to store for example, analytical results.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"omero_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"OMERO",
                "contributors":[
                    "Jean-Marie Burel"
                ],
                "page_id":"ome",
                "affiliations":[
                    "Euro BioImaging"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "storage",
                        "data_analysis",
                        "metadata"
                    ],
                    "your_domain":[
                        "bioimaging_data"
                    ]
                },
                "description":"OMERO is a software platform for managing, sharing and analysing images data.",
                "training":[
                    {
                        "name":"General information about the OME ecosystem",
                        "url":"https:\/\/www.openmicroscopy.org"
                    },
                    {
                        "name":"Collection of presentations given over the years",
                        "url":"https:\/\/downloads.openmicroscopy.org\/presentations\/"
                    },
                    {
                        "name":"Technical documentation for developers, system administrators",
                        "url":"https:\/\/docs.openmicroscopy.org\/omero\/latest\/"
                    },
                    {
                        "name":"Collection of workflow describing to how use the system, with links to scripts and notebooks",
                        "url":"https:\/\/omero-guides.readthedocs.io\/en\/latest\/"
                    },
                    {
                        "name":"YouTube channel with tutorials and presentations",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCyySB9ZzNi8aBGYqcxSrauQ"
                    },
                    {
                        "name":"I3D:bio's OMERO Training Videos 2023: Research Data Management for Microscopy",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU"
                    },
                    {
                        "name":"Imaging Forum - discussions about imaging related topics",
                        "url":"https:\/\/forum.image.sc\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_omero_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/omero_assembly.md",
        "file_name":"omero_assembly.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"atabase and offers a more flexible structure based on HDF5 to store for example, analytical results. This allows analytical results generated by 3rd party softwares e.g. {% tool \"cellprofiler\" %}, {% tool \"ilastik\" %}, etc., to be stored alongside the images. Recommendations and software tools are being developed to capture acquisition metadata importable into OMERO e.g.\n{% tool \"4dn-bina-ome-quarep\" %}. {% include image.html file=\"ome_informatics.png\" caption=\"Schematic overview of the OMERO tool assembly.\" alt=\"Schematic overview of the OMERO tool assembly.\" %}\nWho is OMERO intended for?\nOMERO is designed to be an institutional repository. It offers a secure central way for scientists, researchers and data stewards to handle their imaging data. All the image data from a facility can be securely stored and managed, using group permissions and user roles to allow controlled access tailored to your institution.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"omero_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"OMERO",
                "contributors":[
                    "Jean-Marie Burel"
                ],
                "page_id":"ome",
                "affiliations":[
                    "Euro BioImaging"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "storage",
                        "data_analysis",
                        "metadata"
                    ],
                    "your_domain":[
                        "bioimaging_data"
                    ]
                },
                "description":"OMERO is a software platform for managing, sharing and analysing images data.",
                "training":[
                    {
                        "name":"General information about the OME ecosystem",
                        "url":"https:\/\/www.openmicroscopy.org"
                    },
                    {
                        "name":"Collection of presentations given over the years",
                        "url":"https:\/\/downloads.openmicroscopy.org\/presentations\/"
                    },
                    {
                        "name":"Technical documentation for developers, system administrators",
                        "url":"https:\/\/docs.openmicroscopy.org\/omero\/latest\/"
                    },
                    {
                        "name":"Collection of workflow describing to how use the system, with links to scripts and notebooks",
                        "url":"https:\/\/omero-guides.readthedocs.io\/en\/latest\/"
                    },
                    {
                        "name":"YouTube channel with tutorials and presentations",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCyySB9ZzNi8aBGYqcxSrauQ"
                    },
                    {
                        "name":"I3D:bio's OMERO Training Videos 2023: Research Data Management for Microscopy",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU"
                    },
                    {
                        "name":"Imaging Forum - discussions about imaging related topics",
                        "url":"https:\/\/forum.image.sc\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_omero_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/omero_assembly.md",
        "file_name":"omero_assembly.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"ged, using group permissions and user roles to allow controlled access tailored to your institution. From private repositories for sensitive data to hosting public data for your website and latest publications, the permissions model is designed to meet the range of researchers needs. OMERO is tried and tested in hundreds of institutions world-wide, with extensive installation and configuration documentation for system administrators and community support via dedicated mailing lists and forums. The OMERO platform uses a Group\/User permission system. The degree to which their data is available to other members of the group depends on the permissions settings for that group. Whenever a user logs on to an OMERO server, they are connected under one of their groups. All data they import and any work that is done is assigned to the current group, however the user can move their data into another group. Users require login credentials to access the system. OMERO also supports the use of an LDAP server. OMERO is an open-source system designed to be extended and integrated with other tools.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"omero_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"OMERO",
                "contributors":[
                    "Jean-Marie Burel"
                ],
                "page_id":"ome",
                "affiliations":[
                    "Euro BioImaging"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "storage",
                        "data_analysis",
                        "metadata"
                    ],
                    "your_domain":[
                        "bioimaging_data"
                    ]
                },
                "description":"OMERO is a software platform for managing, sharing and analysing images data.",
                "training":[
                    {
                        "name":"General information about the OME ecosystem",
                        "url":"https:\/\/www.openmicroscopy.org"
                    },
                    {
                        "name":"Collection of presentations given over the years",
                        "url":"https:\/\/downloads.openmicroscopy.org\/presentations\/"
                    },
                    {
                        "name":"Technical documentation for developers, system administrators",
                        "url":"https:\/\/docs.openmicroscopy.org\/omero\/latest\/"
                    },
                    {
                        "name":"Collection of workflow describing to how use the system, with links to scripts and notebooks",
                        "url":"https:\/\/omero-guides.readthedocs.io\/en\/latest\/"
                    },
                    {
                        "name":"YouTube channel with tutorials and presentations",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCyySB9ZzNi8aBGYqcxSrauQ"
                    },
                    {
                        "name":"I3D:bio's OMERO Training Videos 2023: Research Data Management for Microscopy",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU"
                    },
                    {
                        "name":"Imaging Forum - discussions about imaging related topics",
                        "url":"https:\/\/forum.image.sc\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_omero_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/omero_assembly.md",
        "file_name":"omero_assembly.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"LDAP server. OMERO is an open-source system designed to be extended and integrated with other tools. The OMERO API allows clients to be written in Java, Python, C++ or MATLAB. The OMERO platform includes a Java client OMERO.insight, a Python-based web client OMERO.web, a Command Line Interface which uses Python, and a Java ImageJ plugin. OMERO also supports a scripting service which allows Python scripts to be run on the server and called from any of the other clients. A vast amount of documentation and code examples for scientists, developers and system administrators are available. A demo server maintained by the OME team is also available for users wishing to try out, request an account. {% include image.html file=\"omero_integration.png\" caption=\"3rd party tools and OMERO\" alt=\"3rd party tools and OMERO.\" %}\nWhich tasks can be solved with OMERO? OMERO can be used for the day-to-day data management of data. - Users can remotely view, handle metadata, analyze, generate figures ready for publication, etc.\n-",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"omero_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"OMERO",
                "contributors":[
                    "Jean-Marie Burel"
                ],
                "page_id":"ome",
                "affiliations":[
                    "Euro BioImaging"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "storage",
                        "data_analysis",
                        "metadata"
                    ],
                    "your_domain":[
                        "bioimaging_data"
                    ]
                },
                "description":"OMERO is a software platform for managing, sharing and analysing images data.",
                "training":[
                    {
                        "name":"General information about the OME ecosystem",
                        "url":"https:\/\/www.openmicroscopy.org"
                    },
                    {
                        "name":"Collection of presentations given over the years",
                        "url":"https:\/\/downloads.openmicroscopy.org\/presentations\/"
                    },
                    {
                        "name":"Technical documentation for developers, system administrators",
                        "url":"https:\/\/docs.openmicroscopy.org\/omero\/latest\/"
                    },
                    {
                        "name":"Collection of workflow describing to how use the system, with links to scripts and notebooks",
                        "url":"https:\/\/omero-guides.readthedocs.io\/en\/latest\/"
                    },
                    {
                        "name":"YouTube channel with tutorials and presentations",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCyySB9ZzNi8aBGYqcxSrauQ"
                    },
                    {
                        "name":"I3D:bio's OMERO Training Videos 2023: Research Data Management for Microscopy",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU"
                    },
                    {
                        "name":"Imaging Forum - discussions about imaging related topics",
                        "url":"https:\/\/forum.image.sc\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_omero_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/omero_assembly.md",
        "file_name":"omero_assembly.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":" - Users can remotely view, handle metadata, analyze, generate figures ready for publication, etc.\n- The plaform can also be used to publish data either using public repository like Image Data Repository (IDR) or by enabling the public user within the OMERO installation in a given institution e.g. Liverpool CCI gallery. - It is the software platform for several public image repositories e.g. {% tool \"image-data-resource\" %},{% tool \"empiar\" %}\n- It is also used as a teaching platform by several institutions e.g. University of Dundee, Harvard Medical school.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"omero_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"OMERO",
                "contributors":[
                    "Jean-Marie Burel"
                ],
                "page_id":"ome",
                "affiliations":[
                    "Euro BioImaging"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_organisation",
                        "storage",
                        "data_analysis",
                        "metadata"
                    ],
                    "your_domain":[
                        "bioimaging_data"
                    ]
                },
                "description":"OMERO is a software platform for managing, sharing and analysing images data.",
                "training":[
                    {
                        "name":"General information about the OME ecosystem",
                        "url":"https:\/\/www.openmicroscopy.org"
                    },
                    {
                        "name":"Collection of presentations given over the years",
                        "url":"https:\/\/downloads.openmicroscopy.org\/presentations\/"
                    },
                    {
                        "name":"Technical documentation for developers, system administrators",
                        "url":"https:\/\/docs.openmicroscopy.org\/omero\/latest\/"
                    },
                    {
                        "name":"Collection of workflow describing to how use the system, with links to scripts and notebooks",
                        "url":"https:\/\/omero-guides.readthedocs.io\/en\/latest\/"
                    },
                    {
                        "name":"YouTube channel with tutorials and presentations",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCyySB9ZzNi8aBGYqcxSrauQ"
                    },
                    {
                        "name":"I3D:bio's OMERO Training Videos 2023: Research Data Management for Microscopy",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU"
                    },
                    {
                        "name":"Imaging Forum - discussions about imaging related topics",
                        "url":"https:\/\/forum.image.sc\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_csc_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"affiliations:\n- FI\n- CSC\n- ELIXIR Europe\ncontributors:\n- Siiri Fuchs\n- Minna Ahokas\n- Janina Juuvinmaa\ndescription: The Center of Science (CSC) provides high-quality ICT expert services\n  for researchers in Finland and their collaborators. page_id: csc\nrelated_pages:\n  your_domain:\n  - human_data\n  your_tasks:\n  - sensitive\n  - dmp\n  - data_security\n  - gdpr_compliance\n  - storage\n  - data_publication\n  - data_transfer\n  - data_analysis\ntitle:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"csc_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_csc_assembly_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"rity\n  - gdpr_compliance\n  - storage\n  - data_publication\n  - data_transfer\n  - data_analysis\ntitle: CSC\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=csc\n- name: CSC - Bioscience webpages\n  url: https:\/\/research.csc.fi\/biosciences\n- name: CSC - Training and events webpages\n  url: https:\/\/www.csc.fi\/en\/training\n- name: CSC - Learning Materials for Bioscientists\n  url: https:\/\/research.csc.fi\/bioscience-learning-materials\n- name: CSC - Data management youtube channel\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/watch?v=Ol7mniw687E&list=PLD5XtevzF3yEZw-8LadtaGVV8Um6CbMja\n- name: CSC - Research data management services for life science research (youtube\n    video)\n  url: https:\/\/youtu.be\/lf9L7PYQrBE\n- name: Data analysis with Chipster - Course packages\n  url: https:\/\/chipster.2.rahtiapp.fi\/manual\/courses.html\n- name: Tutorials and lecture playlists on different topics (youtube)\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/channel\/UCnL-Lx5gGlW01OkskZL7JEQ\/playlists",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"csc_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_csc_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":0,
        "total_chunks":7,
        "content":"What is the CSC data management tool assembly?\nCSC  IT Center for Science  and ELIXIR Finland provide services, tools and software for managing research data throughout the project life cycle. Services cover computing environments, analysis programs, tools for storing and sharing data during the project as well as opening and discovering research data. Furthermore, ELIXIR-FI provides flexible infrastructure for bioinformatics data analysis. Services are actively developed, and hence, please visit CSC web pages for the latest updates. Who can use the CSC data management tool assembly?\nCSC and ELIXIR-FI services are available for researchers affiliated with a Finnish academic organisation or research institutes and their international collaborators. Most of CSCs services are free of charge for academic research, education and training purposes in Finnish higher education institutions and state research institutes.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"csc_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"CSC",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Janina Juuvinmaa"
                ],
                "description":"The Center of Science (CSC) provides high-quality ICT expert services for researchers in Finland and their collaborators.",
                "page_id":"csc",
                "affiliations":[
                    "FI",
                    "CSC",
                    "ELIXIR Europe"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "dmp",
                        "data_security",
                        "gdpr_compliance",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=csc"
                    },
                    {
                        "name":"CSC - Bioscience webpages",
                        "url":"https:\/\/research.csc.fi\/biosciences"
                    },
                    {
                        "name":"CSC - Training and events webpages",
                        "url":"https:\/\/www.csc.fi\/en\/training"
                    },
                    {
                        "name":"CSC - Learning Materials for Bioscientists",
                        "url":"https:\/\/research.csc.fi\/bioscience-learning-materials"
                    },
                    {
                        "name":"CSC - Data management youtube channel",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=Ol7mniw687E&list=PLD5XtevzF3yEZw-8LadtaGVV8Um6CbMja"
                    },
                    {
                        "name":"CSC - Research data management services for life science research (youtube video)",
                        "url":"https:\/\/youtu.be\/lf9L7PYQrBE"
                    },
                    {
                        "name":"Data analysis with Chipster - Course packages",
                        "url":"https:\/\/chipster.2.rahtiapp.fi\/manual\/courses.html"
                    },
                    {
                        "name":"Tutorials and lecture playlists on different topics (youtube)",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCnL-Lx5gGlW01OkskZL7JEQ\/playlists"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_csc_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":1,
        "total_chunks":7,
        "content":"cation and training purposes in Finnish higher education institutions and state research institutes. Researchers can start using services by registering anaccountand get bioinformatics user support from our service desk. How can you access the CSC data management tool assembly? You can access all CSC services through several secure authentication methods. Start by registering an account at CSC with your home organization HAKA or VIRTU login or by contacting our service desk. Afterwards you can also use ELIXIR login. Find more information from CSC accounts and support web pages how to get access to different services. For what can you use the CSC data management tool assembly?\n{% include image.html file=\"fi_csc_assembly_v2.svg\" caption=\"Figure 1. The CSC - IT Center for Science data management tool assembly.\" alt=\"CSC RDMkit\" %}\nData management planning\nResearch funders often require a data management plan (DMP) as part of the funding application process or after funding has been approved.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"csc_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"CSC",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Janina Juuvinmaa"
                ],
                "description":"The Center of Science (CSC) provides high-quality ICT expert services for researchers in Finland and their collaborators.",
                "page_id":"csc",
                "affiliations":[
                    "FI",
                    "CSC",
                    "ELIXIR Europe"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "dmp",
                        "data_security",
                        "gdpr_compliance",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=csc"
                    },
                    {
                        "name":"CSC - Bioscience webpages",
                        "url":"https:\/\/research.csc.fi\/biosciences"
                    },
                    {
                        "name":"CSC - Training and events webpages",
                        "url":"https:\/\/www.csc.fi\/en\/training"
                    },
                    {
                        "name":"CSC - Learning Materials for Bioscientists",
                        "url":"https:\/\/research.csc.fi\/bioscience-learning-materials"
                    },
                    {
                        "name":"CSC - Data management youtube channel",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=Ol7mniw687E&list=PLD5XtevzF3yEZw-8LadtaGVV8Um6CbMja"
                    },
                    {
                        "name":"CSC - Research data management services for life science research (youtube video)",
                        "url":"https:\/\/youtu.be\/lf9L7PYQrBE"
                    },
                    {
                        "name":"Data analysis with Chipster - Course packages",
                        "url":"https:\/\/chipster.2.rahtiapp.fi\/manual\/courses.html"
                    },
                    {
                        "name":"Tutorials and lecture playlists on different topics (youtube)",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCnL-Lx5gGlW01OkskZL7JEQ\/playlists"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_csc_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":2,
        "total_chunks":7,
        "content":"management plan (DMP) as part of the funding application process or after funding has been approved. See e.g. guidance on creating a DMP for the Research Council of Finland (former Academy of Finland). There are several tools to guide you through the planning process, such asDMPTuuli, a Finnish instance of DMPonline which includes guidance and templates provided by different organisations and funders. DMPs created in DMPTuuli are not yet machine-actionable or linked to the CSC data management tool assembly services. However, a DMP is a valuable document when contacting and using the CSC research data management services. Other available DMP tools include {%tool \"data-stewardship-wizard\" %} and {%tool \"dmponline\" %}. Furthermore, research data support services at Finnish research organisations offer help and guidance through the planning process and when making decisions on data management. Data collection\nWhen you startcollecting data and need a storing environment where you can, for example, host cumulating data, Allas Object Storage is the recommended option.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"csc_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"CSC",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Janina Juuvinmaa"
                ],
                "description":"The Center of Science (CSC) provides high-quality ICT expert services for researchers in Finland and their collaborators.",
                "page_id":"csc",
                "affiliations":[
                    "FI",
                    "CSC",
                    "ELIXIR Europe"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "dmp",
                        "data_security",
                        "gdpr_compliance",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=csc"
                    },
                    {
                        "name":"CSC - Bioscience webpages",
                        "url":"https:\/\/research.csc.fi\/biosciences"
                    },
                    {
                        "name":"CSC - Training and events webpages",
                        "url":"https:\/\/www.csc.fi\/en\/training"
                    },
                    {
                        "name":"CSC - Learning Materials for Bioscientists",
                        "url":"https:\/\/research.csc.fi\/bioscience-learning-materials"
                    },
                    {
                        "name":"CSC - Data management youtube channel",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=Ol7mniw687E&list=PLD5XtevzF3yEZw-8LadtaGVV8Um6CbMja"
                    },
                    {
                        "name":"CSC - Research data management services for life science research (youtube video)",
                        "url":"https:\/\/youtu.be\/lf9L7PYQrBE"
                    },
                    {
                        "name":"Data analysis with Chipster - Course packages",
                        "url":"https:\/\/chipster.2.rahtiapp.fi\/manual\/courses.html"
                    },
                    {
                        "name":"Tutorials and lecture playlists on different topics (youtube)",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCnL-Lx5gGlW01OkskZL7JEQ\/playlists"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_csc_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":3,
        "total_chunks":7,
        "content":"nt where you can, for example, host cumulating data, Allas Object Storage is the recommended option. Indeed, Allas is CSCs general purpose research data storage server, which can be accessed on the CSC servers as well as from anywhere on the internet. Allas can be used both for static research data that needs to be available for analysis and to collect cumulating data. For example, if you work with sequence data, the sequencing provider can transfer the data directly to Allas under your project. However, as an object storage system, Allas is not suitable for very dynamic data like SQL databases. Data processing and analysis\nFor processing, analysing and storing data during the research project, CSC offers several computing platforms. These include both environments for non-sensitive and sensitive data. Depending on your needs, you can choose from a wide variety of computing resources: useChipster software for high-throughput data such as RNA-seq and single-cell RNA-seq, build your own custom virtual machine, or utilise the full power of our world-class supercomputers.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"csc_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"CSC",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Janina Juuvinmaa"
                ],
                "description":"The Center of Science (CSC) provides high-quality ICT expert services for researchers in Finland and their collaborators.",
                "page_id":"csc",
                "affiliations":[
                    "FI",
                    "CSC",
                    "ELIXIR Europe"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "dmp",
                        "data_security",
                        "gdpr_compliance",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=csc"
                    },
                    {
                        "name":"CSC - Bioscience webpages",
                        "url":"https:\/\/research.csc.fi\/biosciences"
                    },
                    {
                        "name":"CSC - Training and events webpages",
                        "url":"https:\/\/www.csc.fi\/en\/training"
                    },
                    {
                        "name":"CSC - Learning Materials for Bioscientists",
                        "url":"https:\/\/research.csc.fi\/bioscience-learning-materials"
                    },
                    {
                        "name":"CSC - Data management youtube channel",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=Ol7mniw687E&list=PLD5XtevzF3yEZw-8LadtaGVV8Um6CbMja"
                    },
                    {
                        "name":"CSC - Research data management services for life science research (youtube video)",
                        "url":"https:\/\/youtu.be\/lf9L7PYQrBE"
                    },
                    {
                        "name":"Data analysis with Chipster - Course packages",
                        "url":"https:\/\/chipster.2.rahtiapp.fi\/manual\/courses.html"
                    },
                    {
                        "name":"Tutorials and lecture playlists on different topics (youtube)",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCnL-Lx5gGlW01OkskZL7JEQ\/playlists"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_csc_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":4,
        "total_chunks":7,
        "content":" build your own custom virtual machine, or utilise the full power of our world-class supercomputers. CSC is hosting EuroHPC's world-class supercomputer LUMI, which is available for researchers across Europe for projects requiring extreme computing capacity. LUMI is one of the world's most competitive supercomputers and one of the most advanced platforms for artificial intelligence. In addition, you can utilise two national supercomputers Puhti and Mahti for medium to large-scale simulations. Pouta and Rahti cloud computing services offer more flexibility, allowing the user to manage the infrastructure. CSCs computers have a wide range of preinstalled scientific software and databases with usage instructions. For management of sensitive data, the SD Connect and SD Desktop services are available. The Sensitive Data Services are designed to facilitate collaborative research across Finland and between Finnish academics and their collaborators. SD Connect allows you to collect, organise and share your encrypted sensitive data in a secure manner via web browser or programmatically.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"csc_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"CSC",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Janina Juuvinmaa"
                ],
                "description":"The Center of Science (CSC) provides high-quality ICT expert services for researchers in Finland and their collaborators.",
                "page_id":"csc",
                "affiliations":[
                    "FI",
                    "CSC",
                    "ELIXIR Europe"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "dmp",
                        "data_security",
                        "gdpr_compliance",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=csc"
                    },
                    {
                        "name":"CSC - Bioscience webpages",
                        "url":"https:\/\/research.csc.fi\/biosciences"
                    },
                    {
                        "name":"CSC - Training and events webpages",
                        "url":"https:\/\/www.csc.fi\/en\/training"
                    },
                    {
                        "name":"CSC - Learning Materials for Bioscientists",
                        "url":"https:\/\/research.csc.fi\/bioscience-learning-materials"
                    },
                    {
                        "name":"CSC - Data management youtube channel",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=Ol7mniw687E&list=PLD5XtevzF3yEZw-8LadtaGVV8Um6CbMja"
                    },
                    {
                        "name":"CSC - Research data management services for life science research (youtube video)",
                        "url":"https:\/\/youtu.be\/lf9L7PYQrBE"
                    },
                    {
                        "name":"Data analysis with Chipster - Course packages",
                        "url":"https:\/\/chipster.2.rahtiapp.fi\/manual\/courses.html"
                    },
                    {
                        "name":"Tutorials and lecture playlists on different topics (youtube)",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCnL-Lx5gGlW01OkskZL7JEQ\/playlists"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_csc_assembly_md_5",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":5,
        "total_chunks":7,
        "content":"nise and share your encrypted sensitive data in a secure manner via web browser or programmatically. SD Desktop is a service that allows a user and their authorized colleagues to access a private computing environment workspace via a web browser and analyse the data within a secure cloud. A restricted version of SD Desktop is also available for processing health and social data for secondary use in compliance with the Finnish law and Findata regulation. Data sharing and publishing\nIt is recommended to publish data in data specific repositories. You can find many options from {% tool \"elixir-deposition-databases-for-biomolecular-data\" %}. Furthermore, CSC and ELIXIR-FI will offer Federated EGA for sensitive human biomedical data that is linked to the central {%tool \"the-european-genome-phenome-archive\" %}\nThe Finnish Federated EGA is part of a European network of repositories for biomedical data. The service will give you the tools to describe your dataset (adding the appropriate metadata) and assigning an EGA accession number.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"csc_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"CSC",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Janina Juuvinmaa"
                ],
                "description":"The Center of Science (CSC) provides high-quality ICT expert services for researchers in Finland and their collaborators.",
                "page_id":"csc",
                "affiliations":[
                    "FI",
                    "CSC",
                    "ELIXIR Europe"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "dmp",
                        "data_security",
                        "gdpr_compliance",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=csc"
                    },
                    {
                        "name":"CSC - Bioscience webpages",
                        "url":"https:\/\/research.csc.fi\/biosciences"
                    },
                    {
                        "name":"CSC - Training and events webpages",
                        "url":"https:\/\/www.csc.fi\/en\/training"
                    },
                    {
                        "name":"CSC - Learning Materials for Bioscientists",
                        "url":"https:\/\/research.csc.fi\/bioscience-learning-materials"
                    },
                    {
                        "name":"CSC - Data management youtube channel",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=Ol7mniw687E&list=PLD5XtevzF3yEZw-8LadtaGVV8Um6CbMja"
                    },
                    {
                        "name":"CSC - Research data management services for life science research (youtube video)",
                        "url":"https:\/\/youtu.be\/lf9L7PYQrBE"
                    },
                    {
                        "name":"Data analysis with Chipster - Course packages",
                        "url":"https:\/\/chipster.2.rahtiapp.fi\/manual\/courses.html"
                    },
                    {
                        "name":"Tutorials and lecture playlists on different topics (youtube)",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCnL-Lx5gGlW01OkskZL7JEQ\/playlists"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_csc_assembly_md_6",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/csc_assembly.md",
        "file_name":"csc_assembly.md",
        "chunk_index":6,
        "total_chunks":7,
        "content":"ls to describe your dataset (adding the appropriate metadata) and assigning an EGA accession number. After publication, you will remain the data controller and decide according to specific policies, who can access the sensitive data for reuse. According to the GDPR, your data will remain within the Finnish borders and, at the same time, they will be accessible and discoverable according to FAIR data principles. In addition to the above mentioned services, you can use nationalFairdata.fi services. Fairdata IDA storage service enables saving, organising and sharing data within the project group and storing the data in an immutable state. After freezing your data in IDA, you can use Qvain, the research dataset description tool, to describe your data and thus create core metadata for your dataset, and publish it. Publishing means that your dataset will be published in Etsin, the research data finder, where you can discover and download any files you have associated with the dataset. Any published dataset is also made available to theResearch.fi portalautomatically by Fairdata services.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"csc_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"CSC",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Janina Juuvinmaa"
                ],
                "description":"The Center of Science (CSC) provides high-quality ICT expert services for researchers in Finland and their collaborators.",
                "page_id":"csc",
                "affiliations":[
                    "FI",
                    "CSC",
                    "ELIXIR Europe"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "dmp",
                        "data_security",
                        "gdpr_compliance",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=csc"
                    },
                    {
                        "name":"CSC - Bioscience webpages",
                        "url":"https:\/\/research.csc.fi\/biosciences"
                    },
                    {
                        "name":"CSC - Training and events webpages",
                        "url":"https:\/\/www.csc.fi\/en\/training"
                    },
                    {
                        "name":"CSC - Learning Materials for Bioscientists",
                        "url":"https:\/\/research.csc.fi\/bioscience-learning-materials"
                    },
                    {
                        "name":"CSC - Data management youtube channel",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=Ol7mniw687E&list=PLD5XtevzF3yEZw-8LadtaGVV8Um6CbMja"
                    },
                    {
                        "name":"CSC - Research data management services for life science research (youtube video)",
                        "url":"https:\/\/youtu.be\/lf9L7PYQrBE"
                    },
                    {
                        "name":"Data analysis with Chipster - Course packages",
                        "url":"https:\/\/chipster.2.rahtiapp.fi\/manual\/courses.html"
                    },
                    {
                        "name":"Tutorials and lecture playlists on different topics (youtube)",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCnL-Lx5gGlW01OkskZL7JEQ\/playlists"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_covid19_data_portal_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/covid19_data_portal.md",
        "file_name":"covid19_data_portal.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- ELIXIR CONVERGE\ncontributors:\n- Guy Cochrane\n- Marianna Ventouratou\n- Nadim Rahman\n- Sam Holt\ndescription: The COVID-19 Data Portal brings together relevant datasets for sharing\n  and analysis to accelerate coronavirus research. page_id: covid19_data_portal\nrelated_pages:\n  your_domain:\n  - human_data\n  - virology\n  your_tasks:\n  - sensitive\n  - existing_data\n  - data_publication\n  - data_analysis\ntitle: COVID-19 Data Portal",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"covid19_data_portal.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_covid19_data_portal_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/covid19_data_portal.md",
        "file_name":"covid19_data_portal.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"What is the European COVID-19 Data Portal? The European COVID-19 Data Portal is part of the European COVID-19 Data Platform, which was launched to facilitate the urgent need to share and analyse COVID-19 data. The portal accelerates research that will provide responses and build solutions, such as vaccines, treatments and public health interventions. The Platform comprises three core components: the SARS-CoV-2 Data Hubs, the Federated European Genome-phenome Archive and the COVID-19 Data Portal. The COVID-19 Data Portal brings together and continuously updates relevant COVID-19 datasets from a breadth of analytical platforms. Data are submitted using the SARS-CoV-2 Data Hubs functions or via other major centres of biomedical data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"covid19_data_portal.md",
            "language":"en",
            "frontmatter":{
                "title":"COVID-19 Data Portal",
                "contributors":[
                    "Guy Cochrane",
                    "Marianna Ventouratou",
                    "Nadim Rahman",
                    "Sam Holt"
                ],
                "page_id":"covid19_data_portal",
                "affiliations":[
                    "ELIXIR CONVERGE"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "existing_data",
                        "data_publication",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data",
                        "virology"
                    ]
                },
                "description":"The COVID-19 Data Portal brings together relevant datasets for sharing and analysis to accelerate coronavirus research."
            }
        }
    },
    {
        "id":"md_content_covid19_data_portal_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/covid19_data_portal.md",
        "file_name":"covid19_data_portal.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"re submitted using the SARS-CoV-2 Data Hubs functions or via other major centres of biomedical data. The data available from the COVID-19 Data Portal cover raw and assembled viral and human sequences, protein structures, proteomics, gene and protein expression data, compound screening, metabolomics and imaging data (from {% tool \"elixir-core-data-resources\" %} and other databases); COVID-19-relevant literature publications and pre-prints are also integrated. The aim is to have a wide variety of open data from across the globe systematised and easily accessible to researchers following the FAIR principles. The European COVID-19 Data Platform enables national data producers to share biomolecular data with the international scientific community, making these data available for reuse. Ultimately, it aims to allow for rapid analysis and dissemination to inform research, public health and health communities in an evidence-based manner. For detailed information on managing infectious disease data, you can always refer to the {% tool \"idtk\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"covid19_data_portal.md",
            "language":"en",
            "frontmatter":{
                "title":"COVID-19 Data Portal",
                "contributors":[
                    "Guy Cochrane",
                    "Marianna Ventouratou",
                    "Nadim Rahman",
                    "Sam Holt"
                ],
                "page_id":"covid19_data_portal",
                "affiliations":[
                    "ELIXIR CONVERGE"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "existing_data",
                        "data_publication",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data",
                        "virology"
                    ]
                },
                "description":"The COVID-19 Data Portal brings together relevant datasets for sharing and analysis to accelerate coronavirus research."
            }
        }
    },
    {
        "id":"md_content_covid19_data_portal_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/covid19_data_portal.md",
        "file_name":"covid19_data_portal.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"iled information on managing infectious disease data, you can always refer to the {% tool \"idtk\" %}. {% include image.html file=\"covid19_page.png\" caption=\"The COVID-19 Data Portal data flow schematic, showing collation, indexing, integration and user-access functions.\" alt=\"COVID-19 Data Portal\" %} How the portal is useful for researchers and how it is supposed to fit into their processes? Researchers benefit the COVID-19 Data Portal in a host of ways, including:\n- discoverability of COVID-19-relevant biomolecular data and related literature;\n- support for the sharing, analysis and publication of newly-generated data;\n- access to integrated COVID-19 data across multiple assay platforms;\n- flexible access to data via web, API and FTP interfaces;\n- access to data exploration and analysis tools. What are the components for the COVID-19 Data Portal?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"covid19_data_portal.md",
            "language":"en",
            "frontmatter":{
                "title":"COVID-19 Data Portal",
                "contributors":[
                    "Guy Cochrane",
                    "Marianna Ventouratou",
                    "Nadim Rahman",
                    "Sam Holt"
                ],
                "page_id":"covid19_data_portal",
                "affiliations":[
                    "ELIXIR CONVERGE"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "existing_data",
                        "data_publication",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data",
                        "virology"
                    ]
                },
                "description":"The COVID-19 Data Portal brings together relevant datasets for sharing and analysis to accelerate coronavirus research."
            }
        }
    },
    {
        "id":"md_content_covid19_data_portal_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/covid19_data_portal.md",
        "file_name":"covid19_data_portal.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"access to data exploration and analysis tools. What are the components for the COVID-19 Data Portal? The COVID-19 Data Portal contains reusable components that will be of value to data stewards, including:\n- discovery API with documented COVID-19 index points across data and literature resources covered by the COVID-19 Data Portal;\n- options for membership of the network of national COVID-19 Data Portals, currently comprising some 8 partners;\n- open source web application to establish a national COVID-19 Data Portal, courtesy of ELIXIR Sweden. For all these components, support is given via ecovid19@ebi.ac.uk. What country specific instances are there and how new instances are deployed? The European COVID-19 Data Portal includes a federation of national data portals, hosted in those nations. As of 2023, this includes Estonia, Greece, Italy, Japan, Luxembourg, Norway, Poland, Slovenia, Spain, Sweden and Turkey. The national COVID-19 Data Portals provide information, guidelines, tools and services to support each nation's researchers in creating and sharing research data on COVID-19.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"covid19_data_portal.md",
            "language":"en",
            "frontmatter":{
                "title":"COVID-19 Data Portal",
                "contributors":[
                    "Guy Cochrane",
                    "Marianna Ventouratou",
                    "Nadim Rahman",
                    "Sam Holt"
                ],
                "page_id":"covid19_data_portal",
                "affiliations":[
                    "ELIXIR CONVERGE"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "existing_data",
                        "data_publication",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data",
                        "virology"
                    ]
                },
                "description":"The COVID-19 Data Portal brings together relevant datasets for sharing and analysis to accelerate coronavirus research."
            }
        }
    },
    {
        "id":"md_content_covid19_data_portal_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/covid19_data_portal.md",
        "file_name":"covid19_data_portal.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"and services to support each nation's researchers in creating and sharing research data on COVID-19. The purpose of the national Portals is to provide an entry and orientation point into national activities including support, data management tools, projects and funding. For centralised data, such as viral sequences, national Portals are closely linked into the central COVID-19 Data Portal to allow users smooth access across the full selection of functions available to them.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"covid19_data_portal.md",
            "language":"en",
            "frontmatter":{
                "title":"COVID-19 Data Portal",
                "contributors":[
                    "Guy Cochrane",
                    "Marianna Ventouratou",
                    "Nadim Rahman",
                    "Sam Holt"
                ],
                "page_id":"covid19_data_portal",
                "affiliations":[
                    "ELIXIR CONVERGE"
                ],
                "related_pages":{
                    "your_tasks":[
                        "sensitive",
                        "existing_data",
                        "data_publication",
                        "data_analysis"
                    ],
                    "your_domain":[
                        "human_data",
                        "virology"
                    ]
                },
                "description":"The COVID-19 Data Portal brings together relevant datasets for sharing and analysis to accelerate coronavirus research."
            }
        }
    },
    {
        "id":"md_fm_molgenis_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/molgenis_assembly.md",
        "file_name":"molgenis_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- BBMRI-NL\ncontributors:\n- Aneas Hodselmans\n- Marije van der Geest\ndescription: Molgenis is a modular web application for scientific data. Flexible data\n  integration platform to find, capture, exchange, manage and analyse scientific data. page_id: molgenis\nrelated_pages: your_domain: []\n  your_tasks:\n  - data_analysis\n  - data_publication\n  - storage\n  - data_quality\n  - transfer\n  - metadata\n  - sensitive_data\ntitle: MOLGENIS\ntraining:\n- name: Intro\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/watch?v=1J2kgLHlgPU\n- name: Tutorials\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/channel\/UCiVR-YZFcBQe0i6RUwE9kyg\n- name: Manual\n  url: https:\/\/molgenis.gitbook.io\/molgenis\/\n- name: Code on github\n  registry: GitHub\n  url: https:\/\/github.com\/molgenis\/molgenis\n- name: Installation\n  url: https:\/\/galaxy.ansible.com\/molgenis\n- name: Demo\n  url: https:\/\/happy-davinci-bb01a7.netlify.app\/#\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"molgenis_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_molgenis_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/molgenis_assembly.md",
        "file_name":"molgenis_assembly.md",
        "chunk_index":0,
        "total_chunks":6,
        "content":"What is the Molgenis tool assembly?\n{% tool \"molgenis\" %} is a modular web application for scientific data. MOLGENIS was born from molecular genetics research (and was called 'molecular genetics information system') but has become relevant to many other scientific areas such as biobanking, rare disease research, patient registries and even energy research. MOLGENIS provides user-friendly and scalable software infrastructures to capture, exchange, and exploit the large amounts of data that is being produced by scientific organizations all around the world. To get an idea of what the software can do, visit our MOLGENIS YouTube channel or our demo page via the related pages. MOLGENIS is an ELIXIR Recommended Interoperability Resource. One of the key features is that it has a completely customisable data system, allowing you to model your data according to your needs. This creates flexibility that other, more static, database applications often lack.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"molgenis_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"MOLGENIS",
                "contributors":[
                    "Aneas Hodselmans",
                    "Marije van der Geest"
                ],
                "description":"Molgenis is a modular web application for scientific data. Flexible data integration platform to find, capture, exchange, manage and analyse scientific data.",
                "page_id":"molgenis",
                "affiliations":[
                    "BBMRI-NL"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_publication",
                        "storage",
                        "data_quality",
                        "transfer",
                        "metadata",
                        "sensitive_data"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Intro",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=1J2kgLHlgPU"
                    },
                    {
                        "name":"Tutorials",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCiVR-YZFcBQe0i6RUwE9kyg"
                    },
                    {
                        "name":"Manual",
                        "url":"https:\/\/molgenis.gitbook.io\/molgenis\/"
                    },
                    {
                        "name":"Code on github",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/molgenis\/molgenis"
                    },
                    {
                        "name":"Installation",
                        "url":"https:\/\/galaxy.ansible.com\/molgenis"
                    },
                    {
                        "name":"Demo",
                        "url":"https:\/\/happy-davinci-bb01a7.netlify.app\/#\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_molgenis_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/molgenis_assembly.md",
        "file_name":"molgenis_assembly.md",
        "chunk_index":1,
        "total_chunks":6,
        "content":"g to your needs. This creates flexibility that other, more static, database applications often lack. It is web-based, meaning you setup a server, install and configure MOLGENIS, load your data and share it. If your data is ready, setting up a useful online research database application can be done in few hours. Another key feature is that MOLGENIS is modular, having all kinds of extension modules to store and interact with your data. A good example are interfaces to create R and Python scripts that interact with your data. This enables you to add your own statistical modules to run statistical analysis, or create plots based on your data within the online environment. Who can use the Molgenis tool assembly? If you are a researcher, a (bio)informatician, a biomedical practitioner, a data manager or anyone else who handles a considerable amount of (scientific) data, then MOLGENIS is a software package that will help you in setting up an online database application in a short time, making your data query-able and allowing you to share your data with collaborators easily.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"molgenis_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"MOLGENIS",
                "contributors":[
                    "Aneas Hodselmans",
                    "Marije van der Geest"
                ],
                "description":"Molgenis is a modular web application for scientific data. Flexible data integration platform to find, capture, exchange, manage and analyse scientific data.",
                "page_id":"molgenis",
                "affiliations":[
                    "BBMRI-NL"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_publication",
                        "storage",
                        "data_quality",
                        "transfer",
                        "metadata",
                        "sensitive_data"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Intro",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=1J2kgLHlgPU"
                    },
                    {
                        "name":"Tutorials",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCiVR-YZFcBQe0i6RUwE9kyg"
                    },
                    {
                        "name":"Manual",
                        "url":"https:\/\/molgenis.gitbook.io\/molgenis\/"
                    },
                    {
                        "name":"Code on github",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/molgenis\/molgenis"
                    },
                    {
                        "name":"Installation",
                        "url":"https:\/\/galaxy.ansible.com\/molgenis"
                    },
                    {
                        "name":"Demo",
                        "url":"https:\/\/happy-davinci-bb01a7.netlify.app\/#\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_molgenis_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/molgenis_assembly.md",
        "file_name":"molgenis_assembly.md",
        "chunk_index":2,
        "total_chunks":6,
        "content":"ort time, making your data query-able and allowing you to share your data with collaborators easily. The MOLGENIS software toolkit enables you to store, edit, analyse, and share your data efficiently. MOLGENIS is open source, free to download and to install yourself. You can also purchase a MOLGENIS instance as a service ready to use from the Genomics Coordination Centrer (GCC), which is the main developer of MOLGENIS. GCC can also provide you with support on entering and managing your data-model on the servers. For what purpose can Molgenis assembly be used?\n{% include image.html file=\"Molgenis_tool_assembly.png\" caption=\"Figure 1. The Molgenis tool assembly.\" alt=\"Molgenis assembly\" %}\nStructured Data Management\nModel, capture, and manage your data. Quickly upload data files, or enter data via user friendly forms. Refine your data model dynamically using MOLGENIS advanced 'object-relational' data definition format and the online metadata editor. Example: https:\/\/hfgp.bbmri.nl\/\nFAIR data sharing\nMake your data findable, interoperable, accessible, reusable (FAIR).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"molgenis_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"MOLGENIS",
                "contributors":[
                    "Aneas Hodselmans",
                    "Marije van der Geest"
                ],
                "description":"Molgenis is a modular web application for scientific data. Flexible data integration platform to find, capture, exchange, manage and analyse scientific data.",
                "page_id":"molgenis",
                "affiliations":[
                    "BBMRI-NL"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_publication",
                        "storage",
                        "data_quality",
                        "transfer",
                        "metadata",
                        "sensitive_data"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Intro",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=1J2kgLHlgPU"
                    },
                    {
                        "name":"Tutorials",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCiVR-YZFcBQe0i6RUwE9kyg"
                    },
                    {
                        "name":"Manual",
                        "url":"https:\/\/molgenis.gitbook.io\/molgenis\/"
                    },
                    {
                        "name":"Code on github",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/molgenis\/molgenis"
                    },
                    {
                        "name":"Installation",
                        "url":"https:\/\/galaxy.ansible.com\/molgenis"
                    },
                    {
                        "name":"Demo",
                        "url":"https:\/\/happy-davinci-bb01a7.netlify.app\/#\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_molgenis_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/molgenis_assembly.md",
        "file_name":"molgenis_assembly.md",
        "chunk_index":3,
        "total_chunks":6,
        "content":"fgp.bbmri.nl\/\nFAIR data sharing\nMake your data findable, interoperable, accessible, reusable (FAIR). MOLGENIS aims to make  data sharing and re-use should easy. MOLGENIS enables you to quickly create explorers for your data sets and variables to the outside world while preventing exposure of (sensitive) data values using the fine-grained permission system. Example: http:\/\/www.palgaopenbaredatabank.nl\nSecure access\nEasily control group, role and individual access. MOLGENIS data is organised following scientific practice. Data can be divided in research groups, within the groups you can assign roles such as 'data manager', 'data editor' and 'data user'. Authentication can be ensured by connecting you institute account via SURFconext (NL) and BBMRI\/LS Login (Europe) or using Google two-factor authentication. Scripting & visualisation\nBioinformaticians can take full control in MOLGENIS. Add scripts in your favorite programming languages (e.g. R, javascript, python) and connect to the data using API's to add great analysis tools and views.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"molgenis_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"MOLGENIS",
                "contributors":[
                    "Aneas Hodselmans",
                    "Marije van der Geest"
                ],
                "description":"Molgenis is a modular web application for scientific data. Flexible data integration platform to find, capture, exchange, manage and analyse scientific data.",
                "page_id":"molgenis",
                "affiliations":[
                    "BBMRI-NL"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_publication",
                        "storage",
                        "data_quality",
                        "transfer",
                        "metadata",
                        "sensitive_data"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Intro",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=1J2kgLHlgPU"
                    },
                    {
                        "name":"Tutorials",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCiVR-YZFcBQe0i6RUwE9kyg"
                    },
                    {
                        "name":"Manual",
                        "url":"https:\/\/molgenis.gitbook.io\/molgenis\/"
                    },
                    {
                        "name":"Code on github",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/molgenis\/molgenis"
                    },
                    {
                        "name":"Installation",
                        "url":"https:\/\/galaxy.ansible.com\/molgenis"
                    },
                    {
                        "name":"Demo",
                        "url":"https:\/\/happy-davinci-bb01a7.netlify.app\/#\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_molgenis_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/molgenis_assembly.md",
        "file_name":"molgenis_assembly.md",
        "chunk_index":4,
        "total_chunks":6,
        "content":"g. R, javascript, python) and connect to the data using API's to add great analysis tools and views. You can also create complete html + javascript apps to customize MOLGENIS further.\nExample: http:\/\/molgenis.org\/ase\nHarmonization and integration\nA common task is to make your data interoperable and run combined analysis, which is much more powerful than running smaller analyses on each data set separately. MOLGENIS offers you multiple 'FAIRification' tools to find related data, codify your data contents and transform different tables into one standardized table. Examples: http:\/\/biobankconnect.org and http:\/\/molgenis.org\/sorta\nTask automation\nAutomate data upload, transformation and statistics. Frequently data from multiple sources must be combined for success. Therefore, data exchanges, transformations, and analyses must be repeated often. To enable  in reproducible science, you can automate tasks with the MOLGENIS job scheduling tools. Questionnaires\nGet data directly from the source. Use the questionnaire tool to ask individuals for input.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"molgenis_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"MOLGENIS",
                "contributors":[
                    "Aneas Hodselmans",
                    "Marije van der Geest"
                ],
                "description":"Molgenis is a modular web application for scientific data. Flexible data integration platform to find, capture, exchange, manage and analyse scientific data.",
                "page_id":"molgenis",
                "affiliations":[
                    "BBMRI-NL"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_publication",
                        "storage",
                        "data_quality",
                        "transfer",
                        "metadata",
                        "sensitive_data"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Intro",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=1J2kgLHlgPU"
                    },
                    {
                        "name":"Tutorials",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCiVR-YZFcBQe0i6RUwE9kyg"
                    },
                    {
                        "name":"Manual",
                        "url":"https:\/\/molgenis.gitbook.io\/molgenis\/"
                    },
                    {
                        "name":"Code on github",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/molgenis\/molgenis"
                    },
                    {
                        "name":"Installation",
                        "url":"https:\/\/galaxy.ansible.com\/molgenis"
                    },
                    {
                        "name":"Demo",
                        "url":"https:\/\/happy-davinci-bb01a7.netlify.app\/#\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_molgenis_assembly_md_5",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/molgenis_assembly.md",
        "file_name":"molgenis_assembly.md",
        "chunk_index":5,
        "total_chunks":6,
        "content":"onnaires\nGet data directly from the source. Use the questionnaire tool to ask individuals for input. The tool provides chapters, subquestions, advanced validations, conditional or 'skip' questions and intermediate save (so you can fill in the rest of the survey later). App development platform\nAdd your own user interfaces to the app store. MOLGENIS gives programmers the complete freedom to create HTML+JavaScript applications using MOLGENIS REST-style programmers interfaces. But it gets even better: you can upload these apps like plugins to become part of MOLGENIS itself and use them seamlessly. High performance computing\nEasily schedule large scale analysis jobs on a computer cluster. MOLGENIS does also provide a high performance computing framework. It is simply called 'compute' and it uses spreadsheets to define workflows, and templates to define workflow steps. It works on the HPC workload managers PBS and SLURM.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"molgenis_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"MOLGENIS",
                "contributors":[
                    "Aneas Hodselmans",
                    "Marije van der Geest"
                ],
                "description":"Molgenis is a modular web application for scientific data. Flexible data integration platform to find, capture, exchange, manage and analyse scientific data.",
                "page_id":"molgenis",
                "affiliations":[
                    "BBMRI-NL"
                ],
                "related_pages":{
                    "your_tasks":[
                        "data_analysis",
                        "data_publication",
                        "storage",
                        "data_quality",
                        "transfer",
                        "metadata",
                        "sensitive_data"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Intro",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/watch?v=1J2kgLHlgPU"
                    },
                    {
                        "name":"Tutorials",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCiVR-YZFcBQe0i6RUwE9kyg"
                    },
                    {
                        "name":"Manual",
                        "url":"https:\/\/molgenis.gitbook.io\/molgenis\/"
                    },
                    {
                        "name":"Code on github",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/molgenis\/molgenis"
                    },
                    {
                        "name":"Installation",
                        "url":"https:\/\/galaxy.ansible.com\/molgenis"
                    },
                    {
                        "name":"Demo",
                        "url":"https:\/\/happy-davinci-bb01a7.netlify.app\/#\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_nels_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/nels_assembly.md",
        "file_name":"nels_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations:\n- ELIXIR Europe\n- 'NO'\ncontributors:\n- Korbinian Bsl\n- Federico Bianchini\n- Erik Hjerde\ndescription: NeLS provides the necessary tools for data management to researchers\n  in Norway and their collaborators. page_id: nels\nrelated_pages: your_domain: []\n  your_tasks:\n  - dmp\n  - data_organisation\n  - storage\n  - data_publication\n  - data_transfer\n  - metadata\ntitle: NeLS\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=NeLS+Norway",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"nels_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_nels_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/nels_assembly.md",
        "file_name":"nels_assembly.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"What is the NeLS data management tool assembly? The Norwegian e-Infrastructure for Life Sciences (NeLS) is an infrastructure provided by ELIXIR Norway. NeLS provides necessary tools for Data Management and covers Planning, Processing, Analysing and Sharing Data Life Cycle stages and offers Data Storage capacities. Who can use the NeLS data management tool assembly? NeLS and the underlying infrastructure are accessible to researchers in Norway and their collaborators. Eligible researchers can apply for storage quotas and get support through the National (Norwegian) bioinformatics support desk contact@bioinfo.no. Most of the tools in NeLS are open-source and can be reused. For what can you use the NeLS data management tool assembly?\n{% include image.html file=\"NeLS_toolkit.svg\" caption=\"Figure 1. The Norwegian e-Infrastructure for Life Sciences (NeLS) Data Management tool assembly.\"",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nels_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"NeLS",
                "contributors":[
                    "Korbinian Bsl",
                    "Federico Bianchini",
                    "Erik Hjerde"
                ],
                "description":"NeLS provides the necessary tools for data management to researchers in Norway and their collaborators.",
                "page_id":"nels",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=NeLS+Norway"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_nels_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/nels_assembly.md",
        "file_name":"nels_assembly.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"n=\"Figure 1. The Norwegian e-Infrastructure for Life Sciences (NeLS) Data Management tool assembly.\" alt=\"NeLS RDMkit\" %}\nYou can access all tools in NeLS using the national solution for secure login and data sharing in the educational and research sector FEIDE when coupled with {% tool \"life-science-login\" %}. The NeLS Data Management tool assembly provides support with Data Management Planning through an instance of the Data Steward Wizard following the guidelines of the major national and European funding bodies. Dedicated references guide you through national infrastructure, resources, laws and regulations and also include the {% tool \"tryggve-elsi-checklist\" %} for Ethical, Legal and Social Implications. Soon you will be able to submit storage request forms for Data Storage in NeLS with defined access permissions through the Data Stewardship Wizard.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nels_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"NeLS",
                "contributors":[
                    "Korbinian Bsl",
                    "Federico Bianchini",
                    "Erik Hjerde"
                ],
                "description":"NeLS provides the necessary tools for data management to researchers in Norway and their collaborators.",
                "page_id":"nels",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=NeLS+Norway"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_nels_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/nels_assembly.md",
        "file_name":"nels_assembly.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":" forms for Data Storage in NeLS with defined access permissions through the Data Stewardship Wizard. Data Storage is the core functionality of NeLS and builds upon a 3 layer-tiered system: the first layer is intended for short-term storage when computing, processing and analysing data; the second layer of medium capacity (NeLS) is intended for sharing and storing active research data, while the third layer (StoreBioinfo) of high capacity is intended for longer storage until the end of a project. Data in the second (NeLS) layer is protected against hardware failure on disk or server level and snapshots of the data are kept for 4 weeks. The third layer is implemented on top of the national research data storage solutions operated by Sigma2 Uninett A\/S and is protected against data loss by snapshots and geo-replication. National Norwegian research infrastructures, such as the Norwegian sequencing infrastructure NorSeq can directly upload data to your NeLS project for you.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nels_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"NeLS",
                "contributors":[
                    "Korbinian Bsl",
                    "Federico Bianchini",
                    "Erik Hjerde"
                ],
                "description":"NeLS provides the necessary tools for data management to researchers in Norway and their collaborators.",
                "page_id":"nels",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=NeLS+Norway"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_nels_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/nels_assembly.md",
        "file_name":"nels_assembly.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"he Norwegian sequencing infrastructure NorSeq can directly upload data to your NeLS project for you. For Processing and Analysing your data, the NeLS Data Management tool assembly provides access to a national instance of Galaxy with ~2000 tools. Data stored in NeLS is directly available within this Galaxy instance, hence you do not need to keep local copies of your data. In order to help you keep track of metadata, NeLS is integrated with the {% tool \"fairdom-seek\" %} web-based cataloguing and sharing platform. You can use any instance of FAIRDOM-SEEK such as the public {% tool \"fairdomhub\" %} to manage metadata associated with your data stored in NeLS and access the data through FAIRDOM-SEEK. FAIRDOM-SEEK uses the ISA (Investigation, Study, Assay) structure to organise your data and recommended minimal information such as sample characteristics, technologies, measurements and relationships between samples, data and models. Public FAIRDOM-SEEK instances like the {% tool \"fairdomhub\" %}  can also be used to collaborate on data and to share them publicly.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nels_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"NeLS",
                "contributors":[
                    "Korbinian Bsl",
                    "Federico Bianchini",
                    "Erik Hjerde"
                ],
                "description":"NeLS provides the necessary tools for data management to researchers in Norway and their collaborators.",
                "page_id":"nels",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=NeLS+Norway"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_nels_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/nels_assembly.md",
        "file_name":"nels_assembly.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"ike the {% tool \"fairdomhub\" %}  can also be used to collaborate on data and to share them publicly. If you are doing modelling, you can also use the inbuilt {% tool \"jws-online\" %} simulator for your SBML models. One recommended way to share your data is to deposit them in the {% tool \"elixir-deposition-databases-for-biomolecular-data\" %}. The NeLS Data Management tool assembly will soon offer tools to help you with the deposition step for data stored in NeLS.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nels_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"NeLS",
                "contributors":[
                    "Korbinian Bsl",
                    "Federico Bianchini",
                    "Erik Hjerde"
                ],
                "description":"NeLS provides the necessary tools for data management to researchers in Norway and their collaborators.",
                "page_id":"nels",
                "affiliations":[
                    "ELIXIR Europe",
                    "NO"
                ],
                "related_pages":{
                    "your_tasks":[
                        "dmp",
                        "data_organisation",
                        "storage",
                        "data_publication",
                        "data_transfer",
                        "metadata"
                    ],
                    "your_domain":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=NeLS+Norway"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_plant_genomics_assembly_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/tool_assembly\/plant_genomics_assembly.md",
        "file_name":"plant_genomics_assembly.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"affiliations: null\ncontributors:\n- Anne-Franoise Adam-Blondon\n- Cyril Pommier\n- Daniel Faria\n- Paulette Lieby\n- Sebastian Beier\n- Erwan Le Floch\ndescription: Tool assembly for managing plant genomic data. faircookbook:\n- name: Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases\n  url: https:\/\/w3id.org\/faircookbook\/FCB061\npage_id: plant_geno_assembly\nrelated_pages:\n  tool_assembly:\n  - plant_pheno_assembly\n  your_domain:\n  - plants\n  your_tasks:\n  - metadata\n  - data_publication\ntitle: Plant Genomics",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"plant_genomics_assembly.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_plant_genomics_assembly_md_0",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_genomics_assembly.md",
        "file_name":"plant_genomics_assembly.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"What is the plant genomics tool assembly? The plant genomics tool assembly is a toolkit for managing plant genomics and genotyping data throughout their life cycle, with a particular focus on ensuring traceability of the biological material to enable interoperability with plant phenotyping data. To enable this, the same persistent identifiers must be used in both the genotyping and phenotyping experiments. It is recommended that the biological plant material is accurately described using rich metadata and stored in a central repository. The tool assembly also provides guidance on how users should structure their analysis results in the form of VCF files to achieve a higher degree of interoperability. Who can use the plant genomics tool assembly? This tool assembly can be used by any researcher producing plant genomic or genotyping data interested in ensuring their data complies with the FAIR principles. How can you access the plant genomics tool assembly?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_genomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Genomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Daniel Faria",
                    "Paulette Lieby",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant genomic data.",
                "page_id":"plant_geno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_pheno_assembly"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_genomics_assembly_md_1",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_genomics_assembly.md",
        "file_name":"plant_genomics_assembly.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"g their data complies with the FAIR principles. How can you access the plant genomics tool assembly? All the components of this tool assembly are publicly available, but most require registration. So anyone can access the tool assembly provided they register for each tool that requires it. For what purpose can you use the plant genomics tool assembly? {% include image.html file=\"plant_genomics.svg\" caption=\"Figure 1. The plant genomics tool assembly.\" alt=\"Tools and resources used in managing plant genomics and genotyping data.\" %}\nData management planning\nThe general principles to be considered are described in the Plant Sciences domain page. {% tool \"data-stewardship-wizard\" %} is a human-friendly tool for machine-actionable DMP collaborative editing. The DSW Plant Sciences project template, available on ELIXIR's DSW instance for researchers can be used for any plant sciences project. When creating the DMP Project, choose the option \"From Project Template\" and search for the \"Plant Sciences\" template.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_genomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Genomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Daniel Faria",
                    "Paulette Lieby",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant genomic data.",
                "page_id":"plant_geno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_pheno_assembly"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_genomics_assembly_md_2",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_genomics_assembly.md",
        "file_name":"plant_genomics_assembly.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"DMP Project, choose the option \"From Project Template\" and search for the \"Plant Sciences\" template. Metadata collection and tracking\nAccurate documentation of the plant biological materials and samples is critical for interoperability, and should comply with the {% tool \"miappe\" %} standard. This information should be submitted to {% tool \"biosamples\" %}, with MIAPPE compliance validated using BioSamples' plant-miappe.json template available on the sample validation page. Submission of sample descriptions to BioSamples can be done as early as the data collection stage, but at the latest, must acompany submission of the genomic data to the {% tool \"european-nucleotide-archive\" %} (ENA) or of genotyping data to the {% tool \"european-variation-archive\" %} (EVA). The complete timeline for submitting plant biological material to BioSamples and resulting genotyping experiment results to ENA and EVA should look like this: 1. Register plant biological material information to BioSamples\n2. Submit Sequencing reads to ENA (using BioSamples IDs to identify material)\n3.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_genomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Genomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Daniel Faria",
                    "Paulette Lieby",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant genomic data.",
                "page_id":"plant_geno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_pheno_assembly"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_genomics_assembly_md_3",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_genomics_assembly.md",
        "file_name":"plant_genomics_assembly.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"ation to BioSamples\n2. Submit Sequencing reads to ENA (using BioSamples IDs to identify material)\n3. Check if used reference genome assembly is INSDC available (GCF \/ GCA accesion number available) 1. If yes proceed to submit VCF at step 4, if no proceed to step 3 b\n    2. Submit reference genome assembly to INSDC (NCBI Genbank \/ EBML-EBI ENA \/ DDBJ) and wait until accession number is issued, then proceed to step 4\n4. Submit VCF file to EVA (using BioSamples IDs to identify material, GCF\/GCA accession for the reference genome assembly)\n{% include callout.html type=\"note\" content=\"Metadata associated with a single sample registered with BioSamples can only be updated from the original account.\" %}\n{% tool \"e-dal-pgp\" %}, FAIRDOM-SEEK instances such as {% tool \"fairdomhub\" %} or Recherche Data Gouv can be used to manage and share experimental metadata, as well as data. Data processing and analysis\nReference genomes for genome assembly and annotation should be obtained from {% tool \"ensembl-plants\" %} or {% tool \"plaza\" %}, if available.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_genomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Genomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Daniel Faria",
                    "Paulette Lieby",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant genomic data.",
                "page_id":"plant_geno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_pheno_assembly"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_plant_genomics_assembly_md_4",
        "source":"markdown_content",
        "file_path":"pages\/tool_assembly\/plant_genomics_assembly.md",
        "file_name":"plant_genomics_assembly.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":" annotation should be obtained from {% tool \"ensembl-plants\" %} or {% tool \"plaza\" %}, if available. Genetic variant data must be produced in the VCF format, and validated using the EVA vcf-validator (https:\/\/github.com\/EBIvariation\/vcf-validator). Please note to only use identifiers of sequences that match the reference genome assembly identifiers. In order to ensure interoperability of VCF files, the VCF meta-information lines should be used: see the Plant sciences page for more details. Data sharing and publishing\nAll sequencing data collected in plant genotyping experiments should be submitted to ENA together with metadata compliant to the GSC MIxS plant associated checklist. Final results of such studies in the form of VCF files should be submitted to EVA. Additionally, supplemental data complementing these two data types is encouraged to be submitted to {% tool \"e-dal-pgp\" %} or Recherche Data Gouv.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"plant_genomics_assembly.md",
            "language":"en",
            "frontmatter":{
                "title":"Plant Genomics",
                "contributors":[
                    "Anne-Franoise Adam-Blondon",
                    "Cyril Pommier",
                    "Daniel Faria",
                    "Paulette Lieby",
                    "Sebastian Beier",
                    "Erwan Le Floch"
                ],
                "description":"Tool assembly for managing plant genomic data.",
                "page_id":"plant_geno_assembly",
                "affiliations":null,
                "related_pages":{
                    "your_tasks":[
                        "metadata",
                        "data_publication"
                    ],
                    "your_domain":[
                        "plants"
                    ],
                    "tool_assembly":[
                        "plant_pheno_assembly"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Improving dataset maturity - MIAPPE-compliant submission to EMBL-EBI databases",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB061"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_si_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/si_resources.md",
        "file_name":"si_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Brane Leskoek\n- Marko Vidak\n- Nadja lender\n- Polonca Ferk\ncoordinators:\n- Brane Leskoek\n- Marko Vidak\n- Nadja lender\ncountry_code: SI\ndescription: This page provides a general overview of national resources on Research\n  Data Management (RDM) in Slovenia. national_resources:\n- description: Publicly available online tool for composing smart data management\n    plans. how_to_access: null\n  instance_of: data-stewardship-wizard\n  name: DS Wizard ELIXIR Slovenia\n  related_pages:\n    your_tasks:\n    - dmp\n  url: https:\/\/slovenia.dsw.elixir-europe.org\/\n- description: Learning Management System. how_to_access: Registration is open to everyone, some classes are closed.\n  name: ELIXIR eLearning Platform\n  url: https:\/\/elixir.mf.uni-lj.si\nrelated_pages: null\ntitle: Slovenia\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/nodes\/slovenia\n- name: ELIXIR eLearning Platform\n  registry: TeSS\n  url: https:\/\/elixir.mf.uni-lj.si\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"si_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_si_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/si_resources.md",
        "file_name":"si_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\nThis page provides a general overview of national resources on Research Data Management (RDM) in Slovenia. An overview of data management services provided by ELIXIR Slovenia can be found on the ELIXIR Slovenia website. Funders\nThe main public funder of research in Slovenia is the Slovenian Research and Innovation Agency (ARIS), which provides stable funding to the scientific community. The funding policy goals are to enable fair competition of scientists and to achieve excellence in science, reflected through participation of Slovenian scientists in European and other international projects. These projects result in high-impact publication with ARIS-funded scientists as leading authors. The Agency follows the policies of open science, scientific integrity, and gender equality. Some of ELIXIR Slovenias activities are funded by the European Union (EU).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"si_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Slovenia",
                "country_code":"SI",
                "description":"This page provides a general overview of national resources on Research Data Management (RDM) in Slovenia.",
                "contributors":[
                    "Brane Leskoek",
                    "Marko Vidak",
                    "Nadja lender",
                    "Polonca Ferk"
                ],
                "coordinators":[
                    "Brane Leskoek",
                    "Marko Vidak",
                    "Nadja lender"
                ],
                "related_pages":null,
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/slovenia"
                    },
                    {
                        "name":"ELIXIR eLearning Platform",
                        "registry":"TeSS",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS Wizard ELIXIR Slovenia",
                        "description":"Publicly available online tool for composing smart data management plans.",
                        "how_to_access":null,
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/slovenia.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"ELIXIR eLearning Platform",
                        "description":"Learning Management System.",
                        "how_to_access":"Registration is open to everyone, some classes are closed.",
                        "url":"https:\/\/elixir.mf.uni-lj.si"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_si_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/si_resources.md",
        "file_name":"si_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ty, and gender equality. Some of ELIXIR Slovenias activities are funded by the European Union (EU). Regulations\nThere are several guidelines and regulations in Slovenia that promote scientific integrity, open science, and research data management. The key aspects of the legal framework are listed below. Slovenian Research and Innovation Agency (ARIS) Guidelines: \nPrinciples for research ethics, integrity and responsible conduct in research, including honesty, objectivity, transparency, and accountability. Open access to scientific publications and data to ensure wider accessibility and dissemination of knowledge. Researchers are encouraged to publish their findings in open access journals and deposit their data in open repositories. Data Management Plans (DMPs) have to be submitted as part of research project proposals. These plans outline how data will be collected, managed, preserved, and shared throughout the research project. Code of Ethics for Researchers:",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"si_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Slovenia",
                "country_code":"SI",
                "description":"This page provides a general overview of national resources on Research Data Management (RDM) in Slovenia.",
                "contributors":[
                    "Brane Leskoek",
                    "Marko Vidak",
                    "Nadja lender",
                    "Polonca Ferk"
                ],
                "coordinators":[
                    "Brane Leskoek",
                    "Marko Vidak",
                    "Nadja lender"
                ],
                "related_pages":null,
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/slovenia"
                    },
                    {
                        "name":"ELIXIR eLearning Platform",
                        "registry":"TeSS",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS Wizard ELIXIR Slovenia",
                        "description":"Publicly available online tool for composing smart data management plans.",
                        "how_to_access":null,
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/slovenia.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"ELIXIR eLearning Platform",
                        "description":"Learning Management System.",
                        "how_to_access":"Registration is open to everyone, some classes are closed.",
                        "url":"https:\/\/elixir.mf.uni-lj.si"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_si_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/si_resources.md",
        "file_name":"si_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"ted, managed, preserved, and shared throughout the research project. Code of Ethics for Researchers: Slovenia adheres to the European Code of Conduct for Research Integrity, which sets out ethical principles and professional standards for researchers. It covers aspects such as research misconduct, data management, authorship, and peer review. National Open Science and Open Education Action Plan:\nPromotion of open science, open education and collaborative research. Improved access to scientific publications and research data. Guidelines and regulations provide comprehensive and up-to-date information on policies concerning scientific integrity, open science, and research data management in Slovenia. Researchers have to consult the relevant guidelines and regulations issued by ARIS, research institutions, and other national bodies.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"si_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Slovenia",
                "country_code":"SI",
                "description":"This page provides a general overview of national resources on Research Data Management (RDM) in Slovenia.",
                "contributors":[
                    "Brane Leskoek",
                    "Marko Vidak",
                    "Nadja lender",
                    "Polonca Ferk"
                ],
                "coordinators":[
                    "Brane Leskoek",
                    "Marko Vidak",
                    "Nadja lender"
                ],
                "related_pages":null,
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/slovenia"
                    },
                    {
                        "name":"ELIXIR eLearning Platform",
                        "registry":"TeSS",
                        "url":"https:\/\/elixir.mf.uni-lj.si\/"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS Wizard ELIXIR Slovenia",
                        "description":"Publicly available online tool for composing smart data management plans.",
                        "how_to_access":null,
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/slovenia.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"ELIXIR eLearning Platform",
                        "description":"Learning Management System.",
                        "how_to_access":"Registration is open to everyone, some classes are closed.",
                        "url":"https:\/\/elixir.mf.uni-lj.si"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_fi_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/fi_resources.md",
        "file_name":"fi_resources.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"contributors:\n- Siiri Fuchs\n- Minna Ahokas\ncoordinators: []\ncountry_code: FI\nnational_resources:\n- description: Chipster is a user-friendly analysis software for high-throughput data\n    such as RNA-seq and single cell RNA-seq. It contains analysis tools and a large\n    reference genome collection. how_to_access: null\n  name: Chipster\n  related_pages:\n    tool_assembly:\n    - csc\n    your_role:\n    - researcher\n    - research_software_engineer\n    your_tasks:\n    - data_analysis\n  url: https:\/\/chipster.csc.fi\/\n- description: Data management planning tool (Finland).",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"fi_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_fi_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/fi_resources.md",
        "file_name":"fi_resources.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"ata_analysis\n  url: https:\/\/chipster.csc.fi\/\n- description: Data management planning tool (Finland). how_to_access: null\n  instance_of: dmproadmap\n  name: DMPTuuli\n  related_pages:\n    tool_assembly:\n    - csc\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - dmp\n  url: https:\/\/www.dmptuuli.fi\/\n- description: With the Fairdata Services you can store, share and publish your research\n    data with easy-to-use web tools.\n  how_to_access: null\n  instance_of: null\n  name: Fairdata.fi\n  related_pages:\n    tool_assembly:\n    - csc\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - storage\n    - data_publication\n    - existing_data\n  url: https:\/\/research.csc.fi\/-\/fairdata-services\n- description: FEGA allows you to store and share sensitive data in Finland in a way\n    that fulfils all the requirements of the General Data Protection Regulation (GDPR). how_to_access: null\n  instance_of: the-european-genome-phenome-archive\n  name: Federated EGA Finland\n  related_pages:\n    tool_assembly:\n    - csc",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"fi_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_fi_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/fi_resources.md",
        "file_name":"fi_resources.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"n-genome-phenome-archive\n  name: Federated EGA Finland\n  related_pages:\n    tool_assembly:\n    - csc your_domain:\n    - human_data\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - sensitive\n    - data_publication\n    - existing_data\n  url: https:\/\/research.csc.fi\/-\/fega\n- description: The Health and Social Data Permit Authority. Findata offers services\n    and enables secure and efficient utilisation of data materials containing health\n    and social data. how_to_access: null\n  instance_of: null\n  name: Findata\n  related_pages:\n    tool_assembly:\n    - csc your_domain:\n    - human_data\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - sensitive\n    - existing_data\n  url: https:\/\/findata.fi\/en\/\n- description: Finnish Biobank Cooperative (FINBB) connects researchers to Finnish\n    biomedical research. Via Fingenious services the researcher can connect to all\n    Finnish public bio banks. how_to_access: null\n  instance_of: null\n  name: Fingenious\n  related_pages:\n    tool_assembly:\n    - csc",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"fi_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_fi_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/fi_resources.md",
        "file_name":"fi_resources.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"to_access: null\n  instance_of: null\n  name: Fingenious\n  related_pages:\n    tool_assembly:\n    - csc your_domain:\n    - human_data\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - sensitive\n  url: https:\/\/site.fingenious.fi\/en\/\n- description: CSC Sensitive Data Services for Research are designed to support secure\n    sensitive data management through web-user interfaces accessible from the user's\n    own computer. how_to_access: null\n  instance_of: null\n  name: Sensitive Data Services for Research\n  related_pages:\n    tool_assembly:\n    - csc your_domain:\n    - human_data\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - sensitive\n    - data_analysis\n    - storage\n    - data_publication\n  url: https:\/\/research.csc.fi\/sensitive-data-services-for-research\n- description: CSC Supercomputers Puhti, Mahti and LUMI performance ranges from medium\n    scale simulations to one of the most competitive supercomputers in the world.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"fi_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_fi_resources_md_4",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/fi_resources.md",
        "file_name":"fi_resources.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"ranges from medium\n    scale simulations to one of the most competitive supercomputers in the world. how_to_access: null\n  instance_of: null\n  name: High performance computing\n  related_pages:\n    tool_assembly:\n    - csc\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - data_analysis\n  url: https:\/\/research.csc.fi\/computing#high-performance-computing\n- description: 'CSC offers a variety of cloud computing services: the Pouta IaaS services\n    and the Rahti container cloud service.'\n  how_to_access: null\n  instance_of: null\n  name: Cloud computing\n  related_pages:\n    tool_assembly:\n    - csc\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - data_analysis\n  url: https:\/\/research.csc.fi\/computing#cloud-computing\ntitle: Finland",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"fi_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_fi_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/fi_resources.md",
        "file_name":"fi_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\nThis is an overview of research data management resources in Finland. These resources are accessible for researchers in Finland and to their collaborators. CSC  IT Center for Science provides comprehensive scientific computing, data management and analysis services and solutions for research in Finland. CSC operates the ELIXIR Finland node and offers medical and bioinformatic research tools developed in Finland and Europe. An overview of data management services provided by ELIXIR Finland and CSC can be found on the ELIXIR Finland website and CSC's Services for Research website. Regulations and policies on research data\nEvery research data involves the questions of rights, legal and ethical issues. Contact you own organisation's data management support services for guidance on ethical and legal compliance and data protection and ownership. If personal data are processed in your research, Data Protection Act will apply to it.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fi_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Finland",
                "country_code":"FI",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas"
                ],
                "coordinators":[

                ],
                "national_resources":[
                    {
                        "name":"Chipster",
                        "description":"Chipster is a user-friendly analysis software for high-throughput data such as RNA-seq and single cell RNA-seq. It contains analysis tools and a large reference genome collection.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/chipster.csc.fi\/"
                    },
                    {
                        "name":"DMPTuuli",
                        "description":"Data management planning tool (Finland).",
                        "instance_of":"dmproadmap",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/www.dmptuuli.fi\/"
                    },
                    {
                        "name":"Fairdata.fi",
                        "description":"With the Fairdata Services you can store, share and publish your research data with easy-to-use web tools.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/-\/fairdata-services"
                    },
                    {
                        "name":"Federated EGA Finland",
                        "description":"FEGA allows you to store and share sensitive data in Finland in a way that fulfils all the requirements of the General Data Protection Regulation (GDPR).",
                        "instance_of":"the-european-genome-phenome-archive",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_publication",
                                "existing_data"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/-\/fega"
                    },
                    {
                        "name":"Findata",
                        "description":"The Health and Social Data Permit Authority. Findata offers services and enables secure and efficient utilisation of data materials containing health and social data.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/findata.fi\/en\/"
                    },
                    {
                        "name":"Fingenious",
                        "description":"Finnish Biobank Cooperative (FINBB) connects researchers to Finnish biomedical research. Via Fingenious services the researcher can connect to all Finnish public bio banks.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/site.fingenious.fi\/en\/"
                    },
                    {
                        "name":"Sensitive Data Services for Research",
                        "description":"CSC Sensitive Data Services for Research are designed to support secure sensitive data management through web-user interfaces accessible from the user's own computer.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_analysis",
                                "storage",
                                "data_publication"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/sensitive-data-services-for-research"
                    },
                    {
                        "name":"High performance computing",
                        "description":"CSC Supercomputers Puhti, Mahti and LUMI performance ranges from medium scale simulations to one of the most competitive supercomputers in the world.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/computing#high-performance-computing"
                    },
                    {
                        "name":"Cloud computing",
                        "description":"CSC offers a variety of cloud computing services: the Pouta IaaS services and the Rahti container cloud service.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/computing#cloud-computing"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fi_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/fi_resources.md",
        "file_name":"fi_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"nd ownership. If personal data are processed in your research, Data Protection Act will apply to it. Data Protection Ombudsman is a national supervisory authority which supervises the compliance with data protection legislation. Ethical review is needed in defined research configurations. See more at Finnish National Board of Research Integrity. National policies\nPolicies of open science and research in Finland outline in detail the strategic principles, objectives and action plans necessary to achieve the objectives set out in the Declaration for Open Science and Research. The policies cover four areas: culture for open scholarship, open access to scholarly publications, open access of research data and methods, and open education and open access to educational resources. Funder policies\nFunders have their individual data policies and mandatory guidelines with regard to research data management. The general expectation is that publicly funded research data are a public good, and should be made openly available with as few restrictions as possible.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fi_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Finland",
                "country_code":"FI",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas"
                ],
                "coordinators":[

                ],
                "national_resources":[
                    {
                        "name":"Chipster",
                        "description":"Chipster is a user-friendly analysis software for high-throughput data such as RNA-seq and single cell RNA-seq. It contains analysis tools and a large reference genome collection.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/chipster.csc.fi\/"
                    },
                    {
                        "name":"DMPTuuli",
                        "description":"Data management planning tool (Finland).",
                        "instance_of":"dmproadmap",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/www.dmptuuli.fi\/"
                    },
                    {
                        "name":"Fairdata.fi",
                        "description":"With the Fairdata Services you can store, share and publish your research data with easy-to-use web tools.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/-\/fairdata-services"
                    },
                    {
                        "name":"Federated EGA Finland",
                        "description":"FEGA allows you to store and share sensitive data in Finland in a way that fulfils all the requirements of the General Data Protection Regulation (GDPR).",
                        "instance_of":"the-european-genome-phenome-archive",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_publication",
                                "existing_data"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/-\/fega"
                    },
                    {
                        "name":"Findata",
                        "description":"The Health and Social Data Permit Authority. Findata offers services and enables secure and efficient utilisation of data materials containing health and social data.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/findata.fi\/en\/"
                    },
                    {
                        "name":"Fingenious",
                        "description":"Finnish Biobank Cooperative (FINBB) connects researchers to Finnish biomedical research. Via Fingenious services the researcher can connect to all Finnish public bio banks.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/site.fingenious.fi\/en\/"
                    },
                    {
                        "name":"Sensitive Data Services for Research",
                        "description":"CSC Sensitive Data Services for Research are designed to support secure sensitive data management through web-user interfaces accessible from the user's own computer.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_analysis",
                                "storage",
                                "data_publication"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/sensitive-data-services-for-research"
                    },
                    {
                        "name":"High performance computing",
                        "description":"CSC Supercomputers Puhti, Mahti and LUMI performance ranges from medium scale simulations to one of the most competitive supercomputers in the world.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/computing#high-performance-computing"
                    },
                    {
                        "name":"Cloud computing",
                        "description":"CSC offers a variety of cloud computing services: the Pouta IaaS services and the Rahti container cloud service.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/computing#cloud-computing"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fi_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/fi_resources.md",
        "file_name":"fi_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"ch data are a public good, and should be made openly available with as few restrictions as possible. Check your funders website for current information and guidance. See e.g. Research Council of Finland policies on open science. Institutional policies\nUniversities and other research organisations and data service providers have data policies describing the principles and policies that are related to the management of research data (e.g CSC Data Policy). In addition, data policies make clear the responsibilities of the organisation and its researchers for managing research data well. Remember to check your organisation's current information and guidance. Domain-specific resources\nFinland has a long tradition of collecting and analysing biobank samples and the associated clinical data. Read more about domain specific resources from ELIXIR-FI webpages. National social and health data resources can be searched in Aineistokatalogi, a catalogue developed in cooperation between The Finnish institute for health and welfare (THL), Statistics Finland, the Data Archives and Sitra.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fi_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Finland",
                "country_code":"FI",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas"
                ],
                "coordinators":[

                ],
                "national_resources":[
                    {
                        "name":"Chipster",
                        "description":"Chipster is a user-friendly analysis software for high-throughput data such as RNA-seq and single cell RNA-seq. It contains analysis tools and a large reference genome collection.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/chipster.csc.fi\/"
                    },
                    {
                        "name":"DMPTuuli",
                        "description":"Data management planning tool (Finland).",
                        "instance_of":"dmproadmap",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/www.dmptuuli.fi\/"
                    },
                    {
                        "name":"Fairdata.fi",
                        "description":"With the Fairdata Services you can store, share and publish your research data with easy-to-use web tools.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/-\/fairdata-services"
                    },
                    {
                        "name":"Federated EGA Finland",
                        "description":"FEGA allows you to store and share sensitive data in Finland in a way that fulfils all the requirements of the General Data Protection Regulation (GDPR).",
                        "instance_of":"the-european-genome-phenome-archive",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_publication",
                                "existing_data"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/-\/fega"
                    },
                    {
                        "name":"Findata",
                        "description":"The Health and Social Data Permit Authority. Findata offers services and enables secure and efficient utilisation of data materials containing health and social data.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/findata.fi\/en\/"
                    },
                    {
                        "name":"Fingenious",
                        "description":"Finnish Biobank Cooperative (FINBB) connects researchers to Finnish biomedical research. Via Fingenious services the researcher can connect to all Finnish public bio banks.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/site.fingenious.fi\/en\/"
                    },
                    {
                        "name":"Sensitive Data Services for Research",
                        "description":"CSC Sensitive Data Services for Research are designed to support secure sensitive data management through web-user interfaces accessible from the user's own computer.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_analysis",
                                "storage",
                                "data_publication"
                            ],
                            "your_domain":[
                                "human_data"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/sensitive-data-services-for-research"
                    },
                    {
                        "name":"High performance computing",
                        "description":"CSC Supercomputers Puhti, Mahti and LUMI performance ranges from medium scale simulations to one of the most competitive supercomputers in the world.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/computing#high-performance-computing"
                    },
                    {
                        "name":"Cloud computing",
                        "description":"CSC offers a variety of cloud computing services: the Pouta IaaS services and the Rahti container cloud service.",
                        "instance_of":null,
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "csc"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/research.csc.fi\/computing#cloud-computing"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_no_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":0,
        "total_chunks":14,
        "content":"contributors:\n- Nazeefa Fatima\n- Federico Bianchini\n- Korbinian Bsl\n- Erin Calhoun\ncoordinators:\n- Korbinian Bsl\n- Nazeefa Fatima\ncountry_code: 'NO'\nnational_resources:\n- description: Feide is the national solution for secure login and data exchange in\n    education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai)\n    through [eduGAIN](https:\/\/edugain.org\/). how_to_access: Everyone with an affiliation to a Norwegian academic institution. name: Feide\n  related_pages:\n    tool_assembly:\n    - tsd\n    - nels\n    - marine_assembly\n  url: https:\/\/www.feide.no\/\n- description: DS-Wizard is a tool to aid the creation, organisation and sharing of\n    data management plans. It provides scientists with guidance, facilitating the\n    understanding of the key components of FAIR-oriented Data Stewardship.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":1,
        "total_chunks":14,
        "content":"uidance, facilitating the\n    understanding of the key components of FAIR-oriented Data Stewardship. The template\n    in this instance provides additional guidance on resources, laws and regulations\n    in Norway.\n  how_to_access: Life Science Login (LS Login) with Feide or upon registration\n  id: dsw-no\n  instance_of: data-stewardship-wizard\n  name: DS-Wizard ELIXIR-Norway\n  related_pages:\n    tool_assembly:\n    - tsd\n    - nels\n    - marine_assembly\n    your_tasks:\n    - dmp\n  url: https:\/\/norway.dsw.elixir-europe.org\/\n- description: DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/). how_to_access: Feide\n  instance_of: null\n  name: EasyDMP\n  related_pages:\n    your_tasks:\n    - dmp\n  url: https:\/\/easydmp.no\/\n- description: META-pipe is a pipeline for annotation and analysis of marine metagenomics\n    samples, which provides insight into phylogenetic diversity, metabolic and functional\n    potential of environmental communities.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":2,
        "total_chunks":14,
        "content":"ht into phylogenetic diversity, metabolic and functional\n    potential of environmental communities. how_to_access: Feide or upon application\n  name: Meta-pipe\n  related_pages:\n    tool_assembly:\n    - marine_assembly\n    your_tasks:\n    - data_analysis\n  url: https:\/\/sfb.mmp2.sigma2.no\/metapipe\/\n- description: The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research\n    efforts and offers guidelines, tools, databases and services to support Norwegian\n    COVID-19 researchers. name: Norwegian COVID-19 Data Portal\n  related_pages:\n    tool_assembly:\n    - covid19_data_portal your_domain:\n    - human_data\n    your_tasks:\n    - sensitive\n    - existing_data\n    - data_publication\n  url: https:\/\/pathogens.no\/\n- description: Federated instance collects metadata of -omics data collections stored\n    in national or regional archives and makes them available for search through the\n    main EGA portal.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":3,
        "total_chunks":14,
        "content":"n national or regional archives and makes them available for search through the\n    main EGA portal. With this solution, sensitive data will not physically leave\n    the country, but will reside on TSD.\n  how_to_access: Life Science Login (LS Login); intended for data from Norwegian institutions\n  instance_of: the-european-genome-phenome-archive\n  name: Federated EGA Norway node\n  related_pages:\n    tool_assembly:\n    - tsd\n    your_domain:\n    - human_data\n    your_tasks:\n    - sensitive\n    - existing_data\n    - data_publication\n  url: https:\/\/ega.elixir.no\/\n- description: Galaxy is an open-source, web-based platform for data-intensive biomedical\n    research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_4",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":4,
        "total_chunks":14,
        "content":"ensive biomedical\n    research. This instance of Galaxy is coupled with NeLS for easy data transfer. how_to_access: Feide or upon application\n  instance_of: galaxy\n  name: usegalaxy.no\n  related_pages:\n    tool_assembly:\n    - nels\n    your_tasks:\n    - data_analysis\n    - sensitive\n    - existing_data\n    - data_publication\n  url: https:\/\/usegalaxy.no\n- description: Norwegian e-Infrastructure for Life Sciences enables Norwegian life\n    scientists and their international collaborators to store, share, archive, and\n    analyse their omics-scale data. how_to_access: Everyone with funding from a Norwegian funder or a project at one\n    of the health regions or universities can get access through Feide or upon application\n    for collaborators. name: NeLS\n  related_pages:\n    tool_assembly:\n    - nels\n    - marine_assembly\n  url: https:\/\/nels.bioinfo.no\n- description: The National Infrastructure for Research Data (NIRD) infrastructure\n    offers storage services, archiving services, and processing capacity for computing\n    on the stored data.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_5",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":5,
        "total_chunks":14,
        "content":" storage services, archiving services, and processing capacity for computing\n    on the stored data. It offers services and capacities to any scientific discipline\n    that requires access to advanced, large-scale, or high-end resources for storing,\n    processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which\n    is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/). how_to_access: A formal application is required to gain access to the storage services.\n  name: NIRD\n  related_pages:\n    tool_assembly:\n    - nels\n    - fairtracks\n    your_tasks:\n    - transfer\n    - storage\n  url: https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html\n- description: The current Norwegian academic HPC infrastructure consists of three\n    systems for different purposes.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_6",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":6,
        "total_chunks":14,
        "content":" current Norwegian academic HPC infrastructure consists of three\n    systems for different purposes. The Norwegian academic high-performance computing\n    and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris),\n    which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2\n    (SIKT)](https:\/\/www.sigma2.no\/). how_to_access: A formal application is required to gain access to the storage services.\n  name: Sigma2 HPC systems\n  related_pages:\n    your_tasks:\n    - data_analysis\n  url: https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html\n- description: NREC is an Infrastructure-as-a-Service (IaaS) project between the University\n    of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as\n    a cloud infrastructure An IaaS is a self-service infrastructure where you spawn\n    standardized servers and storage instantly, as needed, from a given resource quota.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_7",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":7,
        "total_chunks":14,
        "content":"re you spawn\n    standardized servers and storage instantly, as needed, from a given resource quota. how_to_access: All users at educational institutions via Feide\n  instance_of: openstack\n  name: Norwegian Research and Education Cloud (NREC)\n  related_pages:\n    your_tasks:\n    - data_analysis\n    - storage\n  url: https:\/\/www.nrec.no\/\n- description: Educloud Research is a platform provided by the Centre for Information\n    Technology (USIT) at the University of Oslo (UiO). This platform provides access\n    to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers\n    batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4)\n    can be stored\/analysed. how_to_access: Educloud Research can be ordered by a project at UiO or by external\n    organisations connected to the University\/University College sector.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_8",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":8,
        "total_chunks":14,
        "content":"oject at UiO or by external\n    organisations connected to the University\/University College sector. name: Educloud Research\n  related_pages:\n    your_tasks:\n    - data_analysis\n    - sensitive\n    - storage\n  url: https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/\n- description: The TSD  Service for Sensitive Data, is a platform for collecting,\n    storing, analysing and sharing sensitive data in compliance with the Norwegian\n    privacy regulation. TSD is developed and operated by UiO.\n  how_to_access: To register a project in TSD you have to attach the ethical approval,\n    to conduct your research, either from REK, NSD, the Norwegian Data Protection\n    Authority or your local Data Protection Officer (DPO).",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_9",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":9,
        "total_chunks":14,
        "content":"m REK, NSD, the Norwegian Data Protection\n    Authority or your local Data Protection Officer (DPO). You can access your project\n    through minID-login.\n  name: TSD\n  related_pages:\n    tool_assembly:\n    - tsd\n    your_domain:\n    - human_data\n    your_tasks:\n    - data_analysis\n    - sensitive\n    - storage\n  url: https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/\n- description: The HUNT Cloud, established in 2013, aims to improve and develop the\n    collection, accessibility and exploration of large-scale information. HUNT Cloud\n    offers cloud services and lab management. It is a key service that has established\n    a framework for data protection, data security, and data management. HUNT Cloud\n    is owned by NTNU and operated by HUNT Research Centre at the Department of Public\n    Health and Nursing at the Faculty of Medicine and Health Sciences. how_to_access: Depending on your organisation, data processor agreements may be\n    signed on various organizational levels.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_10",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":10,
        "total_chunks":14,
        "content":" on your organisation, data processor agreements may be\n    signed on various organizational levels. For example, your Department will be\n    the internal data controller at NTNU.\n  name: HUNTCloud\n  related_pages: your_domain:\n    - human_data\n    your_tasks:\n    - data_analysis\n    - sensitive\n    - storage\n  url: https:\/\/www.ntnu.edu\/mh\/huntcloud\n- description: SAFE (secure access to research data and e-infrastructure) is  the\n    solution for the secure processing of sensitive personal data in research at the\n    University of Bergen. SAFE is based on the Norwegian Code of conduct for information\n    security in the health and care sector (Normen) and ensures confidentiality,\n    integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and\n    external partners get access to dedicated resources for processing of sensitive\n    personal data. how_to_access: Access to SAFE requires a University of Bergen computer account.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_11",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":11,
        "total_chunks":14,
        "content":"e\n    personal data. how_to_access: Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners\n    if needed.\n  name: SAFE\n  related_pages: your_domain:\n    - human_data\n    your_tasks:\n    - data_analysis\n    - sensitive\n    - storage\n  url: https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure\n- description: System for Risk and compliance. Processing of personal data in research\n    and student projects at UiB.\n  how_to_access: Through Feide, only if you are based at the UiB\n  name: RETTE\n  related_pages:\n    your_domain:\n    - human_data\n    your_role:\n    - policy_maker\n    - data_steward\n    your_tasks:\n    - data_security\n    - gdpr_compliance\n    - sensitive\n  url: https:\/\/rette.app.uib.no\/\n- description: DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about\n    using DataverseNO as institutional repositories for open research data.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_12",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":12,
        "total_chunks":14,
        "content":"partner agreements about\n    using DataverseNO as institutional repositories for open research data. how_to_access: open access\n  instance_of: dataverse\n  name: DataverseNO\n  related_pages: your_domain: []\n    your_role: []\n    your_tasks:\n    - data_publication\n  url: https:\/\/dataverse.no\/\n- description: General information about open research, especially open access and\n    guidance for researchers and institutions. name: openscience.no\n  url: https:\/\/www.openscience.no\/\n- description: Nettskjema is a solution for designing and managing data collections\n    using online forms and surveys. It can be used for collecting sensitive data and\n    offers a high degree of security and privacy. how_to_access: Feide, TSD, or via ID-porten upon application.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_no_resources_md_13",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":13,
        "total_chunks":14,
        "content":"a high degree of security and privacy. how_to_access: Feide, TSD, or via ID-porten upon application. name: Nettskjema\n  related_pages:\n    tool_assembly:\n    - tsd\n    your_tasks:\n    - sensitive\n  url: https:\/\/nettskjema.no\/\nref_to_main_resources:\n- mardb\n- marfun\nrelated_pages:\n  tool_assembly:\n  - tsd\n  - nels\n  - marine_assembly\n  - fairtracks\ntitle: Norway\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway\n- name: ELIXIR Norway community in Zenodo\n  registry: Zenodo\n  url: https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"no_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_no_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":0,
        "total_chunks":16,
        "content":"Introduction\nThis page provides an overview of the data management resources in Norway. The target audience is the Norwegian scientific community in the life sciences and collaborators. plan.research-data.no is a national knowledge base on research data management. The Data Stewardship Wizard instance from ELIXIR Norway provides an interactive way to navigate these recommendations and resources. You can also find condensed information in the interlinked RDM LookUp from ELIXIR Norway. The Norwegian Ministry of Education and Research's \"National strategy on access to and sharing of research data\" from 2018 is an initiative aimed at fostering open, equitable, and efficient sharing of research data in Norway. For researchers in Norway and their international partners, this strategy lays the groundwork for creating a robust, collaborative research environment where data is shared freely but responsibly.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":1,
        "total_chunks":16,
        "content":"r creating a robust, collaborative research environment where data is shared freely but responsibly. The national strategy underscores Norway's commitment to scientific advancement and maintaining ethical and legal standards in a data-driven era. Funder policies on research data\nNorges Forskningsrd (Research Council of Norway) is the primary funding body in Norway for research. The research data management policy of RCN requires a Data Management Plan (DMP), preferably also available in the DMP Common Standard as supported by for example by {% tool \"data-stewardship-wizard\" %} after a positive funding decision for each project. A DMP has to be submitted as part of a final report. RCN recommends following the Practical Guide to the International Alignment of Research Data Management by Science Europe, the organisation of research funders and performers. In addition to advising policies for open science and open access, RCN provides recommendations on how to make research data available.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":2,
        "total_chunks":16,
        "content":"r open science and open access, RCN provides recommendations on how to make research data available. From 2023 and onwards, a project grant application submitted to RCN is assessed for open science best practices. Institutional policies on research data\nWe provide here a non-exhaustive list of research institutions with Data Management Policies in Norway:\n\nNorwegian University of Life Sciences (NMBU) Norwegian University of Science and Technology (NTNU)\nUniversity of Bergen (UiB)\nUniversity of Oslo (UiO) The Arctic University of Norway (UiT)\nOslo University Hospital (OUS)\nUniversity of Stavanger (UiS)\nUniversity of Agder (UiA)\nNord University\nInland Norway University of Applied Sciences\nVID Specialized University\nSvalbard Integrated Arctic Earth Observing System, SIOS\n\nInstitutional storage guidelines\nMost universities in Norway classify data into four categories, depending on access requirements. These categories are based on recommendations from SIKT. * Open (Green): Information can be available to everyone, without special access rights.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_3",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":3,
        "total_chunks":16,
        "content":" from SIKT. * Open (Green): Information can be available to everyone, without special access rights. * Restricted (Yellow): Information must have some protections if access by unauthorised persons could harm the institution or collaborators in some way. The information can be available both internally and externally with controlled access rights. * Confidential (Red): Information must have strict access rights if unauthorised access would cause damage to public interests, individuals, the institution, or collaborators. * Strictly confidential (Black): Information must have the strictest access rights if unauthorised access could cause significant damage (for example, highly confidential research or confidential addresses). Details and provided solutions vary according to each institution: * Norwegian University of Life Sciences (NMBU) - login\n* Norwegian University of Science and Technology (NTNU)\n* University of Bergen (UiB)\n* University of Oslo (UiO)\n*",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_4",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":4,
        "total_chunks":16,
        "content":"niversity of Science and Technology (NTNU)\n* University of Bergen (UiB)\n* University of Oslo (UiO)\n* The Arctic University of Norway (UiT)\n* VID Specialized University\nInstitutional guidelines related to personal data\n\nGuidance for personal research in the healthcare system\nNorwegian University of Life Sciences (NMBU)\nNorwegian University of Science and Technology (NTNU) - Privacy in research guidelines, also available in Norwegian\nNorwegian University of Science and Technology - Health research guidelines\nUniversity of Bergen (UiB), also available in Norwegian\nUniversity of Oslo (UiO) The Arctic University of Norway (UiT), full guidelines available as pdf\nVID Specialized University\n\nSupport services\nHelpdesks\nThe ELIXIR Norway Helpdesk offers bioinformatics and data management support together with documentation and support for using ELIXIR Norway's life science infrastructures. Researchers in Norway as well as international collaboratorsincluding private companies and governmental research institutionscan contact the Helpdesk to request access to data management services.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_5",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":5,
        "total_chunks":16,
        "content":"mental research institutionscan contact the Helpdesk to request access to data management services. The Global Biodiversity Information Facility (GBIF) Norway Helpdesk supplies IT-services and assistance with deposition of biodiversity data to affiliated organizations. If you are not currently part of the GBIF community, you can follow their guidelines to request endorsement. The GBIF network supports four classes of datasets: resources metadata, checklists, occurrences, and sampling-event data. The ELSI helpdesk for biobanking facilitates compliance with Norway-specific regulations and standards for ethical, legal, and societal issues, as part of Biobank Norway (BBMRI-NO). Institutional research data teams\n\nNorges teknisk-naturvitenskapelige universitet (NTNU)\nUniversity of Bergen (UiB)\nUniversity of Oslo (UiO) The Arctic University of Norway (UiT)\nUniversity of Stavanger (UiS)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_6",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":6,
        "total_chunks":16,
        "content":"n (UiB)\nUniversity of Oslo (UiO) The Arctic University of Norway (UiT)\nUniversity of Stavanger (UiS) University of Agder\nNord University\nUniversity of Inland Norway\nVID Specialized University\nSvalbard Integrated Arctic Earth Observing System, SIOS\n\nOther data management infrastructures\nSikt is a Norwegian governmental agency that provides (sensitive) personal data protection services to research and education institutions in Norway. Sikt offers guidelines, tools for creating data management plans, and assistance with the legal aspects of personal data management. NRIS, a collaboration between Sigma2 (a subsidiary of Sikt) and four universities, gives technical and administrative support to researchers in Norway on large-scale data storage and high-performance computing.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_7",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":7,
        "total_chunks":16,
        "content":"trative support to researchers in Norway on large-scale data storage and high-performance computing. Communities for research data management support personnel\nThere are several RDM communities (with subject or local focus) in Norway to enable exchange and discussion:\n\nLife-Science RDM Group\nRDA Norway\nUniversity of Oslo Data Manager Network\nBergen Research Data Network\nGIDA-Spmi -Smi Research Data Governance, members from Norway, Sweden and Finland\nDataverseNO Network of Expertise\nFAIR Data Forum by Nordic e-Infrastructure Collaboration (NeIC)\nSensitive Data Forum by NeIC\n\nData Management Planning\nA data management plan (DMP) is currently requested by:\n* The research performing institutions \n* RCN upon project funding\n* International funding programs (e.g. Horizon Europe, European Research Council)\nA DMP typically contains information about data handling during a project and after its completion and makes it possible to identify (and budget for) significant issues to be resolved (e.g. storage).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_8",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":8,
        "total_chunks":16,
        "content":"and makes it possible to identify (and budget for) significant issues to be resolved (e.g. storage). While some of the institutions mentioned above require DMPs to follow a certain standard, this does not apply to all local institutions (e.g. UiO does not currently enforce any specific template. There are several tools available for creating a DMP. There is a joint knowledge resource for data management planning in Norwegian research under plan.research-data.no\nELIXIR Norway provides access to a national instance of the Data Stewardship Wizard (DSW), an internationally developed tool that has been adapted to better suit the needs of Norwegian researchers, PIs, and institutions. Both RCN and BOTT (Bergen, Oslo, Trondheim, Troms) university libraries list the DSW as a preferred tool, particularly for life sciences data. DSW provides templates that are compliant with all different funders' regulations and offers machine-actionable DMP exports. To facilitate the adoption of best practices, the ELIXIR-NO DSW instance also provides a collection of exemplar DMPs.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_9",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":9,
        "total_chunks":16,
        "content":" adoption of best practices, the ELIXIR-NO DSW instance also provides a collection of exemplar DMPs. These DMPs are partially pre-filled with domain-specific recommendations and can be used as a starting point for your own projects. Life science-specific infrastructures\/resources\nWe have included here both general and topic-specific resources, that help to simplify and streamline data management practices and to protect your research data. These resources can help you increase productivity while ensuring that your research is compliant, transparent, and reproducible. Norwegian e-Infrastructure for Life Sciences (NeLS) tool assembly\nELIXIR Norway offers the comprehensive NeLS tool assembly for researchers in Norway and their international collaborators. NeLS serves as a unified resource for planning, processing, analysing, and sharing research data throughout your project's life cycle. You can use the Norwegian instance of the Data Stewardship Wizard to simplify data management planning, including compliance with relevant laws and regulations.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_10",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":10,
        "total_chunks":16,
        "content":"izard to simplify data management planning, including compliance with relevant laws and regulations. NeLS' multi-tiered storage system, accessible via FEIDE and the ELIXIR Authentication and Authorization infrastructure, provides a secure platform for data storage. Integration with platforms like Galaxy and SEEK gives easy access to versatile data management tools. For more information, visit the Norwegian e-Infrastructure for Life Sciences (NeLS) tool assembly RDMkit page. Federated European Genome-phenome Archive (EGA) Norway node\nEstablished by ELIXIR Norway and hosted by the University of Oslo, the Norwegian Federated EGA node provides a secure, controlled platform for sharing and archiving sensitive personal data. This service prioritises making sensitive data findable, accessible, interoperable, and reusable (FAIR) while fully complying with GDPR and the Norwegian Personal Data Act. You can boost the visibility of your datasets while maintaining control over access permissions with a designated data access committee.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_11",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":11,
        "total_chunks":16,
        "content":" datasets while maintaining control over access permissions with a designated data access committee. Learn more at the Norwegian node of the European genome-phenome archive for sensitive human (genetic) data. Norwegian tools assembly for sensitive personal data\nELIXIR Norway's tools assembly for personally identifiable datasets is based on the University of Oslo's Services for Sensitive Data (TSD). TSD provides resources to help you comply with Norwegian and European regulations regarding sensitive personal data. You can also store, process, and analyse your data in a secure, restricted environment and use a wide range of integrated data management tools. More details are available on the National Norwegian services for sensitive (personal) data tool assembly RDMkit page. The Norwegian Pathogen Portal\nThe Norwegian Pathogen Portal acts as a specialised hub for collecting, storing, and analysing Covid-19 related research data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_12",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":12,
        "total_chunks":16,
        "content":"tal acts as a specialised hub for collecting, storing, and analysing Covid-19 related research data. You can access research data, tools, and workflows with the assurance of data security and privacy in compliance with national and EU data protection regulations. Marine metagenomics portal tool assembly\nThe Norwegian marine metagenomics portal tool assembly offers comprehensive resources for researchers and students. While the data storage tools through NeLS are primarily for users in Norway, the data analysis tools and repositories are globally accessible. The Marine Metagenomics Portal (MMP) is a rich collection of high-quality, curated microbial genomics and metagenomics resources. The toolkit is described in detail on the Marine metagenomics Portal tool assembly RDMkit page. Ethical committees and general authorities",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_13",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":13,
        "total_chunks":16,
        "content":"the Marine metagenomics Portal tool assembly RDMkit page. Ethical committees and general authorities We provide here a list of ethics committees and guidelines, relevant to life sciences data, that are responsible for national regulations in Norway:\nData privacy\n\nNorwegian Data Protection Authority\n\nHealth research\n\nRegional Ethic committees (for health research)\nMedical devices, medicines, dietary supplements,natural substances or other substances: Norwegian Medicine Agency\n\nGeneral Research Ethics Committees\n\nNorwegian National Research Ethics Committees\n\nRelevant ethical guidelines\n\nGeneral guidelines for research ethics\nGuidelines for Research Ethics in Science and Technology\nGuidelines for research ethical and scientifically assessment of qualitative research projects\nGuidelines for Internet Research Ethics\nGuidelines for the use of genetic studies of humans\nPayment to participants in medical or health research\nGuidelines for the inclusion of women\nEthical guidelines for clinical trial of drugs\nGuidelines for research ethical and scientifically assessment of qualitative research projects\n\nThrough the Research Ethics Committees, the following recommendations were made binding in Norway and it is therefore advised to take them into consideration for data ethics:\n*.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_14",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":14,
        "total_chunks":16,
        "content":"de binding in Norway and it is therefore advised to take them into consideration for data ethics:\n*. The Vancouver Recommendations\n* Declaration of Helsinki\n* The Oviedo Convention\nLaws and regulations relevant to life sciences research data\nThese are some of the laws relevant for research data management in Norway. You should refer to the relevant laws and ethical guidelines in your DMP (e.g. in Norway's instance of the Data Stewardship Wizard (DSW)). Some of the legal information is only accessible after login with Feide. Data privacy\n\nPersonal Data Act\nRegulations on the processing of personal data Forskrift om behandling av personopplysninger\nTransitional rules on the processing of personal data Overgangsregler om behandling av personopplysninger\nThe Norwegian Data Protection Agency:",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_content_no_resources_md_15",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/no_resources.md",
        "file_name":"no_resources.md",
        "chunk_index":15,
        "total_chunks":16,
        "content":"sonal data Overgangsregler om behandling av personopplysninger\nThe Norwegian Data Protection Agency: Journalistic, academic, artistic and literary purposes\nThe Norwegian Data Protection Agency: Code of Conduct on Information Security and Internal Control\n\nHealth research data\n\nHealth Research Act\nRegulations on the organization of medical and health research\nComments to health research legislative work by the Norwegian government\nHealth Register Act\nRegulations on population-based health surveys\nHealth Personnel Act\nPatient and User Rights Act\nMedicines Act\nRegulations on clinical trials of medical products for human use\nBiotechnology Act (on the medical use of biotechnology)\ne-helse Direktoratet: Normen: Norms for health research data\n\nOther laws of potential relevance to life sciences research data\n\nArchive Act\nResearch Ethics Act\nPatent Act\nCopyright Act\nAct on Universities and Colleges Act\nNational Security Act\nGenetic Engineering Act\nBiodiversity Act\nRegulations on the protection of traditional knowledge related to genetic material\nNorwegian Environment Agency: Guidelines on sensitive species data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"no_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Norway",
                "country_code":"NO",
                "contributors":[
                    "Nazeefa Fatima",
                    "Federico Bianchini",
                    "Korbinian Bsl",
                    "Erin Calhoun"
                ],
                "coordinators":[
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "nels",
                        "marine_assembly",
                        "fairtracks"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Norway"
                    },
                    {
                        "name":"ELIXIR Norway community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-no\/?page=1&size=20"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Feide",
                        "description":"Feide is the national solution for secure login and data exchange in education and research. Feide can be linked with [Life Science Login (LS Login)](https:\/\/elixir-europe.org\/services\/compute\/aai) through [eduGAIN](https:\/\/edugain.org\/).",
                        "how_to_access":"Everyone with an affiliation to a Norwegian academic institution.",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/www.feide.no\/"
                    },
                    {
                        "name":"DS-Wizard ELIXIR-Norway",
                        "id":"dsw-no",
                        "description":"DS-Wizard is a tool to aid the creation, organisation and sharing of data management plans. It provides scientists with guidance, facilitating the understanding of the key components of FAIR-oriented Data Stewardship. The template in this instance provides additional guidance on resources, laws and regulations in Norway.",
                        "how_to_access":"Life Science Login (LS Login) with Feide or upon registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "tool_assembly":[
                                "tsd",
                                "nels",
                                "marine_assembly"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/norway.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"EasyDMP",
                        "description":"DMP tool from [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "instance_of":null,
                        "how_to_access":"Feide",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/easydmp.no\/"
                    },
                    {
                        "name":"Meta-pipe",
                        "description":"META-pipe is a pipeline for annotation and analysis of marine metagenomics samples, which provides insight into phylogenetic diversity, metabolic and functional potential of environmental communities.",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ],
                            "tool_assembly":[
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/sfb.mmp2.sigma2.no\/metapipe\/"
                    },
                    {
                        "name":"Norwegian COVID-19 Data Portal",
                        "description":"The Norwegian COVID-19 Data Portal aims to bundle the Norwegian research efforts and offers guidelines, tools, databases and services to support Norwegian COVID-19 researchers.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "url":"https:\/\/pathogens.no\/"
                    },
                    {
                        "name":"Federated EGA Norway node",
                        "description":"Federated instance collects metadata of -omics data collections stored in national or regional archives and makes them available for search through the main EGA portal. With this solution, sensitive data will not physically leave the country, but will reside on TSD.",
                        "how_to_access":"Life Science Login (LS Login); intended for data from Norwegian institutions",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/ega.elixir.no\/"
                    },
                    {
                        "name":"usegalaxy.no",
                        "description":"Galaxy is an open-source, web-based platform for data-intensive biomedical research. This instance of Galaxy is coupled with NeLS for easy data transfer.",
                        "instance_of":"galaxy",
                        "how_to_access":"Feide or upon application",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ],
                            "tool_assembly":[
                                "nels"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.no"
                    },
                    {
                        "name":"NeLS",
                        "description":"Norwegian e-Infrastructure for Life Sciences enables Norwegian life scientists and their international collaborators to store, share, archive, and analyse their omics-scale data.",
                        "how_to_access":"Everyone with funding from a Norwegian funder or a project at one of the health regions or universities can get access through Feide or upon application for collaborators.",
                        "related_pages":{
                            "tool_assembly":[
                                "nels",
                                "marine_assembly"
                            ]
                        },
                        "url":"https:\/\/nels.bioinfo.no"
                    },
                    {
                        "name":"NIRD",
                        "description":"The National Infrastructure for Research Data (NIRD) infrastructure offers storage services, archiving services, and processing capacity for computing on the stored data. It offers services and capacities to any scientific discipline that requires access to advanced, large-scale, or high-end resources for storing, processing, publishing research data or searching digital databases and collections. This service is owned and operated by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "transfer",
                                "storage"
                            ],
                            "tool_assembly":[
                                "nels",
                                "fairtracks"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/files_storage\/nird_lmd.html"
                    },
                    {
                        "name":"Sigma2 HPC systems",
                        "description":"The current Norwegian academic HPC infrastructure consists of three systems for different purposes. The Norwegian academic high-performance computing and storage infrastructure is maintained by [Sigma2 NRIS](https:\/\/sigma2.no\/nris), which is a joint collaboration between UiO, UiB, NTNU, UiT, and [UNINETT Sigma2 (SIKT)](https:\/\/www.sigma2.no\/).",
                        "how_to_access":"A formal application is required to gain access to the storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/documentation.sigma2.no\/hpc_machines\/hardware_overview.html"
                    },
                    {
                        "name":"Norwegian Research and Education Cloud (NREC)",
                        "description":"NREC is an Infrastructure-as-a-Service (IaaS) project between the University of Bergen and the University of Oslo, with additional contributions from NeIC (Nordic e-Infrastructure Collaboration) and Uninett., commonly referred to as a cloud infrastructure An IaaS is a self-service infrastructure where you spawn standardized servers and storage instantly, as needed, from a given resource quota.",
                        "how_to_access":"All users at educational institutions via Feide",
                        "instance_of":"openstack",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.nrec.no\/"
                    },
                    {
                        "name":"Educloud Research",
                        "description":"Educloud Research is a platform provided by the Centre for Information Technology (USIT) at the University of Oslo (UiO). This platform provides access to a work environment accessible to collaborators from other institutions or countries. This service provides a storage solution and a low-threshold HPC system that offers batch job submission (SLURM) and interactive nodes. Data up to the [red classification  level](https:\/\/www.uio.no\/english\/services\/it\/security\/lsis\/data-classes.html#toc4) can be stored\/analysed.",
                        "how_to_access":"Educloud Research can be ordered by a project at UiO or by external organisations connected to the University\/University College sector.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/platforms\/edu-research\/"
                    },
                    {
                        "name":"TSD",
                        "description":"The TSD  Service for Sensitive Data, is a platform for collecting, storing, analysing and sharing sensitive data in compliance with the Norwegian privacy regulation.  TSD is developed and operated by UiO.",
                        "how_to_access":"To register a project in TSD you have to attach the ethical approval, to conduct your research, either from REK, NSD, the Norwegian Data Protection Authority or your local Data Protection Officer (DPO). You can access your project through minID-login.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/www.uio.no\/english\/services\/it\/research\/sensitive-data\/"
                    },
                    {
                        "name":"HUNTCloud",
                        "description":"The HUNT Cloud, established in 2013, aims to improve and develop the collection, accessibility and exploration of large-scale information. HUNT Cloud offers cloud services and lab management. It is a key service that has established a framework for data protection, data security, and data management. HUNT Cloud is owned by NTNU and operated by HUNT Research Centre at the Department of Public Health and Nursing at the Faculty of Medicine and Health Sciences.",
                        "how_to_access":"Depending on your organisation, data processor agreements may be signed on various organizational levels. For example, your Department will be the internal data controller at NTNU.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.ntnu.edu\/mh\/huntcloud"
                    },
                    {
                        "name":"SAFE",
                        "description":"SAFE (secure access to research data and e-infrastructure) is  the solution for the secure processing of sensitive personal data in research at the University of Bergen. SAFE is based on the Norwegian Code of conduct for information security in the health and care sector (Normen) and ensures confidentiality, integrity, and availability are preserved when processing sensitive personal data. Through SAFE, the IT department offers a service where employees, students and external partners get access to dedicated resources for processing of sensitive personal data.",
                        "how_to_access":"Access to SAFE requires a University of Bergen computer account. However, each department has approvers who can create external accounts for partners if needed.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.uib.no\/en\/it\/131011\/safe-secure-access-research-data-and-e-infrastructure"
                    },
                    {
                        "name":"RETTE",
                        "description":"System for Risk and compliance. Processing of personal data in research and student projects at UiB.",
                        "how_to_access":"Through Feide, only if you are based at the UiB",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "data_security",
                                "gdpr_compliance",
                                "sensitive"
                            ],
                            "your_role":[
                                "policy_maker",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/rette.app.uib.no\/"
                    },
                    {
                        "name":"DataverseNO",
                        "description":"DataverseNO is a national, generic repository for open research data. Various Norwegian research institutions have established partner agreements about using DataverseNO as institutional repositories for open research data.",
                        "how_to_access":"open access",
                        "instance_of":"dataverse",
                        "related_pages":{
                            "your_domain":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[

                            ]
                        },
                        "url":"https:\/\/dataverse.no\/"
                    },
                    {
                        "name":"openscience.no",
                        "description":"General information about open research, especially open access and guidance for researchers and institutions.",
                        "url":"https:\/\/www.openscience.no\/"
                    },
                    {
                        "name":"Nettskjema",
                        "description":"Nettskjema is a solution for designing and managing data collections using online forms and surveys. It can be used for collecting sensitive data and offers a high degree of security and privacy.",
                        "how_to_access":"Feide, TSD, or via ID-porten upon application.",
                        "related_pages":{
                            "your_tasks":[
                                "sensitive"
                            ],
                            "tool_assembly":[
                                "tsd"
                            ]
                        },
                        "url":"https:\/\/nettskjema.no\/"
                    }
                ],
                "ref_to_main_resources":[
                    "mardb",
                    "marfun"
                ]
            }
        }
    },
    {
        "id":"md_fm_se_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"contributors:\n- Stephan Nylinder\n- Yvonne Kallberg\n- Niclas Jareborg\ncoordinators:\n- Niclas Jareborg\n- Yvonne Kallberg\ncountry_code: SE\nnational_resources:\n- description: Data Stewardship Wizard is a tool to be used when planning for data\n    management, including generating a data management plan (DMP). This instance provides\n    guidance with focus towards Swedish life science researchers, including national\n    resources. how_to_access: ELIXIR AAI login\n  instance_of: data-stewardship-wizard\n  name: DS-Wizard ELIXIR-SE\n  related_pages:\n    your_tasks:\n    - dmp\n  url: https:\/\/dsw.scilifelab.se\/\n- description: A repository for publishing any kind of research-related data, e.g.\n    documents, figures, or presentations. how_to_access: Available to everyone with an affiliation to a Swedish academic institution.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"se_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_se_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"tations. how_to_access: Available to everyone with an affiliation to a Swedish academic institution. instance_of: figshare\n  name: SciLifeLab Data Repository (Figshare)\n  related_pages:\n    your_tasks:\n    - existing_data\n    - data_publication\n  url: https:\/\/scilifelab.figshare.com\/\n- description: Free consultation service regarding data management questions in life\n    science research. how_to_access: Available to everyone with an affiliation to a Swedish academic institution. name: NBIS Data Management Consultation\n  related_pages:\n    your_tasks:\n    - dmp\n    - data_publication\n    - sensitive\n  url: https:\/\/nbis.se\/services\/guidance-on-data-management\n- description: The Swedish Pathogens Portal provides information, guidelines, tools\n    and services to support researchers to utilise Swedish and European infrastructures\n    for data sharing.\n  name: Swedish Pathogens Portal\n  related_pages:\n    tool_assembly:\n    - covid19_data_portal",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"se_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_se_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"ring.\n  name: Swedish Pathogens Portal\n  related_pages:\n    tool_assembly:\n    - covid19_data_portal your_domain:\n    - human_data\n    your_tasks:\n    - sensitive\n    - existing_data\n    - data_publication\n  url: https:\/\/pathogens.se\/\n- description: The National Academic Infrastructure for Supercomputing in Sweden\n    (NAISS) is a national research infrastructure that makes available large-scale\n    high-performance computing resources, storage capacity, and advanced user support,\n    for Swedish research. how_to_access: An application is required to gain access to the compute and storage\n    services.\n  name: NAISS\n  related_pages:\n    your_tasks:\n    - data_analysis\n    - storage\n  url: https:\/\/www.naiss.se\/\n- description: Knowledge hub for the management of life science research data in Sweden.\n  name: SciLifeLab RDM Guidelines\n  url: https:\/\/data-guidelines.scilifelab.se\/\n- description: Guidelines as well as further information on legal considerations when\n    working with human biomedical data. name: Human Data Guidelines\n  related_pages:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"se_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_se_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"iderations when\n    working with human biomedical data. name: Human Data Guidelines\n  related_pages: your_domain:\n    - human_data\n    your_tasks:\n    - sensitive\n  url: https:\/\/data-guidelines.scilifelab.se\/topics\/research-involving-human-data\/\n- description: Secure archiving and sharing of genetic and phenotypic data resulting\n    from Swedish biomedical research projects. instance_of: the-european-genome-phenome-archive\n  name: Federated EGA Sweden node\n  related_pages: your_domain:\n    - human_data\n    your_tasks:\n    - sensitive\n    - existing_data\n    - data_publication\n  url: https:\/\/fega.nbis.se\/\ntitle: Sweden\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Sweden&scientific_topics=Data+management\n- name: SciLifeLab Data Management YouTube\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/playlist?list=PL1nnHOyxN_WdqnzLqbmWJz_i0f2anT9cS",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"se_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_se_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":0,
        "total_chunks":6,
        "content":"Introduction\nThis page provides a general overview of national resources on research data management (RDM) in Sweden, directed towards researchers and official collaborators. National goals and long term data management achievements are provided in the Research Bill 2020\/21-60. The Swedish ELIXIR node National Bioinformatics Infrastructure Sweden (NBIS) offers support and training in data management to life science researchers in Sweden, in collaboration with the Data Centre at Science for Life Laboratory (SciLifeLab). Funders with policies\nThe Swedish Research Council has a government mandate to coordinate and promote Swedens work on introducing open access to research data, with the goal for transition to open access to research data to be fully implemented by 2026.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"se_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Sweden",
                "country_code":"SE",
                "contributors":[
                    "Stephan Nylinder",
                    "Yvonne Kallberg",
                    "Niclas Jareborg"
                ],
                "coordinators":[
                    "Niclas Jareborg",
                    "Yvonne Kallberg"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Sweden&scientific_topics=Data+management"
                    },
                    {
                        "name":"SciLifeLab Data Management YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL1nnHOyxN_WdqnzLqbmWJz_i0f2anT9cS"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS-Wizard ELIXIR-SE",
                        "description":"Data Stewardship Wizard is a tool to be used when planning for data management, including generating a data management plan (DMP). This instance provides guidance with focus towards Swedish life science researchers, including national resources.",
                        "how_to_access":"ELIXIR AAI login",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dsw.scilifelab.se\/"
                    },
                    {
                        "name":"SciLifeLab Data Repository (Figshare)",
                        "description":"A repository for publishing any kind of research-related data, e.g. documents, figures, or presentations.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "instance_of":"figshare",
                        "related_pages":{
                            "your_tasks":[
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/scilifelab.figshare.com\/"
                    },
                    {
                        "name":"NBIS Data Management Consultation",
                        "description":"Free consultation service regarding data management questions in life science research.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp",
                                "data_publication",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/nbis.se\/services\/guidance-on-data-management"
                    },
                    {
                        "name":"Swedish Pathogens Portal",
                        "description":"The Swedish Pathogens Portal provides information, guidelines, tools and services to support researchers to utilise Swedish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/pathogens.se\/"
                    },
                    {
                        "name":"NAISS",
                        "description":"The National Academic Infrastructure for Supercomputing in Sweden (NAISS) is a national research infrastructure that makes available large-scale high-performance computing resources, storage capacity, and advanced user support, for Swedish research.",
                        "how_to_access":"An application is required to gain access to the compute and storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.naiss.se\/"
                    },
                    {
                        "name":"SciLifeLab RDM Guidelines",
                        "description":"Knowledge hub for the management of life science research data in Sweden.",
                        "url":"https:\/\/data-guidelines.scilifelab.se\/"
                    },
                    {
                        "name":"Human Data Guidelines",
                        "description":"Guidelines as well as further information on legal considerations when working with human biomedical data.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/data-guidelines.scilifelab.se\/topics\/research-involving-human-data\/"
                    },
                    {
                        "name":"Federated EGA Sweden node",
                        "description":"Secure archiving and sharing of genetic and phenotypic data resulting from Swedish biomedical research projects.",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fega.nbis.se\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_se_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":1,
        "total_chunks":6,
        "content":" data, with the goal for transition to open access to research data to be fully implemented by 2026. As of 2019 all who receive grants from the council must have a data management plan (DMP), written according to their DMP template, which is a partially reworked version of Science Europes \"Core Requirements for Data Management Plans\". Formas - The Swedish Research Council for Environment, Agricultural Sciences and Spatial Planning - has a policy on open access to research data, and requires that a DMP is written and can be shown upon request. Authorities and Regulations\nIf personal data is processed in your research, contact your institutes Data Protection Officer, and if available, the Research Data Office (see list at end of page), for guidance on ethical and legal compliance. The following is a list of ethical and legal committees, authorities and regulations of interest: Authorities\n\nSwedish Ethical Review Authority\nSwedish Authority for Privacy Protection (IMY)\n\nRegulations\n\nThe Ethics Review Act (in Swedish) The Patient Data Act (in Swedish)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"se_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Sweden",
                "country_code":"SE",
                "contributors":[
                    "Stephan Nylinder",
                    "Yvonne Kallberg",
                    "Niclas Jareborg"
                ],
                "coordinators":[
                    "Niclas Jareborg",
                    "Yvonne Kallberg"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Sweden&scientific_topics=Data+management"
                    },
                    {
                        "name":"SciLifeLab Data Management YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL1nnHOyxN_WdqnzLqbmWJz_i0f2anT9cS"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS-Wizard ELIXIR-SE",
                        "description":"Data Stewardship Wizard is a tool to be used when planning for data management, including generating a data management plan (DMP). This instance provides guidance with focus towards Swedish life science researchers, including national resources.",
                        "how_to_access":"ELIXIR AAI login",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dsw.scilifelab.se\/"
                    },
                    {
                        "name":"SciLifeLab Data Repository (Figshare)",
                        "description":"A repository for publishing any kind of research-related data, e.g. documents, figures, or presentations.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "instance_of":"figshare",
                        "related_pages":{
                            "your_tasks":[
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/scilifelab.figshare.com\/"
                    },
                    {
                        "name":"NBIS Data Management Consultation",
                        "description":"Free consultation service regarding data management questions in life science research.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp",
                                "data_publication",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/nbis.se\/services\/guidance-on-data-management"
                    },
                    {
                        "name":"Swedish Pathogens Portal",
                        "description":"The Swedish Pathogens Portal provides information, guidelines, tools and services to support researchers to utilise Swedish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/pathogens.se\/"
                    },
                    {
                        "name":"NAISS",
                        "description":"The National Academic Infrastructure for Supercomputing in Sweden (NAISS) is a national research infrastructure that makes available large-scale high-performance computing resources, storage capacity, and advanced user support, for Swedish research.",
                        "how_to_access":"An application is required to gain access to the compute and storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.naiss.se\/"
                    },
                    {
                        "name":"SciLifeLab RDM Guidelines",
                        "description":"Knowledge hub for the management of life science research data in Sweden.",
                        "url":"https:\/\/data-guidelines.scilifelab.se\/"
                    },
                    {
                        "name":"Human Data Guidelines",
                        "description":"Guidelines as well as further information on legal considerations when working with human biomedical data.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/data-guidelines.scilifelab.se\/topics\/research-involving-human-data\/"
                    },
                    {
                        "name":"Federated EGA Sweden node",
                        "description":"Secure archiving and sharing of genetic and phenotypic data resulting from Swedish biomedical research projects.",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fega.nbis.se\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_se_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":2,
        "total_chunks":6,
        "content":" Protection (IMY)\n\nRegulations\n\nThe Ethics Review Act (in Swedish) The Patient Data Act (in Swedish) The Biobank Act (in Swedish)\nThe Archives Act (in Swedish)\nLag (2018:218) med kompletterande bestmmelser till EU:s dataskyddsfrordning\n\nDomain-specific infrastructures and resources\nThe SciLifeLab Data Centre  provides services for IT and data management, including Data Stewardship Wizard instance (for writing data management plans), the Swedish Pathogens Portal, and the SciLifeLab Data Repository. Data stewards at NBIS (ELIXIR-SE) provide consultation and support services regarding data management questions, including e.g. guidance when writing data management plans and when doing submissions to domain-specific repositories. For information about this and other resources at NBIS please see the Data Management page. An important resource is the FEGA Sweden, a secure data archive and sharing platform for sensitive datasets, which will be integrated with the {% tool \"the-european-genome-phenome-archive\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"se_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Sweden",
                "country_code":"SE",
                "contributors":[
                    "Stephan Nylinder",
                    "Yvonne Kallberg",
                    "Niclas Jareborg"
                ],
                "coordinators":[
                    "Niclas Jareborg",
                    "Yvonne Kallberg"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Sweden&scientific_topics=Data+management"
                    },
                    {
                        "name":"SciLifeLab Data Management YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL1nnHOyxN_WdqnzLqbmWJz_i0f2anT9cS"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS-Wizard ELIXIR-SE",
                        "description":"Data Stewardship Wizard is a tool to be used when planning for data management, including generating a data management plan (DMP). This instance provides guidance with focus towards Swedish life science researchers, including national resources.",
                        "how_to_access":"ELIXIR AAI login",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dsw.scilifelab.se\/"
                    },
                    {
                        "name":"SciLifeLab Data Repository (Figshare)",
                        "description":"A repository for publishing any kind of research-related data, e.g. documents, figures, or presentations.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "instance_of":"figshare",
                        "related_pages":{
                            "your_tasks":[
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/scilifelab.figshare.com\/"
                    },
                    {
                        "name":"NBIS Data Management Consultation",
                        "description":"Free consultation service regarding data management questions in life science research.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp",
                                "data_publication",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/nbis.se\/services\/guidance-on-data-management"
                    },
                    {
                        "name":"Swedish Pathogens Portal",
                        "description":"The Swedish Pathogens Portal provides information, guidelines, tools and services to support researchers to utilise Swedish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/pathogens.se\/"
                    },
                    {
                        "name":"NAISS",
                        "description":"The National Academic Infrastructure for Supercomputing in Sweden (NAISS) is a national research infrastructure that makes available large-scale high-performance computing resources, storage capacity, and advanced user support, for Swedish research.",
                        "how_to_access":"An application is required to gain access to the compute and storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.naiss.se\/"
                    },
                    {
                        "name":"SciLifeLab RDM Guidelines",
                        "description":"Knowledge hub for the management of life science research data in Sweden.",
                        "url":"https:\/\/data-guidelines.scilifelab.se\/"
                    },
                    {
                        "name":"Human Data Guidelines",
                        "description":"Guidelines as well as further information on legal considerations when working with human biomedical data.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/data-guidelines.scilifelab.se\/topics\/research-involving-human-data\/"
                    },
                    {
                        "name":"Federated EGA Sweden node",
                        "description":"Secure archiving and sharing of genetic and phenotypic data resulting from Swedish biomedical research projects.",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fega.nbis.se\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_se_resources_md_3",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":3,
        "total_chunks":6,
        "content":"sitive datasets, which will be integrated with the {% tool \"the-european-genome-phenome-archive\" %}. The National Academic Infrastructure for Supercomputing in Sweden (NAISS) is a national research infrastructure that provides resources and user support for large scale computation and data storage to meet the needs of researchers from all scientific disciplines and from all over Sweden. Of particular use for life science researchers is the NAISS-SENS project which provides high-performance computing resources for analyzing sensitive data. Swedish National Data Service (SND) with its network of almost 40 higher education institutions and public research institutes, provides researchers with a coordinated and quality-assured system for finding, describing, and sharing research data, nationally as well as internationally.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"se_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Sweden",
                "country_code":"SE",
                "contributors":[
                    "Stephan Nylinder",
                    "Yvonne Kallberg",
                    "Niclas Jareborg"
                ],
                "coordinators":[
                    "Niclas Jareborg",
                    "Yvonne Kallberg"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Sweden&scientific_topics=Data+management"
                    },
                    {
                        "name":"SciLifeLab Data Management YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL1nnHOyxN_WdqnzLqbmWJz_i0f2anT9cS"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS-Wizard ELIXIR-SE",
                        "description":"Data Stewardship Wizard is a tool to be used when planning for data management, including generating a data management plan (DMP). This instance provides guidance with focus towards Swedish life science researchers, including national resources.",
                        "how_to_access":"ELIXIR AAI login",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dsw.scilifelab.se\/"
                    },
                    {
                        "name":"SciLifeLab Data Repository (Figshare)",
                        "description":"A repository for publishing any kind of research-related data, e.g. documents, figures, or presentations.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "instance_of":"figshare",
                        "related_pages":{
                            "your_tasks":[
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/scilifelab.figshare.com\/"
                    },
                    {
                        "name":"NBIS Data Management Consultation",
                        "description":"Free consultation service regarding data management questions in life science research.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp",
                                "data_publication",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/nbis.se\/services\/guidance-on-data-management"
                    },
                    {
                        "name":"Swedish Pathogens Portal",
                        "description":"The Swedish Pathogens Portal provides information, guidelines, tools and services to support researchers to utilise Swedish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/pathogens.se\/"
                    },
                    {
                        "name":"NAISS",
                        "description":"The National Academic Infrastructure for Supercomputing in Sweden (NAISS) is a national research infrastructure that makes available large-scale high-performance computing resources, storage capacity, and advanced user support, for Swedish research.",
                        "how_to_access":"An application is required to gain access to the compute and storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.naiss.se\/"
                    },
                    {
                        "name":"SciLifeLab RDM Guidelines",
                        "description":"Knowledge hub for the management of life science research data in Sweden.",
                        "url":"https:\/\/data-guidelines.scilifelab.se\/"
                    },
                    {
                        "name":"Human Data Guidelines",
                        "description":"Guidelines as well as further information on legal considerations when working with human biomedical data.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/data-guidelines.scilifelab.se\/topics\/research-involving-human-data\/"
                    },
                    {
                        "name":"Federated EGA Sweden node",
                        "description":"Secure archiving and sharing of genetic and phenotypic data resulting from Swedish biomedical research projects.",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fega.nbis.se\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_se_resources_md_4",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":4,
        "total_chunks":6,
        "content":"ed system for finding, describing, and sharing research data, nationally as well as internationally. The SND network has agreed to create local units for managing research data (Data Access Units (DAUs)), with the main task to assist researchers in their respective organisation in making research data as accessible as possible, via training and support in data management. SND also provides a DMP checklist to support researchers in writing data management plans. List of universities with established Research Data Offices or Data Access Units (DAUs), with links to local online resources and contact information:\n* Chalmers University of Technology - Research Data Support - dataoffice@chalmers.se\n* Karolinska Institutet - Research Data Support - rdo@ki.se\n* KTH Royal Institute of Technology - Research Data Support - researchdata@kth.se\n* Linkping University - Research Data Support - datamanagement@liu.se\n* Linnaeus University - Research Data Support - dau@lnu.se\n* Lund University - Research Data Support - See web page for contact information\n*",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"se_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Sweden",
                "country_code":"SE",
                "contributors":[
                    "Stephan Nylinder",
                    "Yvonne Kallberg",
                    "Niclas Jareborg"
                ],
                "coordinators":[
                    "Niclas Jareborg",
                    "Yvonne Kallberg"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Sweden&scientific_topics=Data+management"
                    },
                    {
                        "name":"SciLifeLab Data Management YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL1nnHOyxN_WdqnzLqbmWJz_i0f2anT9cS"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS-Wizard ELIXIR-SE",
                        "description":"Data Stewardship Wizard is a tool to be used when planning for data management, including generating a data management plan (DMP). This instance provides guidance with focus towards Swedish life science researchers, including national resources.",
                        "how_to_access":"ELIXIR AAI login",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dsw.scilifelab.se\/"
                    },
                    {
                        "name":"SciLifeLab Data Repository (Figshare)",
                        "description":"A repository for publishing any kind of research-related data, e.g. documents, figures, or presentations.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "instance_of":"figshare",
                        "related_pages":{
                            "your_tasks":[
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/scilifelab.figshare.com\/"
                    },
                    {
                        "name":"NBIS Data Management Consultation",
                        "description":"Free consultation service regarding data management questions in life science research.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp",
                                "data_publication",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/nbis.se\/services\/guidance-on-data-management"
                    },
                    {
                        "name":"Swedish Pathogens Portal",
                        "description":"The Swedish Pathogens Portal provides information, guidelines, tools and services to support researchers to utilise Swedish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/pathogens.se\/"
                    },
                    {
                        "name":"NAISS",
                        "description":"The National Academic Infrastructure for Supercomputing in Sweden (NAISS) is a national research infrastructure that makes available large-scale high-performance computing resources, storage capacity, and advanced user support, for Swedish research.",
                        "how_to_access":"An application is required to gain access to the compute and storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.naiss.se\/"
                    },
                    {
                        "name":"SciLifeLab RDM Guidelines",
                        "description":"Knowledge hub for the management of life science research data in Sweden.",
                        "url":"https:\/\/data-guidelines.scilifelab.se\/"
                    },
                    {
                        "name":"Human Data Guidelines",
                        "description":"Guidelines as well as further information on legal considerations when working with human biomedical data.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/data-guidelines.scilifelab.se\/topics\/research-involving-human-data\/"
                    },
                    {
                        "name":"Federated EGA Sweden node",
                        "description":"Secure archiving and sharing of genetic and phenotypic data resulting from Swedish biomedical research projects.",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fega.nbis.se\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_se_resources_md_5",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/se_resources.md",
        "file_name":"se_resources.md",
        "chunk_index":5,
        "total_chunks":6,
        "content":"port - dau@lnu.se\n* Lund University - Research Data Support - See web page for contact information\n* Stockholm University - Research Data Support - opendata@su.se\n* Swedish University of Agricultural Sciences - Research Data Support - dms@slu.se\n* Ume University - Research Data Support - See contact page\n* University of Gothenburg - Research Data Support - researchdata@gu.se\n* Uppsala University - Research Data Support - dataoffice@uu.se\n* rebro University - Research Data Support - See web page for contact information",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"se_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Sweden",
                "country_code":"SE",
                "contributors":[
                    "Stephan Nylinder",
                    "Yvonne Kallberg",
                    "Niclas Jareborg"
                ],
                "coordinators":[
                    "Niclas Jareborg",
                    "Yvonne Kallberg"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/events?include_expired=true&node=Sweden&scientific_topics=Data+management"
                    },
                    {
                        "name":"SciLifeLab Data Management YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PL1nnHOyxN_WdqnzLqbmWJz_i0f2anT9cS"
                    }
                ],
                "national_resources":[
                    {
                        "name":"DS-Wizard ELIXIR-SE",
                        "description":"Data Stewardship Wizard is a tool to be used when planning for data management, including generating a data management plan (DMP). This instance provides guidance with focus towards Swedish life science researchers, including national resources.",
                        "how_to_access":"ELIXIR AAI login",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dsw.scilifelab.se\/"
                    },
                    {
                        "name":"SciLifeLab Data Repository (Figshare)",
                        "description":"A repository for publishing any kind of research-related data, e.g. documents, figures, or presentations.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "instance_of":"figshare",
                        "related_pages":{
                            "your_tasks":[
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/scilifelab.figshare.com\/"
                    },
                    {
                        "name":"NBIS Data Management Consultation",
                        "description":"Free consultation service regarding data management questions in life science research.",
                        "how_to_access":"Available to everyone with an affiliation to a Swedish academic institution.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp",
                                "data_publication",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/nbis.se\/services\/guidance-on-data-management"
                    },
                    {
                        "name":"Swedish Pathogens Portal",
                        "description":"The Swedish Pathogens Portal provides information, guidelines, tools and services to support researchers to utilise Swedish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/pathogens.se\/"
                    },
                    {
                        "name":"NAISS",
                        "description":"The National Academic Infrastructure for Supercomputing in Sweden (NAISS) is a national research infrastructure that makes available large-scale high-performance computing resources, storage capacity, and advanced user support, for Swedish research.",
                        "how_to_access":"An application is required to gain access to the compute and storage services.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.naiss.se\/"
                    },
                    {
                        "name":"SciLifeLab RDM Guidelines",
                        "description":"Knowledge hub for the management of life science research data in Sweden.",
                        "url":"https:\/\/data-guidelines.scilifelab.se\/"
                    },
                    {
                        "name":"Human Data Guidelines",
                        "description":"Guidelines as well as further information on legal considerations when working with human biomedical data.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/data-guidelines.scilifelab.se\/topics\/research-involving-human-data\/"
                    },
                    {
                        "name":"Federated EGA Sweden node",
                        "description":"Secure archiving and sharing of genetic and phenotypic data resulting from Swedish biomedical research projects.",
                        "instance_of":"the-european-genome-phenome-archive",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing_data",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fega.nbis.se\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_ch_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"contributors:\n- Gregoire Rossier\n- Vassilios Ioannidis\ncoordinators:\n- Gregoire Rossier\n- Vassilios Ioannidis\ncountry_code: CH\nnational_resources:\n- description: OLOS is a Swiss-based data management portal, to help Swiss researchers\n    safely manage, publish and preserve their data.\n  how_to_access: null\n  instance_of: null\n  name: OLOS\n  registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role: []\n    your_tasks:\n    - storage\n    - data_publication\n  url: https:\/\/www.dlcm.ch\/olos\n- description: SWISSUbase is a national cross-disciplinary solution for Swiss universities\n    and other research organizations in need of local institutional data repositories\n    for their researchers. The platform relies on international archiving standards\n    and processes to ensure that data are preserved and accessible in the long-term.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ch_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_ch_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"iving standards\n    and processes to ensure that data are preserved and accessible in the long-term. how_to_access: null\n  instance_of: null\n  name: SWISSUbase\n  registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role: []\n    your_tasks:\n    - storage\n    - data_publication\n  url: https:\/\/www.swissubase.ch\/\n- description: openRDM.swiss offers research data management as a service to the scientific\n    community, based on the powerful openBIS platform. how_to_access: null\n  instance_of: null\n  name: OpenRDM.swiss\n  registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role: []\n    your_tasks:\n    - data_analysis\n  url: https:\/\/openbis.ch\/index.php\/openrdm-swiss\/\n- description: An open-source knowledge infrastructure for collaborative and reproducible\n    data science. how_to_access: null\n  instance_of: null\n  name: Renku\n  registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ch_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_ch_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"egistry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role: []\n    your_tasks:\n    - data_analysis\n  url: https:\/\/renkulab.io\/\n- description: A secure IT network for the responsible processing of health-related\n    data. how_to_access: null\n  instance_of: null\n  name: BioMedIT\n  registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly: []\n    your_domain:\n    - human_data\n    your_role: []\n    your_tasks:\n    - data_analysis\n    - sensitive\n  url: https:\/\/www.biomedit.ch\/\n- description: A secure One-health online platform that enables near real-time sharing\n    under controlled access of pathogen whole genome sequences (WGS) and their associated\n    clinical\/epidemiological metadata. Since 20221 it has centralized and processed\n    all SARS-CoV-2 sequencing data within the national genomic surveillance program. how_to_access: null\n  instance_of: null\n  name: Swiss Pathogen Surveillance Platform (SPSP)",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ch_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_ch_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"program. how_to_access: null\n  instance_of: null\n  name: Swiss Pathogen Surveillance Platform (SPSP) registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly:\n    - covid19_data_portal your_domain: []\n    your_role: []\n    your_tasks:\n    - existing_data\n  url: https:\/\/spsp.ch\/\n- description: Digit Object Repository at the Libr4RI (4 ETH Domain Research Institutes,\n    that are EAWAG, EMPA, PSI, WSL). how_to_access: null\n  instance_of: null\n  name: DORA\n  registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role: []\n    your_tasks:\n    - data_publication\n  url: https:\/\/www.dora.lib4ri.ch\/\n- description: This instance of DMPonline is provided by the Service des ressources\n    informationnelles et archives (UNIRIS) of the University of Lausanne (UNIL) to\n    help its community of researchers to write a Data Management Plan (DMP).",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ch_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_ch_resources_md_4",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"y of Lausanne (UNIL) to\n    help its community of researchers to write a Data Management Plan (DMP). how_to_access: null\n  instance_of: dmponline\n  name: UNIL DMP Online\n  registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role: []\n    your_tasks:\n    - dmp\n  url: https:\/\/dmp.unil.ch\/\n- description: This is a tool to help scientists generate data management plans for\n    SNSF -unded projects. The Word document produced complies with the SNSF instructions\n    for creating DMPs. how_to_access: null\n  instance_of: null\n  name: SIB\/Vital-IT Canvas Generator\n  registry:\n    biotools: null\n    fairsharing: null\n    tess: null\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role: []\n    your_tasks:\n    - dmp\n  url: https:\/\/dmp.vital-it.ch\/\nref_to_main_resources: null\nrelated_pages:\n  tool_assembly: []\ntitle: Switzerland\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/nodes\/switzerland",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ch_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_ch_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"Introduction\nThis page provides useful information and resources about research data management in Switzerland. Check the overview of ELIXIR Switzerland and its services. Governance and Funders\nSERI\nThe State Secretariat for Education, Research and Innovation (SERI) within the Federal Department of Economic Affairs, Education and Research EAER is the federal governments specialised agency for national and international matters concerning education, research and innovation policy. SNFS\nThe Swiss National Science Foundation (SNSF) supports scientific research in all academic disciplines  from physics to medicine to sociology. At the end of 2021, the SNSF was funding 5,700 projects involving more than 20,000 researchers, which makes it the leading Swiss institution for promoting scientific research. Swissuniversities\nSwissuniversities is the common voice of the Swiss universities and promotes cooperation and coordination between the universities and the various types of universities.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ch_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Switzerland",
                "country_code":"CH",
                "contributors":[
                    "Gregoire Rossier",
                    "Vassilios Ioannidis"
                ],
                "coordinators":[
                    "Gregoire Rossier",
                    "Vassilios Ioannidis"
                ],
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/switzerland"
                    }
                ],
                "ref_to_main_resources":null,
                "national_resources":[
                    {
                        "name":"OLOS",
                        "description":"OLOS is a Swiss-based data management portal, to help Swiss researchers safely manage, publish and preserve their data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.dlcm.ch\/olos",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"SWISSUbase",
                        "description":"SWISSUbase is a national cross-disciplinary solution for Swiss universities and other research organizations in need of local institutional data repositories for their researchers. The platform relies on international archiving standards and processes to ensure that data are preserved and accessible in the long-term.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.swissubase.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"OpenRDM.swiss",
                        "description":"openRDM.swiss offers research data management as a service to the scientific community, based on the powerful openBIS platform.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/openbis.ch\/index.php\/openrdm-swiss\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"Renku",
                        "description":"An open-source knowledge infrastructure for collaborative and reproducible data science.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/renkulab.io\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"BioMedIT",
                        "description":"A secure IT network for the responsible processing of health-related data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/www.biomedit.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"Swiss Pathogen Surveillance Platform (SPSP)",
                        "description":"A secure One-health online platform that enables near real-time sharing under controlled access of pathogen whole genome sequences (WGS) and their associated clinical\/epidemiological metadata. Since 20221 it has centralized and processed all SARS-CoV-2 sequencing data within the national genomic surveillance program.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/spsp.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"DORA",
                        "description":"Digit Object Repository at the Libr4RI (4 ETH Domain Research Institutes, that are EAWAG, EMPA, PSI, WSL).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.dora.lib4ri.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"UNIL DMP Online",
                        "description":"This instance of DMPonline is provided by the Service des ressources informationnelles et archives (UNIRIS) of the University of Lausanne (UNIL) to help its community of researchers to write a Data Management Plan (DMP).",
                        "how_to_access":null,
                        "instance_of":"dmponline",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.unil.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"SIB\/Vital-IT Canvas Generator",
                        "description":"This is a tool to help scientists generate data management plans for SNSF -unded projects. The Word document produced complies with the SNSF instructions for creating DMPs.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.vital-it.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ch_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"romotes cooperation and coordination between the universities and the various types of universities. ETH Domain\nThe ETH Domain falls under the authority of the Federal Department of Economic Affairs, Education and Research (EAER). It comprises Switzerlands two federal institutes of technology (FIT)  ETH Zurich and the EPFL in Lausanne  and four research institutes: the Paul Scherrer Institute (PSI), the Swiss Federal Institute for Forest, Snow and Landscape Research (WSL), the Swiss Federal Laboratories for Materials Science and Technology (Empa) and the Swiss Federal Institute of Aquatic Science and Technology (Eawag). National initiatives\nSwiss Open Research Data\nIn 2021, the State Secretariat for Education, Research and Innovation (SERI), the Swiss Conference of Rectors of Higher Education Institutions (swissuniversities), the Swiss National Science Foundation (SNSF) and Switzerlands two federal institutes of technology (ETHZ in Zurich and EPFL in Lausanne) signed an agreement to develop a national strategy on open research data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ch_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Switzerland",
                "country_code":"CH",
                "contributors":[
                    "Gregoire Rossier",
                    "Vassilios Ioannidis"
                ],
                "coordinators":[
                    "Gregoire Rossier",
                    "Vassilios Ioannidis"
                ],
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/switzerland"
                    }
                ],
                "ref_to_main_resources":null,
                "national_resources":[
                    {
                        "name":"OLOS",
                        "description":"OLOS is a Swiss-based data management portal, to help Swiss researchers safely manage, publish and preserve their data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.dlcm.ch\/olos",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"SWISSUbase",
                        "description":"SWISSUbase is a national cross-disciplinary solution for Swiss universities and other research organizations in need of local institutional data repositories for their researchers. The platform relies on international archiving standards and processes to ensure that data are preserved and accessible in the long-term.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.swissubase.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"OpenRDM.swiss",
                        "description":"openRDM.swiss offers research data management as a service to the scientific community, based on the powerful openBIS platform.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/openbis.ch\/index.php\/openrdm-swiss\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"Renku",
                        "description":"An open-source knowledge infrastructure for collaborative and reproducible data science.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/renkulab.io\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"BioMedIT",
                        "description":"A secure IT network for the responsible processing of health-related data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/www.biomedit.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"Swiss Pathogen Surveillance Platform (SPSP)",
                        "description":"A secure One-health online platform that enables near real-time sharing under controlled access of pathogen whole genome sequences (WGS) and their associated clinical\/epidemiological metadata. Since 20221 it has centralized and processed all SARS-CoV-2 sequencing data within the national genomic surveillance program.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/spsp.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"DORA",
                        "description":"Digit Object Repository at the Libr4RI (4 ETH Domain Research Institutes, that are EAWAG, EMPA, PSI, WSL).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.dora.lib4ri.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"UNIL DMP Online",
                        "description":"This instance of DMPonline is provided by the Service des ressources informationnelles et archives (UNIRIS) of the University of Lausanne (UNIL) to help its community of researchers to write a Data Management Plan (DMP).",
                        "how_to_access":null,
                        "instance_of":"dmponline",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.unil.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"SIB\/Vital-IT Canvas Generator",
                        "description":"This is a tool to help scientists generate data management plans for SNSF -unded projects. The Word document produced complies with the SNSF instructions for creating DMPs.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.vital-it.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ch_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"rich and EPFL in Lausanne) signed an agreement to develop a national strategy on open research data. The Swiss ORD Strategy provides a framework for the development of practices built around sharing research data in Switzerland, and for governing the services and infrastructures that support researchers and enable ORD practices. It should enable Switzerland to implement a coherent and ambitious open science policy in line with European and global developments. SPHN - Swiss Personalized Health Network\nSPHN is a national initiative under the leadership of the Swiss Academy of Medical Sciences (SAMS). In collaboration with the SIB Swiss Institute of Bioinformatics it contributes to the development, implementation and validation of coordinated data infrastructures in order to make health-relevant data interoperable and shareable for research in Switzerland.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ch_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Switzerland",
                "country_code":"CH",
                "contributors":[
                    "Gregoire Rossier",
                    "Vassilios Ioannidis"
                ],
                "coordinators":[
                    "Gregoire Rossier",
                    "Vassilios Ioannidis"
                ],
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/switzerland"
                    }
                ],
                "ref_to_main_resources":null,
                "national_resources":[
                    {
                        "name":"OLOS",
                        "description":"OLOS is a Swiss-based data management portal, to help Swiss researchers safely manage, publish and preserve their data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.dlcm.ch\/olos",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"SWISSUbase",
                        "description":"SWISSUbase is a national cross-disciplinary solution for Swiss universities and other research organizations in need of local institutional data repositories for their researchers. The platform relies on international archiving standards and processes to ensure that data are preserved and accessible in the long-term.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.swissubase.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"OpenRDM.swiss",
                        "description":"openRDM.swiss offers research data management as a service to the scientific community, based on the powerful openBIS platform.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/openbis.ch\/index.php\/openrdm-swiss\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"Renku",
                        "description":"An open-source knowledge infrastructure for collaborative and reproducible data science.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/renkulab.io\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"BioMedIT",
                        "description":"A secure IT network for the responsible processing of health-related data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/www.biomedit.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"Swiss Pathogen Surveillance Platform (SPSP)",
                        "description":"A secure One-health online platform that enables near real-time sharing under controlled access of pathogen whole genome sequences (WGS) and their associated clinical\/epidemiological metadata. Since 20221 it has centralized and processed all SARS-CoV-2 sequencing data within the national genomic surveillance program.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/spsp.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"DORA",
                        "description":"Digit Object Repository at the Libr4RI (4 ETH Domain Research Institutes, that are EAWAG, EMPA, PSI, WSL).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.dora.lib4ri.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"UNIL DMP Online",
                        "description":"This instance of DMPonline is provided by the Service des ressources informationnelles et archives (UNIRIS) of the University of Lausanne (UNIL) to help its community of researchers to write a Data Management Plan (DMP).",
                        "how_to_access":null,
                        "instance_of":"dmponline",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.unil.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"SIB\/Vital-IT Canvas Generator",
                        "description":"This is a tool to help scientists generate data management plans for SNSF -unded projects. The Word document produced complies with the SNSF instructions for creating DMPs.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.vital-it.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ch_resources_md_3",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ch_resources.md",
        "file_name":"ch_resources.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"tures in order to make health-relevant data interoperable and shareable for research in Switzerland. Regulations and policies on research data\nFunder policy\n\nSNSF\n\nInstitutional policy\n\nETHZ\nUniversity of Basel\nUniversity of Geneva\n\nInstitutional RDM support and services\n\nUniversity of Basel\nUniversity of Bern\nUniversity of Fribourg\nUniversity of Geneva\nUniversity of Lausanne\nUniversity of St.Gallen\nUniversity of Zurich\nETHZ\nEPFL\nCHUV Library (BiUM)\nLibr4RI - Library for the research institutes of the ETH domain (EAWAG, EMPA, PSI & WSL)\nSWITCH - secure infrastructure for data sharing, storage and archive",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ch_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Switzerland",
                "country_code":"CH",
                "contributors":[
                    "Gregoire Rossier",
                    "Vassilios Ioannidis"
                ],
                "coordinators":[
                    "Gregoire Rossier",
                    "Vassilios Ioannidis"
                ],
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/switzerland"
                    }
                ],
                "ref_to_main_resources":null,
                "national_resources":[
                    {
                        "name":"OLOS",
                        "description":"OLOS is a Swiss-based data management portal, to help Swiss researchers safely manage, publish and preserve their data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.dlcm.ch\/olos",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"SWISSUbase",
                        "description":"SWISSUbase is a national cross-disciplinary solution for Swiss universities and other research organizations in need of local institutional data repositories for their researchers. The platform relies on international archiving standards and processes to ensure that data are preserved and accessible in the long-term.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "storage",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.swissubase.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"OpenRDM.swiss",
                        "description":"openRDM.swiss offers research data management as a service to the scientific community, based on the powerful openBIS platform.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/openbis.ch\/index.php\/openrdm-swiss\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"Renku",
                        "description":"An open-source knowledge infrastructure for collaborative and reproducible data science.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/renkulab.io\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"BioMedIT",
                        "description":"A secure IT network for the responsible processing of health-related data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_analysis",
                                "sensitive"
                            ]
                        },
                        "url":"https:\/\/www.biomedit.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"Swiss Pathogen Surveillance Platform (SPSP)",
                        "description":"A secure One-health online platform that enables near real-time sharing under controlled access of pathogen whole genome sequences (WGS) and their associated clinical\/epidemiological metadata. Since 20221 it has centralized and processed all SARS-CoV-2 sequencing data within the national genomic surveillance program.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/spsp.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"DORA",
                        "description":"Digit Object Repository at the Libr4RI (4 ETH Domain Research Institutes, that are EAWAG, EMPA, PSI, WSL).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/www.dora.lib4ri.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"UNIL DMP Online",
                        "description":"This instance of DMPonline is provided by the Service des ressources informationnelles et archives (UNIRIS) of the University of Lausanne (UNIL) to help its community of researchers to write a Data Management Plan (DMP).",
                        "how_to_access":null,
                        "instance_of":"dmponline",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.unil.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    },
                    {
                        "name":"SIB\/Vital-IT Canvas Generator",
                        "description":"This is a tool to help scientists generate data management plans for SNSF -unded projects. The Word document produced complies with the SNSF instructions for creating DMPs.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[

                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.vital-it.ch\/",
                        "registry":{
                            "biotools":null,
                            "fairsharing":null,
                            "tess":null
                        }
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_de_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/de_resources.md",
        "file_name":"de_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"contributors:\n- Ulrike Wittig\ncoordinators:\n- Ulrike Wittig\ncountry_code: DE\nnational_resources:\n- description: Electronic Laboratory Notebook (ELN) selection service. name: ELN Finder\n  related_pages:\n    your_role:\n    - researcher\n    - research_software_engineer\n    your_tasks:\n    - metadata\n  url: https:\/\/eln-finder.ulb.tu-darmstadt.de\/home\n- description: Guide for Electronic Laboratory Notebooks (ELN). name: ELN Guide\n  related_pages:\n    your_role:\n    - researcher\n    - research_software_engineer\n    your_tasks:\n    - metadata\n  url: https:\/\/repository.publisso.de\/resource\/frl:6425772\n- description: Video Tutorials for Electronic Laboratory Notebooks (ELN). name: ELN Video Tutorials\n  related_pages:\n    your_role:\n    - researcher\n    - research_software_engineer\n    your_tasks:\n    - metadata\n  url: https:\/\/www.youtube.com\/playlist?list=PLJYlS0FDTMq17tvYMeuI2Ct5XtykRFy0K\n- description: DMP creation and support by German Federation for Biological Data (GFBio).",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"de_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_de_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/de_resources.md",
        "file_name":"de_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"5XtykRFy0K\n- description: DMP creation and support by German Federation for Biological Data (GFBio). name: GFBio Data Management Plan Tool\n  related_pages:\n    your_tasks:\n    - dmp\n  url: https:\/\/www.gfbio.org\/plan\n- description: The German Human Genome-Phenome Archive.\n  name: GHGA\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - storage\n    - metadata\n  url: https:\/\/ghga.dkfz.de\/\n- description: Open access publishing platform for life sciences.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"de_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_de_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/de_resources.md",
        "file_name":"de_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"adata\n  url: https:\/\/ghga.dkfz.de\/\n- description: Open access publishing platform for life sciences. name: PUBLISSO\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - data_publication\n  url: https:\/\/www.publisso.de\/en\/\n- description: Research Data Management Organiser.\n  name: RDMO\n  related_pages:\n    your_tasks:\n    - dmp\n  url: https:\/\/rdmorganiser.github.io\/\nref_to_main_resources:\n- bacdive\n- brenda\n- brenda-tissue-ontology\n- chemotion\n- copasi\n- dataplan\n- e-dal\n- e-dal-pgp\n- enzymeml\n- eurisco\n- fairdom-seek\n- fairdomhub\n- galaxy\n- pangaea\n- sabiork\n- standards-for-reporting-enzyme-data\n- strenda-db\ntitle: Germany\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/materials?node=Germany",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"de_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_de_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/de_resources.md",
        "file_name":"de_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\nThis page provides useful information and resources with a focus on research data management in Germany. An overview of services provided by ELIXIR Germany can be found on the websites of de.NBI\/ELIXIR Germany and ELIXIR.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"de_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Germany",
                "country_code":"DE",
                "contributors":[
                    "Ulrike Wittig"
                ],
                "coordinators":[
                    "Ulrike Wittig"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Germany"
                    }
                ],
                "national_resources":[
                    {
                        "name":"ELN Finder",
                        "description":"Electronic Laboratory Notebook (ELN) selection service.",
                        "url":"https:\/\/eln-finder.ulb.tu-darmstadt.de\/home",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"ELN Guide",
                        "description":"Guide for Electronic Laboratory Notebooks (ELN).",
                        "url":"https:\/\/repository.publisso.de\/resource\/frl:6425772",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"ELN Video Tutorials",
                        "description":"Video Tutorials for Electronic Laboratory Notebooks (ELN).",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PLJYlS0FDTMq17tvYMeuI2Ct5XtykRFy0K",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"GFBio Data Management Plan Tool",
                        "description":"DMP creation and support by German Federation for Biological Data (GFBio).",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/www.gfbio.org\/plan"
                    },
                    {
                        "name":"GHGA",
                        "description":"The German Human Genome-Phenome Archive.",
                        "related_pages":{
                            "your_tasks":[
                                "storage",
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/ghga.dkfz.de\/"
                    },
                    {
                        "name":"PUBLISSO",
                        "description":"Open access publishing platform for life sciences.",
                        "related_pages":{
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/www.publisso.de\/en\/"
                    },
                    {
                        "name":"RDMO",
                        "description":"Research Data Management Organiser.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/rdmorganiser.github.io\/"
                    }
                ],
                "ref_to_main_resources":[
                    "bacdive",
                    "brenda",
                    "brenda-tissue-ontology",
                    "chemotion",
                    "copasi",
                    "dataplan",
                    "e-dal",
                    "e-dal-pgp",
                    "enzymeml",
                    "eurisco",
                    "fairdom-seek",
                    "fairdomhub",
                    "galaxy",
                    "pangaea",
                    "sabiork",
                    "standards-for-reporting-enzyme-data",
                    "strenda-db"
                ]
            }
        }
    },
    {
        "id":"md_content_de_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/de_resources.md",
        "file_name":"de_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ervices provided by ELIXIR Germany can be found on the websites of de.NBI\/ELIXIR Germany and ELIXIR. Funders\n\nBMBF - Federal Ministry of Research, Technology and Space (Bundesministerium fr Forschung, Technologie und Raumfahrt)\nDFG - Deutsche Forschungsgemeinschaft\nOverview of Research Funding in Germany\n\nPolicies and Recommendations for Research Data\n\nList of Research Data Policies and Recommendations\nBMBF - Aktionsplan Forschungsdaten\nDFG Checklist for handling research data\nforschungsdaten. info - Portal for information on research data management\nforschungsdaten. org - Information and guidelines for research data\nDINI\/nestor-AG Forschungsdaten\nOpen Access Guidelines\nPUBLISSO - Research Data Management Guidelines\n\nResearch Data Initiatives\n\nNFDI - National Research Data Infrastructure (Nationale Forschungsdaten Infrastruktur)\nde. NBI - German Network for Bioinformatics Infrastructure\nre3data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"de_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Germany",
                "country_code":"DE",
                "contributors":[
                    "Ulrike Wittig"
                ],
                "coordinators":[
                    "Ulrike Wittig"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Germany"
                    }
                ],
                "national_resources":[
                    {
                        "name":"ELN Finder",
                        "description":"Electronic Laboratory Notebook (ELN) selection service.",
                        "url":"https:\/\/eln-finder.ulb.tu-darmstadt.de\/home",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"ELN Guide",
                        "description":"Guide for Electronic Laboratory Notebooks (ELN).",
                        "url":"https:\/\/repository.publisso.de\/resource\/frl:6425772",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"ELN Video Tutorials",
                        "description":"Video Tutorials for Electronic Laboratory Notebooks (ELN).",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PLJYlS0FDTMq17tvYMeuI2Ct5XtykRFy0K",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"GFBio Data Management Plan Tool",
                        "description":"DMP creation and support by German Federation for Biological Data (GFBio).",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/www.gfbio.org\/plan"
                    },
                    {
                        "name":"GHGA",
                        "description":"The German Human Genome-Phenome Archive.",
                        "related_pages":{
                            "your_tasks":[
                                "storage",
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/ghga.dkfz.de\/"
                    },
                    {
                        "name":"PUBLISSO",
                        "description":"Open access publishing platform for life sciences.",
                        "related_pages":{
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/www.publisso.de\/en\/"
                    },
                    {
                        "name":"RDMO",
                        "description":"Research Data Management Organiser.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/rdmorganiser.github.io\/"
                    }
                ],
                "ref_to_main_resources":[
                    "bacdive",
                    "brenda",
                    "brenda-tissue-ontology",
                    "chemotion",
                    "copasi",
                    "dataplan",
                    "e-dal",
                    "e-dal-pgp",
                    "enzymeml",
                    "eurisco",
                    "fairdom-seek",
                    "fairdomhub",
                    "galaxy",
                    "pangaea",
                    "sabiork",
                    "standards-for-reporting-enzyme-data",
                    "strenda-db"
                ]
            }
        }
    },
    {
        "id":"md_content_de_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/de_resources.md",
        "file_name":"de_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"e Forschungsdaten Infrastruktur)\nde. NBI - German Network for Bioinformatics Infrastructure\nre3data. org - Registry of Research Data Repositories\nGFBio - German Federation for Biological Data\nFAIRDOM - Consortium of Services for Research Data Management\nZB MED - Infrastructure and research centre for information and data in the life sciences.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"de_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Germany",
                "country_code":"DE",
                "contributors":[
                    "Ulrike Wittig"
                ],
                "coordinators":[
                    "Ulrike Wittig"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Germany"
                    }
                ],
                "national_resources":[
                    {
                        "name":"ELN Finder",
                        "description":"Electronic Laboratory Notebook (ELN) selection service.",
                        "url":"https:\/\/eln-finder.ulb.tu-darmstadt.de\/home",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"ELN Guide",
                        "description":"Guide for Electronic Laboratory Notebooks (ELN).",
                        "url":"https:\/\/repository.publisso.de\/resource\/frl:6425772",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"ELN Video Tutorials",
                        "description":"Video Tutorials for Electronic Laboratory Notebooks (ELN).",
                        "url":"https:\/\/www.youtube.com\/playlist?list=PLJYlS0FDTMq17tvYMeuI2Ct5XtykRFy0K",
                        "related_pages":{
                            "your_tasks":[
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ]
                        }
                    },
                    {
                        "name":"GFBio Data Management Plan Tool",
                        "description":"DMP creation and support by German Federation for Biological Data (GFBio).",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/www.gfbio.org\/plan"
                    },
                    {
                        "name":"GHGA",
                        "description":"The German Human Genome-Phenome Archive.",
                        "related_pages":{
                            "your_tasks":[
                                "storage",
                                "metadata"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/ghga.dkfz.de\/"
                    },
                    {
                        "name":"PUBLISSO",
                        "description":"Open access publishing platform for life sciences.",
                        "related_pages":{
                            "your_tasks":[
                                "data_publication"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ]
                        },
                        "url":"https:\/\/www.publisso.de\/en\/"
                    },
                    {
                        "name":"RDMO",
                        "description":"Research Data Management Organiser.",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/rdmorganiser.github.io\/"
                    }
                ],
                "ref_to_main_resources":[
                    "bacdive",
                    "brenda",
                    "brenda-tissue-ontology",
                    "chemotion",
                    "copasi",
                    "dataplan",
                    "e-dal",
                    "e-dal-pgp",
                    "enzymeml",
                    "eurisco",
                    "fairdom-seek",
                    "fairdomhub",
                    "galaxy",
                    "pangaea",
                    "sabiork",
                    "standards-for-reporting-enzyme-data",
                    "strenda-db"
                ]
            }
        }
    },
    {
        "id":"md_fm_it_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/it_resources.md",
        "file_name":"it_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Marco Carraro\n- Ivan Mieti\ncoordinators:\n- Marco Carraro\ncountry_code: IT\nnational_resources:\n- description: Italian portal dedicated to the field of open science. how_to_access: null\n  instance_of: null\n  name: Open-science.it\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - data_steward\n    - researcher\n    your_tasks:\n    - dmp\n  url: https:\/\/open-science.it\/\nrelated_pages:\n  tool_assembly: []\ntitle: Italy\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/materials?node=Italy",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"it_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_it_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/it_resources.md",
        "file_name":"it_resources.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"Introduction\nThis page provides a general overview of national resources on Research Data Management (RDM) in Italy. ICDI (Italian Computing and Data Infrastructure) is a forum created by representatives of the main Italian research institutions and e-Infrastructures. Aim of this initiative is the promotion of synergies at national level in order to strengthen the Italian effort in tackling the current European challenges in data management, such as the European Open Science Cloud (EOSC), the European Data Infrastructure (EDI) and High Performance Computing (HPC). Its activities articulate around tre main actions:\n\nFederated cloud platform task force\nEOSC competence centre task force\nNational working groups\n\nData management support and training for life science researchers is provided at national level by the Italian ELIXIR Node, hosted at the Italian Infrastructure for Bioinformatics (IIB).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"it_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Italy",
                "country_code":"IT",
                "contributors":[
                    "Marco Carraro",
                    "Ivan Mieti"
                ],
                "coordinators":[
                    "Marco Carraro"
                ],
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Italy"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Open-science.it",
                        "description":"Italian portal dedicated to the field of open science.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/open-science.it\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_it_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/it_resources.md",
        "file_name":"it_resources.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"nal level by the Italian ELIXIR Node, hosted at the Italian Infrastructure for Bioinformatics (IIB). The Research Data Alliance (RDA) Italian Node is hosted at the CNR Institute of Information Science and Technologies (CNR-ISTI) and provides support and training for both humanities and STEM. Italian OpenAIRE NOAD (National Open Access Desk) is in place in order to develop capacity at local level and to provide expert advice on infrastructures, supporting workflows for open science. Open-science.it\nOpen-science.it  is the Italian portal dedicated to the field of open science (in Italian). The resource is part of ICDI  activities, hosting the Open-science.it editorial committee. Information in the portal is organised according to the point of view of 4 types of users:\n* researchers \n* funding bodies\n* local institutions\n* citizens\nIn addition, a catalogue of more than 50 open access policy documents from Italian universities is available, along with international reference documents as reports, recommendations and guidelines about open science.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"it_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Italy",
                "country_code":"IT",
                "contributors":[
                    "Marco Carraro",
                    "Ivan Mieti"
                ],
                "coordinators":[
                    "Marco Carraro"
                ],
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Italy"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Open-science.it",
                        "description":"Italian portal dedicated to the field of open science.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/open-science.it\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_be_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/be_resources.md",
        "file_name":"be_resources.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"contributors:\n- Flora D'Anna\ncoordinators:\n- Flora D'Anna\ncountry_code: BE\nnational_resources:\n- description: RDM Guide describes Belgian data management guidelines, resources,\n    tools and services available for researchers in Life Sciences.\n  how_to_access: null\n  name: RDM Guide\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks: []\n  url: https:\/\/rdm.elixir-belgium.org\n- description: Galaxy Belgium is a Galaxy instance managed by the Belgian ELIXIR node,\n    funded by the Flemish government, which utilizing infrastructure provided by the\n    Flemish Supercomputer Center (VSC). how_to_access: null\n  instance_of: galaxy\n  name: Galaxy Belgium\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - researcher\n    your_tasks:\n    - data_analysis\n  url: https:\/\/usegalaxy.be\n- description: This instance of DMPonline is provided by the DMPbelgium Consortium.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"be_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_be_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/be_resources.md",
        "file_name":"be_resources.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"s:\/\/usegalaxy.be\n- description: This instance of DMPonline is provided by the DMPbelgium Consortium. We can help you write and maintain data management plans for your research. how_to_access: Affiliation with one of the universities of the consortium is required. instance_of: dmproadmap\n  name: DMPonline.be\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - data_steward\n    - researcher\n    your_tasks:\n    - dmp\n  url: https:\/\/dmponline.be\n- description: PIPPA, the PSB Interface for Plant Phenotype Analysis, is the central\n    web interface and database that provides the tools for the management of the plant\n    imaging robots on the one hand, and the analysis of images and data on the other\n    hand. how_to_access: null\n  name: PIPPA\n  registry:\n    biotools: PIPPA\n  related_pages:\n    tool_assembly:\n    - plant_pheno_assembly\n    your_domain:\n    - plants\n    your_role:\n    - data_steward\n    - researcher\n    - research_software_engineer\n    your_tasks: []\n  url: https:\/\/pippa.psb.ugent.be\n- description:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"be_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_be_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/be_resources.md",
        "file_name":"be_resources.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"    - research_software_engineer\n    your_tasks: []\n  url: https:\/\/pippa.psb.ugent.be\n- description: Belnet is the privileged partner of higher education, research and\n    administration for connectivity. We provide high-bandwidth internet access and\n    related services for our specific target groups.\n  how_to_access: null\n  name: Belnet\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - data_steward\n    - researcher\n    - research_software_engineer\n    your_tasks:\n    - transfer\n  url: https:\/\/belnet.be\/en\n- description: VSC is the Flanders' most highly integrated high-performance research\n    computing environment, providing world-class services to government, industry,\n    and researchers. how_to_access: null\n  name: Flemish Supercomputing Center (VSC)\n  related_pages:\n    tool_assembly:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"be_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_be_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/be_resources.md",
        "file_name":"be_resources.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":" how_to_access: null\n  name: Flemish Supercomputing Center (VSC)\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - data_steward\n    - research_software_engineer\n    your_tasks:\n    - data_analysis\n    - storage\n  url: https:\/\/www.vscentrum.be\nref_to_main_resources:\n- fairdom-seek\n- galaxy\n- workflowhub\n- ena-upload-tool\ntitle: Belgium\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/materials?node=Belgium\n- name: ELIXIR Belgium community in Zenodo\n  registry: Zenodo\n  url: https:\/\/zenodo.org\/communities\/elixir-be\/?page=1&size=20\n- name: ELIXIR Belgium YouTube\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/channel\/UC7XUideTn8tFCOC-lhT9-Aw",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"be_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_be_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/be_resources.md",
        "file_name":"be_resources.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"Introduction\nAn overview of data management services provided by ELIXIR Belgium can be found on the ELIXIR Belgium website. Details about national guidelines, tools and resources can be found at RDM Guide. The Flemish Government approved the Flemish Open Science policy plan and the establishment of the Flemish Open Science Board (FOSB). The mandate of the FOSB is to develop the policy on Open Science and to advise on how to spend the resources that will be used for this purpose. FOSB is the strategic steering body of the Flemish Research Data Network (FRDN), a network of 36 Flemish research performing organizations that collaborate on Open and FAIR data. FRDN supports individual institutions to implement the Open Science policy of the Flemish government, and to connect with international initiatives, such as the European Open Science Cloud (EOSC). Funders and assistance\nIn line with European funders, Belgian research funders require Data Management Plans (DMP) and support Open Science.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"be_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Belgium",
                "country_code":"BE",
                "contributors":[
                    "Flora D'Anna"
                ],
                "coordinators":[
                    "Flora D'Anna"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Belgium"
                    },
                    {
                        "name":"ELIXIR Belgium community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-be\/?page=1&size=20"
                    },
                    {
                        "name":"ELIXIR Belgium YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UC7XUideTn8tFCOC-lhT9-Aw"
                    }
                ],
                "ref_to_main_resources":[
                    "fairdom-seek",
                    "galaxy",
                    "workflowhub",
                    "ena-upload-tool"
                ],
                "national_resources":[
                    {
                        "name":"RDM Guide",
                        "description":"RDM Guide describes Belgian data management guidelines, resources, tools and services available for researchers in Life Sciences.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[

                            ]
                        },
                        "url":"https:\/\/rdm.elixir-belgium.org"
                    },
                    {
                        "name":"Galaxy Belgium",
                        "description":"Galaxy Belgium is a Galaxy instance managed by the Belgian ELIXIR node, funded by the Flemish government, which utilizing infrastructure provided by the Flemish Supercomputer Center (VSC).",
                        "how_to_access":null,
                        "instance_of":"galaxy",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.be"
                    },
                    {
                        "name":"DMPonline.be",
                        "description":"This instance of DMPonline is provided by the DMPbelgium Consortium. We can help you write and maintain data management plans for your research.",
                        "how_to_access":"Affiliation with one of the universities of the consortium is required.",
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmponline.be"
                    },
                    {
                        "name":"PIPPA",
                        "description":"PIPPA, the PSB Interface for Plant Phenotype Analysis, is the central web interface and database that provides the tools for the management of the plant imaging robots on the one hand, and the analysis of images and data on the other hand.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "plant_pheno_assembly"
                            ],
                            "your_domain":[
                                "plants"
                            ],
                            "your_role":[
                                "data_steward",
                                "researcher",
                                "research_software_engineer"
                            ],
                            "your_tasks":[

                            ]
                        },
                        "url":"https:\/\/pippa.psb.ugent.be",
                        "registry":{
                            "biotools":"PIPPA"
                        }
                    },
                    {
                        "name":"Belnet",
                        "description":"Belnet is the privileged partner of higher education, research and administration for connectivity. We provide high-bandwidth internet access and related services for our specific target groups.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "researcher",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "transfer"
                            ]
                        },
                        "url":"https:\/\/belnet.be\/en"
                    },
                    {
                        "name":"Flemish Supercomputing Center (VSC)",
                        "description":"VSC is the Flanders' most highly integrated high-performance research computing environment, providing world-class services to government, industry, and researchers.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.vscentrum.be"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_be_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/be_resources.md",
        "file_name":"be_resources.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"pean funders, Belgian research funders require Data Management Plans (DMP) and support Open Science. Consult the funders' webpage and their policy about data management and Open Science. * Research Foundation - Flanders (FWO). * FWO Research policy. * The Belgian Science Policy Office (BELSPO). * Kom op tegen Kanker. * Special Research Fund (BOF) from Universities. * Fonds de la Recherche Scientifique (FNRS). * FNRS Scientific policy. * EU-Team and\/or Research support team from Universities. * National Contact Points (NCPs) for help with navigating the EU funding system.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"be_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Belgium",
                "country_code":"BE",
                "contributors":[
                    "Flora D'Anna"
                ],
                "coordinators":[
                    "Flora D'Anna"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Belgium"
                    },
                    {
                        "name":"ELIXIR Belgium community in Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-be\/?page=1&size=20"
                    },
                    {
                        "name":"ELIXIR Belgium YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UC7XUideTn8tFCOC-lhT9-Aw"
                    }
                ],
                "ref_to_main_resources":[
                    "fairdom-seek",
                    "galaxy",
                    "workflowhub",
                    "ena-upload-tool"
                ],
                "national_resources":[
                    {
                        "name":"RDM Guide",
                        "description":"RDM Guide describes Belgian data management guidelines, resources, tools and services available for researchers in Life Sciences.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[

                            ]
                        },
                        "url":"https:\/\/rdm.elixir-belgium.org"
                    },
                    {
                        "name":"Galaxy Belgium",
                        "description":"Galaxy Belgium is a Galaxy instance managed by the Belgian ELIXIR node, funded by the Flemish government, which utilizing infrastructure provided by the Flemish Supercomputer Center (VSC).",
                        "how_to_access":null,
                        "instance_of":"galaxy",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/usegalaxy.be"
                    },
                    {
                        "name":"DMPonline.be",
                        "description":"This instance of DMPonline is provided by the DMPbelgium Consortium. We can help you write and maintain data management plans for your research.",
                        "how_to_access":"Affiliation with one of the universities of the consortium is required.",
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmponline.be"
                    },
                    {
                        "name":"PIPPA",
                        "description":"PIPPA, the PSB Interface for Plant Phenotype Analysis, is the central web interface and database that provides the tools for the management of the plant imaging robots on the one hand, and the analysis of images and data on the other hand.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[
                                "plant_pheno_assembly"
                            ],
                            "your_domain":[
                                "plants"
                            ],
                            "your_role":[
                                "data_steward",
                                "researcher",
                                "research_software_engineer"
                            ],
                            "your_tasks":[

                            ]
                        },
                        "url":"https:\/\/pippa.psb.ugent.be",
                        "registry":{
                            "biotools":"PIPPA"
                        }
                    },
                    {
                        "name":"Belnet",
                        "description":"Belnet is the privileged partner of higher education, research and administration for connectivity. We provide high-bandwidth internet access and related services for our specific target groups.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "researcher",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "transfer"
                            ]
                        },
                        "url":"https:\/\/belnet.be\/en"
                    },
                    {
                        "name":"Flemish Supercomputing Center (VSC)",
                        "description":"VSC is the Flanders' most highly integrated high-performance research computing environment, providing world-class services to government, industry, and researchers.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.vscentrum.be"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_ie_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/ie_resources.md",
        "file_name":"ie_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Siobhn Cleary\ncoordinators:\n- Lars Jermiin\n- Siobhn Cleary\ncountry_code: IE\ntitle: Ireland\ntraining:\n- name: ELIXIR Ireland Training\n  registry: ELIXIR Ireland\n  url: https:\/\/elixir-ireland.ie\/training.html",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ie_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_ie_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ie_resources.md",
        "file_name":"ie_resources.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"Introduction\nThis page gives an overview of national guidelines and resources for data management planning. All data management services provided by ELIXIR-Ireland can be accessed through the ELIXIR-Ireland website. Funder guidelines and policies\nIrish research funding agencies support Open Science and require data management plans (DMPs) as part of their application process. Consult the funders webpages for guidelines and information about research data management. Science Foundation Ireland Guidelines and Policies for Open Research and Data Management and link to SFI DMP guidance (PDF Document)) Irish Research Council Policies (Link to PDF for IRC DMP Tips and Advice)\nHealth Research Board Management and Sharing of Data Policy and Open Research Data Guidelines\n\nNational services, initiatives and guidelines\n\nNational Open Research Forum \nNational Action Plan for Open Research\nHEA Principles of Good Practice in Research within Irish Higher Education Institutes (PDF)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ie_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Ireland",
                "country_code":"IE",
                "contributors":[
                    "Siobhn Cleary"
                ],
                "coordinators":[
                    "Lars Jermiin",
                    "Siobhn Cleary"
                ],
                "training":[
                    {
                        "name":"ELIXIR Ireland Training",
                        "registry":"ELIXIR Ireland",
                        "url":"https:\/\/elixir-ireland.ie\/training.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ie_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ie_resources.md",
        "file_name":"ie_resources.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":" Research\nHEA Principles of Good Practice in Research within Irish Higher Education Institutes (PDF) Institutional policies\nHere are non-exhaustive lists of data management policies and open research policies from the universities across Ireland. Data Management Policies from Irish Universities\n\nUniversity College Dublin (UCD Library Data Management Checklist)\nUniversity of Galway (PDF)\nUniversity College Cork (PDF) Royal College of Surgeons in Ireland\nMunster Technological University (PDF) University of Limerick Health Research Policy\n\nOpen Research Policies from Irish Universities\n\nMaynooth University\nRoyal College of Surgeons in Ireland\nMunster Technological University (PDF)\nSouth East Technological University (PDF)\nTechnological University Dublin (PDF)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ie_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Ireland",
                "country_code":"IE",
                "contributors":[
                    "Siobhn Cleary"
                ],
                "coordinators":[
                    "Lars Jermiin",
                    "Siobhn Cleary"
                ],
                "training":[
                    {
                        "name":"ELIXIR Ireland Training",
                        "registry":"ELIXIR Ireland",
                        "url":"https:\/\/elixir-ireland.ie\/training.html"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_gr_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"contributors:\n- Eleni Adamidi\n- Thanasis Vergoulis\n- Alexandros Dimopoulos\ncoordinators:\n- Thanasis Vergoulis\n- Alexandros Dimopoulos\ncountry_code: GR\ndescription: A comprehensive guide to research data management (RDM) in Greece, featuring\n  tools, resources, and services tailored for the life sciences community. national_resources:\n- description: HYPATIA is a cloud-based infrastructure that has been developed to\n    support the computational needs of the ELIXIR Greece community and the wider life\n    sciences community including researchers and institutions in Greece and internationally. how_to_access: Login via Life Science (LS) Login required.\n  name: HYPATIA - Cloud Infrastructure for ELIXIR Greece\n  related_pages:\n    your_tasks:\n    - data_analysis\n    - storage\n    - transfer\n  url: https:\/\/hypatia.athenarc.gr\/\n- description: An instance of the Genomic Data Infrastructure",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"gr_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_gr_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"er\n  url: https:\/\/hypatia.athenarc.gr\/\n- description: An instance of the Genomic Data Infrastructure [GDI](https:\/\/gdi.onemilliongenomes.eu\/)\n    on ELIXIR Greece, for secure genomic data management, including storage, discovery,\n    access, and reception. This is a pilot instance based on the GDI Starter Kit.\n  how_to_access: Login via Life Science (LS) Login required to access ELIXIR-Greece\n    GDI Portal.\n  name: National instance of Genomic Data Infrastructure for ELIXIR Greece\n  related_pages: your_domain:\n    - human_data\n    your_tasks:\n    - sensitive\n    - data_publication\n    - existing_data\n  url: https:\/\/login.gdi.elixir-greece.org\/\n- description: Provides information, guidelines, tools and services to support researchers\n    to utilise Greek and European infrastructures for data sharing.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"gr_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_gr_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":" services to support researchers\n    to utilise Greek and European infrastructures for data sharing. The portal is\n    a national node of the European COVID-19 Data Portal.\n  instance_of: covid-19-data-portal\n  name: Greek COVID-19 Portal\n  related_pages:\n    tool_assembly:\n    - covid19_data_portal\n  url: https:\/\/covid19dataportal.gr\/\nref_to_main_resources:\n- argos\ntitle: Greece\ntraining:\n- description: This presentation provides an overview of the data, tools, and standards\n    used in ELIXIR Greece, as well as guidelines for effective research data management,\n    with an emphasis on best practices for open science and data stewardship.\n  name: 'ELIXIR GREECE: Prospects of data and tools for ELIXIR Greece'\n  registry: Zenodo\n  url: https:\/\/zenodo.org\/records\/4043630#.ZACFtE_Nx60\n- description: This presentation highlights how the local Greek Galaxy instance at\n    usegalaxy.elixir-greece.org makes SARS-CoV-2 data analysis accessible and reproducible\n    using open software and public research infrastructures.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"gr_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_gr_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"ta analysis accessible and reproducible\n    using open software and public research infrastructures. It showcases practical\n    workflows in genomics, proteomics, evolution, and cheminformatics, with comprehensive\n    training materials available to support collaborative research. name: The ELIXIR GREECE Galaxy server including best practices tools and workflows\n    for the analysis of SARS-CoV-2 data\n  registry: Zenodo\n  url: https:\/\/zenodo.org\/records\/4042834#.ZACFUk9vD9M",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"gr_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_gr_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"Introduction\nThis page provides useful information and resources with a focus on research data management in Greece. An overview of services provided by ELIXIR Greece can be found on the node website . Funders in Greece\nResearch funding in Greece is primarily provided by National and European funding agencies. The major national funders supporting Open Science and Research Data Management (RDM) include:\n\nThe Hellenic Foundation for Research and Innovation (HFRI) which is a key funder supporting fundamental and applied research in Greece. HFRI Policies and Requirements:\n  - Encourages Open Science and FAIR data principles.\n  - Requires researchers to submit a Data Management Plan (DMP) in various time points depending on each call.\n  - Supports infrastructure for Open Access to research outputs. The General Secretariat for Research and Innovation (GSRI) which operates under the Ministry of Development and Investments and funds major research projects in Greece.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gr_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Greece",
                "description":"A comprehensive guide to research data management (RDM) in Greece, featuring tools, resources, and services tailored for the life sciences community.",
                "country_code":"GR",
                "contributors":[
                    "Eleni Adamidi",
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "coordinators":[
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "training":[
                    {
                        "name":"ELIXIR GREECE: Prospects of data and tools for ELIXIR Greece",
                        "registry":"Zenodo",
                        "description":"This presentation provides an overview of the data, tools, and standards used in ELIXIR Greece, as well as guidelines for effective research data management, with an emphasis on best practices for open science and data stewardship.",
                        "url":"https:\/\/zenodo.org\/records\/4043630#.ZACFtE_Nx60"
                    },
                    {
                        "name":"The ELIXIR GREECE Galaxy server including best practices tools and workflows for the analysis of SARS-CoV-2 data",
                        "registry":"Zenodo",
                        "description":"This presentation highlights how the local Greek Galaxy instance at usegalaxy.elixir-greece.org makes SARS-CoV-2 data analysis accessible and reproducible using open software and public research infrastructures. It showcases practical workflows in genomics, proteomics, evolution, and cheminformatics, with comprehensive training materials available to support collaborative research.",
                        "url":"https:\/\/zenodo.org\/records\/4042834#.ZACFUk9vD9M"
                    }
                ],
                "ref_to_main_resources":[
                    "argos"
                ],
                "national_resources":[
                    {
                        "name":"HYPATIA - Cloud Infrastructure for ELIXIR Greece",
                        "description":"HYPATIA is a cloud-based infrastructure that has been developed to support the computational needs of the ELIXIR Greece community and the wider life sciences community including researchers and institutions in Greece and internationally.",
                        "how_to_access":"Login via Life Science (LS) Login required.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage",
                                "transfer"
                            ]
                        },
                        "url":"https:\/\/hypatia.athenarc.gr\/"
                    },
                    {
                        "name":"National instance of Genomic Data Infrastructure for ELIXIR Greece",
                        "description":"An instance of the Genomic Data Infrastructure [GDI](https:\/\/gdi.onemilliongenomes.eu\/) on ELIXIR Greece, for secure genomic data management, including storage, discovery, access, and reception. This is a pilot instance based on the GDI Starter Kit.",
                        "how_to_access":"Login via Life Science (LS) Login required to access ELIXIR-Greece GDI Portal.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/login.gdi.elixir-greece.org\/"
                    },
                    {
                        "name":"Greek COVID-19 Portal",
                        "description":"Provides information, guidelines, tools and services to support researchers to utilise Greek and European infrastructures for data sharing. The portal is a national node of the European COVID-19 Data Portal.",
                        "url":"https:\/\/covid19dataportal.gr\/",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "instance_of":"covid-19-data-portal"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gr_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"rates under the Ministry of Development and Investments and funds major research projects in Greece. GSRI Policies and Requirements:\n  - Funds research projects across all disciplines, including Open Science initiatives. - Promotes adherence to EOSC policies and data sharing. - Provides funding for data infrastructures, repositories, and research data management tools. Policies and Recommendations for Research Data in Greece\nGreece has made significant progress in adopting Open Science policies, aligning with European initiatives such as the European Open Science Cloud (EOSC). The country has established a national initiative called Hellenic Open Science Initiative to coordinate and implement national policies for Open Science and research data management. The Hellenic Open Science Initiative (HOSI) was founded on February 28, 2022, by 13 leading Greek research, technology, and innovation organizations. Its goal is to support the coordinated and participatory implementation of Open Science policies in Greece while ensuring national representation in EOSC.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gr_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Greece",
                "description":"A comprehensive guide to research data management (RDM) in Greece, featuring tools, resources, and services tailored for the life sciences community.",
                "country_code":"GR",
                "contributors":[
                    "Eleni Adamidi",
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "coordinators":[
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "training":[
                    {
                        "name":"ELIXIR GREECE: Prospects of data and tools for ELIXIR Greece",
                        "registry":"Zenodo",
                        "description":"This presentation provides an overview of the data, tools, and standards used in ELIXIR Greece, as well as guidelines for effective research data management, with an emphasis on best practices for open science and data stewardship.",
                        "url":"https:\/\/zenodo.org\/records\/4043630#.ZACFtE_Nx60"
                    },
                    {
                        "name":"The ELIXIR GREECE Galaxy server including best practices tools and workflows for the analysis of SARS-CoV-2 data",
                        "registry":"Zenodo",
                        "description":"This presentation highlights how the local Greek Galaxy instance at usegalaxy.elixir-greece.org makes SARS-CoV-2 data analysis accessible and reproducible using open software and public research infrastructures. It showcases practical workflows in genomics, proteomics, evolution, and cheminformatics, with comprehensive training materials available to support collaborative research.",
                        "url":"https:\/\/zenodo.org\/records\/4042834#.ZACFUk9vD9M"
                    }
                ],
                "ref_to_main_resources":[
                    "argos"
                ],
                "national_resources":[
                    {
                        "name":"HYPATIA - Cloud Infrastructure for ELIXIR Greece",
                        "description":"HYPATIA is a cloud-based infrastructure that has been developed to support the computational needs of the ELIXIR Greece community and the wider life sciences community including researchers and institutions in Greece and internationally.",
                        "how_to_access":"Login via Life Science (LS) Login required.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage",
                                "transfer"
                            ]
                        },
                        "url":"https:\/\/hypatia.athenarc.gr\/"
                    },
                    {
                        "name":"National instance of Genomic Data Infrastructure for ELIXIR Greece",
                        "description":"An instance of the Genomic Data Infrastructure [GDI](https:\/\/gdi.onemilliongenomes.eu\/) on ELIXIR Greece, for secure genomic data management, including storage, discovery, access, and reception. This is a pilot instance based on the GDI Starter Kit.",
                        "how_to_access":"Login via Life Science (LS) Login required to access ELIXIR-Greece GDI Portal.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/login.gdi.elixir-greece.org\/"
                    },
                    {
                        "name":"Greek COVID-19 Portal",
                        "description":"Provides information, guidelines, tools and services to support researchers to utilise Greek and European infrastructures for data sharing. The portal is a national node of the European COVID-19 Data Portal.",
                        "url":"https:\/\/covid19dataportal.gr\/",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "instance_of":"covid-19-data-portal"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gr_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"ry implementation of Open Science policies in Greece while ensuring national representation in EOSC. HOSI Key Policies:\n   - Open Science is a national priority and is integrated into Greeces Digital Transformation Strategy. - Policies are based on the principle \"as open as possible, as closed as necessary. \"\n   - National coordination efforts support FAIR (Findable, Accessible, Interoperable, Reusable) data principles. The National Research Data Management Policy aims to ensure open access to research data, particularly for publicly funded research. The policy is outlined in the National Plan for Open Science, including:\n\nKey Principles:\n   - Open by default: Research data must be openly available unless legal or ethical restrictions apply.\n   - FAIR principles: Research data should be managed following international standards for metadata and licensing.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gr_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Greece",
                "description":"A comprehensive guide to research data management (RDM) in Greece, featuring tools, resources, and services tailored for the life sciences community.",
                "country_code":"GR",
                "contributors":[
                    "Eleni Adamidi",
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "coordinators":[
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "training":[
                    {
                        "name":"ELIXIR GREECE: Prospects of data and tools for ELIXIR Greece",
                        "registry":"Zenodo",
                        "description":"This presentation provides an overview of the data, tools, and standards used in ELIXIR Greece, as well as guidelines for effective research data management, with an emphasis on best practices for open science and data stewardship.",
                        "url":"https:\/\/zenodo.org\/records\/4043630#.ZACFtE_Nx60"
                    },
                    {
                        "name":"The ELIXIR GREECE Galaxy server including best practices tools and workflows for the analysis of SARS-CoV-2 data",
                        "registry":"Zenodo",
                        "description":"This presentation highlights how the local Greek Galaxy instance at usegalaxy.elixir-greece.org makes SARS-CoV-2 data analysis accessible and reproducible using open software and public research infrastructures. It showcases practical workflows in genomics, proteomics, evolution, and cheminformatics, with comprehensive training materials available to support collaborative research.",
                        "url":"https:\/\/zenodo.org\/records\/4042834#.ZACFUk9vD9M"
                    }
                ],
                "ref_to_main_resources":[
                    "argos"
                ],
                "national_resources":[
                    {
                        "name":"HYPATIA - Cloud Infrastructure for ELIXIR Greece",
                        "description":"HYPATIA is a cloud-based infrastructure that has been developed to support the computational needs of the ELIXIR Greece community and the wider life sciences community including researchers and institutions in Greece and internationally.",
                        "how_to_access":"Login via Life Science (LS) Login required.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage",
                                "transfer"
                            ]
                        },
                        "url":"https:\/\/hypatia.athenarc.gr\/"
                    },
                    {
                        "name":"National instance of Genomic Data Infrastructure for ELIXIR Greece",
                        "description":"An instance of the Genomic Data Infrastructure [GDI](https:\/\/gdi.onemilliongenomes.eu\/) on ELIXIR Greece, for secure genomic data management, including storage, discovery, access, and reception. This is a pilot instance based on the GDI Starter Kit.",
                        "how_to_access":"Login via Life Science (LS) Login required to access ELIXIR-Greece GDI Portal.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/login.gdi.elixir-greece.org\/"
                    },
                    {
                        "name":"Greek COVID-19 Portal",
                        "description":"Provides information, guidelines, tools and services to support researchers to utilise Greek and European infrastructures for data sharing. The portal is a national node of the European COVID-19 Data Portal.",
                        "url":"https:\/\/covid19dataportal.gr\/",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "instance_of":"covid-19-data-portal"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gr_resources_md_3",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"iples: Research data should be managed following international standards for metadata and licensing. - Permanent Identifiers: Research data must be assigned persistent digital identifiers (DOIs).\n   - Machine-readable metadata: Research software must be documented using OpenAIRE Guidelines, codemeta.json, and {% tool \"schema-org\" %} attributes.\n   - Open Data Licenses: Researchers should use standardized open licenses, with a preference for CC-BY (Attribution Only). - Mandatory Data Management Plans (DMPs): All research projects must include a Data Management Plan (DMP). Part of the National Research Data Management Policy has been embedded in the Greeces Digital Transformation Strategy 2020-2025. This strategy highlights Open Science as a key pillar for modernizing the countrys research landscape outlining its importance in fostering collaboration, transparency, and innovation in scientific research. The strategy aligns with European Open Science Cloud (EOSC) guidelines, ensuring interoperability with European research infrastructures and reinforcing Greeces role in EOSC.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gr_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Greece",
                "description":"A comprehensive guide to research data management (RDM) in Greece, featuring tools, resources, and services tailored for the life sciences community.",
                "country_code":"GR",
                "contributors":[
                    "Eleni Adamidi",
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "coordinators":[
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "training":[
                    {
                        "name":"ELIXIR GREECE: Prospects of data and tools for ELIXIR Greece",
                        "registry":"Zenodo",
                        "description":"This presentation provides an overview of the data, tools, and standards used in ELIXIR Greece, as well as guidelines for effective research data management, with an emphasis on best practices for open science and data stewardship.",
                        "url":"https:\/\/zenodo.org\/records\/4043630#.ZACFtE_Nx60"
                    },
                    {
                        "name":"The ELIXIR GREECE Galaxy server including best practices tools and workflows for the analysis of SARS-CoV-2 data",
                        "registry":"Zenodo",
                        "description":"This presentation highlights how the local Greek Galaxy instance at usegalaxy.elixir-greece.org makes SARS-CoV-2 data analysis accessible and reproducible using open software and public research infrastructures. It showcases practical workflows in genomics, proteomics, evolution, and cheminformatics, with comprehensive training materials available to support collaborative research.",
                        "url":"https:\/\/zenodo.org\/records\/4042834#.ZACFUk9vD9M"
                    }
                ],
                "ref_to_main_resources":[
                    "argos"
                ],
                "national_resources":[
                    {
                        "name":"HYPATIA - Cloud Infrastructure for ELIXIR Greece",
                        "description":"HYPATIA is a cloud-based infrastructure that has been developed to support the computational needs of the ELIXIR Greece community and the wider life sciences community including researchers and institutions in Greece and internationally.",
                        "how_to_access":"Login via Life Science (LS) Login required.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage",
                                "transfer"
                            ]
                        },
                        "url":"https:\/\/hypatia.athenarc.gr\/"
                    },
                    {
                        "name":"National instance of Genomic Data Infrastructure for ELIXIR Greece",
                        "description":"An instance of the Genomic Data Infrastructure [GDI](https:\/\/gdi.onemilliongenomes.eu\/) on ELIXIR Greece, for secure genomic data management, including storage, discovery, access, and reception. This is a pilot instance based on the GDI Starter Kit.",
                        "how_to_access":"Login via Life Science (LS) Login required to access ELIXIR-Greece GDI Portal.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/login.gdi.elixir-greece.org\/"
                    },
                    {
                        "name":"Greek COVID-19 Portal",
                        "description":"Provides information, guidelines, tools and services to support researchers to utilise Greek and European infrastructures for data sharing. The portal is a national node of the European COVID-19 Data Portal.",
                        "url":"https:\/\/covid19dataportal.gr\/",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "instance_of":"covid-19-data-portal"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gr_resources_md_4",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/gr_resources.md",
        "file_name":"gr_resources.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"uring interoperability with European research infrastructures and reinforcing Greeces role in EOSC. Domain-specific infrastructures or resources\nThe Greek COVID-19 Portal provides information, guidelines, tools and services to support researchers to utilise Greek and European infrastructures for data sharing. The portal is a national node of the European COVID-19 Data Portal.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gr_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Greece",
                "description":"A comprehensive guide to research data management (RDM) in Greece, featuring tools, resources, and services tailored for the life sciences community.",
                "country_code":"GR",
                "contributors":[
                    "Eleni Adamidi",
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "coordinators":[
                    "Thanasis Vergoulis",
                    "Alexandros Dimopoulos"
                ],
                "training":[
                    {
                        "name":"ELIXIR GREECE: Prospects of data and tools for ELIXIR Greece",
                        "registry":"Zenodo",
                        "description":"This presentation provides an overview of the data, tools, and standards used in ELIXIR Greece, as well as guidelines for effective research data management, with an emphasis on best practices for open science and data stewardship.",
                        "url":"https:\/\/zenodo.org\/records\/4043630#.ZACFtE_Nx60"
                    },
                    {
                        "name":"The ELIXIR GREECE Galaxy server including best practices tools and workflows for the analysis of SARS-CoV-2 data",
                        "registry":"Zenodo",
                        "description":"This presentation highlights how the local Greek Galaxy instance at usegalaxy.elixir-greece.org makes SARS-CoV-2 data analysis accessible and reproducible using open software and public research infrastructures. It showcases practical workflows in genomics, proteomics, evolution, and cheminformatics, with comprehensive training materials available to support collaborative research.",
                        "url":"https:\/\/zenodo.org\/records\/4042834#.ZACFUk9vD9M"
                    }
                ],
                "ref_to_main_resources":[
                    "argos"
                ],
                "national_resources":[
                    {
                        "name":"HYPATIA - Cloud Infrastructure for ELIXIR Greece",
                        "description":"HYPATIA is a cloud-based infrastructure that has been developed to support the computational needs of the ELIXIR Greece community and the wider life sciences community including researchers and institutions in Greece and internationally.",
                        "how_to_access":"Login via Life Science (LS) Login required.",
                        "related_pages":{
                            "your_tasks":[
                                "data_analysis",
                                "storage",
                                "transfer"
                            ]
                        },
                        "url":"https:\/\/hypatia.athenarc.gr\/"
                    },
                    {
                        "name":"National instance of Genomic Data Infrastructure for ELIXIR Greece",
                        "description":"An instance of the Genomic Data Infrastructure [GDI](https:\/\/gdi.onemilliongenomes.eu\/) on ELIXIR Greece, for secure genomic data management, including storage, discovery, access, and reception. This is a pilot instance based on the GDI Starter Kit.",
                        "how_to_access":"Login via Life Science (LS) Login required to access ELIXIR-Greece GDI Portal.",
                        "related_pages":{
                            "your_domain":[
                                "human_data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/login.gdi.elixir-greece.org\/"
                    },
                    {
                        "name":"Greek COVID-19 Portal",
                        "description":"Provides information, guidelines, tools and services to support researchers to utilise Greek and European infrastructures for data sharing. The portal is a national node of the European COVID-19 Data Portal.",
                        "url":"https:\/\/covid19dataportal.gr\/",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ]
                        },
                        "instance_of":"covid-19-data-portal"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_pt_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"contributors:\n- Jorge Oliveira\n- Ana Portugal Melo\n- Gil Poiares-Oliveira\ncoordinators:\n- Jorge Oliveira\n- Gil Poiares-Oliveira\ncountry_code: PT\nnational_resources:\n- description: This instance of Dataverse is provided by the BioData.pt. We can help\n    you write and maintain data management plans for your research. how_to_access: Open registration. Target users are researchers of BioData.pt associate\n    organisations. instance_of: dataverse\n  name: BioData.pt Data Management Portal (DMPortal)\n  registry:\n    biotools: dmportal\n    fairsharing: b2f583\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - storage\n  url: https:\/\/dmportal.biodata.pt\/\n- description: This tool guides users through generating Data Management Plans.\n  how_to_access: Open registration. Target users are researchers of BioData.pt associate\n    organisations.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"pt_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_pt_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"o_access: Open registration. Target users are researchers of BioData.pt associate\n    organisations. instance_of: data-stewardship-wizard\n  name: BioData.pt Data Stewardship Wizard\n  registry:\n    biotools: Data_Stewardship_Wizard\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - dmp\n  url: https:\/\/biodatapt.dsw.elixir-europe.org\/\n- description: Capacity building program in data management for the life sciences\n    to empower researchers and institutions in managing their data more effectively\n    and efficiently.\n  instance_of: null\n  name: Ready for BioData Management?\n  related_pages:\n    your_role:\n    - researcher\n    your_tasks:\n    - dmp\n    - dm_coordination\n  url: https:\/\/biodata.pt\/training\/programmes\/r4bdm\n- description: An electronic lab notebook (ELN) for BioData.pt training programmes\n    (data wiped periodically). how_to_access: For trainees of BioData.pt training programmes.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"pt_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_pt_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"rammes\n    (data wiped periodically). how_to_access: For trainees of BioData.pt training programmes. inistance_of: eLabFTW\n  name: eLab BioData.pt\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    - principal_investigator\n    your_tasks:\n    - metadata\n    - data_quality\n    - dm_coordination\n    - data_protection\n    - data_organization\n    - data_provenance\n    - machine_actionability\n  url: https:\/\/elab.biodata.pt\/\n- description: National directory of repositories and digital scientific journals,\n    in the fields of science and culture. name: INDEXAR\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - data_publication\n    - existing_data\n  url: https:\/\/www.indexar.pt\/\n- description: Open data portal of the Portuguese Public Administration.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"pt_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_pt_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"rl: https:\/\/www.indexar.pt\/\n- description: Open data portal of the Portuguese Public Administration. instance_of: udata\n  name: dados.gov.pt\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - data_publication\n    - existing_data\n  url: https:\/\/dados.gov.pt\ntitle: Portugal\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/materials?node=Portugal\n- name: Training at BioData.pt\n  registry: BioData.pt\n  url: https:\/\/biodata.pt\/training\n- name: BioData.pt GitHub\n  registry: GitHub\n  url: https:\/\/github.com\/BioData-PT\n- name: BioData.pt YouTube\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/@BioDataPT",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"pt_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_pt_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"Introduction\nThis page provides an overview of data management resources in Portugal, with a particular focus on the life and health sciences research communities, and research data management resources and services provided by BioData.pt | ELIXIR Portugal. Funders\nFundao para a Cincia e a Tecnologia\nThe Foundation for Science and Technology (Fundao para a Cincia e a Tecnologia, FCT) is the national public agency\nproviding support for research for science, innovation, and technology in all domains. It is a public institute of special resposibility under\nthe tutelage and superintendence of the Ministry of Education, Science and Innovation. FCT provides their own Data Management Plan template, which is availabe as a PDF (in Portuguese) and in {% tool \"argos\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"pt_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Portugal",
                "country_code":"PT",
                "contributors":[
                    "Jorge Oliveira",
                    "Ana Portugal Melo",
                    "Gil Poiares-Oliveira"
                ],
                "coordinators":[
                    "Jorge Oliveira",
                    "Gil Poiares-Oliveira"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Portugal"
                    },
                    {
                        "name":"Training at BioData.pt",
                        "registry":"BioData.pt",
                        "url":"https:\/\/biodata.pt\/training"
                    },
                    {
                        "name":"BioData.pt GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/BioData-PT"
                    },
                    {
                        "name":"BioData.pt YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/@BioDataPT"
                    }
                ],
                "national_resources":[
                    {
                        "name":"BioData.pt Data Management Portal (DMPortal)",
                        "description":"This instance of Dataverse is provided by the BioData.pt. We can help you write and maintain data management plans for your research.",
                        "instance_of":"dataverse",
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "storage"
                            ]
                        },
                        "registry":{
                            "biotools":"dmportal",
                            "fairsharing":"b2f583"
                        },
                        "url":"https:\/\/dmportal.biodata.pt\/"
                    },
                    {
                        "name":"BioData.pt Data Stewardship Wizard",
                        "description":"This tool guides users through generating Data Management Plans.",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "registry":{
                            "biotools":"Data_Stewardship_Wizard"
                        },
                        "url":"https:\/\/biodatapt.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"Ready for BioData Management?",
                        "description":"Capacity building program in data management for the life sciences to empower researchers and institutions in managing their data more effectively and efficiently.",
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "dm_coordination"
                            ]
                        },
                        "url":"https:\/\/biodata.pt\/training\/programmes\/r4bdm"
                    },
                    {
                        "name":"eLab BioData.pt",
                        "description":"An electronic lab notebook (ELN) for BioData.pt training programmes (data wiped periodically).",
                        "inistance_of":"eLabFTW",
                        "how_to_access":"For trainees of BioData.pt training programmes.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "principal_investigator"
                            ],
                            "your_tasks":[
                                "metadata",
                                "data_quality",
                                "dm_coordination",
                                "data_protection",
                                "data_organization",
                                "data_provenance",
                                "machine_actionability"
                            ]
                        },
                        "url":"https:\/\/elab.biodata.pt\/"
                    },
                    {
                        "name":"INDEXAR",
                        "description":"National directory of repositories and digital scientific journals, in the fields of science and culture.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.indexar.pt\/"
                    },
                    {
                        "name":"dados.gov.pt",
                        "description":"Open data portal of the Portuguese Public Administration.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/dados.gov.pt",
                        "instance_of":"udata"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_pt_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"Data Management Plan template, which is availabe as a PDF (in Portuguese) and in {% tool \"argos\" %}. National Infrastructures and Resources\nFundao para a Computao Cientfica Nacional\nThe Foundation for National Scientific Computing (Fundao para a Computao Cientfica Nacional, FCCN) is the Scientific\nComputing Unit of FCT. FCCN provides high-speed Internet connectivity and IT services to the Portuguese higher education and research system. National Network for Advanced Computing\nThe RNCA - National Network for Advanced Computing - is managed by FCCN, with the aim of making advanced computing services available to the research, technology and innovation communities. RCNA's network of operational centres include the EuroHPC Deucalion supercomputer. It is a member of the Iberian Advanced Computing Network, with also includes the MareNostrum supercomputers in Spain. POLEN\nPOLEN is a project developed by FCCN which aims to address the needs of the scientific and education communities in\nresearch data management.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"pt_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Portugal",
                "country_code":"PT",
                "contributors":[
                    "Jorge Oliveira",
                    "Ana Portugal Melo",
                    "Gil Poiares-Oliveira"
                ],
                "coordinators":[
                    "Jorge Oliveira",
                    "Gil Poiares-Oliveira"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Portugal"
                    },
                    {
                        "name":"Training at BioData.pt",
                        "registry":"BioData.pt",
                        "url":"https:\/\/biodata.pt\/training"
                    },
                    {
                        "name":"BioData.pt GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/BioData-PT"
                    },
                    {
                        "name":"BioData.pt YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/@BioDataPT"
                    }
                ],
                "national_resources":[
                    {
                        "name":"BioData.pt Data Management Portal (DMPortal)",
                        "description":"This instance of Dataverse is provided by the BioData.pt. We can help you write and maintain data management plans for your research.",
                        "instance_of":"dataverse",
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "storage"
                            ]
                        },
                        "registry":{
                            "biotools":"dmportal",
                            "fairsharing":"b2f583"
                        },
                        "url":"https:\/\/dmportal.biodata.pt\/"
                    },
                    {
                        "name":"BioData.pt Data Stewardship Wizard",
                        "description":"This tool guides users through generating Data Management Plans.",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "registry":{
                            "biotools":"Data_Stewardship_Wizard"
                        },
                        "url":"https:\/\/biodatapt.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"Ready for BioData Management?",
                        "description":"Capacity building program in data management for the life sciences to empower researchers and institutions in managing their data more effectively and efficiently.",
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "dm_coordination"
                            ]
                        },
                        "url":"https:\/\/biodata.pt\/training\/programmes\/r4bdm"
                    },
                    {
                        "name":"eLab BioData.pt",
                        "description":"An electronic lab notebook (ELN) for BioData.pt training programmes (data wiped periodically).",
                        "inistance_of":"eLabFTW",
                        "how_to_access":"For trainees of BioData.pt training programmes.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "principal_investigator"
                            ],
                            "your_tasks":[
                                "metadata",
                                "data_quality",
                                "dm_coordination",
                                "data_protection",
                                "data_organization",
                                "data_provenance",
                                "machine_actionability"
                            ]
                        },
                        "url":"https:\/\/elab.biodata.pt\/"
                    },
                    {
                        "name":"INDEXAR",
                        "description":"National directory of repositories and digital scientific journals, in the fields of science and culture.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.indexar.pt\/"
                    },
                    {
                        "name":"dados.gov.pt",
                        "description":"Open data portal of the Portuguese Public Administration.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/dados.gov.pt",
                        "instance_of":"udata"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_pt_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"h aims to address the needs of the scientific and education communities in\nresearch data management. It also aims to promote open science, and the sharing and preservation of research data generated within the scope of\nprojects developed with public funding. Research Data Management Forum\nThe Research Data Management Forum (Frum de Gesto de Dados de Informao) is a space for the debate and sharing of\nideas, projects, and best practices in Research Data Management, aiming to join together RDM support professionals in research institutions and\nscience funding organisations. National Center for Advanced Computing\nThe National Center for Advanced Computing (CNCA) (previously National Distributed Computing Infrastructure) provides computing and data services to the national scientific and academic community in all areas of knowledge. CNCA is especially oriented to provide scientific computing services, supporting researchers and the participation in national and international projects.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"pt_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Portugal",
                "country_code":"PT",
                "contributors":[
                    "Jorge Oliveira",
                    "Ana Portugal Melo",
                    "Gil Poiares-Oliveira"
                ],
                "coordinators":[
                    "Jorge Oliveira",
                    "Gil Poiares-Oliveira"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Portugal"
                    },
                    {
                        "name":"Training at BioData.pt",
                        "registry":"BioData.pt",
                        "url":"https:\/\/biodata.pt\/training"
                    },
                    {
                        "name":"BioData.pt GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/BioData-PT"
                    },
                    {
                        "name":"BioData.pt YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/@BioDataPT"
                    }
                ],
                "national_resources":[
                    {
                        "name":"BioData.pt Data Management Portal (DMPortal)",
                        "description":"This instance of Dataverse is provided by the BioData.pt. We can help you write and maintain data management plans for your research.",
                        "instance_of":"dataverse",
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "storage"
                            ]
                        },
                        "registry":{
                            "biotools":"dmportal",
                            "fairsharing":"b2f583"
                        },
                        "url":"https:\/\/dmportal.biodata.pt\/"
                    },
                    {
                        "name":"BioData.pt Data Stewardship Wizard",
                        "description":"This tool guides users through generating Data Management Plans.",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "registry":{
                            "biotools":"Data_Stewardship_Wizard"
                        },
                        "url":"https:\/\/biodatapt.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"Ready for BioData Management?",
                        "description":"Capacity building program in data management for the life sciences to empower researchers and institutions in managing their data more effectively and efficiently.",
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "dm_coordination"
                            ]
                        },
                        "url":"https:\/\/biodata.pt\/training\/programmes\/r4bdm"
                    },
                    {
                        "name":"eLab BioData.pt",
                        "description":"An electronic lab notebook (ELN) for BioData.pt training programmes (data wiped periodically).",
                        "inistance_of":"eLabFTW",
                        "how_to_access":"For trainees of BioData.pt training programmes.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "principal_investigator"
                            ],
                            "your_tasks":[
                                "metadata",
                                "data_quality",
                                "dm_coordination",
                                "data_protection",
                                "data_organization",
                                "data_provenance",
                                "machine_actionability"
                            ]
                        },
                        "url":"https:\/\/elab.biodata.pt\/"
                    },
                    {
                        "name":"INDEXAR",
                        "description":"National directory of repositories and digital scientific journals, in the fields of science and culture.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.indexar.pt\/"
                    },
                    {
                        "name":"dados.gov.pt",
                        "description":"Open data portal of the Portuguese Public Administration.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/dados.gov.pt",
                        "instance_of":"udata"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_pt_resources_md_3",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"uting services, supporting researchers and the participation in national and international projects. Life and Health Sciences Infrastructures and Resources\nBioData.pt\nBioData.pt is the national research infrastructure for life and health data, and the host of ELIXIR Portugal. BioData.pt is a registered\nnonprofit association of several major Portuguese universities and research institutes acting in the life and health sciences. It is integrated in the National Roadmap of Research Infrastructures of Strategic Interest (RNIE). BioData.pt, through its affiliate institutions, provides a wide array of RDM tools, databases, and training programmes tailored towards the Life and Health Sciences communities, which are aggregated in its Services page. Institutional policies on research data in Portugal\nSome institutions implemented their own data management policies. Here are few examples from the organisations in Life and Health Sciences: * Centre of Marine Sciences (CCMAR)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"pt_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Portugal",
                "country_code":"PT",
                "contributors":[
                    "Jorge Oliveira",
                    "Ana Portugal Melo",
                    "Gil Poiares-Oliveira"
                ],
                "coordinators":[
                    "Jorge Oliveira",
                    "Gil Poiares-Oliveira"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Portugal"
                    },
                    {
                        "name":"Training at BioData.pt",
                        "registry":"BioData.pt",
                        "url":"https:\/\/biodata.pt\/training"
                    },
                    {
                        "name":"BioData.pt GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/BioData-PT"
                    },
                    {
                        "name":"BioData.pt YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/@BioDataPT"
                    }
                ],
                "national_resources":[
                    {
                        "name":"BioData.pt Data Management Portal (DMPortal)",
                        "description":"This instance of Dataverse is provided by the BioData.pt. We can help you write and maintain data management plans for your research.",
                        "instance_of":"dataverse",
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "storage"
                            ]
                        },
                        "registry":{
                            "biotools":"dmportal",
                            "fairsharing":"b2f583"
                        },
                        "url":"https:\/\/dmportal.biodata.pt\/"
                    },
                    {
                        "name":"BioData.pt Data Stewardship Wizard",
                        "description":"This tool guides users through generating Data Management Plans.",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "registry":{
                            "biotools":"Data_Stewardship_Wizard"
                        },
                        "url":"https:\/\/biodatapt.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"Ready for BioData Management?",
                        "description":"Capacity building program in data management for the life sciences to empower researchers and institutions in managing their data more effectively and efficiently.",
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "dm_coordination"
                            ]
                        },
                        "url":"https:\/\/biodata.pt\/training\/programmes\/r4bdm"
                    },
                    {
                        "name":"eLab BioData.pt",
                        "description":"An electronic lab notebook (ELN) for BioData.pt training programmes (data wiped periodically).",
                        "inistance_of":"eLabFTW",
                        "how_to_access":"For trainees of BioData.pt training programmes.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "principal_investigator"
                            ],
                            "your_tasks":[
                                "metadata",
                                "data_quality",
                                "dm_coordination",
                                "data_protection",
                                "data_organization",
                                "data_provenance",
                                "machine_actionability"
                            ]
                        },
                        "url":"https:\/\/elab.biodata.pt\/"
                    },
                    {
                        "name":"INDEXAR",
                        "description":"National directory of repositories and digital scientific journals, in the fields of science and culture.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.indexar.pt\/"
                    },
                    {
                        "name":"dados.gov.pt",
                        "description":"Open data portal of the Portuguese Public Administration.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/dados.gov.pt",
                        "instance_of":"udata"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_pt_resources_md_4",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/pt_resources.md",
        "file_name":"pt_resources.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"few examples from the organisations in Life and Health Sciences: * Centre of Marine Sciences (CCMAR) * Instituto Gulbenkian de Cincia (IGC)\n* NOVA Institute of Medical Systems Biology (NIMSB)\nFinding more\nPortugal has a large number of Research Data Management and Open Data initiatives at the national, local, and institutional level. Initiatives such as INDEXAR and dados.gov.pt aggregate existing resources to facilitate locating the right one for the user's needs.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"pt_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Portugal",
                "country_code":"PT",
                "contributors":[
                    "Jorge Oliveira",
                    "Ana Portugal Melo",
                    "Gil Poiares-Oliveira"
                ],
                "coordinators":[
                    "Jorge Oliveira",
                    "Gil Poiares-Oliveira"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Portugal"
                    },
                    {
                        "name":"Training at BioData.pt",
                        "registry":"BioData.pt",
                        "url":"https:\/\/biodata.pt\/training"
                    },
                    {
                        "name":"BioData.pt GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/BioData-PT"
                    },
                    {
                        "name":"BioData.pt YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/@BioDataPT"
                    }
                ],
                "national_resources":[
                    {
                        "name":"BioData.pt Data Management Portal (DMPortal)",
                        "description":"This instance of Dataverse is provided by the BioData.pt. We can help you write and maintain data management plans for your research.",
                        "instance_of":"dataverse",
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "storage"
                            ]
                        },
                        "registry":{
                            "biotools":"dmportal",
                            "fairsharing":"b2f583"
                        },
                        "url":"https:\/\/dmportal.biodata.pt\/"
                    },
                    {
                        "name":"BioData.pt Data Stewardship Wizard",
                        "description":"This tool guides users through generating Data Management Plans.",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "how_to_access":"Open registration. Target users are researchers of BioData.pt associate organisations.",
                        "registry":{
                            "biotools":"Data_Stewardship_Wizard"
                        },
                        "url":"https:\/\/biodatapt.dsw.elixir-europe.org\/"
                    },
                    {
                        "name":"Ready for BioData Management?",
                        "description":"Capacity building program in data management for the life sciences to empower researchers and institutions in managing their data more effectively and efficiently.",
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "dm_coordination"
                            ]
                        },
                        "url":"https:\/\/biodata.pt\/training\/programmes\/r4bdm"
                    },
                    {
                        "name":"eLab BioData.pt",
                        "description":"An electronic lab notebook (ELN) for BioData.pt training programmes (data wiped periodically).",
                        "inistance_of":"eLabFTW",
                        "how_to_access":"For trainees of BioData.pt training programmes.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "principal_investigator"
                            ],
                            "your_tasks":[
                                "metadata",
                                "data_quality",
                                "dm_coordination",
                                "data_protection",
                                "data_organization",
                                "data_provenance",
                                "machine_actionability"
                            ]
                        },
                        "url":"https:\/\/elab.biodata.pt\/"
                    },
                    {
                        "name":"INDEXAR",
                        "description":"National directory of repositories and digital scientific journals, in the fields of science and culture.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.indexar.pt\/"
                    },
                    {
                        "name":"dados.gov.pt",
                        "description":"Open data portal of the Portuguese Public Administration.",
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "data_publication",
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/dados.gov.pt",
                        "instance_of":"udata"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_es_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"contributors:\n- Laura Portell Silva\n- Salvador Capella-Gutierrez\n- Eva Alloza\ncoordinators:\n- Salvador Capella-Gutierrez\ncountry_code: ES\nnational_resources:\n- description: The Spanish Supercomputing Network's mission is to offer the resources\n    and services of supercomputing and data management necessary for the development\n    of innovative and high-quality scientific and technological projects, through\n    competitive calls based on the scientific excellence of the projects to be developed. how_to_access: null\n  name: Red Espaola de Supercomputacin\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    - research_software_engineer\n  url: https:\/\/www.res.es\/en\n- description: Spanish academic and research network that provides advanced communication\n    services to the scientific community and national universities.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"es_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_es_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":" provides advanced communication\n    services to the scientific community and national universities. how_to_access: null\n  name: RedIRIS\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    - research_software_engineer\n  url: https:\/\/www.rediris.es\/\n- description: The national aggregator of open access repositories. This platform\n    brings together all the Spanish digital infrastructures in which open access research\n    results are published and \/ or deposited. how_to_access: null\n  name: Recolecta\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    - research_software_engineer\n  url: https:\/\/recolecta.fecyt.es\/repositorios-recolectados\n- description: Open data portal of the spanish government. A meeting point for the\n    various actors that make up the open data ecosystem.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"es_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_es_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"spanish government. A meeting point for the\n    various actors that make up the open data ecosystem. how_to_access: null\n  name: Datos.gob.es\n  related_pages:\n    your_role:\n    - researcher\n    - data_steward\n    - research_software_engineer\n  url: https:\/\/datos.gob.es\/\ntitle: Spain\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/materials?node=Spain&scientific_topics=Data+management",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"es_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_es_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":0,
        "total_chunks":6,
        "content":"Introduction\nThis page gives an overview of some of the data management resources in Spain. The target audience is the Spanish scientific community in the life sciences and their collaborators. The INB\/ELIXIR Spain serves as a national node of the European ELIXIR infrastructure, offering guidance on research data management tailored to the Spanish scientific context. The Spanish Ministry of Science and Innovation has developed the National Strategy for Open Science (Estrategia Nacional de Ciencia Abierta), launched in 2023, which promotes open, equitable, and efficient sharing of research data across Spain. For researchers in Spain and their international partners, this strategy establishes the foundation for a collaborative and innovative research ecosystem where data is shared responsibly and transparently. The national strategy highlights Spains dedication to scientific progress while upholding ethical and legal standards in an increasingly data-driven world.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"es_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Spain",
                "country_code":"ES",
                "contributors":[
                    "Laura Portell Silva",
                    "Salvador Capella-Gutierrez",
                    "Eva Alloza"
                ],
                "coordinators":[
                    "Salvador Capella-Gutierrez"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Spain&scientific_topics=Data+management"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Red Espaola de Supercomputacin",
                        "description":"The Spanish Supercomputing Network's mission is to offer the resources and services of supercomputing and data management necessary for the development of innovative and high-quality scientific and technological projects, through competitive calls based on the scientific excellence of the projects to be developed.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.res.es\/en"
                    },
                    {
                        "name":"RedIRIS",
                        "description":"Spanish academic and research network that provides advanced communication services to the scientific community and national universities.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.rediris.es\/"
                    },
                    {
                        "name":"Recolecta",
                        "description":"The national aggregator of open access repositories. This platform brings together all the Spanish digital infrastructures in which open access research results are published and \/ or deposited.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/recolecta.fecyt.es\/repositorios-recolectados"
                    },
                    {
                        "name":"Datos.gob.es",
                        "description":"Open data portal of the spanish government. A meeting point for the various actors that make up the open data ecosystem.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/datos.gob.es\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_es_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":1,
        "total_chunks":6,
        "content":"cientific progress while upholding ethical and legal standards in an increasingly data-driven world. In addition, a guideline on how to prepare a data management plan by the Spanish National Research Council (CSIC) can be found here. Relevant initiatives\n\nAporta: An initiative that aims to harmonize and efficiently take advantage of the synergies between ongoing open data projects. It seeks to always drive and coordinate actions being carried out by different levels of the administration, the private sector and academic field, according to an integrating governance model. Research Data Alliance (RDA) in Spain: This is the space dedicated to the activities, news and events of the RDA Spanish Node. E-science network: Inclusive initiative that combines efforts, shares information and aims to strengthen the position of Spanish institutions within the framework of the European Open Science Cloud (EOSC). SOMMa Open Science group: SOMMa embraces Open Science to make research more collaborative, reproducible, and accessible, and to engage all levels of an inquiring society.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"es_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Spain",
                "country_code":"ES",
                "contributors":[
                    "Laura Portell Silva",
                    "Salvador Capella-Gutierrez",
                    "Eva Alloza"
                ],
                "coordinators":[
                    "Salvador Capella-Gutierrez"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Spain&scientific_topics=Data+management"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Red Espaola de Supercomputacin",
                        "description":"The Spanish Supercomputing Network's mission is to offer the resources and services of supercomputing and data management necessary for the development of innovative and high-quality scientific and technological projects, through competitive calls based on the scientific excellence of the projects to be developed.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.res.es\/en"
                    },
                    {
                        "name":"RedIRIS",
                        "description":"Spanish academic and research network that provides advanced communication services to the scientific community and national universities.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.rediris.es\/"
                    },
                    {
                        "name":"Recolecta",
                        "description":"The national aggregator of open access repositories. This platform brings together all the Spanish digital infrastructures in which open access research results are published and \/ or deposited.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/recolecta.fecyt.es\/repositorios-recolectados"
                    },
                    {
                        "name":"Datos.gob.es",
                        "description":"Open data portal of the spanish government. A meeting point for the various actors that make up the open data ecosystem.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/datos.gob.es\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_es_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":2,
        "total_chunks":6,
        "content":" more collaborative, reproducible, and accessible, and to engage all levels of an inquiring society. CSUC support on Research Data Management: Guidelines supporting universities and research centres to adapt the management of their research data to the requirements of funding bodies following the FAIR principles (Findable, Accessible, Interoperable and Reusable). Gaia-x Hub Espaa: A regional initiative supporting the European Gaia-X project, fostering secure, federated data infrastructure and collaboration. It aims to align local efforts with Gaia-X standards and promote data-driven innovation in Spain. Barcelona Declaration on Open Research Information: A declaration that advocates for the free and open sharing of research data and publications to promote transparency and collaboration in science. It encourages institutions and researchers to adopt open practices, enhancing accessibility to knowledge for global progress and innovation. Aside of the national initiatives, there are also other territorial initiatives that can be found in this page.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"es_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Spain",
                "country_code":"ES",
                "contributors":[
                    "Laura Portell Silva",
                    "Salvador Capella-Gutierrez",
                    "Eva Alloza"
                ],
                "coordinators":[
                    "Salvador Capella-Gutierrez"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Spain&scientific_topics=Data+management"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Red Espaola de Supercomputacin",
                        "description":"The Spanish Supercomputing Network's mission is to offer the resources and services of supercomputing and data management necessary for the development of innovative and high-quality scientific and technological projects, through competitive calls based on the scientific excellence of the projects to be developed.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.res.es\/en"
                    },
                    {
                        "name":"RedIRIS",
                        "description":"Spanish academic and research network that provides advanced communication services to the scientific community and national universities.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.rediris.es\/"
                    },
                    {
                        "name":"Recolecta",
                        "description":"The national aggregator of open access repositories. This platform brings together all the Spanish digital infrastructures in which open access research results are published and \/ or deposited.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/recolecta.fecyt.es\/repositorios-recolectados"
                    },
                    {
                        "name":"Datos.gob.es",
                        "description":"Open data portal of the spanish government. A meeting point for the various actors that make up the open data ecosystem.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/datos.gob.es\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_es_resources_md_3",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":3,
        "total_chunks":6,
        "content":"e national initiatives, there are also other territorial initiatives that can be found in this page. Institutional policies on research data\nNon-exhaustive list of research institutions with Data Management Policies in Spain:\n- ESADE Research Data Management guidelines\n- CERCA Data Management Strategy\n- Autonomous University of Barcelona Institutional policy for open access to research data\n- CRAI support on Research Data Management\n- Univeristy of Girona Research Data Management Policy\n- UPF Research Data Management\n- Single portal UPC for Research Data Management\n- UDL Research Data Management\nLife science-specific infrastructures\/resources\nA collection of general and topic-specific resources has been compiled to help streamline data management practices and protect research data. These resources aim to boost productivity while ensuring research is conducted in a compliant, transparent, and reproducible manner. Federated European Genome-phenome Archive (FEGA)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"es_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Spain",
                "country_code":"ES",
                "contributors":[
                    "Laura Portell Silva",
                    "Salvador Capella-Gutierrez",
                    "Eva Alloza"
                ],
                "coordinators":[
                    "Salvador Capella-Gutierrez"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Spain&scientific_topics=Data+management"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Red Espaola de Supercomputacin",
                        "description":"The Spanish Supercomputing Network's mission is to offer the resources and services of supercomputing and data management necessary for the development of innovative and high-quality scientific and technological projects, through competitive calls based on the scientific excellence of the projects to be developed.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.res.es\/en"
                    },
                    {
                        "name":"RedIRIS",
                        "description":"Spanish academic and research network that provides advanced communication services to the scientific community and national universities.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.rediris.es\/"
                    },
                    {
                        "name":"Recolecta",
                        "description":"The national aggregator of open access repositories. This platform brings together all the Spanish digital infrastructures in which open access research results are published and \/ or deposited.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/recolecta.fecyt.es\/repositorios-recolectados"
                    },
                    {
                        "name":"Datos.gob.es",
                        "description":"Open data portal of the spanish government. A meeting point for the various actors that make up the open data ecosystem.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/datos.gob.es\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_es_resources_md_4",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":4,
        "total_chunks":6,
        "content":" a compliant, transparent, and reproducible manner. Federated European Genome-phenome Archive (FEGA) Spanish node\nThe FEGA is the primary European resource for discovering and accessing sensitive human -omics- data consented for secondary use. The network comprises national repositories that ensure data remains in local jurisdictions while being discoverable through the main EGA portal and accessed across international borders in a federated manner. The Spanish National Bioinformatics Institute (INB), as the ELIXIR node in Spain, and in collaboration with the EGA team at the Centre for Genomic Regulation (CRG), has established the Spanish Federated EGA node (ES-FEGA), primarily hosted at BSC facilities. Spanish COVID-19 Data Portal\nThe Spanish COVID-19 Data Portal provides information, guidelines, tools and services to support researchers in utilising Spanish and European infrastructures for data sharing, in particular the European COVID-19 Data Portal.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"es_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Spain",
                "country_code":"ES",
                "contributors":[
                    "Laura Portell Silva",
                    "Salvador Capella-Gutierrez",
                    "Eva Alloza"
                ],
                "coordinators":[
                    "Salvador Capella-Gutierrez"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Spain&scientific_topics=Data+management"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Red Espaola de Supercomputacin",
                        "description":"The Spanish Supercomputing Network's mission is to offer the resources and services of supercomputing and data management necessary for the development of innovative and high-quality scientific and technological projects, through competitive calls based on the scientific excellence of the projects to be developed.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.res.es\/en"
                    },
                    {
                        "name":"RedIRIS",
                        "description":"Spanish academic and research network that provides advanced communication services to the scientific community and national universities.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.rediris.es\/"
                    },
                    {
                        "name":"Recolecta",
                        "description":"The national aggregator of open access repositories. This platform brings together all the Spanish digital infrastructures in which open access research results are published and \/ or deposited.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/recolecta.fecyt.es\/repositorios-recolectados"
                    },
                    {
                        "name":"Datos.gob.es",
                        "description":"Open data portal of the spanish government. A meeting point for the various actors that make up the open data ecosystem.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/datos.gob.es\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_es_resources_md_5",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/es_resources.md",
        "file_name":"es_resources.md",
        "chunk_index":5,
        "total_chunks":6,
        "content":"nish and European infrastructures for data sharing, in particular the European COVID-19 Data Portal. For those interested in ongoing large research projects in Spain, we have compiled a list of projects funded by major funding agencies. The INB\/ELIXIR-ES portfolio of resources\nThe Spanish National Bioinformatics Institute (INB), renewed its Service Delivery Plan (SDP) in the second half of 2023. The renewed INB\/ELIXIR-ES SDP is composed of 40 resources offered, developed and maintained by 24 groups in 12 institutions across Spain. This periodical assessment allows reviewing the current offer by the node and offer an up-to-date portfolio of resources to ELIXIR, directly impacting the Life Sciences community.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"es_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Spain",
                "country_code":"ES",
                "contributors":[
                    "Laura Portell Silva",
                    "Salvador Capella-Gutierrez",
                    "Eva Alloza"
                ],
                "coordinators":[
                    "Salvador Capella-Gutierrez"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?node=Spain&scientific_topics=Data+management"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Red Espaola de Supercomputacin",
                        "description":"The Spanish Supercomputing Network's mission is to offer the resources and services of supercomputing and data management necessary for the development of innovative and high-quality scientific and technological projects, through competitive calls based on the scientific excellence of the projects to be developed.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.res.es\/en"
                    },
                    {
                        "name":"RedIRIS",
                        "description":"Spanish academic and research network that provides advanced communication services to the scientific community and national universities.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/www.rediris.es\/"
                    },
                    {
                        "name":"Recolecta",
                        "description":"The national aggregator of open access repositories. This platform brings together all the Spanish digital infrastructures in which open access research results are published and \/ or deposited.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/recolecta.fecyt.es\/repositorios-recolectados"
                    },
                    {
                        "name":"Datos.gob.es",
                        "description":"Open data portal of the spanish government. A meeting point for the various actors that make up the open data ecosystem.",
                        "how_to_access":null,
                        "related_pages":{
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ]
                        },
                        "url":"https:\/\/datos.gob.es\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_lu_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/lu_resources.md",
        "file_name":"lu_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"contributors:\n- Pinar Alper\n- Marina Popleteeva\n- Vilem Ded\n- Wei Gu\ncoordinators:\n- Wei Gu\ncountry_code: LU\nnational_resources:\n- description: A training instance of Data Steward Wizard (DSW), which has the FNR\n    and the DPIA templates. how_to_access: registration\n  instance_of: data-stewardship-wizard\n  name: learning. DSW\n  related_pages:\n    your_tasks:\n    - dmp\n  url: https:\/\/learning.dsw.elixir-europe.org\/dashboard\n- description: This instance of DMPOnline is provided by ELIXIR Luxembourg and has\n    FNR template for Data Management Plan (DMP).",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"lu_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_lu_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/lu_resources.md",
        "file_name":"lu_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":" DMPOnline is provided by ELIXIR Luxembourg and has\n    FNR template for Data Management Plan (DMP). how_to_access: registration\n  instance_of: dmproadmap\n  name: DPMRoadmap @ ELIXIR Luxembourg\n  related_pages:\n    your_tasks:\n    - dmp\n  url: https:\/\/dmponline.elixir-luxembourg.org\/\n- description: The Luxembourgish COVID-19 Data Portal acts as a collection of links\n    and provides information to support researchers to utilise Luxembourgish and European\n    infrastructures for data sharing.\n  name: Luxembourg Covid-19 data portal\n  related_pages:\n    tool_assembly:\n    - covid19_data_portal",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"lu_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_lu_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/lu_resources.md",
        "file_name":"lu_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":" name: Luxembourg Covid-19 data portal\n  related_pages:\n    tool_assembly:\n    - covid19_data_portal your_domain:\n    - human data\n    your_tasks:\n    - sensitive\n    - existing data\n    - data publication\n  url: https:\/\/covid19dataportal.lu\/\nref_to_main_resources:\n- fair-cookbook\n- covid-19-disease-map\n- daisy\n- data-catalog\n- dpia-knowledge-model\nrelated_pages:\n  tool_assembly:\n  - transmed\ntitle: Luxembourg\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/nodes\/luxembourg\n- name: Materials for the ELIXIR Luxembourg course on \"Best Practices in Research\n    Data Management and Stewardship. \"\n  registry: Zenodo\n  url: https:\/\/zenodo.org\/communities\/elixir-lu\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"lu_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_lu_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/lu_resources.md",
        "file_name":"lu_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\n\nOn this page you will find an overview of data management resources available for the Luxembourgish life science research community. In addition to information provided here, the reader is advised to read the Research Luxembourg website, which describes the Luxembourg research landscape and developments. Funders\nLuxembourgs main research funding body is the Fonds National de la Recherch (FNR). The FNR promotes open-access to scientific publication through its open-access fund. To increase the re-usability of research outputs the FNR adopts a research data management policy and expects all funded projects to prepare and implement Data Management Plans (DMP) in line with Science Europe guidelines. DMP guiding questions are provided in the FNR grant management system.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"lu_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Luxembourg",
                "country_code":"LU",
                "contributors":[
                    "Pinar Alper",
                    "Marina Popleteeva",
                    "Vilem Ded",
                    "Wei Gu"
                ],
                "coordinators":[
                    "Wei Gu"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/luxembourg"
                    },
                    {
                        "name":"Materials for the ELIXIR Luxembourg course on \"Best Practices in Research Data Management and Stewardship.\"",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-lu\/"
                    }
                ],
                "ref_to_main_resources":[
                    "fair-cookbook",
                    "covid-19-disease-map",
                    "daisy",
                    "data-catalog",
                    "dpia-knowledge-model"
                ],
                "national_resources":[
                    {
                        "name":"learning.DSW",
                        "description":"A training instance of Data Steward Wizard (DSW), which has the FNR and the DPIA templates.",
                        "how_to_access":"registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/learning.dsw.elixir-europe.org\/dashboard"
                    },
                    {
                        "name":"DPMRoadmap @ ELIXIR Luxembourg",
                        "description":"This instance of DMPOnline is provided by ELIXIR Luxembourg and has FNR template for Data Management Plan (DMP).",
                        "how_to_access":"registration",
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmponline.elixir-luxembourg.org\/"
                    },
                    {
                        "name":"Luxembourg Covid-19 data portal",
                        "description":"The Luxembourgish COVID-19 Data Portal acts as a collection of links and provides information to support researchers to utilise Luxembourgish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing data",
                                "data publication"
                            ]
                        },
                        "url":"https:\/\/covid19dataportal.lu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_lu_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/lu_resources.md",
        "file_name":"lu_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"th Science Europe guidelines. DMP guiding questions are provided in the FNR grant management system. Regulations\n\nLuxembourgs National Commission for Data Protection (CNPD), through its Open Data Protection Laboratory (DaProLab), provides online guidance and information sessions on data protection for research. Luxembourgs National Research Ethics Committee (CNER) provides ethical oversight and individual assessment for research projects, particularly for the collection, use and secondary use of data\/samples from human subjects. Research infrastructures and resources\n\nELIXIR Lxembourg provides resources for life science data management, focusing on the areas of translational biomedicine data hosting, data protection, data FAIRification and reproducible research. ELIXIR Luxembourg provides the TransMed tool assembly to support research project with sensitive human data. The Luxembourgish node of EATRIS provides services in translational medicine.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"lu_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Luxembourg",
                "country_code":"LU",
                "contributors":[
                    "Pinar Alper",
                    "Marina Popleteeva",
                    "Vilem Ded",
                    "Wei Gu"
                ],
                "coordinators":[
                    "Wei Gu"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/luxembourg"
                    },
                    {
                        "name":"Materials for the ELIXIR Luxembourg course on \"Best Practices in Research Data Management and Stewardship.\"",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-lu\/"
                    }
                ],
                "ref_to_main_resources":[
                    "fair-cookbook",
                    "covid-19-disease-map",
                    "daisy",
                    "data-catalog",
                    "dpia-knowledge-model"
                ],
                "national_resources":[
                    {
                        "name":"learning.DSW",
                        "description":"A training instance of Data Steward Wizard (DSW), which has the FNR and the DPIA templates.",
                        "how_to_access":"registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/learning.dsw.elixir-europe.org\/dashboard"
                    },
                    {
                        "name":"DPMRoadmap @ ELIXIR Luxembourg",
                        "description":"This instance of DMPOnline is provided by ELIXIR Luxembourg and has FNR template for Data Management Plan (DMP).",
                        "how_to_access":"registration",
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmponline.elixir-luxembourg.org\/"
                    },
                    {
                        "name":"Luxembourg Covid-19 data portal",
                        "description":"The Luxembourgish COVID-19 Data Portal acts as a collection of links and provides information to support researchers to utilise Luxembourgish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing data",
                                "data publication"
                            ]
                        },
                        "url":"https:\/\/covid19dataportal.lu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_lu_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/lu_resources.md",
        "file_name":"lu_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":" sensitive human data. The Luxembourgish node of EATRIS provides services in translational medicine. Luxembourg National Data Service (LNDS) is a government established organisation aiming to support and stimulate value creation from data in Luxembourg. LNDS provides a variety of data management and stewardship services to enable the secondary use of data. LNDS services are domain-agnostic and support the life sciences as well as other domains. The Integrated BioBank of Luxembourg (IBBL) is a not-for-profit institute and the national biobanking platform hosted within the Luxembourg Institute of Health (LIH). IBBL provides a full range of biobanking services to the biomedical sector including the industry, academia and EU consortia. University of Luxembourgs High-Performance Computing Platform (ULHPC) and the EuroHPC  Joint Intitiatives MeluXina supercomputer offer HPC capabilities for Luxembourg researchers, public sector and the industry.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"lu_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Luxembourg",
                "country_code":"LU",
                "contributors":[
                    "Pinar Alper",
                    "Marina Popleteeva",
                    "Vilem Ded",
                    "Wei Gu"
                ],
                "coordinators":[
                    "Wei Gu"
                ],
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/luxembourg"
                    },
                    {
                        "name":"Materials for the ELIXIR Luxembourg course on \"Best Practices in Research Data Management and Stewardship.\"",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-lu\/"
                    }
                ],
                "ref_to_main_resources":[
                    "fair-cookbook",
                    "covid-19-disease-map",
                    "daisy",
                    "data-catalog",
                    "dpia-knowledge-model"
                ],
                "national_resources":[
                    {
                        "name":"learning.DSW",
                        "description":"A training instance of Data Steward Wizard (DSW), which has the FNR and the DPIA templates.",
                        "how_to_access":"registration",
                        "instance_of":"data-stewardship-wizard",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/learning.dsw.elixir-europe.org\/dashboard"
                    },
                    {
                        "name":"DPMRoadmap @ ELIXIR Luxembourg",
                        "description":"This instance of DMPOnline is provided by ELIXIR Luxembourg and has FNR template for Data Management Plan (DMP).",
                        "how_to_access":"registration",
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmponline.elixir-luxembourg.org\/"
                    },
                    {
                        "name":"Luxembourg Covid-19 data portal",
                        "description":"The Luxembourgish COVID-19 Data Portal acts as a collection of links and provides information to support researchers to utilise Luxembourgish and European infrastructures for data sharing.",
                        "related_pages":{
                            "tool_assembly":[
                                "covid19_data_portal"
                            ],
                            "your_domain":[
                                "human data"
                            ],
                            "your_tasks":[
                                "sensitive",
                                "existing data",
                                "data publication"
                            ]
                        },
                        "url":"https:\/\/covid19dataportal.lu\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_ee_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/ee_resources.md",
        "file_name":"ee_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Heleri Inno\n- Diana Pilvar\ncoordinators:\n- Heleri Inno\ncountry_code: EE\nnational_resources:\n- description: This is the Estonian instance of  Galaxy, which is an open source,\n    web-based platform for data intensive biomedical research. how_to_access: null\n  instance_of: galaxy\n  name: Galaxy Estonia\n  related_pages:\n    tool_assembly: null\n    your_domain: null\n    your_role:\n    - researcher\n    your_tasks:\n    - data_analysis\n  url: https:\/\/galaxy.hpc.ut.ee\/\ntitle: Estonia",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ee_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_ee_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ee_resources.md",
        "file_name":"ee_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\nThis page provides an overview of the data management resources and initiatives in Estonia. All these references are meant for Estonian researchers and their collaborators. The Estonian government has released an Estonian Research and Development, Innovation and Entrepreneurship Strategy 2021-2035 in Estonian and in English. Funders\n\nEstonian Research Council\nRepublic of Estonia Education and Youth Board\n\nRelevant initiatives\n\nOrganisations\n\nEstonian Research Council open science policies, surveys and documentation. ELIXIR Estonia Data Management page: general information about data management and specific recommendations and references on how to manage your scientific data in Estonia. Open Knowledge Estonia Promoter of data competence and digital literacy in Estonia.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ee_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Estonia",
                "country_code":"EE",
                "contributors":[
                    "Heleri Inno",
                    "Diana Pilvar"
                ],
                "coordinators":[
                    "Heleri Inno"
                ],
                "national_resources":[
                    {
                        "name":"Galaxy Estonia",
                        "description":"This is the Estonian instance of  Galaxy, which is an open source, web-based platform for data intensive biomedical research.",
                        "how_to_access":null,
                        "instance_of":"galaxy",
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":null,
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/galaxy.hpc.ut.ee\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ee_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ee_resources.md",
        "file_name":"ee_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"data in Estonia. Open Knowledge Estonia Promoter of data competence and digital literacy in Estonia. Data management policy in National Institute of Chemical Physics and Biophysics (in Estonian)\n\nOpen Science in Estonia\n\nOpen Science in Estonia - the official Open Science branding of Estonia, developed by the University of Tartu Library; contains information about community, infrastructure, initiatives, and services. Open Science page for University of Tartu Library includes guidelines on how to write a Data Management Plan\nOpen Science page for Library of Estonian University of Life Sciences\nOpen Science page for Tallinn University of Technology\nOpen Science page for The Academic Library of Tallinn University\n\nDomain-specific infrastructures or resources\n\nELIXIR Estonia list of services that are provided. Estonian Research Information System contains information about the researchers and the projects. DataDOI is an Estonian National repository. PlutoF is a data management and publishing platform.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ee_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Estonia",
                "country_code":"EE",
                "contributors":[
                    "Heleri Inno",
                    "Diana Pilvar"
                ],
                "coordinators":[
                    "Heleri Inno"
                ],
                "national_resources":[
                    {
                        "name":"Galaxy Estonia",
                        "description":"This is the Estonian instance of  Galaxy, which is an open source, web-based platform for data intensive biomedical research.",
                        "how_to_access":null,
                        "instance_of":"galaxy",
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":null,
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/galaxy.hpc.ut.ee\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ee_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/ee_resources.md",
        "file_name":"ee_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"ts. DataDOI is an Estonian National repository. PlutoF is a data management and publishing platform. The High Performance Computing Center\nEstonian Scientific Computing Infrastructure ETAIS\nCovid-19 Data Portal",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ee_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Estonia",
                "country_code":"EE",
                "contributors":[
                    "Heleri Inno",
                    "Diana Pilvar"
                ],
                "coordinators":[
                    "Heleri Inno"
                ],
                "national_resources":[
                    {
                        "name":"Galaxy Estonia",
                        "description":"This is the Estonian instance of  Galaxy, which is an open source, web-based platform for data intensive biomedical research.",
                        "how_to_access":null,
                        "instance_of":"galaxy",
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":null,
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/galaxy.hpc.ut.ee\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_uk_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/uk_resources.md",
        "file_name":"uk_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"contributors:\n- Munazah Andrabi\n- Robert Andrews\n- Nicola Soranzo\n- Kellie Snow\n- Sara Morsy\n- Branka Franicevic\n- Emma Karoune\n- Saskia Lawson-Tovey\n- Graham Parton\ncoordinators:\n- Robert Andrews\n- Munazah Andrabi\ncountry_code: GB\nnational_resources:\n- description: DMPonline is a web-based tool that supports researchers to develop\n    data management and sharing plans. It contains the latest funder templates and\n    best practice guidelines to support users to create good quality DMPs. how_to_access: null\n  instance_of: dmproadmap\n  name: DMPonline\n  related_pages:\n    your_role:\n    - data_steward\n    - researcher\n    your_tasks:\n    - dmp\n  url: https:\/\/dmponline.dcc.ac.uk\/\n- description: The CyVerse Data Store is a cloud-based storage space, accessible via\n    the CyVerse Discovery Environment (DE), a virtual bioinformatics lab workbench,\n    and developer APIs such as the AGAVE API.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"uk_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_uk_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/uk_resources.md",
        "file_name":"uk_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ironment (DE), a virtual bioinformatics lab workbench,\n    and developer APIs such as the AGAVE API. In the DE, users can share datasets\n    and tools to analyse data with as many or as few people as they wish. how_to_access: null\n  instance_of: null\n  name: CyVerse UK\n  related_pages:\n    your_role:\n    - data_steward\n    - researcher\n    your_tasks:\n    - metadata\n  url: https:\/\/cyverseuk.org\/\n- description: Guidance on the research data lifecycle that signposts resources from\n    a wide range of organisations and websites. how_to_access: null\n  instance_of: null\n  name: Jisc Research data management toolkit\n  related_pages:\n    your_role:\n    - data_steward\n    - researcher\n    your_tasks:\n    - metadata\n  url: https:\/\/web.archive.org\/web\/20230530165420\/https:\/\/www.jisc.ac.uk\/guides\/rdm-toolkit\n- description: Linked data schemas for the fields of agriculture, food, agri-business,\n    plant biology.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"uk_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_uk_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/uk_resources.md",
        "file_name":"uk_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"cription: Linked data schemas for the fields of agriculture, food, agri-business,\n    plant biology. how_to_access: null\n  instance_of: null\n  name: Agrischema\n  related_pages:\n    your_role:\n    - data_steward\n    - researcher\n    your_tasks:\n    - metadata\n  url: https:\/\/github.com\/Rothamsted\/agri-schemas\n- description: InterMine integrates heterogenous data sources, making it easy to query\n    and analyse data. how_to_access: null\n  instance_of: null\n  name: InterMine\n  related_pages:\n    your_role:\n    - data_steward\n    - researcher\n    your_tasks:\n    - metadata\n  url: http:\/\/intermine.org\/\nref_to_main_resources:\n- workflowhub\n- fairdom-seek\n- copo\ntitle: United Kingdom",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"uk_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_uk_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/uk_resources.md",
        "file_name":"uk_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\nThis page provides an overview of the data management resources in the UK. The target audience is the scientific community in the life sciences and collaborators. Funder policies, guidelines and data management plan (DMP) templates\n\n\nUK Research and Innovation (UKRI): Publishing your research findings, Concordat on open research and Open access policy\n\n\nBiotechnology and Biological Sciences Research Council (BBSRC): Data sharing policy\n\nMedical Research Council (MRC): DM guidelines, DMP template and Data sharing policy\nWellcome Trust: DM and sharing guidelines\nThe Royal Society: DM and sharing guidelines\nCancer Research UK: DM and sharing guidelines\nBritish Heart Foundation: DM and sharing guidelines\nHorizon 2020: DM guidelines and DMP template\n\nNational policies and recommendations for research data\n\nUK Data Protection Act (2018) is the UKs implementation of the General Data Protection Regulation (GDPR)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"uk_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"United Kingdom",
                "country_code":"GB",
                "contributors":[
                    "Munazah Andrabi",
                    "Robert Andrews",
                    "Nicola Soranzo",
                    "Kellie Snow",
                    "Sara Morsy",
                    "Branka Franicevic",
                    "Emma Karoune",
                    "Saskia Lawson-Tovey",
                    "Graham Parton"
                ],
                "coordinators":[
                    "Robert Andrews",
                    "Munazah Andrabi"
                ],
                "national_resources":[
                    {
                        "name":"DMPonline",
                        "description":"DMPonline is a web-based tool that supports researchers to develop data management and sharing plans. It contains the latest funder templates and best practice guidelines to support users to create good quality DMPs.",
                        "how_to_access":null,
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmponline.dcc.ac.uk\/"
                    },
                    {
                        "name":"CyVerse UK",
                        "description":"The CyVerse Data Store is a cloud-based storage space, accessible via the CyVerse Discovery Environment (DE), a virtual bioinformatics lab workbench, and developer APIs such as the AGAVE API. In the DE, users can share datasets and tools to analyse data with as many or as few people as they wish.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/cyverseuk.org\/"
                    },
                    {
                        "name":"Jisc Research data management toolkit",
                        "description":"Guidance on the research data lifecycle that signposts resources from a wide range of organisations and websites.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/web.archive.org\/web\/20230530165420\/https:\/\/www.jisc.ac.uk\/guides\/rdm-toolkit"
                    },
                    {
                        "name":"Agrischema",
                        "description":"Linked data schemas for the fields of agriculture, food, agri-business, plant biology.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/github.com\/Rothamsted\/agri-schemas"
                    },
                    {
                        "name":"InterMine",
                        "description":"InterMine integrates heterogenous data sources, making it easy to query and analyse data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"http:\/\/intermine.org\/"
                    }
                ],
                "ref_to_main_resources":[
                    "workflowhub",
                    "fairdom-seek",
                    "copo"
                ]
            }
        }
    },
    {
        "id":"md_content_uk_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/uk_resources.md",
        "file_name":"uk_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"ta Protection Act (2018) is the UKs implementation of the General Data Protection Regulation (GDPR) The Five Safes framework enabling data services to provide safe research access to data\nGoldacre Review into how the efficient and safe use of health data for research and analysis can benefit patients and the healthcare sector\nBuilding Trusted Research Environments; the paper covers principles, approaches and guidelines for data sharing and linkage practice within TREs, as well as examples of best practices.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"uk_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"United Kingdom",
                "country_code":"GB",
                "contributors":[
                    "Munazah Andrabi",
                    "Robert Andrews",
                    "Nicola Soranzo",
                    "Kellie Snow",
                    "Sara Morsy",
                    "Branka Franicevic",
                    "Emma Karoune",
                    "Saskia Lawson-Tovey",
                    "Graham Parton"
                ],
                "coordinators":[
                    "Robert Andrews",
                    "Munazah Andrabi"
                ],
                "national_resources":[
                    {
                        "name":"DMPonline",
                        "description":"DMPonline is a web-based tool that supports researchers to develop data management and sharing plans. It contains the latest funder templates and best practice guidelines to support users to create good quality DMPs.",
                        "how_to_access":null,
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmponline.dcc.ac.uk\/"
                    },
                    {
                        "name":"CyVerse UK",
                        "description":"The CyVerse Data Store is a cloud-based storage space, accessible via the CyVerse Discovery Environment (DE), a virtual bioinformatics lab workbench, and developer APIs such as the AGAVE API. In the DE, users can share datasets and tools to analyse data with as many or as few people as they wish.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/cyverseuk.org\/"
                    },
                    {
                        "name":"Jisc Research data management toolkit",
                        "description":"Guidance on the research data lifecycle that signposts resources from a wide range of organisations and websites.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/web.archive.org\/web\/20230530165420\/https:\/\/www.jisc.ac.uk\/guides\/rdm-toolkit"
                    },
                    {
                        "name":"Agrischema",
                        "description":"Linked data schemas for the fields of agriculture, food, agri-business, plant biology.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/github.com\/Rothamsted\/agri-schemas"
                    },
                    {
                        "name":"InterMine",
                        "description":"InterMine integrates heterogenous data sources, making it easy to query and analyse data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"http:\/\/intermine.org\/"
                    }
                ],
                "ref_to_main_resources":[
                    "workflowhub",
                    "fairdom-seek",
                    "copo"
                ]
            }
        }
    },
    {
        "id":"md_content_uk_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/uk_resources.md",
        "file_name":"uk_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"guidelines for data sharing and linkage practice within TREs, as well as examples of best practices. Domain-specific data infrastructures\n\nCLIMB-BIG-DATA project providing cloud infrastructure and storage for big data microbial bioinformatics\nDigital Curation Centre Organisation offering a range of services to assist UK institutions in digital curation and data management\nGenomics England: The Research Environment\nHealth Data Research Innovation Gateway Search engine\/portal to discover and access UK health-related datasets, and any associated health data resources such as tools, projects, and publications\nNERC EDS (Natural Environment Research Council Environmental Data Service) providing data stewardship services for environmental data\nNHS England: Trusted Research Environment service\nNHS Research Scotland: Scotland Data Safe Haven programme\nSAIL Databank: UK Secure eResearch Platform in Wales\nUK Data Service Secure Lab providing controlled access to sensitive and confidential data\nThe Safepod Network providing approved researchers with access to sensitive data\nUK Biobank large-scale biomedical database and research resource\nUK Data Archive collection of social, economic and population data\nClinical Practice Research Datalink CPRD supports public health and clinical studies in the UK, by maintaining a collection of anonymised health datasets representing the UK population.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"uk_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"United Kingdom",
                "country_code":"GB",
                "contributors":[
                    "Munazah Andrabi",
                    "Robert Andrews",
                    "Nicola Soranzo",
                    "Kellie Snow",
                    "Sara Morsy",
                    "Branka Franicevic",
                    "Emma Karoune",
                    "Saskia Lawson-Tovey",
                    "Graham Parton"
                ],
                "coordinators":[
                    "Robert Andrews",
                    "Munazah Andrabi"
                ],
                "national_resources":[
                    {
                        "name":"DMPonline",
                        "description":"DMPonline is a web-based tool that supports researchers to develop data management and sharing plans. It contains the latest funder templates and best practice guidelines to support users to create good quality DMPs.",
                        "how_to_access":null,
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmponline.dcc.ac.uk\/"
                    },
                    {
                        "name":"CyVerse UK",
                        "description":"The CyVerse Data Store is a cloud-based storage space, accessible via the CyVerse Discovery Environment (DE), a virtual bioinformatics lab workbench, and developer APIs such as the AGAVE API. In the DE, users can share datasets and tools to analyse data with as many or as few people as they wish.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/cyverseuk.org\/"
                    },
                    {
                        "name":"Jisc Research data management toolkit",
                        "description":"Guidance on the research data lifecycle that signposts resources from a wide range of organisations and websites.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/web.archive.org\/web\/20230530165420\/https:\/\/www.jisc.ac.uk\/guides\/rdm-toolkit"
                    },
                    {
                        "name":"Agrischema",
                        "description":"Linked data schemas for the fields of agriculture, food, agri-business, plant biology.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"https:\/\/github.com\/Rothamsted\/agri-schemas"
                    },
                    {
                        "name":"InterMine",
                        "description":"InterMine integrates heterogenous data sources, making it easy to query and analyse data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "your_role":[
                                "data_steward",
                                "researcher"
                            ],
                            "your_tasks":[
                                "metadata"
                            ]
                        },
                        "url":"http:\/\/intermine.org\/"
                    }
                ],
                "ref_to_main_resources":[
                    "workflowhub",
                    "fairdom-seek",
                    "copo"
                ]
            }
        }
    },
    {
        "id":"md_fm_fr_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/fr_resources.md",
        "file_name":"fr_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Olivier Collin\ncoordinators: []\ncountry_code: FR\nnational_resources:\n- description: Online questionnaire for the development of data management plans -\n    repository of DMPs. how_to_access: null\n  instance_of: dmproadmap\n  name: DMP OPIDoR\n  related_pages:\n    tool_assembly:\n    - ifb\n    your_role:\n    - researcher\n    - data_steward\n    your_tasks:\n    - dmp\n  url: https:\/\/dmp.opidor.fr\nref_to_main_resources:\n- phis\n- faidare\ntitle: France",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"fr_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_fr_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/fr_resources.md",
        "file_name":"fr_resources.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"Introduction\nThis is an overview of research data management resources in France. These resources are accessible for researchers in France and to their collaborators. The french governement has set up the \"Committee for Open Science\" that mobilises education and research stakeholders to support the implementation of National Open Science Policy. The second national plan for open science has been released in 2021. Funders\nExamples of funders with Data Management Policies:\n\nANR (Agence Nationale de la Recherche)\nCNRS\nInserm\nINRAE\nCEA\nIRD\n\nRegulations\nIn December 2021 the government passed a law about scientific integrity that includes many aspects of open science and research data management. In 2016, a law for a \"digital republic\" was passed to promote the circulation of data and knowledge through the opening of public data, the creation of a public data service and free access to public research documents.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fr_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"France",
                "country_code":"FR",
                "contributors":[
                    "Olivier Collin"
                ],
                "coordinators":[

                ],
                "ref_to_main_resources":[
                    "phis",
                    "faidare"
                ],
                "national_resources":[
                    {
                        "name":"DMP OPIDoR",
                        "description":"Online questionnaire for the development of data management plans - repository of DMPs.",
                        "how_to_access":null,
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "tool_assembly":[
                                "ifb"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.opidor.fr"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_fr_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/fr_resources.md",
        "file_name":"fr_resources.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":" of public data, the creation of a public data service and free access to public research documents. Domain-specific infrastructures\/resources\n\n\nRDA-France is a subsection of RDA dedicated to the activities, news and events of the RDA French Node. Recherche Data Gouv is a national federated research data platform that will be available in the first quarter of 2022. HAL is an open archive where authors can deposit scholarly documents from all academic fields. Software Heritage goal is to collect and preserve software in source code form bu harvesting public code repositories. DORANum is a training resource for best practices in data management and sharing.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"fr_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"France",
                "country_code":"FR",
                "contributors":[
                    "Olivier Collin"
                ],
                "coordinators":[

                ],
                "ref_to_main_resources":[
                    "phis",
                    "faidare"
                ],
                "national_resources":[
                    {
                        "name":"DMP OPIDoR",
                        "description":"Online questionnaire for the development of data management plans - repository of DMPs.",
                        "how_to_access":null,
                        "instance_of":"dmproadmap",
                        "related_pages":{
                            "tool_assembly":[
                                "ifb"
                            ],
                            "your_role":[
                                "researcher",
                                "data_steward"
                            ],
                            "your_tasks":[
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/dmp.opidor.fr"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_cz_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/cz_resources.md",
        "file_name":"cz_resources.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"contributors:\n- Karel Berka\n- Marek Suchnek\ncoordinators:\n- Karel Berka\ncountry_code: CZ\nnational_resources:\n- description: Galaxy MetaCentrum is a Galaxy instance managed by the Czech ELIXIR\n    node and [e-INFRA](https:\/\/www.e-infra.cz\/en). It provides extra support for [RepeatExplorer](https:\/\/repeatexplorer-elixir.cerit-sc.cz\/)\n    tool for plant genomic analysis. how_to_access: null\n  instance_of: galaxy\n  name: Galaxy MetaCentrum\n  registry:\n    biotools: repeat_explorer\n  related_pages:\n    tool_assembly: []\n    your_domain:\n    - plant\n    your_role:\n    - researcher\n    your_tasks:\n    - data_analysis\n  url: https:\/\/galaxy.metacentrum.cz\/\n- description: e-INFRA CZ provides integrated high-performance research computing\/data\n    storage environment, providing world-class services to government, industry, and\n    researchers. It also cooperates with European Open Science Cloud (EOSC) implementation\n    in the Czech Republic.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"cz_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_cz_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/cz_resources.md",
        "file_name":"cz_resources.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"It also cooperates with European Open Science Cloud (EOSC) implementation\n    in the Czech Republic. how_to_access: null\n  name: e-INFRA CZ (Supercomputing and Data Services)\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - data_steward\n    - research_software_engineer\n    your_tasks:\n    - data_analysis\n    - storage\n  url: https:\/\/www.e-infra.cz\/en\n- description: CESNET-hosted ownCloud is a 100 GB cloud storage freely available for\n    Czech scientists to manage their data from any research projects. how_to_access: To use the CESNET-hosted ownCloud, you have to be an employee or\n    a student of a Czech academic organization. For technical reasons, you have to\n    have an account in [eduID.cz](https:\/\/eduid.cz). instance_of: owncloud\n  name: ownCloud@CESNET\n  related_pages:\n    tool_assembly: []\n    your_domain:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"cz_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_cz_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/cz_resources.md",
        "file_name":"cz_resources.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"nstance_of: owncloud\n  name: ownCloud@CESNET\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - researcher\n    - research_software_engineer\n    your_tasks:\n    - storage\n    - data_transfer\n    - data_organisation\n  url: https:\/\/du.cesnet.cz\/en\/navody\/owncloud\/start\/\n- description: National Repository (NR) is a service provided to the scientific and\n    research communities in the Czech Republic to store their generated research data\n    together with persistent DOI identifier. NR service is currently under the pilot\n    program. how_to_access: To use National Repository, you have to be an employee or a student\n    of a Czech academic organization. For technical reasons, you have to have an account\n    in [eduID.cz](https:\/\/eduid.cz) and if you want to upload. instance_of: null\n  name: Czech National Repository\n  related_pages:\n    tool_assembly:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"cz_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_cz_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/cz_resources.md",
        "file_name":"cz_resources.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":"t to upload. instance_of: null\n  name: Czech National Repository\n  related_pages:\n    tool_assembly: []\n    your_domain: []\n    your_role:\n    - researcher\n    - data_steward\n    - research_software_engineer\n    your_tasks:\n    - storage\n    - existing_data\n    - identifiers\n    - dmp\n  url: https:\/\/data.narodni-repozitar.cz\/\nref_to_main_resources:\n- galaxy\n- data-stewardship-wizard\nrelated_pages:\n  tool_assembly: []\ntitle: Czech Republic\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/content_providers\/elixir-the-czech-republic-node\n- name: ELIXIR-CZ YouTube\n  registry: YouTube\n  url: https:\/\/www.youtube.com\/channel\/UCt0SKet24szBGjN-V1d4EKw\n- name: ELIXIR-CZ GitHub\n  registry: GitHub\n  url: https:\/\/github.com\/ELIXIR-CZ\n- name: ELIXIR-CZ Zenodo\n  registry: Zenodo\n  url: https:\/\/zenodo.org\/communities\/elixir-cz\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"cz_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_cz_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/cz_resources.md",
        "file_name":"cz_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"Introduction\nAn overview of data management services provided by the ELIXIR Czech Republic can be found on the ELIXIR Czech Republic website. Details about national guidelines, tools and services can be found as RDM services. Funders\nIn line with European funders, Czech research funders are asking for Data Management Plans (DMP) and support Open Science. Consult the funders' webpage and their policy about data management and Open Science. * Czech Science Foundation (GAR)\n  * GAR Research policy\n* Technology Agency of the Czech Republic (TAR)\n* TAR Open Access policy\n* Special Research Fund (BOF) from Universities\n*  Programme Johannes Amos Comenius (OP JAK)\n* EU-Team and\/or Research support team from Universities\n  * Charles University Open Science Support Centre\n  * Masaryk University Open Science\n  * Palack University Open Science\n* National Information Centre for European Research (NICER), Technology Centre Prague (for help with navigating the EU funding system)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cz_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Czech Republic",
                "country_code":"CZ",
                "contributors":[
                    "Karel Berka",
                    "Marek Suchnek"
                ],
                "coordinators":[
                    "Karel Berka"
                ],
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/content_providers\/elixir-the-czech-republic-node"
                    },
                    {
                        "name":"ELIXIR-CZ YouTube",
                        "registry":"YouTube",
                        "url":"https:\/\/www.youtube.com\/channel\/UCt0SKet24szBGjN-V1d4EKw"
                    },
                    {
                        "name":"ELIXIR-CZ GitHub",
                        "registry":"GitHub",
                        "url":"https:\/\/github.com\/ELIXIR-CZ"
                    },
                    {
                        "name":"ELIXIR-CZ Zenodo",
                        "registry":"Zenodo",
                        "url":"https:\/\/zenodo.org\/communities\/elixir-cz\/"
                    }
                ],
                "ref_to_main_resources":[
                    "galaxy",
                    "data-stewardship-wizard"
                ],
                "national_resources":[
                    {
                        "name":"Galaxy MetaCentrum",
                        "description":"Galaxy MetaCentrum is a Galaxy instance managed by the Czech ELIXIR node and [e-INFRA](https:\/\/www.e-infra.cz\/en). It provides extra support for [RepeatExplorer](https:\/\/repeatexplorer-elixir.cerit-sc.cz\/) tool for plant genomic analysis.",
                        "how_to_access":null,
                        "instance_of":"galaxy",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[
                                "plant"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis"
                            ]
                        },
                        "url":"https:\/\/galaxy.metacentrum.cz\/",
                        "registry":{
                            "biotools":"repeat_explorer"
                        }
                    },
                    {
                        "name":"e-INFRA CZ (Supercomputing and Data Services)",
                        "description":"e-INFRA CZ provides integrated high-performance research computing\/data storage environment, providing world-class services to government, industry, and researchers. It also cooperates with European Open Science Cloud (EOSC) implementation in the Czech Republic.",
                        "how_to_access":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "data_steward",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.e-infra.cz\/en"
                    },
                    {
                        "name":"ownCloud@CESNET",
                        "description":"CESNET-hosted ownCloud is a 100 GB cloud storage freely available for Czech scientists to manage their data from any research projects.",
                        "how_to_access":"To use the CESNET-hosted ownCloud, you have to be an employee or a student of a Czech academic organization. For technical reasons, you have to have an account in [eduID.cz](https:\/\/eduid.cz).",
                        "instance_of":"owncloud",
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "researcher",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "storage",
                                "data_transfer",
                                "data_organisation"
                            ]
                        },
                        "url":"https:\/\/du.cesnet.cz\/en\/navody\/owncloud\/start\/"
                    },
                    {
                        "name":"Czech National Repository",
                        "description":"National Repository (NR) is a service provided to the scientific and research communities in the Czech Republic to store their generated research data together with persistent DOI identifier. NR service is currently under the pilot program.",
                        "how_to_access":"To use National Repository, you have to be an employee or a student of a Czech academic organization. For technical reasons, you have to have an account in [eduID.cz](https:\/\/eduid.cz) and if you want to upload.",
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":[

                            ],
                            "your_domain":[

                            ],
                            "your_role":[
                                "researcher",
                                "data_steward",
                                "research_software_engineer"
                            ],
                            "your_tasks":[
                                "storage",
                                "existing_data",
                                "identifiers",
                                "dmp"
                            ]
                        },
                        "url":"https:\/\/data.narodni-repozitar.cz\/"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_cy_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/cy_resources.md",
        "file_name":"cy_resources.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Anastasis Oulas\n- Nicolas Kylilis\n- Nestoras Karathanasis\n- George Spyrou\n- Vasilis Promponas\ncoordinators:\n- Anastasis Oulas\ncountry_code: CY\nnational_resources: null\nref_to_main_resources: null\nrelated_pages: null\ntitle: Cyprus\ntraining: null",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"cy_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_cy_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/cy_resources.md",
        "file_name":"cy_resources.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"Introduction\nThis page provides a general overview of national resources and initiatives on research data management (RDM) in Cyprus\nFunders\nThe Research and Innovation Foundation (RIF) is the national authority in charge of supporting and promoting research, technological development and innovation in Cyprus. Regulations\nThe Cyprus National Policy of the Republic of Cyprus for Open Science Practices (PDF document) was recently revised to include research data management and planning. The Cyprus National Bioethics Committee (document EEBK3). All medical records and biological material are kept under secure conditions at a specially prepared \nBiobank suite with absolute confidentiality and protection of sensitive data of personal character, \nin compliance with the European General Data Protection Regulation (GDPR).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cy_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Cyprus",
                "country_code":"CY",
                "contributors":[
                    "Anastasis Oulas",
                    "Nicolas Kylilis",
                    "Nestoras Karathanasis",
                    "George Spyrou",
                    "Vasilis Promponas"
                ],
                "coordinators":[
                    "Anastasis Oulas"
                ],
                "related_pages":null,
                "training":null,
                "ref_to_main_resources":null,
                "national_resources":null
            }
        }
    },
    {
        "id":"md_content_cy_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/cy_resources.md",
        "file_name":"cy_resources.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"a of personal character, \nin compliance with the European General Data Protection Regulation (GDPR). Domain-specific infrastructures or resources\nThe Cyprus National Initiatives for Open Science in Europe  NI4OS Europe, aims to be a core contributor to the European Open Science Cloud (EOSC) service portfolio, commit to EOSC governance and ensure inclusiveness on the European level for enabling global Open Science\nThe Cyprus Institite of Neurology and Genetics (CING) acted as a hub for COVID-19 data during the pandemic. CING was involved in biosample collection and high-throughput data analysis of samples using Next Generation Sequencing (NGS). The development of the Cyprus Biobank came with the success in funding by the European Commission in the framework of \nprogram H2020-WIDESPREAD-01-2018-2019: Teaming Phase 2, for 15mi for 7 years. The project is entitled: Biobanking and the Cyprus Human Genome Project.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cy_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Cyprus",
                "country_code":"CY",
                "contributors":[
                    "Anastasis Oulas",
                    "Nicolas Kylilis",
                    "Nestoras Karathanasis",
                    "George Spyrou",
                    "Vasilis Promponas"
                ],
                "coordinators":[
                    "Anastasis Oulas"
                ],
                "related_pages":null,
                "training":null,
                "ref_to_main_resources":null,
                "national_resources":null
            }
        }
    },
    {
        "id":"md_content_cy_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/cy_resources.md",
        "file_name":"cy_resources.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"e 2, for 15mi for 7 years. The project is entitled: Biobanking and the Cyprus Human Genome Project. The project \nis supplemented by another 15mi by the Government of Cyprus and another 8mi by the \nUniversity of Cyprus for a duration of 15 years, October 1, 2019 to September 30, 2034. It aims to upgrade the current infrastructure into a Center of Excellence in Biobanking and Biomedical Research.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"cy_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Cyprus",
                "country_code":"CY",
                "contributors":[
                    "Anastasis Oulas",
                    "Nicolas Kylilis",
                    "Nestoras Karathanasis",
                    "George Spyrou",
                    "Vasilis Promponas"
                ],
                "coordinators":[
                    "Anastasis Oulas"
                ],
                "related_pages":null,
                "training":null,
                "ref_to_main_resources":null,
                "national_resources":null
            }
        }
    },
    {
        "id":"md_fm_nl_resources_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":0,
        "total_chunks":7,
        "content":"contributors:\n- Mijke Jetten\n- Celia van Gelder\n- Rob Hooft\ncoordinators:\n- Mijke Jetten\ncountry_code: NL\nnational_resources:\n- description: Health-RI provides a set of tools and services available to the biomedical\n    research community. how_to_access: null\n  instance_of: null\n  name: Health-RI Service Catalogue\n  related_pages:\n    tool_assembly: null your_domain:\n    - human_data\n    your_role:\n    - researcher\n    your_tasks:\n    - data_analysis\n    - existing_data\n    - storage\n  url: https:\/\/www.health-ri.nl\/services\/health-ri-service-catalogue\n- description: Biobanking Netherlands makes biosamples, images and data findable,\n    accessible and usable for health research. how_to_access: null\n  instance_of: null\n  name: BBMRI catalogue\n  related_pages:\n    tool_assembly: null",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"nl_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_nl_resources_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":1,
        "total_chunks":7,
        "content":"to_access: null\n  instance_of: null\n  name: BBMRI catalogue\n  related_pages:\n    tool_assembly: null your_domain:\n    - human_data\n    your_role:\n    - researcher\n    your_tasks:\n    - data_analysis\n    - existing_data\n    - storage\n  url: https:\/\/www.bbmri.nl\n- description: cBioPortal provides a web-based resource for researchers to explore,\n    visualize, analyze, and share multidimensional cancer genomic datasets, as well\n    as other studies involving multidimensional genomic data. how_to_access: null\n  instance_of: null\n  name: cBioPortal for Cancer Genomics\n  related_pages:\n    tool_assembly: null your_domain:\n    - human_data\n    your_role:\n    - researcher\n    your_tasks:\n    - data_analysis\n    - existing_data\n    - storage\n  url: https:\/\/www.cbioportal.org\n- description: The national statistical office, Statistics Netherlands (CBS), provides\n    reliable statistical information and data in the life sciences and health domain.\n  how_to_access: null\n  instance_of: null\n  name:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"nl_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_nl_resources_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":2,
        "total_chunks":7,
        "content":"n and data in the life sciences and health domain.\n  how_to_access: null\n  instance_of: null\n  name: CBS, Statistics Netherlands\n  related_pages:\n    tool_assembly: null\n    your_domain:\n    - human_data\n    your_role:\n    - researcher\n    your_tasks:\n    - existing_data\n  url: https:\/\/www.cbs.nl\/en-gb\/our-services\/customised-services-microdata\/microdata-conducting-your-own-research\/microdata-catalogue\n- description: More than 130 Technology Hotels offer access to high-end technology\n    and expertise in the field of bioimaging, bioinformatics, genomics, medical imaging,\n    metabolomics, phenotyping, proteomics, structural biology, and\/or systems biology. how_to_access: null\n  instance_of: null\n  name: Technology Hotels\n  related_pages:\n    tool_assembly: null",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"nl_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_nl_resources_md_3",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":3,
        "total_chunks":7,
        "content":"_access: null\n  instance_of: null\n  name: Technology Hotels\n  related_pages:\n    tool_assembly: null your_domain:\n    - human_data\n    - bioimaging_data\n    - proteomics\n    your_role:\n    - researcher\n    your_tasks:\n    - compliance\n  url: https:\/\/www.dtls.nl\/technology-hotels\/list\n- description: To support investigators and health care professionals with tools and\n    services in their search for ways to overcome the pandemic and itshealth consequences. how_to_access: null\n  instance_of: null\n  name: Dutch COVID-19 Data Support Programme\n  related_pages:\n    tool_assembly: null",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"nl_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_nl_resources_md_4",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":4,
        "total_chunks":7,
        "content":"ance_of: null\n  name: Dutch COVID-19 Data Support Programme\n  related_pages:\n    tool_assembly: null your_domain:\n    - human_data\n    your_role:\n    - researcher\n    your_tasks:\n    - existing_data\n  url: https:\/\/www.health-ri.nl\/initiatives\/dutch-covid-19-data-support-programme\n- description: The Dutch National Institute for Public Health and the Environment\n    (RIVM), together with other organisations, provides numbers and explanation on\n    relevant topics, to prevent duplication of data collection.\n  how_to_access: null\n  instance_of: null\n  name: RIVM Health and Healthcare Data\n  related_pages:\n    tool_assembly: null\n    your_domain:\n    - human_data\n    your_role:\n    - researcher\n    your_tasks:\n    - existing_data\n  url: https:\/\/www.vzinfo.nl\n- description: Guidelines on data stewardship and practical toolbox for researchers\n    at Dutch University Medical Centres (UMCs).",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"nl_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_nl_resources_md_5",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":5,
        "total_chunks":7,
        "content":"ta stewardship and practical toolbox for researchers\n    at Dutch University Medical Centres (UMCs). how_to_access: null\n  instance_of: null\n  name: Handbook for Adequate Natural Data Stewardship\n  related_pages:\n    tool_assembly: null\n    your_domain:\n    - human_data\n    your_role:\n    - researcher\n    your_tasks:\n    - dmp\n    - compliance\n  url: https:\/\/www.health-ri.nl\/services\/hands\n- description: Shared reference tool for knowledge on data management. how_to_access: null\n  instance_of: null\n  name: 23 Things for Research Data Management tool\n  related_pages:\n    tool_assembly: null your_domain:\n    - human_data\n    your_role: null\n    your_tasks:\n    - dmp\n    - compliance\n  url: https:\/\/23things.sites.uu.nl\/\n- description: Online tool which helps researchers and data managers assess how much\n    they know about the requirements for making datasets findable, accessible, interoperable,\n    and reusable (FAIR) before uploading them into a data repository.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"nl_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_nl_resources_md_6",
        "source":"markdown_frontmatter",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":6,
        "total_chunks":7,
        "content":"le, accessible, interoperable,\n    and reusable (FAIR) before uploading them into a data repository. how_to_access: null\n  instance_of: null\n  name: FAIR-Aware\n  related_pages:\n    tool_assembly: null\n    your_domain: null\n    your_role:\n    - researcher\n    your_tasks:\n    - dmp\n    - compliance\n    - data_publication\n  url: https:\/\/fairaware.dans.knaw.nl\nref_to_main_resources:\n- fairsharing\n- molgenis\n- xnat\n- data-stewardship-wizard\ntitle: Netherlands\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  registry_url: https:\/\/tess.elixir-europe.org\n  url: https:\/\/tess.elixir-europe.org\/nodes\/netherlands\n- name: ELIXIR Netherlands community in Zenodo\n  registry: Zenodo\n  registry_url: https:\/\/zenodo.org\n  url: https:\/\/zenodo.org\/communities\/dtl\/\n- name: Professionalising data stewardship. Dutch projects in Zenodo\n  registry: Zenodo\n  registry_url: https:\/\/zenodo.org\n  url: https:\/\/zenodo.org\/communities\/nl-ds-pd-ls\/",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"nl_resources.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_nl_resources_md_0",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"Introduction\nThis is an overview of research data management resources in the Netherlands, relevant for researchers in the Netherlands and to their collaborators. The ELIXIR Netherlands website provides information on the organisation of and resources for ELIXIR Netherlands partners. The Dutch ELIXIR Node is hosted by the Dutch Techcentre for Life Sciences (DTL), a public-private partnership of more than 50 life science institutions, and focuses on data stewardship capacity building, services and infrastructure to support FAIR implementation for the Dutch life science research. Funders\nNational funders NWO and ZonMw consider responsible research data management an essential component of good research practice. They promote FAIR data stewardship - among others via mandatory data management plans, the requirement to deposit and share (meta)data, and facilitating researchers in creating FAIR data, with help of the GO FAIR Foundation, Health-RI and DTL.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nl_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Netherlands",
                "country_code":"NL",
                "contributors":[
                    "Mijke Jetten",
                    "Celia van Gelder",
                    "Rob Hooft"
                ],
                "coordinators":[
                    "Mijke Jetten"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/netherlands"
                    },
                    {
                        "name":"ELIXIR Netherlands community in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/dtl\/"
                    },
                    {
                        "name":"Professionalising data stewardship. Dutch projects in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/nl-ds-pd-ls\/"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Health-RI Service Catalogue",
                        "description":"Health-RI provides a set of tools and services available to the biomedical research community.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/health-ri-service-catalogue"
                    },
                    {
                        "name":"BBMRI catalogue",
                        "description":"Biobanking Netherlands makes biosamples, images and data findable, accessible and usable for health research.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.bbmri.nl"
                    },
                    {
                        "name":"cBioPortal for Cancer Genomics",
                        "description":"cBioPortal provides a web-based resource for researchers to explore, visualize, analyze, and share multidimensional cancer genomic datasets, as well as other studies involving multidimensional genomic data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.cbioportal.org"
                    },
                    {
                        "name":"CBS, Statistics Netherlands",
                        "description":"The national statistical office, Statistics Netherlands (CBS), provides reliable statistical information and data in the life sciences and health domain.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.cbs.nl\/en-gb\/our-services\/customised-services-microdata\/microdata-conducting-your-own-research\/microdata-catalogue"
                    },
                    {
                        "name":"Technology Hotels",
                        "description":"More than 130 Technology Hotels offer access to high-end technology and expertise in the field of bioimaging, bioinformatics, genomics, medical imaging, metabolomics, phenotyping, proteomics, structural biology, and\/or systems biology.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data",
                                "bioimaging_data",
                                "proteomics"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.dtls.nl\/technology-hotels\/list"
                    },
                    {
                        "name":"Dutch COVID-19 Data Support Programme",
                        "description":"To support investigators and health care professionals with tools and services in their search for ways to overcome the pandemic and itshealth consequences.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/initiatives\/dutch-covid-19-data-support-programme"
                    },
                    {
                        "name":"RIVM Health and Healthcare Data",
                        "description":"The Dutch National Institute for Public Health and the Environment (RIVM), together with other organisations, provides numbers and explanation on relevant topics, to prevent duplication of data collection.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.vzinfo.nl"
                    },
                    {
                        "name":"Handbook for Adequate Natural Data Stewardship",
                        "description":"Guidelines on data stewardship and practical toolbox for researchers at Dutch University Medical Centres (UMCs).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/hands"
                    },
                    {
                        "name":"23 Things for Research Data Management tool",
                        "description":"Shared reference tool for knowledge on data management.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":null,
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/23things.sites.uu.nl\/"
                    },
                    {
                        "name":"FAIR-Aware",
                        "description":"Online tool which helps researchers and data managers assess how much they know about the requirements for making datasets findable, accessible, interoperable, and reusable (FAIR) before uploading them into a data repository.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":null,
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fairaware.dans.knaw.nl"
                    }
                ],
                "ref_to_main_resources":[
                    "fairsharing",
                    "molgenis",
                    "xnat",
                    "data-stewardship-wizard"
                ]
            }
        }
    },
    {
        "id":"md_content_nl_resources_md_1",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"ilitating researchers in creating FAIR data, with help of the GO FAIR Foundation, Health-RI and DTL. For information on the requirements for FAIR data stewardship, visit the funders webpages and consult their particular policies on data management and Open Science. National initiatives\nTogether with Health-RI, DTL is leading the national roadmap for the Thematic Digital Competence Center (TDCC) for Life Science & Health (LSH), funded by NWO. The TDCC LSH network was established in the spring of 2022, and is contributing to strengthening and harmonising the digital practises among stakeholders in the broad Dutch research domains of life sciences and biomedical\/health sciences. The TDCC-LSH is collaborating cross-domain with Social Sciences and Humanities (TDCC-SSH) and Natural and Engineering Sciences (TDCC-NES).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nl_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Netherlands",
                "country_code":"NL",
                "contributors":[
                    "Mijke Jetten",
                    "Celia van Gelder",
                    "Rob Hooft"
                ],
                "coordinators":[
                    "Mijke Jetten"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/netherlands"
                    },
                    {
                        "name":"ELIXIR Netherlands community in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/dtl\/"
                    },
                    {
                        "name":"Professionalising data stewardship. Dutch projects in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/nl-ds-pd-ls\/"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Health-RI Service Catalogue",
                        "description":"Health-RI provides a set of tools and services available to the biomedical research community.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/health-ri-service-catalogue"
                    },
                    {
                        "name":"BBMRI catalogue",
                        "description":"Biobanking Netherlands makes biosamples, images and data findable, accessible and usable for health research.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.bbmri.nl"
                    },
                    {
                        "name":"cBioPortal for Cancer Genomics",
                        "description":"cBioPortal provides a web-based resource for researchers to explore, visualize, analyze, and share multidimensional cancer genomic datasets, as well as other studies involving multidimensional genomic data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.cbioportal.org"
                    },
                    {
                        "name":"CBS, Statistics Netherlands",
                        "description":"The national statistical office, Statistics Netherlands (CBS), provides reliable statistical information and data in the life sciences and health domain.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.cbs.nl\/en-gb\/our-services\/customised-services-microdata\/microdata-conducting-your-own-research\/microdata-catalogue"
                    },
                    {
                        "name":"Technology Hotels",
                        "description":"More than 130 Technology Hotels offer access to high-end technology and expertise in the field of bioimaging, bioinformatics, genomics, medical imaging, metabolomics, phenotyping, proteomics, structural biology, and\/or systems biology.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data",
                                "bioimaging_data",
                                "proteomics"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.dtls.nl\/technology-hotels\/list"
                    },
                    {
                        "name":"Dutch COVID-19 Data Support Programme",
                        "description":"To support investigators and health care professionals with tools and services in their search for ways to overcome the pandemic and itshealth consequences.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/initiatives\/dutch-covid-19-data-support-programme"
                    },
                    {
                        "name":"RIVM Health and Healthcare Data",
                        "description":"The Dutch National Institute for Public Health and the Environment (RIVM), together with other organisations, provides numbers and explanation on relevant topics, to prevent duplication of data collection.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.vzinfo.nl"
                    },
                    {
                        "name":"Handbook for Adequate Natural Data Stewardship",
                        "description":"Guidelines on data stewardship and practical toolbox for researchers at Dutch University Medical Centres (UMCs).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/hands"
                    },
                    {
                        "name":"23 Things for Research Data Management tool",
                        "description":"Shared reference tool for knowledge on data management.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":null,
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/23things.sites.uu.nl\/"
                    },
                    {
                        "name":"FAIR-Aware",
                        "description":"Online tool which helps researchers and data managers assess how much they know about the requirements for making datasets findable, accessible, interoperable, and reusable (FAIR) before uploading them into a data repository.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":null,
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fairaware.dans.knaw.nl"
                    }
                ],
                "ref_to_main_resources":[
                    "fairsharing",
                    "molgenis",
                    "xnat",
                    "data-stewardship-wizard"
                ]
            }
        }
    },
    {
        "id":"md_content_nl_resources_md_2",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":"main with Social Sciences and Humanities (TDCC-SSH) and Natural and Engineering Sciences (TDCC-NES). Moreover, DTL also coordinates the National Programme Open Science (NPOS) FAIR Data Programme Line, and has delivered the reports Towards FAIR data steward as profession for the lifesciences and Professionalising data stewardship in the Netherlands, including the NPOS\/ELIXIR Data Stewardship Competency Framework. The following national services provide useful information and support:\n*",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nl_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Netherlands",
                "country_code":"NL",
                "contributors":[
                    "Mijke Jetten",
                    "Celia van Gelder",
                    "Rob Hooft"
                ],
                "coordinators":[
                    "Mijke Jetten"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/netherlands"
                    },
                    {
                        "name":"ELIXIR Netherlands community in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/dtl\/"
                    },
                    {
                        "name":"Professionalising data stewardship. Dutch projects in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/nl-ds-pd-ls\/"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Health-RI Service Catalogue",
                        "description":"Health-RI provides a set of tools and services available to the biomedical research community.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/health-ri-service-catalogue"
                    },
                    {
                        "name":"BBMRI catalogue",
                        "description":"Biobanking Netherlands makes biosamples, images and data findable, accessible and usable for health research.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.bbmri.nl"
                    },
                    {
                        "name":"cBioPortal for Cancer Genomics",
                        "description":"cBioPortal provides a web-based resource for researchers to explore, visualize, analyze, and share multidimensional cancer genomic datasets, as well as other studies involving multidimensional genomic data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.cbioportal.org"
                    },
                    {
                        "name":"CBS, Statistics Netherlands",
                        "description":"The national statistical office, Statistics Netherlands (CBS), provides reliable statistical information and data in the life sciences and health domain.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.cbs.nl\/en-gb\/our-services\/customised-services-microdata\/microdata-conducting-your-own-research\/microdata-catalogue"
                    },
                    {
                        "name":"Technology Hotels",
                        "description":"More than 130 Technology Hotels offer access to high-end technology and expertise in the field of bioimaging, bioinformatics, genomics, medical imaging, metabolomics, phenotyping, proteomics, structural biology, and\/or systems biology.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data",
                                "bioimaging_data",
                                "proteomics"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.dtls.nl\/technology-hotels\/list"
                    },
                    {
                        "name":"Dutch COVID-19 Data Support Programme",
                        "description":"To support investigators and health care professionals with tools and services in their search for ways to overcome the pandemic and itshealth consequences.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/initiatives\/dutch-covid-19-data-support-programme"
                    },
                    {
                        "name":"RIVM Health and Healthcare Data",
                        "description":"The Dutch National Institute for Public Health and the Environment (RIVM), together with other organisations, provides numbers and explanation on relevant topics, to prevent duplication of data collection.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.vzinfo.nl"
                    },
                    {
                        "name":"Handbook for Adequate Natural Data Stewardship",
                        "description":"Guidelines on data stewardship and practical toolbox for researchers at Dutch University Medical Centres (UMCs).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/hands"
                    },
                    {
                        "name":"23 Things for Research Data Management tool",
                        "description":"Shared reference tool for knowledge on data management.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":null,
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/23things.sites.uu.nl\/"
                    },
                    {
                        "name":"FAIR-Aware",
                        "description":"Online tool which helps researchers and data managers assess how much they know about the requirements for making datasets findable, accessible, interoperable, and reusable (FAIR) before uploading them into a data repository.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":null,
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fairaware.dans.knaw.nl"
                    }
                ],
                "ref_to_main_resources":[
                    "fairsharing",
                    "molgenis",
                    "xnat",
                    "data-stewardship-wizard"
                ]
            }
        }
    },
    {
        "id":"md_content_nl_resources_md_3",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":"ship Competency Framework. The following national services provide useful information and support:\n* The National Coordination Point Research Data Management (LCRDM)\n* SURF, the collaborative organisation for IT in Dutch education and research\n* DANS, the Dutch national centre of expertise and repository for research data\n* 4TU.ResearchData, the Dutch national data repository for science, engineering and design \n* Netherlands eScience Center (NleSC), building and applying software to enhance the use of computing and digital technologies in academic research\n* Research Data Netherlands (RDNL), collaboration of SURF, 4TU.ResearchData, DANS and DTL to contribute to strengthening the National Programme Open Science, and helping create a FAIR research ecosystem across science fields, and its Essentials 4 Data Support Training \n* The DTL Data Stewards Interest Group (DSIG), the Dutch (and beyond) community hub for data stewardship that enables informal and inclusive knowledge and experience exchange\n* NL-RSE, the Dutch community of people writing and contributing to research software\n*",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nl_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Netherlands",
                "country_code":"NL",
                "contributors":[
                    "Mijke Jetten",
                    "Celia van Gelder",
                    "Rob Hooft"
                ],
                "coordinators":[
                    "Mijke Jetten"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/netherlands"
                    },
                    {
                        "name":"ELIXIR Netherlands community in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/dtl\/"
                    },
                    {
                        "name":"Professionalising data stewardship. Dutch projects in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/nl-ds-pd-ls\/"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Health-RI Service Catalogue",
                        "description":"Health-RI provides a set of tools and services available to the biomedical research community.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/health-ri-service-catalogue"
                    },
                    {
                        "name":"BBMRI catalogue",
                        "description":"Biobanking Netherlands makes biosamples, images and data findable, accessible and usable for health research.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.bbmri.nl"
                    },
                    {
                        "name":"cBioPortal for Cancer Genomics",
                        "description":"cBioPortal provides a web-based resource for researchers to explore, visualize, analyze, and share multidimensional cancer genomic datasets, as well as other studies involving multidimensional genomic data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.cbioportal.org"
                    },
                    {
                        "name":"CBS, Statistics Netherlands",
                        "description":"The national statistical office, Statistics Netherlands (CBS), provides reliable statistical information and data in the life sciences and health domain.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.cbs.nl\/en-gb\/our-services\/customised-services-microdata\/microdata-conducting-your-own-research\/microdata-catalogue"
                    },
                    {
                        "name":"Technology Hotels",
                        "description":"More than 130 Technology Hotels offer access to high-end technology and expertise in the field of bioimaging, bioinformatics, genomics, medical imaging, metabolomics, phenotyping, proteomics, structural biology, and\/or systems biology.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data",
                                "bioimaging_data",
                                "proteomics"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.dtls.nl\/technology-hotels\/list"
                    },
                    {
                        "name":"Dutch COVID-19 Data Support Programme",
                        "description":"To support investigators and health care professionals with tools and services in their search for ways to overcome the pandemic and itshealth consequences.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/initiatives\/dutch-covid-19-data-support-programme"
                    },
                    {
                        "name":"RIVM Health and Healthcare Data",
                        "description":"The Dutch National Institute for Public Health and the Environment (RIVM), together with other organisations, provides numbers and explanation on relevant topics, to prevent duplication of data collection.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.vzinfo.nl"
                    },
                    {
                        "name":"Handbook for Adequate Natural Data Stewardship",
                        "description":"Guidelines on data stewardship and practical toolbox for researchers at Dutch University Medical Centres (UMCs).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/hands"
                    },
                    {
                        "name":"23 Things for Research Data Management tool",
                        "description":"Shared reference tool for knowledge on data management.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":null,
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/23things.sites.uu.nl\/"
                    },
                    {
                        "name":"FAIR-Aware",
                        "description":"Online tool which helps researchers and data managers assess how much they know about the requirements for making datasets findable, accessible, interoperable, and reusable (FAIR) before uploading them into a data repository.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":null,
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fairaware.dans.knaw.nl"
                    }
                ],
                "ref_to_main_resources":[
                    "fairsharing",
                    "molgenis",
                    "xnat",
                    "data-stewardship-wizard"
                ]
            }
        }
    },
    {
        "id":"md_content_nl_resources_md_4",
        "source":"markdown_content",
        "file_path":"pages\/national_resources\/nl_resources.md",
        "file_name":"nl_resources.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"nce exchange\n* NL-RSE, the Dutch community of people writing and contributing to research software\n* The Dutch Open Science Communities (OSC), independent, bottom up local communities comprising members of various scientific disciplines and career stages, who want to learn more about Open Science\n* RDA-NL, the Dutch Research Data Alliance Node \nAssistance\n\nResearchers seeking practical assistance best check RDM in the Netherlands, which provides information on the various local universities and university medical centers support desks\nResearchers can contact the Health-RI service desk for practical guidelines, tools and services, or the ELSI servicedesk for ethical, legal and social issues\nThe X-omics helpdesk provides researchers assistance with X-omics research infrastructure",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"nl_resources.md",
            "language":"en",
            "frontmatter":{
                "title":"Netherlands",
                "country_code":"NL",
                "contributors":[
                    "Mijke Jetten",
                    "Celia van Gelder",
                    "Rob Hooft"
                ],
                "coordinators":[
                    "Mijke Jetten"
                ],
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/nodes\/netherlands"
                    },
                    {
                        "name":"ELIXIR Netherlands community in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/dtl\/"
                    },
                    {
                        "name":"Professionalising data stewardship. Dutch projects in Zenodo",
                        "registry":"Zenodo",
                        "registry_url":"https:\/\/zenodo.org",
                        "url":"https:\/\/zenodo.org\/communities\/nl-ds-pd-ls\/"
                    }
                ],
                "national_resources":[
                    {
                        "name":"Health-RI Service Catalogue",
                        "description":"Health-RI provides a set of tools and services available to the biomedical research community.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/health-ri-service-catalogue"
                    },
                    {
                        "name":"BBMRI catalogue",
                        "description":"Biobanking Netherlands makes biosamples, images and data findable, accessible and usable for health research.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.bbmri.nl"
                    },
                    {
                        "name":"cBioPortal for Cancer Genomics",
                        "description":"cBioPortal provides a web-based resource for researchers to explore, visualize, analyze, and share multidimensional cancer genomic datasets, as well as other studies involving multidimensional genomic data.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "data_analysis",
                                "existing_data",
                                "storage"
                            ]
                        },
                        "url":"https:\/\/www.cbioportal.org"
                    },
                    {
                        "name":"CBS, Statistics Netherlands",
                        "description":"The national statistical office, Statistics Netherlands (CBS), provides reliable statistical information and data in the life sciences and health domain.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.cbs.nl\/en-gb\/our-services\/customised-services-microdata\/microdata-conducting-your-own-research\/microdata-catalogue"
                    },
                    {
                        "name":"Technology Hotels",
                        "description":"More than 130 Technology Hotels offer access to high-end technology and expertise in the field of bioimaging, bioinformatics, genomics, medical imaging, metabolomics, phenotyping, proteomics, structural biology, and\/or systems biology.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data",
                                "bioimaging_data",
                                "proteomics"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.dtls.nl\/technology-hotels\/list"
                    },
                    {
                        "name":"Dutch COVID-19 Data Support Programme",
                        "description":"To support investigators and health care professionals with tools and services in their search for ways to overcome the pandemic and itshealth consequences.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/initiatives\/dutch-covid-19-data-support-programme"
                    },
                    {
                        "name":"RIVM Health and Healthcare Data",
                        "description":"The Dutch National Institute for Public Health and the Environment (RIVM), together with other organisations, provides numbers and explanation on relevant topics, to prevent duplication of data collection.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "existing_data"
                            ]
                        },
                        "url":"https:\/\/www.vzinfo.nl"
                    },
                    {
                        "name":"Handbook for Adequate Natural Data Stewardship",
                        "description":"Guidelines on data stewardship and practical toolbox for researchers at Dutch University Medical Centres (UMCs).",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/www.health-ri.nl\/services\/hands"
                    },
                    {
                        "name":"23 Things for Research Data Management tool",
                        "description":"Shared reference tool for knowledge on data management.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":[
                                "human_data"
                            ],
                            "your_role":null,
                            "your_tasks":[
                                "dmp",
                                "compliance"
                            ]
                        },
                        "url":"https:\/\/23things.sites.uu.nl\/"
                    },
                    {
                        "name":"FAIR-Aware",
                        "description":"Online tool which helps researchers and data managers assess how much they know about the requirements for making datasets findable, accessible, interoperable, and reusable (FAIR) before uploading them into a data repository.",
                        "how_to_access":null,
                        "instance_of":null,
                        "related_pages":{
                            "tool_assembly":null,
                            "your_domain":null,
                            "your_role":[
                                "researcher"
                            ],
                            "your_tasks":[
                                "dmp",
                                "compliance",
                                "data_publication"
                            ]
                        },
                        "url":"https:\/\/fairaware.dans.knaw.nl"
                    }
                ],
                "ref_to_main_resources":[
                    "fairsharing",
                    "molgenis",
                    "xnat",
                    "data-stewardship-wizard"
                ]
            }
        }
    },
    {
        "id":"md_fm_ethics_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Karel Berka\n- Erin Calhoun\n- Paulette Lieby\n- Anamika Chatterjee\n- Korbinian Bsl\ndescription: Working on aspects in the management of research data that can raise\n  ethical issues\npage_id: ethics\nrelated_pages:\n  tool_assembly:\n  - covid19_data_portal\n  - transmed\n  - tsd\n  - csc\ntitle: Ethical aspects\ntraining:\n- name: Learning material on ethics in RDM\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/materials?q=ethics",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"ethics.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_ethics_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":0,
        "total_chunks":14,
        "content":"Ethics refers to moral principles and norms that help us identify right from wrong within a particular context. Ethical issues\/concerns typically arise when these principles conflict. Navigating through such concerns often requires one to compare the benefits of an action with its potential harmful consequences. When it comes to research involving human participants, such ethical concerns may appear when accessing, using, or sharing data of a sensitive nature, for example health or personal data. Ethics, however, goes beyond the issue of compliance with legal obligations, and the collection and use of data. The Open Data Institute narrows ethics in the RDM context to:\n\nA branch of ethics that evaluates data practices with the potential to adversely impact on people and society  in data collection, sharing and use. Which aspects of RDM might raise ethical issues?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":1,
        "total_chunks":14,
        "content":"and society  in data collection, sharing and use. Which aspects of RDM might raise ethical issues? Description\nEthical issues refer to moral principles and standards that guide human conduct and define what is considered right or wrong within a particular context. Considerations\n\n\nThere are different aspects in the management of research data that can raise ethical issues. It is important to distinguish between ethical issues and legal behaviour. Ethical standards may vary across cultures, disciplines, and professional organisations. Researchers are expected to adhere to these ethical principles even if certain practices are not explicitly prohibited by law. Often these standards are collected in declarations and guidelines, which may be backed by laws. Legal behaviour, on the other hand, refers to compliance with applicable laws, regulations, and policies. Legal requirements provide a baseline level of conduct that researchers must meet to avoid legal sanctions. However, legal compliance does not necessarily guarantee ethical behaviour.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":2,
        "total_chunks":14,
        "content":"o avoid legal sanctions. However, legal compliance does not necessarily guarantee ethical behaviour. Some actions may be legally permissible but raise ethical concerns, while others may be ethically unquestionable but explicitly prohibited by specific legislation. Ethical issues arise most often in research on or involving humans affecting human dignity and autonomy. These issues are partly addressed by the General Data Protection Regulation (see also the RDMkit data protection page) There are additional considerations connected to health research. Under the viewpoint of RDM you should especially consider:\n\nFree and informed consent, the possibility of its withdrawal, its documentation, withdrawal (connected with data deletion) and its representation in a machine-actionable way (see also What information must be given individuals whose data is collected, the EU clinical trials regulation and respective national health research legislations)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":3,
        "total_chunks":14,
        "content":"s collected, the EU clinical trials regulation and respective national health research legislations) Balancing access to research data and privacy of research participants (see How much data can be collected, the EU clinical trials regulation and respective national health research legislations) Unintentional discrimination of research participants, such as different perception of symptom severity in different population groups\nFindings about participants that are outside of the original research question(s): see Purpose of data processing and Incidental findings Archives - BBMRI-ERIC\n\n\n\nOther ethical questions are arising from the impact of research outcomes, including data on the interest of communities or individuals\n\nFair management of intellectual property rights - also see",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":4,
        "total_chunks":14,
        "content":"e interest of communities or individuals\n\nFair management of intellectual property rights - also see e.g. Access and Benefit-sharing (ABS)\nPublication of research data that might impact the reputation of communities or individuals\nPublication of research data that might impact economical interests of  communities or individuals\nPublication of research data that might impact security of society, communities or individuals\n\n\n\nThere are also general research ethics considerations that are relevant in the context of research data, including:\n\nWhat are the reasons justifying the exclusion\/inclusion of research data in a particular context? Is the data source accurate and trustworthy? How can bias in practices of research data management be identified and minimised\/avoided? Assessment of models and algorithms used with respect to possible bias\nCan the research data be misinterpreted?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":5,
        "total_chunks":14,
        "content":"of models and algorithms used with respect to possible bias\nCan the research data be misinterpreted? Prevention of withholding of research data\nPrevention of manipulation and fraud of research data\nAssessment of who is excluded or included to data access and why\nHow can harm to other beings and the environment be identified and mitigated in a timely manner?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":6,
        "total_chunks":14,
        "content":"why\nHow can harm to other beings and the environment be identified and mitigated in a timely manner? Solutions\n\nAssess potential ethical implication through an ethics review\nYour local ethics committee can help you to review the ethical implications of the project or might guide you to more relevant bodies and resources\n\n\nIn order to address challenges when working with human data (see also the RDMkit page on human data)\nUsed standardised consent forms (see e.g. {% tool \"ga4gh-regulatory-and-ethics-toolkit\" %}) with clauses that can be represented in a machine actionable way using the {% tool \"data-use-ontology\" %} and {% tool \"informed-consent-ontology\" %})\nBefore you start collecting\/processing data, be transparent about these in the consent form and also about the cases when withdrawal is no longer possible due to anonymization, aggregation, or other data processing. Anticipate the possibility of consent\/data withdrawal and implement administrative and technical processes.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":7,
        "total_chunks":14,
        "content":"ate the possibility of consent\/data withdrawal and implement administrative and technical processes. Data should be anonymized whenever possible (this is a non-reversible process), pseudonymisation (this is a reversible process) enhances data protection in cases where this is not possible (see also Recommendations on shaping technology according to GDPR provisions and the RDMkit data protection page) Data analysis approaches that have potential to cause stigmatisation should be considered in advance and be discussed as part of an ethics review\nCreate processes for incidental findings before you start collecting data, include the way the participant wants you to deal with it in the consent form",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":8,
        "total_chunks":14,
        "content":"start collecting data, include the way the participant wants you to deal with it in the consent form In order to manage the impact of data collection and sharing:\nThe management of intellectual property rights connected with the data, if any, should be planned early on (RDMkit data management plan page), be part of collaboration\/consortium agreements, and make use of standard licensing terms\nThe Nagoya Protocol regulates access to genetic resources and conditions for transfer of genetic resources and traditional knowledge across counties. For implementations into national law please consult the ABS Clearing House (also see RDMkit compliance monitoring & measurement)  \nLaws & Regulations concerning biosecurity, data export control and national interests might be linked from the RDMkit national resources pages\nIn order to ensure conformity with ethical research principles, the following should also be considered for data management:\nFollow general research ethics laws and guidelines (see below)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":9,
        "total_chunks":14,
        "content":"so be considered for data management:\nFollow general research ethics laws and guidelines (see below) Minimise suffering of animals in research to the absolute minimum, following the guidelines and laws relevant to your location as a baseline. A sound documentation and management of research outputs is an essential cornerstone to reduce unnecessary repetitions of experiments. Consider the use of specialised LIMS systems to capture relevant metadata\nReflect on potential future implications of the outcome of research and data capture and sharing for society and environment ({% tool \"rri-toolkit\" %}, {% tool \"rri-self-reflection-tool\" %}) involving stakeholders of the research is an important measure in order to receive feedback. If data is presented to stakeholders, this should happen in an accessible format and might require pre-processing, visualisation and guidance. Transparency and reproducibility of the research project underpin the scientific rigour of the project and reduce unnecessary duplication of efforts.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":10,
        "total_chunks":14,
        "content":"project underpin the scientific rigour of the project and reduce unnecessary duplication of efforts. Good RDM following the FAIR principles is a cornerstone of these efforts. Continuous tracking of provenance from e.g. research subjects to samples to data and semantic annotation of processes (documentation and metadata) can enhance the trustworthiness and value of research findings. Automated sharing of research data after a specific period or milestones and deliverables in a project can be a good mechanism to enhance the openness of a project (data management coordination) How can I identify regulations, guidelines and laws connected to ethics in my research context? Considerations\n\nIn all cases, your institutions Data Protection Officer (DPO) is the person to refer to when considering ethical and legal aspects of data management. When looking for recommendations and regulations, it is best to start from the local, that is, starting what is applicable within your discipline, and nationally.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":11,
        "total_chunks":14,
        "content":"o start from the local, that is, starting what is applicable within your discipline, and nationally. Then (if applicable), EU policies, directives and regulations are to be explored, as well as global recommendations (for example, from the UNESCO). The solutions given below do not attempt to be exhaustive and highlight only the most relevant ones.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":12,
        "total_chunks":14,
        "content":"The solutions given below do not attempt to be exhaustive and highlight only the most relevant ones. Solutions\n\nUse domain and national pages in the RDMkit as a starting point\nFollow national legislation in terms of\nData protection\nConduct of health research, research on humans and animal studies\nFramework on research ethics\nBio and national security\n\n\nConsult national, regional, institutional Ethics Boards\nMake use of guiding principles, recommendations, guidelines, ethical standards and declarations from professional associations and\nWMA Declaration of Helsinki  Ethical Principles for Medical Research Involving Human Subjects \nFor animal research: the Three Rs principle \nFor data produced with Machine Learning (ML) techniques: the recommendations from UNESCO, and the DOME guidelines, a product of the ELIXIR ML focus group \n\n\nResources and Policies from research infrastructures\n{% tool \"bbmri-eric-s-elsi-knowledge-base\" %} and the BBMRI Helpdesk and Services\nELIXIR ELSI Policy ELIXIR Ethics Policy \n\n\nCheck existing EU policies, directives and regulations\nThe General Data Protection Regulation see also the RDMKit page on GDPR compliance.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_ethics_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/ethics.md",
        "file_name":"ethics.md",
        "chunk_index":13,
        "total_chunks":14,
        "content":" and regulations\nThe General Data Protection Regulation see also the RDMKit page on GDPR compliance. The European Clinical Trials Regulation\n\n\n\nFurther materials\n\nBasic ethical principles are compliant with relevant international regulations:\nUniversal Declaration of Human Rights, 10 December 1948\nArticle 8 of the European Convention on Human Rights\nCouncil of Europe Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data 1981 (convention 108)\nCharter of Fundamental Rights of the European Union 2010\/C 83\/0215\nDirective 95\/46\/EC of the European Parliament of 24 October 1995 on the protection of individuals with regard to the processing of Personal Data and on the free movement of such data",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"ethics.md",
            "language":"en",
            "frontmatter":{
                "title":"Ethical aspects",
                "contributors":[
                    "Karel Berka",
                    "Erin Calhoun",
                    "Paulette Lieby",
                    "Anamika Chatterjee",
                    "Korbinian Bsl"
                ],
                "description":"Working on aspects in the management of research data that can raise ethical issues",
                "page_id":"ethics",
                "related_pages":{
                    "tool_assembly":[
                        "covid19_data_portal",
                        "transmed",
                        "tsd",
                        "csc"
                    ]
                },
                "training":[
                    {
                        "name":"Learning material on ethics in RDM",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/materials?q=ethics"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_existing_data_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Rob Hooft\n- Flora D'Anna\n- Pinar Alper\n- Yvonne Kallberg\n- Karel Berka\n- Marko Vidak\n- Olivier Collin\n- Ulrike Wittig\ndescription: How to find and reuse existing data. dsw:\n- name: Is there any pre-existing data?\n  uuid: efc80cc8-8318-4f8c-acb7-dc1c60e491c1\nfaircookbook:\n- name: Licensing\n  url: https:\/\/w3id.org\/faircookbook\/FCB032\npage_id: existing_data\nrelated_pages:\n  tool_assembly: []\ntitle: Existing data",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"existing_data.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_existing_data_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":0,
        "total_chunks":8,
        "content":"How can you find existing data? Description\nMany datasets could exist that you can reuse for your project. Even if you know the literature very well, you can not assume that you know everything that is available. Datasets that you should be looking for can either be collected for the same purpose in another earlier project, but it could also have been collected for a completely different purpose and still serve your goals. Considerations\n\n\nCreation of scientific data can be a costly process. For a research project to receive funding one needs to justify, in the projects data management plan, the need for data creation and why reuse is not possible. Therefore it is advised to always check first if there exists suitable data to reuse for your project. When the outputs of a project are to be published, the methodology of selecting a source dataset will be subjected to peer review.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"existing_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Existing data",
                "contributors":[
                    "Rob Hooft",
                    "Flora D'Anna",
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Karel Berka",
                    "Marko Vidak",
                    "Olivier Collin",
                    "Ulrike Wittig"
                ],
                "page_id":"existing_data",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "description":"How to find and reuse existing data.",
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_existing_data_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":1,
        "total_chunks":8,
        "content":"are to be published, the methodology of selecting a source dataset will be subjected to peer review. Following community best practice for data discovery and documenting your method will help you later in reviews. List the characteristics of the datasets you are looking for, e.g. format, availability, coverage, etc. This enables you to formulate the search terms. Please see Gregory K. et al. Eleven quick tips for finding research data. PLoS Comput Biol 14(4): e1006038 (2018) for more information. Solutions\n\n\nLocate the repositories relevant for your field. Check the bibliography on relevant publications, and check where the authors of those papers have stored their data. Note those repositories. If papers dont provide data, contact the authors. Data papers provide peer-reviewed descriptions of publicly available datasets or databases and link to the data source in repositories. Data papers can be published in dedicated journals, such as Scientific Data, or be a specific article type in conventional journals.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"existing_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Existing data",
                "contributors":[
                    "Rob Hooft",
                    "Flora D'Anna",
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Karel Berka",
                    "Marko Vidak",
                    "Olivier Collin",
                    "Ulrike Wittig"
                ],
                "page_id":"existing_data",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "description":"How to find and reuse existing data.",
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_existing_data_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":2,
        "total_chunks":8,
        "content":"dedicated journals, such as Scientific Data, or be a specific article type in conventional journals. Search for research communities in the field, and find out whether they have policies for data submission that mention data repositories. For instance, ELIXIR communities in Life Sciences. Locate the primary journals in the field, and find out what data repositories they endorse. Journal websites will have a Submitter Guide, where youll find lists of recommended deposition databases per discipline, or generalist repositories. For instance, {% tool \"scientific-data-s-recommended-repositories\" %}. You can also find the databases supported by a journal through the policy interface of {% tool \"fairsharing\" %}. Search registries for suitable data repositories. {% tool \"fairsharing\" %} is an ELIXIR resource listing repositories. {% tool \"re3data\" %} lists repositories from all fields of science. {% tool \"google-dataset-search\" %} or {% tool \"datacite\" %} for localization of datasets.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"existing_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Existing data",
                "contributors":[
                    "Rob Hooft",
                    "Flora D'Anna",
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Karel Berka",
                    "Marko Vidak",
                    "Olivier Collin",
                    "Ulrike Wittig"
                ],
                "page_id":"existing_data",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "description":"How to find and reuse existing data.",
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_existing_data_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":3,
        "total_chunks":8,
        "content":"f science. {% tool \"google-dataset-search\" %} or {% tool \"datacite\" %} for localization of datasets. The {% tool \"omicsdi\" %} provides a knowledge discovery framework across heterogeneous omics data (genomics, proteomics, transcriptomics and metabolomics). The {% tool \"elixir-core-data-resources\" %} list of knowledge resources recommended by ELIXIR. {% tool \"openaire-explore\" %} provides linked open research datasets. {% tool \"mendeley-data\" %} is linked with the Mendeley social network. Search through all repositories you found to identify what you could use. Give priority to curated repositories. How can you reuse existing data? Description\nWhen you find data of interest, you should first check if the quality is good and if you are allowed to use the data for your purpose. This process might be difficult, so you can find guidelines and tools below. Considerations\n\n\nBefore reusing the data, make sure to check if a licence is attached and that it allows your intended use of the data. Check if metadata or documentation are provided with the data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"existing_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Existing data",
                "contributors":[
                    "Rob Hooft",
                    "Flora D'Anna",
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Karel Berka",
                    "Marko Vidak",
                    "Olivier Collin",
                    "Ulrike Wittig"
                ],
                "page_id":"existing_data",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "description":"How to find and reuse existing data.",
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_existing_data_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":4,
        "total_chunks":8,
        "content":"allows your intended use of the data. Check if metadata or documentation are provided with the data. Metadata and documentation should provide enough information for a correct interpretation and reuse of the data. The use of standard metadata schemas and ontologies increase reusability of the data. Quality of the data is of utmost importance. You should check whether there is a data curation process on the repository (automatic, manual, community). This information should be available on the repositorys website. Check if the repository provides a quality status of each dataset (e.g. star rating system or quality indicators). The data you choose to reuse may be versioned. Before you start to reuse it you should decide which version of the dataset you will use. Solutions\n\n\nVerify that the data is suitable for reuse. Check the licences or repository policy for data usage. Data from publications can generally be used but make sure that you cite the publication as reference. If you cannot find the licence of the data, contact the authors. No licence means no reuse allowed.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"existing_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Existing data",
                "contributors":[
                    "Rob Hooft",
                    "Flora D'Anna",
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Karel Berka",
                    "Marko Vidak",
                    "Olivier Collin",
                    "Ulrike Wittig"
                ],
                "page_id":"existing_data",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "description":"How to find and reuse existing data.",
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_existing_data_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":5,
        "total_chunks":8,
        "content":" If you cannot find the licence of the data, contact the authors. No licence means no reuse allowed. If you are reusing personal (identifiable) or even sensitive data, some extra care needs to be taken (see Human data and Sensitive data pages): Make sure you select a data repository that has a clear, published data access\/use policy. You do not want to be liable for improper reuse of personal information. For instance, if youre downloading human data from some labs website make sure there is a statement\/confirmation that the data was collected with ethical and legal considerations in place. Sensitive data is often shared under restrictions. Check in the description of the access conditions whether these match with your project (i.e. whether you would be able to successfully ask to get access to the data). For instance, certain datasets can only be accessed by projects with Ethics\/Institutional Review Board approval or some can only be used within a specific research field. Verify the quality of the data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"existing_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Existing data",
                "contributors":[
                    "Rob Hooft",
                    "Flora D'Anna",
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Karel Berka",
                    "Marko Vidak",
                    "Olivier Collin",
                    "Ulrike Wittig"
                ],
                "page_id":"existing_data",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "description":"How to find and reuse existing data.",
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_existing_data_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":6,
        "total_chunks":8,
        "content":" approval or some can only be used within a specific research field. Verify the quality of the data. Some repositories have quality indicators, such as:\n\nStar system indicating level of curation, e.g. for manually curated\/non-curated entries. {% tool \"evidence-and-conclusion-ontology\" %}. Detailed quality assessment methods. For instance, PDB has several structure quality assessment metrics. If metadata is available, check the quality of metadata. For instance, information about experimental setup, sample preparation, data analysis\/processing can be necessary to reuse the data and reproduce the experiments. Decide which version (if present) of the data you will use. You can decide to  always use the version that is available at the start of the project. You would do this if switching to the new versions would not be very beneficial to the project or it would require major changes. In this case, you need to make sure that you and others, who want to reproduce your results, can access the old version at a later stage too.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"existing_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Existing data",
                "contributors":[
                    "Rob Hooft",
                    "Flora D'Anna",
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Karel Berka",
                    "Marko Vidak",
                    "Olivier Collin",
                    "Ulrike Wittig"
                ],
                "page_id":"existing_data",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "description":"How to find and reuse existing data.",
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_existing_data_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/existing_data.md",
        "file_name":"existing_data.md",
        "chunk_index":7,
        "total_chunks":8,
        "content":"you and others, who want to reproduce your results, can access the old version at a later stage too. You can update to the latest versions if new ones come out during your project. You would do this if the new version does not require major changes in your project workflow, and\/or if the updates could improve your project. In this case, consider that you may need to re-do all your calculations based on a new version of the dataset and make sure that everything stays consistent.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"existing_data.md",
            "language":"en",
            "frontmatter":{
                "title":"Existing data",
                "contributors":[
                    "Rob Hooft",
                    "Flora D'Anna",
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Karel Berka",
                    "Marko Vidak",
                    "Olivier Collin",
                    "Ulrike Wittig"
                ],
                "page_id":"existing_data",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "description":"How to find and reuse existing data.",
                "dsw":[
                    {
                        "name":"Is there any pre-existing data?",
                        "uuid":"efc80cc8-8318-4f8c-acb7-dc1c60e491c1"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_quality_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_quality.md",
        "file_name":"data_quality.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Wei Gu\n- Pinar Alper\n- Kees van Bochove\ndescription: How to ensure high quality of research data. dsw:\n- name: Will you monitor data integrity once it has been collected?\n  uuid: 02b3fed1-0b50-4a80-b8b6-a225a1107022\n- name: Will you be using quality processes?\n  uuid: ba38b16d-2154-4372-b445-7854a6e90443\nfaircookbook:\n- name: Introducing Provenance Information\n  url: https:\/\/w3id.org\/faircookbook\/FCB036\npage_id: data_quality\nrelated_pages:\n  tool_assembly: []\ntitle: Data quality",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_quality.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_quality_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_quality.md",
        "file_name":"data_quality.md",
        "chunk_index":0,
        "total_chunks":5,
        "content":"How do you ensure the quality of research data?\nDescription\nData quality is a term that can be understood in many ways. In enterprise context, it often refers to master data management as defined by the ISO 8000 standards. In science, the quality of data is closely linked to the suitability of the data for (re)use for a particular purpose and it is a key attribute of research data. Data quality affects the reliability of research results and it is a key factor increasing the reusability of data for secondary research. Data quality control can take place at any stage during the research data lifecycle. That said, you should ensure that the necessary procedures are defined during data management planning. Considerations\nQuality control is most typically performed during data collection but it should not be neglected in later stages of research data lifecycle.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_quality.md",
            "language":"en",
            "frontmatter":{
                "title":"Data quality",
                "contributors":[
                    "Wei Gu",
                    "Pinar Alper",
                    "Kees van Bochove"
                ],
                "description":"How to ensure high quality of research data.",
                "page_id":"data_quality",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you monitor data integrity once it has been collected?",
                        "uuid":"02b3fed1-0b50-4a80-b8b6-a225a1107022"
                    },
                    {
                        "name":"Will you be using quality processes?",
                        "uuid":"ba38b16d-2154-4372-b445-7854a6e90443"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_quality_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_quality.md",
        "file_name":"data_quality.md",
        "chunk_index":1,
        "total_chunks":5,
        "content":"ed during data collection but it should not be neglected in later stages of research data lifecycle. The type of data as well as instruments and processes adopted for data collection in your research will determine the quality assurance measures you can take. Examples of such measures are:\n\nsetup data management working group (DMWG) that includes people who generate data, analyse data and data managers;\nfor data collection: DMWG to plan and define data dictionary (including validation rules) before collecting data;\nfor metadata collection: DMWG to plan and define metadata data templates;\nuse electronic data capture systems;\nautomated quality monitoring through tools, pipelines, dashboards;\ntraining of study participants and researchers, surveyors or other staff involved;\nadopting standards;\ninstrument calibrations;\nrepeated samples;\npost collection data curation;\ndata peer-review. Certain areas such as clinical studies, or those involving Next Generation Sequencing have commonly working methods to ensure data quality.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_quality.md",
            "language":"en",
            "frontmatter":{
                "title":"Data quality",
                "contributors":[
                    "Wei Gu",
                    "Pinar Alper",
                    "Kees van Bochove"
                ],
                "description":"How to ensure high quality of research data.",
                "page_id":"data_quality",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you monitor data integrity once it has been collected?",
                        "uuid":"02b3fed1-0b50-4a80-b8b6-a225a1107022"
                    },
                    {
                        "name":"Will you be using quality processes?",
                        "uuid":"ba38b16d-2154-4372-b445-7854a6e90443"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_quality_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_quality.md",
        "file_name":"data_quality.md",
        "chunk_index":2,
        "total_chunks":5,
        "content":" or those involving Next Generation Sequencing have commonly working methods to ensure data quality. Consider familiarising yourself with data quality standards or established working practices in your field of study. There are many frameworks proposed in the literature to define and evaluate overall data quality, such as:\n\nthe four data quality dimensions (Accuracy, Relevancy, Representation, Accessibility) by Wang;\nthe five Cs of Sherman (Clean, Consistent, Conformed, Current and Comprehensive), and the three categories from Kahn (Conformance, Completeness and Plausibility), for electronic health data. Kahn also proposes two different modes to evaluate these components:\nverification (focusing on the intrinsic consistency, such as adherence to a format or specified value range);\nvalidation (focusing on the alignment of values with respect to external benchmarks). For health data, a nice example of working out what data quality means can be found in the {% tool \"ohdsi\" %} community. The context in this case is observational healthcare data represented in the {% tool \"omop-cdm\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_quality.md",
            "language":"en",
            "frontmatter":{
                "title":"Data quality",
                "contributors":[
                    "Wei Gu",
                    "Pinar Alper",
                    "Kees van Bochove"
                ],
                "description":"How to ensure high quality of research data.",
                "page_id":"data_quality",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you monitor data integrity once it has been collected?",
                        "uuid":"02b3fed1-0b50-4a80-b8b6-a225a1107022"
                    },
                    {
                        "name":"Will you be using quality processes?",
                        "uuid":"ba38b16d-2154-4372-b445-7854a6e90443"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_quality_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_quality.md",
        "file_name":"data_quality.md",
        "chunk_index":3,
        "total_chunks":5,
        "content":" The context in this case is observational healthcare data represented in the {% tool \"omop-cdm\" %}. Solutions\n\nElectronic data capturing system: {% tool \"redcap\" %} allows you to design electronic data capture forms and allows you to monitor the quality of data collected via those forms. An example of data dictionary illustrating the elements and factors that should be defined for the variable needed by data collection. The World Bank provides quality assurance guidance for survey design and execution. The U.S. National Institute's of Health's provides introductory training material on data quality. Bio.tools' listing for computational tools and pipelines for data quality control in life sciences. Data integration tools that include pre-defined building blocks to monitor and check data quality, such as Pentaho Community Edition (CE), Talend Open Studio. Data curation tools such as {% tool \"openrefine\" %} that help you to identify quality issues, correct (curate) them, carry out transformations in the collected data with easy-to-use graphic interface and visualisation.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_quality.md",
            "language":"en",
            "frontmatter":{
                "title":"Data quality",
                "contributors":[
                    "Wei Gu",
                    "Pinar Alper",
                    "Kees van Bochove"
                ],
                "description":"How to ensure high quality of research data.",
                "page_id":"data_quality",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you monitor data integrity once it has been collected?",
                        "uuid":"02b3fed1-0b50-4a80-b8b6-a225a1107022"
                    },
                    {
                        "name":"Will you be using quality processes?",
                        "uuid":"ba38b16d-2154-4372-b445-7854a6e90443"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_quality_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_quality.md",
        "file_name":"data_quality.md",
        "chunk_index":4,
        "total_chunks":5,
        "content":"arry out transformations in the collected data with easy-to-use graphic interface and visualisation. It also documents all the steps during the curation for reproducibility and backtracking. For health data, the Book of OHDSI has several chapters on methods for assessing the data quality of observational health datasets, split out by data quality, clinical validity, software validity and method validity. Frameworks proposed in the literature, to define and evaluate overall data quality, could be used to create computational representations of the data quality of a dataset. OHDSI DataQualityDashboard, which leverages the Kahn framework referenced above (adapted from original thehyve.nl blogpost), is a software framework for assessing the quality and suitability of routinely generated healthcare data that is represented in the {% tool \"omop-cdm\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_quality.md",
            "language":"en",
            "frontmatter":{
                "title":"Data quality",
                "contributors":[
                    "Wei Gu",
                    "Pinar Alper",
                    "Kees van Bochove"
                ],
                "description":"How to ensure high quality of research data.",
                "page_id":"data_quality",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you monitor data integrity once it has been collected?",
                        "uuid":"02b3fed1-0b50-4a80-b8b6-a225a1107022"
                    },
                    {
                        "name":"Will you be using quality processes?",
                        "uuid":"ba38b16d-2154-4372-b445-7854a6e90443"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_sensitivity_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"contributors:\n- Rob Hooft\n- Yvonne Kallberg\n- Pinar Alper\n- Markus Englund\n- Thanasis Vergoulis\n- Robert Andrews\n- Nazeefa Fatima\ndescription: How to identify the sensitivity of different research data types\ndsw:\n- name: Are there privacy reasons why your data can not be open? uuid: 019db0b3-9067-4134-8bfd-76db3cfc572a\n- name: Will you collect any data connected to a person, \"personal data\"? uuid: 49c009cb-a38c-4836-9780-8a8b3dd1cbac\n- name: How is pseudonymization handled? uuid: 59748a7b-f729-404d-babe-3147e2c6b247\n- name: Could the coupling of data create a danger of re-identification of pseudo-\n    or anonymized personal data? uuid: 6b3d62a5-1d4d-49e1-aaf1-0a8b398a7ac3\n- name: Does this dataset contain personal data? uuid: a1d76760-053c-4706-80a2-cfb6c6a061f3\n- name: Does this dataset contain sensitive information? uuid: cc95b399-7d8d-4232-bccf-686f78c91bff\n- name: Are personal data sufficiently protected?",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_sensitivity.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_data_sensitivity_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"mation? uuid: cc95b399-7d8d-4232-bccf-686f78c91bff\n- name: Are personal data sufficiently protected? uuid: d5990471-0618-42cd-92cb-bbbfd4f61532\nfaircookbook:\n- name: Declaring data permitted uses\n  url: https:\/\/w3id.org\/faircookbook\/FCB035\npage_id: sensitive\nredirect_from: sensitive_data\nrelated_pages:\n  tool_assembly:\n  - tsd\n  - covid19_data_portal\n  - transmed\ntitle: Data sensitivity\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22sensitive+data%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_sensitivity.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_sensitivity_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":0,
        "total_chunks":7,
        "content":"Is your data sensitive? Description\nIn general, data can be categorised into two types i.e. sensitive data and non-sensitive data. Non-sensitive data can be shared openly without a risk of any harm. The term sensitive data is used when making data publicly available could put people, organisations, countries, and\/or ecosystems at risk - this could be for example, personal or commercial information, and it could also be information about habitat, geographical location, and breeding grounds of endangered\/vulnerable species. Such data sensitivity must be protected against unauthorized access, and therefore one should be cautious when deadling with potentitally sensitive or sensitive information. It is important to identifty, at early stage of data management process, that at which point data becomes sensitive or what parts of (existing or newly generated) data are sensitive.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_sensitivity.md",
            "language":"en",
            "frontmatter":{
                "title":"Data sensitivity",
                "contributors":[
                    "Rob Hooft",
                    "Yvonne Kallberg",
                    "Pinar Alper",
                    "Markus Englund",
                    "Thanasis Vergoulis",
                    "Robert Andrews",
                    "Nazeefa Fatima"
                ],
                "description":"How to identify the sensitivity of different research data types",
                "page_id":"sensitive",
                "redirect_from":"sensitive_data",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22sensitive+data%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Are there privacy reasons why your data can not be open?",
                        "uuid":"019db0b3-9067-4134-8bfd-76db3cfc572a"
                    },
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"How is pseudonymization handled?",
                        "uuid":"59748a7b-f729-404d-babe-3147e2c6b247"
                    },
                    {
                        "name":"Could the coupling of data create a danger of re-identification of pseudo- or anonymized personal data?",
                        "uuid":"6b3d62a5-1d4d-49e1-aaf1-0a8b398a7ac3"
                    },
                    {
                        "name":"Does this dataset contain personal data?",
                        "uuid":"a1d76760-053c-4706-80a2-cfb6c6a061f3"
                    },
                    {
                        "name":"Does this dataset contain sensitive information?",
                        "uuid":"cc95b399-7d8d-4232-bccf-686f78c91bff"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_sensitivity_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":1,
        "total_chunks":7,
        "content":"hich point data becomes sensitive or what parts of (existing or newly generated) data are sensitive. What is considered sensitive information is usually regulated by national laws and may differ between countries, so it is important to take into consideration both global and local regulations and policies. Considerations\n\nIf you deal with any information about individuals from the EU, you are bound by the {% tool \"eu-general-data-protection-regulation\" %}. In GDPR, such data is called \"personal data\". In the context of GDPR \"special category data\" is a subclass of \"personal data\" that is potentially even more harmful, and GDPR prescribes very strict rules for dealing with this data. Article 9 of GDPR defines the special categories as data consisting of racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership, genetic data, biometric data, data concerning health or data concerning a natural person's sex life or sexual orientation. Confusingly, these special categories are sometimes colloquially called \"sensitive data\".",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_sensitivity.md",
            "language":"en",
            "frontmatter":{
                "title":"Data sensitivity",
                "contributors":[
                    "Rob Hooft",
                    "Yvonne Kallberg",
                    "Pinar Alper",
                    "Markus Englund",
                    "Thanasis Vergoulis",
                    "Robert Andrews",
                    "Nazeefa Fatima"
                ],
                "description":"How to identify the sensitivity of different research data types",
                "page_id":"sensitive",
                "redirect_from":"sensitive_data",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22sensitive+data%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Are there privacy reasons why your data can not be open?",
                        "uuid":"019db0b3-9067-4134-8bfd-76db3cfc572a"
                    },
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"How is pseudonymization handled?",
                        "uuid":"59748a7b-f729-404d-babe-3147e2c6b247"
                    },
                    {
                        "name":"Could the coupling of data create a danger of re-identification of pseudo- or anonymized personal data?",
                        "uuid":"6b3d62a5-1d4d-49e1-aaf1-0a8b398a7ac3"
                    },
                    {
                        "name":"Does this dataset contain personal data?",
                        "uuid":"a1d76760-053c-4706-80a2-cfb6c6a061f3"
                    },
                    {
                        "name":"Does this dataset contain sensitive information?",
                        "uuid":"cc95b399-7d8d-4232-bccf-686f78c91bff"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_sensitivity_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":2,
        "total_chunks":7,
        "content":"ientation. Confusingly, these special categories are sometimes colloquially called \"sensitive data\". Note that this page is concerned with the broader definition of \"sensitive data\". Information in Life Science projects are for the most part categorised under health and genetic data and are considered special category data under the GDPR. You need to assess whether or not your dataset contains attributes that can lead to the identification of a person. Note that combinations of attributes that are themselves not identifiable can be identifiable together. See the definitions described in the How can you de-identify your data section. You need to know the de-identification status of your data. Life Science research data rarely contains directly identifying attributes. Research data would typically be pseudonymised or anonymised. If you work with personal data, you must understand the difference between these two (see under de-identification below).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_sensitivity.md",
            "language":"en",
            "frontmatter":{
                "title":"Data sensitivity",
                "contributors":[
                    "Rob Hooft",
                    "Yvonne Kallberg",
                    "Pinar Alper",
                    "Markus Englund",
                    "Thanasis Vergoulis",
                    "Robert Andrews",
                    "Nazeefa Fatima"
                ],
                "description":"How to identify the sensitivity of different research data types",
                "page_id":"sensitive",
                "redirect_from":"sensitive_data",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22sensitive+data%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Are there privacy reasons why your data can not be open?",
                        "uuid":"019db0b3-9067-4134-8bfd-76db3cfc572a"
                    },
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"How is pseudonymization handled?",
                        "uuid":"59748a7b-f729-404d-babe-3147e2c6b247"
                    },
                    {
                        "name":"Could the coupling of data create a danger of re-identification of pseudo- or anonymized personal data?",
                        "uuid":"6b3d62a5-1d4d-49e1-aaf1-0a8b398a7ac3"
                    },
                    {
                        "name":"Does this dataset contain personal data?",
                        "uuid":"a1d76760-053c-4706-80a2-cfb6c6a061f3"
                    },
                    {
                        "name":"Does this dataset contain sensitive information?",
                        "uuid":"cc95b399-7d8d-4232-bccf-686f78c91bff"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_sensitivity_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":3,
        "total_chunks":7,
        "content":"onal data, you must understand the difference between these two (see under de-identification below). For some studies there is a cohort owner, often a clinical party or a trusted third party that can map study participant keys back to names and surnames. Such data is considered pseudonymous. If there are no means to map the data back to individuals, then the data is considered anonymous and is out of the scope of the GDPR. You should keep in mind that anonymising data is a notoriously difficult task. Does your dataset contain a wide array of attributes, or exhibit unique traits\/patterns such that one can reasonably expect that not more than a dozen people in the world have those together? In that case, you can not assume that it is anonymous. Such data run the risk of being linked back to individuals through various technical means. You need to take into account that technical means to identify people in the future may be more powerful than than they are right now: i.e. data that is anonymous right now may not be anonymous forever.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_sensitivity.md",
            "language":"en",
            "frontmatter":{
                "title":"Data sensitivity",
                "contributors":[
                    "Rob Hooft",
                    "Yvonne Kallberg",
                    "Pinar Alper",
                    "Markus Englund",
                    "Thanasis Vergoulis",
                    "Robert Andrews",
                    "Nazeefa Fatima"
                ],
                "description":"How to identify the sensitivity of different research data types",
                "page_id":"sensitive",
                "redirect_from":"sensitive_data",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22sensitive+data%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Are there privacy reasons why your data can not be open?",
                        "uuid":"019db0b3-9067-4134-8bfd-76db3cfc572a"
                    },
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"How is pseudonymization handled?",
                        "uuid":"59748a7b-f729-404d-babe-3147e2c6b247"
                    },
                    {
                        "name":"Could the coupling of data create a danger of re-identification of pseudo- or anonymized personal data?",
                        "uuid":"6b3d62a5-1d4d-49e1-aaf1-0a8b398a7ac3"
                    },
                    {
                        "name":"Does this dataset contain personal data?",
                        "uuid":"a1d76760-053c-4706-80a2-cfb6c6a061f3"
                    },
                    {
                        "name":"Does this dataset contain sensitive information?",
                        "uuid":"cc95b399-7d8d-4232-bccf-686f78c91bff"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_sensitivity_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":4,
        "total_chunks":7,
        "content":"ul than than they are right now: i.e. data that is anonymous right now may not be anonymous forever. Solutions\n\nIdentify what legislations and regulations there are that you are expected to follow. Your institution's website may give you hints on where you can look for information about data sensitivity. If you cannot determine if your data is sensitive, contact someone with expert knowledge in that area. How can you de-identify your data?\nDescription\nData anonymization is the process of irreversibly modifying personal data in such a way that subjects cannot be identified directly or indirectly by anyone, including the study team. If data are anonymized, no one can link data back to the subject. Pseudonymization is a process where identifying-fields within data records are replaced by artificial identifiers called pseudonyms or pseudonymized IDs. Pseudonymization ensures no one can link data back to the subject, apart from nominated members of the study team who will be able to link pseudonyms to identifying records, such as name and address.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_sensitivity.md",
            "language":"en",
            "frontmatter":{
                "title":"Data sensitivity",
                "contributors":[
                    "Rob Hooft",
                    "Yvonne Kallberg",
                    "Pinar Alper",
                    "Markus Englund",
                    "Thanasis Vergoulis",
                    "Robert Andrews",
                    "Nazeefa Fatima"
                ],
                "description":"How to identify the sensitivity of different research data types",
                "page_id":"sensitive",
                "redirect_from":"sensitive_data",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22sensitive+data%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Are there privacy reasons why your data can not be open?",
                        "uuid":"019db0b3-9067-4134-8bfd-76db3cfc572a"
                    },
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"How is pseudonymization handled?",
                        "uuid":"59748a7b-f729-404d-babe-3147e2c6b247"
                    },
                    {
                        "name":"Could the coupling of data create a danger of re-identification of pseudo- or anonymized personal data?",
                        "uuid":"6b3d62a5-1d4d-49e1-aaf1-0a8b398a7ac3"
                    },
                    {
                        "name":"Does this dataset contain personal data?",
                        "uuid":"a1d76760-053c-4706-80a2-cfb6c6a061f3"
                    },
                    {
                        "name":"Does this dataset contain sensitive information?",
                        "uuid":"cc95b399-7d8d-4232-bccf-686f78c91bff"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_sensitivity_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":5,
        "total_chunks":7,
        "content":"the study team who will be able to link pseudonyms to identifying records, such as name and address. Data anonymization involves modifying a dataset so that it is impossible to identify a subject from their data. Pseudonymization involves replacing identifying data with artificial IDs, for example, replacing a healthcare record ID with an internal participant ID only known to a named clinician working in the study. Considerations\nBoth anonymization and pseudonymization are approaches that comply with the GDPR. Simply removing identifiers cannot guarantee data anonymity. A dataset may contain unique traits\/patterns that could identify individuals. An example of this would be recording 2 potentially unrelated attributes such as the instance of a rare disease and country of residence, where there is only a single case of this disease in this country. Data that is anonymous currently may not be anonymous in the future. Future datasets on the same individual may disclose their identity.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_sensitivity.md",
            "language":"en",
            "frontmatter":{
                "title":"Data sensitivity",
                "contributors":[
                    "Rob Hooft",
                    "Yvonne Kallberg",
                    "Pinar Alper",
                    "Markus Englund",
                    "Thanasis Vergoulis",
                    "Robert Andrews",
                    "Nazeefa Fatima"
                ],
                "description":"How to identify the sensitivity of different research data types",
                "page_id":"sensitive",
                "redirect_from":"sensitive_data",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22sensitive+data%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Are there privacy reasons why your data can not be open?",
                        "uuid":"019db0b3-9067-4134-8bfd-76db3cfc572a"
                    },
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"How is pseudonymization handled?",
                        "uuid":"59748a7b-f729-404d-babe-3147e2c6b247"
                    },
                    {
                        "name":"Could the coupling of data create a danger of re-identification of pseudo- or anonymized personal data?",
                        "uuid":"6b3d62a5-1d4d-49e1-aaf1-0a8b398a7ac3"
                    },
                    {
                        "name":"Does this dataset contain personal data?",
                        "uuid":"a1d76760-053c-4706-80a2-cfb6c6a061f3"
                    },
                    {
                        "name":"Does this dataset contain sensitive information?",
                        "uuid":"cc95b399-7d8d-4232-bccf-686f78c91bff"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_sensitivity_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_sensitivity.md",
        "file_name":"data_sensitivity.md",
        "chunk_index":6,
        "total_chunks":7,
        "content":" not be anonymous in the future. Future datasets on the same individual may disclose their identity. Anonymization techniques can sometimes damage the statistical properties of the data, for example, translating current participant age into an age range. Solutions\nAn example of pseudonymization is where participants in a study are assigned a non-identifying ID and all identifying data (such as name and address) are removed from the metadata to be shared. The mapping of this ID to personal data is held separately and securely by a named researcher who will not share this data. There are well-established data anonymization approaches, such as k-anonymity, l-diversity, and differential privacy.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_sensitivity.md",
            "language":"en",
            "frontmatter":{
                "title":"Data sensitivity",
                "contributors":[
                    "Rob Hooft",
                    "Yvonne Kallberg",
                    "Pinar Alper",
                    "Markus Englund",
                    "Thanasis Vergoulis",
                    "Robert Andrews",
                    "Nazeefa Fatima"
                ],
                "description":"How to identify the sensitivity of different research data types",
                "page_id":"sensitive",
                "redirect_from":"sensitive_data",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "covid19_data_portal",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22sensitive+data%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Are there privacy reasons why your data can not be open?",
                        "uuid":"019db0b3-9067-4134-8bfd-76db3cfc572a"
                    },
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"How is pseudonymization handled?",
                        "uuid":"59748a7b-f729-404d-babe-3147e2c6b247"
                    },
                    {
                        "name":"Could the coupling of data create a danger of re-identification of pseudo- or anonymized personal data?",
                        "uuid":"6b3d62a5-1d4d-49e1-aaf1-0a8b398a7ac3"
                    },
                    {
                        "name":"Does this dataset contain personal data?",
                        "uuid":"a1d76760-053c-4706-80a2-cfb6c6a061f3"
                    },
                    {
                        "name":"Does this dataset contain sensitive information?",
                        "uuid":"cc95b399-7d8d-4232-bccf-686f78c91bff"
                    },
                    {
                        "name":"Are personal data sufficiently protected?",
                        "uuid":"d5990471-0618-42cd-92cb-bbbfd4f61532"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_creating_dataflow_diagram_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/creating_dataflow_diagram.md",
        "file_name":"creating_dataflow_diagram.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Vilem Ded\ndescription: Best practices to capture your planned data-flow in a diagram. page_id: creating_dataflow_diagram\ntitle: Creating a data-flow diagram",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"creating_dataflow_diagram.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_creating_dataflow_diagram_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/creating_dataflow_diagram.md",
        "file_name":"creating_dataflow_diagram.md",
        "chunk_index":0,
        "total_chunks":6,
        "content":"How to create a data-flow diagram? Description\nCreating a data-flow diagram for your research project greatly enhances your data management process. While Data Management Plans (DMPs) can span tens or even hundreds of pages, a diagram offers a more concise and accessible way to represent your data-flow. This visual approach helps bridge the gap between partners who may have varying perceptions and levels of understanding, ensuring everyone is aligned. Diagrams make it easier to identify potential issues by highlighting undocumented data sources or destinations that might otherwise go unnoticed in a lengthy document. A well-crafted data-flow diagram also boosts the engagement of less-involved partners or stakeholders, giving them a clear and intuitive way to contribute to the planning process. Considerations\n\nA simple diagram can significantly improve clarity and communication and it's essential to first consider the complexity of the data-flow.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"creating_dataflow_diagram.md",
            "language":"en",
            "frontmatter":{
                "title":"Creating a data-flow diagram",
                "contributors":[
                    "Vilem Ded"
                ],
                "description":"Best practices to capture your planned data-flow in a diagram.",
                "page_id":"creating_dataflow_diagram"
            }
        }
    },
    {
        "id":"md_content_creating_dataflow_diagram_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/creating_dataflow_diagram.md",
        "file_name":"creating_dataflow_diagram.md",
        "chunk_index":1,
        "total_chunks":6,
        "content":"rove clarity and communication and it's essential to first consider the complexity of the data-flow. For complex project with multiple steps, data sources, or stakeholders, a diagram is invaluable for identifying steps, dependencies, potential issues and ensuring everyone has a shared understanding. The more complex the data-flow, the more time and effort it will take to create and update the diagram. It is important to plan carefully and ensure that the time invested in diagram creation and updates is manageable and that your contribution is clearly recognized. A diagram may include sensitive or confidential information or reveal critical details that could be exploited by attackers, such as system vulnerabilities or data access points. Therefore, be cautious about sharing information publicly. Ensure that appropriate security measures are in place and such information is properly protected to prevent security breaches. While a diagram is a helpful tool, it is usually not legally binding without a formal, written description of the data-flow.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"creating_dataflow_diagram.md",
            "language":"en",
            "frontmatter":{
                "title":"Creating a data-flow diagram",
                "contributors":[
                    "Vilem Ded"
                ],
                "description":"Best practices to capture your planned data-flow in a diagram.",
                "page_id":"creating_dataflow_diagram"
            }
        }
    },
    {
        "id":"md_content_creating_dataflow_diagram_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/creating_dataflow_diagram.md",
        "file_name":"creating_dataflow_diagram.md",
        "chunk_index":2,
        "total_chunks":6,
        "content":"pful tool, it is usually not legally binding without a formal, written description of the data-flow. Its good practice to complement your diagram with a full textual annex to ensure the process is well-documented and understood. Content of the diagram will depend on many factors. It is good practice to start with definition of the targeted audience (project partners, data managers, funders, public) and main purpose (capturing life of project data, clarification of data protection framework, description of pre-processing steps). Based on the targeted audience and purpose, you can then more precisely define the scope of your diagram, i.e. what (not) to include. These can be physical assets and entities (partners\/people, storage locations, instruments, datasets, documents) or logical elements of your project (processes, data types, partner roles). Same as DMPs, the diagram is a living resource and should be updated as the research project progresses. Solution\n\n\nStart with a simple top level diagram. Share it and get feedback on what can be refined. You can follow these steps.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"creating_dataflow_diagram.md",
            "language":"en",
            "frontmatter":{
                "title":"Creating a data-flow diagram",
                "contributors":[
                    "Vilem Ded"
                ],
                "description":"Best practices to capture your planned data-flow in a diagram.",
                "page_id":"creating_dataflow_diagram"
            }
        }
    },
    {
        "id":"md_content_creating_dataflow_diagram_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/creating_dataflow_diagram.md",
        "file_name":"creating_dataflow_diagram.md",
        "chunk_index":3,
        "total_chunks":6,
        "content":"le top level diagram. Share it and get feedback on what can be refined. You can follow these steps. List all assets. List all partners and actors.\nList all processes.\nDefine data sources - such as instrument, patient, collaborator, lab. Define final data locations (sinks) - for example, archives, repositories, external processes, ingestion zones. Start drawing visual elements representing the outer interface (sources and sinks) and move inwards. Iteratively refine the diagram based on items which were not yet included. Too complex diagrams can be split. Define sub-processes and detect input\/output flows or interfaces. Various attributes of visual elements can be mapped to aesthetics. These can be:\nsquare for process performed automatically vs. rectangle for process performed manually (shape);\nred line for sensitive data flow vs. blue for non-sensitive data (line color);\ncolor, fill, border. Be consistent in mapping the of aesthetics.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"creating_dataflow_diagram.md",
            "language":"en",
            "frontmatter":{
                "title":"Creating a data-flow diagram",
                "contributors":[
                    "Vilem Ded"
                ],
                "description":"Best practices to capture your planned data-flow in a diagram.",
                "page_id":"creating_dataflow_diagram"
            }
        }
    },
    {
        "id":"md_content_creating_dataflow_diagram_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/creating_dataflow_diagram.md",
        "file_name":"creating_dataflow_diagram.md",
        "chunk_index":4,
        "total_chunks":6,
        "content":"or non-sensitive data (line color);\ncolor, fill, border. Be consistent in mapping the of aesthetics. For example, instead of using fill colors to depict encryption status (red vs blue) and collaborator's roles (green for researchers vs blue for contractors), you can use small key icons for the encryption status (shape). Include a legend if the aesthetics is complicated. Don't forget to include the date of last update, version and your name. Source files for the diagrams should be vector based to facilitate portability and reuse. For example, Scalable Vector Graphics (SVG). For dissemination, you can use a raster-graphics file format such as Portable Network Graphics (PNG) or other. Use a vector graphics tool of your preference. Open source: {% tool \"draw-io\" %}, {% tool \"inkscape\" %}, {% tool \"libre-office-draw\" %}. Licensed: MS Visio, Miro.com, Corel Draw, MS PowerPoint, Affinity Designer or Adobe Illustrator. Investigate your tool and all features it provides.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"creating_dataflow_diagram.md",
            "language":"en",
            "frontmatter":{
                "title":"Creating a data-flow diagram",
                "contributors":[
                    "Vilem Ded"
                ],
                "description":"Best practices to capture your planned data-flow in a diagram.",
                "page_id":"creating_dataflow_diagram"
            }
        }
    },
    {
        "id":"md_content_creating_dataflow_diagram_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/creating_dataflow_diagram.md",
        "file_name":"creating_dataflow_diagram.md",
        "chunk_index":5,
        "total_chunks":6,
        "content":"erPoint, Affinity Designer or Adobe Illustrator. Investigate your tool and all features it provides. E.g. {% tool \"draw-io\" %} allows you to host the diagram in {% tool \"github\" %} making it a very convenient tool for collaborative editing.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"creating_dataflow_diagram.md",
            "language":"en",
            "frontmatter":{
                "title":"Creating a data-flow diagram",
                "contributors":[
                    "Vilem Ded"
                ],
                "description":"Best practices to capture your planned data-flow in a diagram.",
                "page_id":"creating_dataflow_diagram"
            }
        }
    },
    {
        "id":"md_fm_dm_coordination_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Robert Andrews\n- Stefanie Meyer\n- Tereza Motalova\n- Graham Parton\n- Marko Petek\n- Maja Zagorak\n- Karolina Zavoralova\n- Karel Berka\n- Korbinian Bsl\n- Flora D'Anna\n- Niclas Jareborg\n- Yvonne Kallberg\n- Paulette Lieby\ndescription: How to coordinate and organise data management activities in collaborative\n  or multi-parter projects. page_id: dm_coordination\nrelated_pages:\n  tool_assembly: []\ntitle: Project data management coordination\ntraining:\n- name: null\n  registry: null\n  url: null",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"dm_coordination.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_dm_coordination_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":0,
        "total_chunks":11,
        "content":"How to organise data management in collaborative projects? Description\nMost national and European funders of (multi-partner) projects now require Data management plans (DMPs) that are evaluated before grant awards. Therefore, coordinators of project consortia need to mobilise a dedicated effort to decide on the approach for data management, developing the DMP, using the DMP as a live document throughout the project, and so on, to ensure that the research outputs from the project follow the FAIR principles. This is a new terrain for many people, requiring them to grasp what this entails and figure out who to approach. Considerations\n\nDuring the writing stage of a grant proposal, members of a multi-partner project or consortium need to agree on how to address data management during and after the project, and formalise the way of working on the grant proposal.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":1,
        "total_chunks":11,
        "content":"ata management during and after the project, and formalise the way of working on the grant proposal. What information regarding data management is needed at different phases (preparation, submission, execution, wrap-up, reporting to the funders) in the project needs to be decided in advance. There is a need to understand the institutional landscape in terms of legal requirements, data policies, IT services, and so on, which are essential to carry out the project. They might vary among individual institutions involved in the project consortium:\nNot every institution has a centralised IT department to support data management; often data management is carried out by the group itself without help from the IT department. Legal and ethical requirements, data policies, etc., can be very different or even not be in place in some institutions. Data management strategies and the types of data generated can change during the project.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":2,
        "total_chunks":11,
        "content":"titutions. Data management strategies and the types of data generated can change during the project. Solutions\nHere, we provide some advice and methods to help consortia with data management coordination tasks:\n\nIn a consortium, establishing a Data Management Working Group (DMWG) should be one of the first actions taken during the establishment of the consortium. Each partner should have representatives for data management, especially the partners that will generate and\/or use a higher volume of data. If possible, the representatives should have a working knowledge of data management. During the writing stage, the DMWG should be responsible for deciding how data management will be addressed during (and after) the project. It is highly recommended that, if possible, the establishment of the DMWG is included as a project task, deliverable or milestone. Each partner should allocate personnel time for the DMWG. Dedicating part of the project (a work package, for instance) to data management helps with clarifying tasks and responsibilities.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":3,
        "total_chunks":11,
        "content":" (a work package, for instance) to data management helps with clarifying tasks and responsibilities. The DMWG should have defined milestones and deliverables in the project plan. All partners should agree on what needs to be added to the budget for data management purposes: hardware requirements (long-term storage space, servers, etc.), cloud services, software licensing, software developers and data stewards\/managers, that collectively contribute to the costs of making data FAIR. It is advisable to consult with available IT support, data centres, and instrument providers at each partners side to evaluate options and costs. DMWG should list the types of data to be collected, including descriptions of file types (to enable archive and sharing) and estimated file sizes (to enable storage costing). Ideally, the DMWG should agree on: data deposition databases, data sharing and archiving, and metadata standards (model, checklist, format, ontologies and controlled vocabularies) during the writing of the proposal.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":4,
        "total_chunks":11,
        "content":"odel, checklist, format, ontologies and controlled vocabularies) during the writing of the proposal. However, if it is not feasible at the writing stage, making these decisions can be added as early tasks, milestones or deliverables of the project.\nAs a monitoring mechanism, some of the milestones and deliverables should be the successful creation of datasets with their metadata and possibly their deposition. If applicable, each partner (actually, its representative) should consult with personal data legislation experts (e.g. GDPR or equivalent), Data Protection Officers (DPOs) and the legal office of the institution (e.g. for technology transfer) to reach a consensus at the consortium level about data protection, availability and open science. It is recommended to discuss as early as possible the licensing and the intellectual property (IP) rights of project outcomes (datasets, software, tools, etc.), to comply with open science requirements and to avoid legal issues later on. Discuss a common plan for the sharing of data, documentation and metadata between partners.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":5,
        "total_chunks":11,
        "content":"ater on. Discuss a common plan for the sharing of data, documentation and metadata between partners. Tools such as {% tool \"fair-implementation-profile\" %} and {% tool \"fip-wizard\" %} could be used to explicitly declare FAIR Implementation Profiles. How to execute data management in collaborative projects? Description\nOnce the project is awarded, the data management plan needs to be executed throughout its duration. Considerations\n\nSome data management challenges may not have been foreseen at the pre-award stage. Possible difficulties during the execution of the DMP by individual partners may arise. Not all partners have the same skills and resources. Possible problems with data exchange between partners can resurface during the project.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":6,
        "total_chunks":11,
        "content":"d resources. Possible problems with data exchange between partners can resurface during the project. Consider contacting and establishing collaborations for depositing data with key repositories, e.g. setting up an {% tool \"ena-compare-data-hubs\" %} for depositing sequence data at the {% tool \"european-nucleotide-archive\" %}\nor collaborating with {% tool \"biostudies\" %}, that can provide a project-specific data collection for early data sharing and sustainable data publishing (see, for example, this dedicated collection for the EU-ToxRisk project on toxicity testing and risk assessment)\n\nSolutions\n\nThe DMWG should have regular meetings to find appropriate solutions to arising data management issues. The DMWG should make sure all partners are able to implement the data management strategies. Establish a strategy for documentation and exchange of data (within the project and with other collaborators): Evaluate the value of your project outcomes (datasets, data, tools, etc.) and establish which of them are worth preserving long term.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":7,
        "total_chunks":11,
        "content":"t outcomes (datasets, data, tools, etc.) and establish which of them are worth preserving long term. Agree on relevant data formats (e.g. TXT, MP4, FASTQ), metadata schemas, checklists and controlled vocabularies\/ontologies that are recognised as standards by scientific communities - all these depend on the type of data generated. Read more about documentation and metadata. Ensure that all partners deposit data according to the agreed data publication strategy. The DMP should be revisited on a regular basis and updated when necessary. Things to look out for are:\nEnsuring that the chosen data repositories are fit for purpose. Ensuring that the metadata standards and the ontologies used are fit for purpose. Ensuring that the strategy for documentation and data exchange is adequate. Planning for long-term storage and data sharing for all partners. Try to keep it simple and find a balance between the amount of necessary details, to avoid making documentation difficult and discouraging. How to sustain and monitor data management in collaborative projects?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":8,
        "total_chunks":11,
        "content":"on difficult and discouraging. How to sustain and monitor data management in collaborative projects? Description\nIf you want to secure a constant effort on research data management across the project period and after the project, with stable data quality, this will require dedicated monitoring and focus from the project management and the DMWG. Considerations\n\nBe aware of a possible lack of storage infrastructure, thus requiring financing that might not be part of the initially proposed project budget. Monitor that data is not lost, e.g. by missing or unimplemented backup procedures. Monitor that metadata is collected, and organised according to agreed standards and no discrepancies between metadata and reality exist (e.g. sample ID mismatches). Copyright licenses connected to the reuse of the project outputs should be applicable long-term beyond the project's lifetime. Some data might need to be made available through restricted access mechanisms, e.g. for sensitive (personal) data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":9,
        "total_chunks":11,
        "content":" need to be made available through restricted access mechanisms, e.g. for sensitive (personal) data. Safeguarding the functionality of a data access committee beyond the project period requires coordination on an institutional level. The quality, size, location, and reuse of datasets might be an object of project reporting and be used as a performance indicator. Solutions\n\nFor long-term preservation of valuable project outcomes, try to look for additional funding within your organization or from other funders, or create a feasible strategy to use e.g. institutional, national, or international repositories, with their preservation policy. Automate backups as much as possible with your IT department and test them. Backup log files should be actively monitored for potential issues. The DMWG should perform regular checks with data hosting project partners to check that data and metadata are produced according to the DMP, and that agreed backup routines are followed.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_dm_coordination_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/dm_coordination.md",
        "file_name":"dm_coordination.md",
        "chunk_index":10,
        "total_chunks":11,
        "content":"t data and metadata are produced according to the DMP, and that agreed backup routines are followed. Post-project preservation of data should consider reproducibility\/replicability of the data from a long-term perspective, as well as the potential reuse value. You might want to consult a data preservation service (e.g. national data centres) regarding larger amounts of data. As an initial inspiration, you can start from this data value checklist and adapt it for your legal framework and domain. Do not leave the data holders with the impossible task of trying to figure out who can have access to the resources, but rather use a license that allows the re-use of data. For instance, some projects or funding bodies demand to use CC-BY-4.0 and refrain from using bespoke, non-standard license terms. If data is to be made available to others through a restricted access mechanism, the access granting procedure and responsibilities must be defined and implemented. Note that this must work after the end of the project.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"dm_coordination.md",
            "language":"en",
            "frontmatter":{
                "title":"Project data management coordination",
                "description":"How to coordinate and organise data management activities in collaborative or multi-parter projects.",
                "contributors":[
                    "Robert Andrews",
                    "Stefanie Meyer",
                    "Tereza Motalova",
                    "Graham Parton",
                    "Marko Petek",
                    "Maja Zagorak",
                    "Karolina Zavoralova",
                    "Karel Berka",
                    "Korbinian Bsl",
                    "Flora D'Anna",
                    "Niclas Jareborg",
                    "Yvonne Kallberg",
                    "Paulette Lieby"
                ],
                "page_id":"dm_coordination",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_management_plan_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_management_plan.md",
        "file_name":"data_management_plan.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Flora D'Anna\n- Daniel Faria\ndescription: How to write a Data Management Plan (DMP). page_id: dmp\nrelated_pages:\n  tool_assembly:\n  - nels\n  - tsd\ntitle: Data management plan\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+management+plan%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_management_plan.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_management_plan_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_management_plan.md",
        "file_name":"data_management_plan.md",
        "chunk_index":0,
        "total_chunks":7,
        "content":"What should you write in a Data Management Plan (DMP)? Description\nA DMP should address a broad range of data management aspects, regardless of funder or institution specific templates. It is important to be aware of the current best practices in DMPs before starting one. For more generic information about data management planning, see also our Planning page. Considerations\nCommon topics of a DMP are:\n* General information about the project. * Description of the datasets that will be used and generated. * Description of metadata, ontologies and data documentation. * Storage solutions, data security and preservation strategy that will be adopted during and after the project. * How, when and where data will be shared and published. * Costs and resources needed for data management. * Ethical and legal issues, such as privacy, intellectual property and licences.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_management_plan.md",
            "language":"en",
            "frontmatter":{
                "title":"Data management plan",
                "contributors":[
                    "Flora D'Anna",
                    "Daniel Faria"
                ],
                "description":"How to write a Data Management Plan (DMP).",
                "page_id":"dmp",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+plan%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_management_plan_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_management_plan.md",
        "file_name":"data_management_plan.md",
        "chunk_index":1,
        "total_chunks":7,
        "content":"or data management. * Ethical and legal issues, such as privacy, intellectual property and licences. Solutions\n\nThis website includes best practices and guidelines about the different aspects of research data management that should be covered in a DMP. Core requirements for DMP have been described by Science Europe. Consider the DMP Common Standard from the Research Data Alliance as a reference data model for organising the different topics. What template should you use to draft your DMP? Description\nA number of DMP templates are currently available, originating from different funding agencies or institutions. Moreover, there are ongoing efforts to develop templates for machine-actionable DMPs. Considerations\n\nEach funding agency could require or recommend a specific DMP template. Your institution could require and recommend a DMP template. Template could be presented as list of questions in text format or in a machine-actionable format.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_management_plan.md",
            "language":"en",
            "frontmatter":{
                "title":"Data management plan",
                "contributors":[
                    "Flora D'Anna",
                    "Daniel Faria"
                ],
                "description":"How to write a Data Management Plan (DMP).",
                "page_id":"dmp",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+plan%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_management_plan_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_management_plan.md",
        "file_name":"data_management_plan.md",
        "chunk_index":2,
        "total_chunks":7,
        "content":". Template could be presented as list of questions in text format or in a machine-actionable format. Solutions\n\nConsult the documentation of your funding agency or institution, or contact them to figure out if they require or recommend a DMP template. A core DMP template has been provided by Science Europe. Read DMP guidelines from the Horizon Europe Programme Guide and the Horizon Europe Annotated Model Grant Agreement. The Horizon Europe DMP template can be downloaded from the Reference Documents page, by clicking on Templates & forms, Project reporting templates and then on Data management plan (HE). Consider adopting the DMP Common Standard model from the Research Data Alliance if you want to produce a machine-actionable DMP template. What tool should you use to write your DMP? Description\nDMPs can be written offline by using the downloaded template in a text document format.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_management_plan.md",
            "language":"en",
            "frontmatter":{
                "title":"Data management plan",
                "contributors":[
                    "Flora D'Anna",
                    "Daniel Faria"
                ],
                "description":"How to write a Data Management Plan (DMP).",
                "page_id":"dmp",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+plan%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_management_plan_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_management_plan.md",
        "file_name":"data_management_plan.md",
        "chunk_index":3,
        "total_chunks":7,
        "content":" Description\nDMPs can be written offline by using the downloaded template in a text document format. However, a number of web-based DMP tools are currently available that greatly facilitate the process, as they usually contain several DMP templates and provide guidance in interpreting and answering the questions. Some of the tools also allow collaboration on a DMP and track the progress as it is a living document. Considerations\n\nCheck what DMP tool is recommended or provided by your funding agency. Check what DMP tool is recommended or provided by your institute. Make sure that the tool you choose includes the DMP template that you need. If you want to produce a machine-actionable DMP, you need to make sure the tool you choose allows exporting the DMP in a machine-actionable format (e.g. JSON) rather than only as a PDF document. Solutions\n\nUse the tool suggested by your funding agency or institution. Choose one of the following online DMP tools (ordered alphabetically).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_management_plan.md",
            "language":"en",
            "frontmatter":{
                "title":"Data management plan",
                "contributors":[
                    "Flora D'Anna",
                    "Daniel Faria"
                ],
                "description":"How to write a Data Management Plan (DMP).",
                "page_id":"dmp",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+plan%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_management_plan_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_management_plan.md",
        "file_name":"data_management_plan.md",
        "chunk_index":4,
        "total_chunks":7,
        "content":"unding agency or institution. Choose one of the following online DMP tools (ordered alphabetically). {% tool \"data-stewardship-wizard\" %}: publicly available open-source tool to collaboratively compose data management plans through smart and customisable questionnaires with FAIRness evaluation. {% tool \"dmp-canvas-generator\" %}: this tool, mainly for researchers in Switzerland, is based on a questionnaire following the structure of the SNSF (Swiss National Science Foundation) instructions for DMP submission. Each Swiss High School can develop a specific template\/canvas. {% tool \"damap\" %}: tool for machine actionable Data Management Plans. {% tool \"dmp-canvas-generator\" %}: this tool, mainly for researchers in Switzerland, is based on a questionnaire following the structure of the SNSF (Swiss National Science Foundation) instructions for DMP submission. Each Swiss High School can develop a specific template\/canvas. {% tool \"dmponline\" %}: tool widely used in Europe and many universities or institutes provide a DMPonline instance to researchers.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_management_plan.md",
            "language":"en",
            "frontmatter":{
                "title":"Data management plan",
                "contributors":[
                    "Flora D'Anna",
                    "Daniel Faria"
                ],
                "description":"How to write a Data Management Plan (DMP).",
                "page_id":"dmp",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+plan%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_management_plan_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_management_plan.md",
        "file_name":"data_management_plan.md",
        "chunk_index":5,
        "total_chunks":7,
        "content":"dely used in Europe and many universities or institutes provide a DMPonline instance to researchers. {% tool \"dmptool\" %}: widely used tool and many universities or institutes provide a DMPTool instance to researchers. {% tool \"dmproadmap\" %}: DMP Roadmap is a Data Management Planning tool. Management and development of DMP Roadmap is jointly provided by the Digital Curation Centre (DCC), http:\/\/www.dcc.ac.uk\/, and the University of California Curation Center (UC3), http:\/\/www.cdlib.org\/services\/uc3\/. The DMPTool and DMPonline sites are both now running from the joint DMPRoadmap codebase. {% tool \"easy-dmp\" %}: tool provided by the pan-European network EUDAT. {% tool \"argos\" %}: the joint effort of OpenAIRE and EUDAT to deliver an open platform for Data Management Planning. Examples of useful resources for writing and implementing a DMP.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_management_plan.md",
            "language":"en",
            "frontmatter":{
                "title":"Data management plan",
                "contributors":[
                    "Flora D'Anna",
                    "Daniel Faria"
                ],
                "description":"How to write a Data Management Plan (DMP).",
                "page_id":"dmp",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+plan%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_management_plan_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_management_plan.md",
        "file_name":"data_management_plan.md",
        "chunk_index":6,
        "total_chunks":7,
        "content":"tform for Data Management Planning. Examples of useful resources for writing and implementing a DMP. {% tool \"fair-implementation-profile\" %} and {% tool \"fip-wizard\" %} are effective instruments for clearly defining and explaining the particular implementation choices required to effectively enact FAIR principles during and after the course of a research project. {% tool \"research-data-management-organiser\" %}: tool that supports the systematic planning, organisation and implementation of research data management throughout the course of a project. Resources about data management plan can be found via the {% tool \"dmplanner\" %} registry. Webinars explaining what a data management plan is and when you might need one, such as the {% tool \"research-management-plan\" %} webinar produced in collaboration with Dr. Rob Hooft, Technical Coordinator of the Dutch TechCentre for Life Sciences, could be useful instruments to learn more about the topic.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_management_plan.md",
            "language":"en",
            "frontmatter":{
                "title":"Data management plan",
                "contributors":[
                    "Flora D'Anna",
                    "Daniel Faria"
                ],
                "description":"How to write a Data Management Plan (DMP).",
                "page_id":"dmp",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+management+plan%22#materials"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_machine_actionability_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"contributors:\n- Karel Berka\n- Flora D'Anna\n- Erik Hjerde\n- Yvonne Kallberg\n- Sirarat Sarntivijai\n- Nazeefa Fatima\n- Rafael Andrade Buono\n- Alex Henderson\n- Korbinian Bsl\n- Dominik Martinat\n- M-Christine Jacquemot-Perbal\ndescription: How to make machine-actionable (meta)data.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"machine_actionability.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_machine_actionability_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"inik Martinat\n- M-Christine Jacquemot-Perbal\ndescription: How to make machine-actionable (meta)data. dsw:\n- name: List the data formats you will be using for interpretation and describe their\n    structure\n  uuid: a797cab9-0829-4787-a096-1b5cedc9147f\nfaircookbook:\n- name: Introducing unique, persistent identifiers\n  url: https:\/\/w3id.org\/faircookbook\/FCB006\n- name: Introducing Search Engine Optimization (SEO)\n  url: https:\/\/w3id.org\/faircookbook\/FCB010\n- name: Creating a metadata profile\n  url: https:\/\/w3id.org\/faircookbook\/FCB026\n- name: Interlinking data from different sources\n  url: https:\/\/w3id.org\/faircookbook\/FCB016\n- name: Inventorying tools for converting data to RDF\n  url: https:\/\/w3id.org\/faircookbook\/FCB051\n- name: Introducing the DATS model\n  url: https:\/\/w3id.org\/faircookbook\/FCB082\n- name: Creating knowledge graphs from unstructured text\n  url: https:\/\/w3id.org\/faircookbook\/FCB081\npage_id: machine_actionability\nrelated_pages:\n  tool_assembly: []\ntitle: Machine actionability",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"machine_actionability.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_machine_actionability_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":0,
        "total_chunks":26,
        "content":"What does machine-readable, machine-actionable and machine-interpretable mean?\nDescription\nMore and more often, funders, data managers\/stewards, IT staff and institutions in general encourage researchers in Life Sciences to generate metadata (and data) in ways that can be retrieved, read and processed by computers (machines). {% include callout.html type=\"important\" content=\"This page covers the WHAT, WHY and HOW of machine-actionable files but not what information to put into machine-actionable metadata files. For more information on this, please review the Metadata management page.\" %}\nConsiderations\n\nIt is common to come across different terms, such as machine-readable, machine-actionable and machine-interpretable, which express different levels of making (meta)data for machines. The definition and the differences between these terms are not always clear and depend on the current technology.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":1,
        "total_chunks":26,
        "content":"n and the differences between these terms are not always clear and depend on the current technology. Computers, software, programming languages, formats and standards evolve quite fast and therefore new inventions could potentially make machine-readable\/actionable any digital object that wasnt before. One example is how developments in computer vision are making more and more the information contained in images, and not just the images themselves,  available for processing. While providing an all-encompassing definition for this topic is not within the scope of this platform, it is important to clarify that (meta)data can be used by machines to different extents, depending on its characteristics. Here, we report a few common definitions. \"Machine-readable: data in a data format that can be automatically read and processed by a computer, such as CSV, JSON, XML, etc. Machine-readable data must be structured data. \", Open Data Handbook. \"Machine-readable data, or computer-readable data, is data in a format that can be processed by a computer.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":2,
        "total_chunks":26,
        "content":"e-readable data, or computer-readable data, is data in a format that can be processed by a computer. Machine-readable data must be structured data. \", Wikipedia.\n\"Machine-actionable: this term refers to information that is structured in a consistent way so that machines, or computers, can be programmed against the structure. \", DDI.\nMachine-interpretable: machines can put the provided information into context and understand the meaning (semantics) and relations contained in the digital object. This concept is related to the Semantic Web vision and the Linked Data concept. See e.g. What Is the Semantic Web?. The terms machine-readable and machine-actionable are often used interchangeably as synonymous. It is because of the variety of possible definitions for data that can be processed in some form by computers, that we decided to use the term machine-actionable in the remainder of this document to refer to this type of (meta)data.\n\nMachine-actionable (meta)data doesn't mean just digital.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":3,
        "total_chunks":26,
        "content":"ument to refer to this type of (meta)data.\n\nMachine-actionable (meta)data doesn't mean just digital. For computers and software, it might not be possible to process the information contained in a digital object (e.g. scanned image). It is also NOT just:\nA digital file that is readable by  some software (i.e. not broken or corrupted). A digital file in an open (non-proprietary) or free  format (ex: .txt, .pdf) that can be read by some software. A digital file that is readable by some non-proprietary software (e.g. .txt, .pdf). \"The appropriate machine-actionable\/readable format may vary by type of data - so, for example, machine-actionable\/readable formats for geographic data may differ from those for tabular data. \", Open Data Handbook. For instance, GML is one of the appropriate format for geographical information. Machine-actionable\/readable formats are typically difficult to read by humans. Human-readable data is \"in a format that can be conveniently read by a human.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":4,
        "total_chunks":26,
        "content":"ult to read by humans. Human-readable data is \"in a format that can be conveniently read by a human. Some human-readable formats, such as PDF, are not machine-actionable\/readable as they are not structured data, i.e. the representation of the data on disk does not represent the actual relationships present in the data. \", Open Data Handbook. For instance, have you ever tried to extract or copy-paste a table from a PDF into a spreadsheet? It is usually very difficult and sometimes even impossible. This is a practical example of why PDF is not easy to read by machines, but it is very easy to read by humans. This occurs because the content in a PDF is described as characters painted or drawn on a space. So text is not text and tables are not tables for a PDF. They are just characters on the page space. Tabular data in CSV file can be quite easy to read by humans, unless the table is very very big. A file in CSV format can be read by machines since it is organised in records (lines) and fields (columns) separated by comma, that is as a table.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":5,
        "total_chunks":26,
        "content":"ince it is organised in records (lines) and fields (columns) separated by comma, that is as a table. So, the computer reads whatever information stored as CSV in this tabular format. Solutions\nFor RDM in Life Sciences, machine-actionable metadata and data should:\n* Be structured data: \"data where the structural relation between elements is explicit in the way the data is stored on a computer disk. \", Open Data Handbook. * Be in a format that allows \"many types of structure to be represented. \", Open Data Handbook. For instance, JSON and XML for text files; certain formats for e.g. images that include structured (meta)data in a structured format. * Common formats such as XML and JSON contribute to syntactic interoperability between machines. * Be interpreted by computer systems unambiguously. The meaning (semantic) of the (meta)data should be unique and shared among computer systems. * Syntaxes such as JSON-LD and RDF\/XML contribute to semantic interoperability.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":6,
        "total_chunks":26,
        "content":"ng computer systems. * Syntaxes such as JSON-LD and RDF\/XML contribute to semantic interoperability. * Not be in PDF format (scanned images of lab books, tables, articles or papers in .pdf)\n* Not be in plain text (.txt) nor Word documents (.docx) formats (e.g. README.txt file). * Not be images, audio nor video (.jpeg, png, etc.). What are the advantages of machine-actionable metadata and data? Description\nNumerous research institutes have already introduced or are going to introduce the use of Electronic Laboratory Notebook (ELN), Laboratory Information Management System (LIMS) or similar systems to manage samples, reagents, metadata and data, during a research project. The reason for this is that this software could organize information in a structured way and make (meta)data more machine-actionable, compared to traditional lab books or individual folders and files in a computer.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":7,
        "total_chunks":26,
        "content":"machine-actionable, compared to traditional lab books or individual folders and files in a computer. The use of machine-actionable (meta)data allows for scalable solutions that can be applied during a projects lifetime, increasing efficiency and ensuring that findings and contributions remain relevant within the research group. Similarly, funders and institutions ask researchers to make their (meta)data FAIR and available in a machine-actionable way. This means that (meta)data should be in databases that can expose it in such a way to allow search engines and harvesting servers to discover it, index it and link it to other relevant contextual information, thus vastly enhancing the likelihood of reusing the data (see Horizon Europe DMP template). Considerations\n\nDuring a research project, scientists and researchers should utilize metadata in order to use, reuse, and expand knowledge by:\nManaging experiments, samples and analysis pipelines. Expanding current datasets e.g. to increase the sample size. Repeating experiments done by colleagues in the team.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":8,
        "total_chunks":26,
        "content":"ent datasets e.g. to increase the sample size. Repeating experiments done by colleagues in the team. Reproducing and confirming findings done by others. Testing new hypotheses on data generated for different purposes. Scalable reuse of existing data is possible only if (meta)data is annotated with commonly used terms and findable by computers (e.g. database browser or search engines). The alternative could be very tedious and inefficient since you might have to:\n\nRead the lab book of previous colleagues until you find the right page(s) where information about previously generated data is provided. Look through numerous (shared) folders to find the documentation about a specific experiment done by previous colleagues that generated the dataset you are interested in. Read all publications about a topic and check if there is a dataset linked to it and\/or available upon request.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":9,
        "total_chunks":26,
        "content":"blications about a topic and check if there is a dataset linked to it and\/or available upon request. Integration of multiple datasets can be straightforward only if each dataset can be easily queried, processed and formatted via software\/programmes that can properly handle structured and big (meta)data files, such as {% tool \"openrefine\" %} and programming languages such as Python or R. Otherwise, manual data integration and processing can be very slow and error-prone. Advantages\nThe advantages of having machine-actionable data and metadata are numerous for all the parties involved. For researchers\nBy providing structured metadata and data to a database that follows standards (metadata schemas, ontologies, file formats, programmatic access, etc.), at the level of each recorded value or observation, researchers:\n* Could more easily query and filter (meta)data based on specific variables, experimental conditions, biological sources and many other parameters, based on the capabilities of the used ELN or data management software.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":12,
        "total_chunks":26,
        "content":"ives and that are involved in diseases?\" in the {% tool \"integrated-database-of-small-molecules\" %}. * Can more easily find reference data and existing data in general, since machine-actionable (meta)data could be found by search engines and domain specific or generic data catalogs and portals. For software developers and repositories managers\n\nImplementation of domain specific metadata schemas and ontologies for data and metadata increases the reusability for researchers. The use of machine-actionable formats and ontologies contribute to syntactic and semantic interoperability of the (meta)data, which can be used by other tools\/software or platforms. Applying RDF syntax to the database can make the (meta)data available for knowledge graphs and semantic web applications. If Application Programming Interface (API) is available, other software\/applications could make complex queries, access the database programmatically and always get up-to-date data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":13,
        "total_chunks":26,
        "content":"ons could make complex queries, access the database programmatically and always get up-to-date data. If the metadata of your database or repository is exposed according to specific standards, it could function as data provider or data source, and be harvested and indexed by\nData catalogues or data portals, such as {% tool \"omicsdi\" %} data format specification and COVID-19 Data Portal. The OpenAIRE aggregator that collects metadata records via OAI-PMH in the majority of cases. Other instances of your data repository software which use OAI-PMH for metadata harvest, such as {% tool \"dataverse\" %} harvesting. Search engines such as Google Dataset Search, which relies on sitemaps.org, {% tool \"schema-org\" %}, {% tool \"data-catalog-vocabulary\" %} and other approaches to datasets discovery. Machine actionable metadata facilitates the automatization of data handling and validation, allowing for easier development of new tools and analysis strategies (e.g. data visualization tools, machine learning and artificial intelligence applications).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":14,
        "total_chunks":26,
        "content":"rategies (e.g. data visualization tools, machine learning and artificial intelligence applications). For the authors of a machine-actionable public dataset\n\nHigh impact of the published data. More citations. More opportunity for collaborations. Opportunity for reproducibility test and confirmation of their results by others. Easy way to reuse the same (meta)data for other research. Improved scalability of their research efforts. For public funders and institutions\/governments\n\nProof that their fundings produced knowledge that is findable and reusable. Transparency. Straightforward collection and indexing of research output in registries for easier impact assessment and report. What makes a file machine-actionable? Description Due to the complexity of the topic and the lack of a unified definition, it is often difficult to identify the characteristics that make information contained in a digital object machine-actionable.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":15,
        "total_chunks":26,
        "content":"identify the characteristics that make information contained in a digital object machine-actionable. Moreover, it is important not only to make a digital file machine-actionable, but also interoperable between different machines, so that different systems can exchange information. The theoretically most machine-actionable format is in practice not achieved or established yet, however we try to list here some of the currently accepted best-practices that should be considered when making a file machine-actionable and interoperable, in Life Sciences research. Considerations\nFor machine-actionability and interoperability, you should consider:\n1. File formats that are data exchange formats (e.g. JSON, XML). 2. (Meta)Data schemas recognised and accepted by communities as standards (e.g. ISA model, {% tool \"ome-data-model-and-file-formats\" %}). The (meta)data schema describes the relations, such as hierarchy, of the elements that constitute the (meta)data model or structure.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":16,
        "total_chunks":26,
        "content":"the relations, such as hierarchy, of the elements that constitute the (meta)data model or structure. 3. Sets of metadata attributes or metadata checklists recognised and accepted by communities (e.g. {% tool \"miappe\" %}, ENA Samples checklists), that capture reporting best practice in the field. 4. Controlled vocabularies and ontologies recognised and accepted by communities to convey meaning or semantics (e.g. EFO, OBI). File format\n\nInformation contained in a digital object is only as accessible as the file format it is saved in. A file format is the way that information is encoded for storage in a computer file. This is often indicated by the file extension, e.g. .csv for a CSV file. Different file formats are preferred for different purposes. For instance:\nPDF is tailored to store and display text and graphics to humans, according to specific layouts, but it is not suitable for exchanging information between machines.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":17,
        "total_chunks":26,
        "content":", according to specific layouts, but it is not suitable for exchanging information between machines. CSV is appropriate to exchange plain text information in a tabular format, but its flat nature makes a challenge to describe more complex relationships between information. XML and JSON formats are widely used for data exchange between systems (such as softwares, platforms or hardwares) and on the web. Both are easy to read and interpreted by machines, but not very human-readable. Exchange file formats using key-value pairs, such as .xml and .json, can wrap or encode the information to be sent or exchanged in a hierarchical (tree) data model. XML is a markup language. It is based on elements enclosed by pairs of tags and attributes (<tag>element<tag>). It is self-explanatory because it contains metadata about the format and tags are chosen by the creator of the .xml file. For instance, <name>Jaguar<name>. JSON format can be easily read in any programming language. It is based on key-value pairs separated by colons ( {key:value} ). For instance, { name: Jaguar }.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_18",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":18,
        "total_chunks":26,
        "content":"t is based on key-value pairs separated by colons ( {key:value} ). For instance, { name: Jaguar }. File formats (or file extensions) for expressing data in triplets (e.g. Jaguar  is in  Jungle) in the Resource Description Framework (RDF) data model are .rdf for RDF\/XML, .jsonld for JSON-LD, .nt for N-Triples and .ttl for Turtle syntax. (Meta)Data schema\n\nA (meta)data schema describes the relations, such as hierarchy, among the elements or pieces of information that constitute the (meta)data model or structure. The relationship between pieces of information in a (meta)data schema can be implicit, following an agreed order (such as the order of columns in a table), or explicitly expressed by additional information in the file. To allow more universal interpretability, explicit additional information on the relationship between the pieces of information is highly advantageous. Some of the (meta)data schemas considered standard in Life Sciences define the relations between elements of the model in a more implicit way (e.g. ISA-TAB,  MAGE-TAB).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_19",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":19,
        "total_chunks":26,
        "content":"define the relations between elements of the model in a more implicit way (e.g. ISA-TAB,  MAGE-TAB). Some data repositories develop customised (meta)data schemas. Different metadata schemas are preferred for different purposes. Some examples are listed below. {% tool \"schema-org\" %} and {% tool \"bioschemas\" %} markup are mostly used to describe web resources and make them findable by Web search engines. {% tool \"data-catalog-vocabulary\" %} is an RDF vocabulary designed to facilitate interoperability between data catalogs published on the Web.\nInvestigation-Study-Assay (ISA) model was originally designed for describing multi-omics experiments in Life Sciences. The DAta Tag Suite (DATS) is a data description model designed and produced to describe datasets and associated metadata in a number of data deposition repositories. The {% tool \"ome-data-model-and-file-formats\" %} is a specification for storing and exchanging data on biological imaging.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_20",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":20,
        "total_chunks":26,
        "content":"model-and-file-formats\" %} is a specification for storing and exchanging data on biological imaging. The W3C consortium has formalised a universal abstract data model to potentially establish relationships among any resource available on the web (people, places, web pages, events, abstract concepts, etc.) called Resource Description Framework (RDF). This universal abstract data model allows us to describe relationships between multiple resources encoded in different formats, following different standards and stored in different locations\/servers on the internet. RDF model consists of sentences in the form of Subject   Predicate  Object, called Triples, that describe the relationship between different pieces of information. An example could be Jaguar  is in  Jungle. Subject and Object can be any resource available on the internet, Predicate (properties) connects resources to other resources or data values, etc.\n\nRDF concept can be written and applied to databases using different syntaxes, such as N-Triples, Turtle,  RDF\/XML, RDFa, JSON-LD.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_21",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":21,
        "total_chunks":26,
        "content":"d applied to databases using different syntaxes, such as N-Triples, Turtle,  RDF\/XML, RDFa, JSON-LD. The benefit is that web browsers can put the provided information with these syntaxes into context and understand the meaning (semantics) and relations contained in the digital object. Information provided in RDF syntaxes is machine-interpretable. Digital objects in these formats can specify the context and the globally unique definition of each resource by referencing other standard metadata schemas and vocabularies\/ontologies to describe web resources, such as {% tool \"schema-org\" %} or {% tool \"bioschemas\" %} (for Life Sciences), {% tool \"data-catalog-vocabulary\" %}, {% tool \"dublincore\" %}, etc. Any metadata schemas and vocabularies\/ontologies describing web resources can be expressed according to standards, such as the Web Ontology Language (OWL), the RDF Schema (RDFS) or the Simple Knowledge Organisation System (SKOS) to provide more expressive definition and inferences\/relationships between terms or pieces of information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_22",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":22,
        "total_chunks":26,
        "content":"vide more expressive definition and inferences\/relationships between terms or pieces of information. Metadata checklist\n\nHere, we define metadata checklists as content in the form of a fixed set of attributes or fields, without any particular order nor structure. Compliance to metadata checklists is not related to the format nor the structure, but rather to the content provided. Many metadata checklists have been adopted as standards by Life Sciences communities (e.g. {% tool \"miappe\" %}). Some data repositories have customised metadata checklists (e.g. ENA Samples checklists). Attributes in a metadata checklist can be ontology terms. For more information see the Data documentation and metadata page. Vocabulary or ontology\nVocabularies and ontologies are meant for describing concepts and relationships within a knowledge domain. For more information see the Data documentation and metadata page. Solutions\n\n(Meta)Data in data exchange formats (XML, JSON, CSV, etc.) that follows a standard metadata schema can be considered machine-actionable and syntactically interoperable.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_23",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":23,
        "total_chunks":26,
        "content":"ows a standard metadata schema can be considered machine-actionable and syntactically interoperable. Ontologies that uniquely identify terms can be included for semantic interoperability. RDF syntaxes, such as RDF\/XML and JSON-LD, support syntactic and semantic interoperability among machines. In other words, these formats convey the structure of the data being presented and the link to the necessary information to interpret its content, e.g. ontologies. Ontology or vocabulary is a way of expressing semantics\/meaning of (meta)data. \n\nExample of machine-interpretable metadata for the word Jaguar in JSON-LD format, which allows to clarify the intended meaning of the word \"Jaguar\" (the animal) and distinguishes it from other possible meanings such as car or computer:\n  { \n  \"@context\": \"http:\/\/bioschemas.org\",  \"hey browser, I am using these definitions\"\n  \"@type\": \"Taxon\",\n  \"@id\": \"https:\/\/www.ncbi.nlm.nih.gov\/Taxonomy\/Browser\/wwwtax.cgi?id=9690\" , \n  \"taxonRank\": \"species\",\n  \"name\": \"Panthera onca\",\n  \"alternateName\": \"Jaguar\"\n  }\n*",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_24",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":24,
        "total_chunks":26,
        "content":"i?id=9690\" , \n  \"taxonRank\": \"species\",\n  \"name\": \"Panthera onca\",\n  \"alternateName\": \"Jaguar\"\n  }\n* Metadata schemas and checklists can be found within RDA curated list of Life Sciences metadata standards or among the reporting guidelines in {%tool \"fairsharing\" %}. * Examples of standard (meta)data schemas, in different formats, in Life Sciences: \n  * ISA-JSON (.json) and ISA-TAB (.txt) - generic metadata framework originally created to describe information about multi-omics experiments. * MAGE-TAB (.txt) - MicroArray Gene Expression Tabular. The format has been developed and adopted by the functional genomics community. * {% tool \"ome-data-model-and-file-formats\" %} (.tiff or .xml) for a wide range of biological imaging modalities. Ontologies to uniquely identify terms can be included. See also Hammer, M., Huisman, M., Rigano, A. et al. Towards community-driven metadata standards for light microscopy: tiered specifications extending the OME model. Nat Methods 18, 14271440 (2021). https:\/\/doi.org\/10.1038\/s41592-021-01327-9. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_machine_actionability_md_25",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/machine_actionability.md",
        "file_name":"machine_actionability.md",
        "chunk_index":25,
        "total_chunks":26,
        "content":"nding the OME model. Nat Methods 18, 14271440 (2021). https:\/\/doi.org\/10.1038\/s41592-021-01327-9. * For more information about metadata schemas and ontologies, see Documentation and Metadata page.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"machine_actionability.md",
            "language":"en",
            "frontmatter":{
                "title":"Machine actionability",
                "contributors":[
                    "Karel Berka",
                    "Flora D'Anna",
                    "Erik Hjerde",
                    "Yvonne Kallberg",
                    "Sirarat Sarntivijai",
                    "Nazeefa Fatima",
                    "Rafael Andrade Buono",
                    "Alex Henderson",
                    "Korbinian Bsl",
                    "Dominik Martinat",
                    "M-Christine Jacquemot-Perbal"
                ],
                "description":"How to make machine-actionable (meta)data.",
                "page_id":"machine_actionability",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"List the data formats you will be using for interpretation and describe their structure",
                        "uuid":"a797cab9-0829-4787-a096-1b5cedc9147f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Inventorying tools for converting data to RDF",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB051"
                    },
                    {
                        "name":"Introducing the DATS model",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB082"
                    },
                    {
                        "name":"Creating knowledge graphs from unstructured text",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB081"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_brokering_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Aitana Neves\n- Parul Tewatia\n- Wolmar Nyberg kerstrm\n- Carla Cummins\n- Nils Peder Willassen\n- Nazeefa Fatima\ndescription: Information on brokering data to data repositories on behalf of data\n  producers. faircookbook:\n- name: Introducing terminologies and ontologies\n  url: https:\/\/w3id.org\/faircookbook\/FCB019\n- name: Creating a data\/variable dictionary\n  url: https:\/\/w3id.org\/faircookbook\/FCB025\n- name: Creating a metadata profile\n  url: https:\/\/w3id.org\/faircookbook\/FCB026\n- name: Selecting terminologies and ontologies\n  url: https:\/\/w3id.org\/faircookbook\/FCB020\n- name: Introducing ontology-related tools and services\n  url: https:\/\/w3id.org\/faircookbook\/FCB022\npage_id: data_brokering\ntitle: Data brokering\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  registry_url: https:\/\/tess.elixir-europe.org\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_brokering.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_brokering_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":0,
        "total_chunks":11,
        "content":"Taking on the data broker role\nDescription\nSometimes it is challenging to exchange data across data producers, infrastructures and data sharing platforms. Some reasons can be that the data has to be pre-processed or enriched to comply with legal or organisational practices, that the data has to be translated to different data formats, or that transferring data requires expertise and access to special interfaces. By acting as a broker, you can fill this gap by negotiating a contract with data providers and\/or recipients and doing the work required to make it convenient for them to exchange data. {: height=\"500px\" width=\"500px\"}\nFigure 1: Data Brokering Workflow. Individual data producers can process the data, store it, and submit it directly to international repositories or public health databases. Alternatively, in the data brokering model, several data producers can submit their data to a common data recipient.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":1,
        "total_chunks":11,
        "content":"n the data brokering model, several data producers can submit their data to a common data recipient. This recipient might be in charge of curating the data, analysing it with common pipelines, storing it, and re-sharing parts of the data to public health databases and international repositories (as agreed with the data providers). The latter service is often referred to as data brokering i.e. sharing data on behalf of others within a well defined ethical and legal framework. Note that legal aspects should be considered along all the steps. Considerations\nThere are many aspects to consider when getting started as a broker. Decide how to interact with the data providers\/recipients, such as to what extent you will be able to adapt your workflows to meet their needs\/requirements. Identify what kind of processing you will handle as a broker, such as (meta)data curation and validation, data masking\/anonymisation.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":2,
        "total_chunks":11,
        "content":"you will handle as a broker, such as (meta)data curation and validation, data masking\/anonymisation. Define the time frame for your commitment and your responsibilities for the data, such as how to handle data loss before delivery, what to do with the data after a successful delivery, how to manage changes to data that has already been delivered, etc.\nIdentify who is responsible for the data before, during and after delivery, such as the data controller\/processor (according to GDPR) and\/or intellectual property owner\/licensee relationships between the provider and recipient\nEnsure that you will be able to establish contracts\/agreements that cover the data and processing that you will handle, such as considerations for data security, licensing, GDPR and general compliance. Estimate and secure the resources required to keep your commitment, such as staff with time and necessary skills, accounts, compute, storage and software\nRefer to the sections below for considerations related to collecting data from data providers and delivering data to public data repositories.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":3,
        "total_chunks":11,
        "content":"ions related to collecting data from data providers and delivering data to public data repositories. Solutions\nThe solutions that you adopt will vary depending on the agreements you have negotiated with data providers and\/or recipients. The following are examples of general solutions that would help you comply with regulations and implement good data management practices. * Data management plan  Many questions that you would answer while writing a data management plan can be relevant to answer when you specify the terms of service for your brokering service, such as data storage, data standards, legal and ethical, etc. * GDPR compliance  If you are working with data concerning people in the EU, you should make sure to comply with both national and international regulations for data protection. * Apply for brokering permissions at the repository where you plan to submit data. For example, you can have a broker account at ENA; in this case, please visit ENA Documentation for guidelines on how to apply for such an account.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":4,
        "total_chunks":11,
        "content":"NA; in this case, please visit ENA Documentation for guidelines on how to apply for such an account. Collecting and processing the metadata and data\nDescription\nData brokering involves collecting data from various data providers (metadata and other data e.g. sequencing files), standardising and curating the data if needed, and then preparing the data for re-sharing e.g. in public international repositories. On the brokering platform, it is recommended that data be stored in a structured manner (e.g. in a relational database), using as much as possible controlled vocabularies and ontologies where they exist. Considerations\n\nData collection should be carefully prepared, notably to define the data model, the metadata and data that are needed for the envisioned applications, assess which fields should be compulsory or optional, follow controlled vocabularies or ontologies, and identify the nature of data (personal, sensitive data) and thereby the required level of security or data treatment (e.g. pseudonymised or anonymised data, ethical consent).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":5,
        "total_chunks":11,
        "content":"uired level of security or data treatment (e.g. pseudonymised or anonymised data, ethical consent). Collection of metadata can be done in various ways, each having its advantages and disadvantages, notably in terms of user-friendliness, ease of processing and data quality. Collection of data files (e.g. sequencing data) should also involve minimal validation where possible (e.g. file extensions, regular checks of file sizes across the database to identify potential outliers with issues, integrity checks (checksum), etc.). Regular data checks should always be performed at the database level, to check unicity of identifiers where expected (e.g. sample identifier within a laboratory is expected to be unique) and identify potential incoherences in the data (e.g. division indicated in the name of a virus versus division indicated in the location field). Data brokers should also consider implementing a mechanism for metadata and data files update within their platform, and define mechanisms to pass on the updates to international repositories.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":6,
        "total_chunks":11,
        "content":"e within their platform, and define mechanisms to pass on the updates to international repositories. Please consider that depending on the update mechanisms in place at the international repositories (e.g.  Application Programming Interface (API) vs manual update via email), this process might become quite time-consuming. Data transfer from the data providers to the data brokering platform will depend on the nature and volume of data. The volume might be larger if data providers can submit data in batches. Clarify with the data providers how the data will be processed, in terms of data curation\/cleaning and downstream data analyses. Data storage needs should be carefully addressed; consider storing data in compressed formats and deleting intermediate files from analyses that could be recomputed if needed to gain a storage space. Solutions\nCollection of metadata can be done in various ways:\n\nElectronic forms (e.g. online form, eCRF) allow controlling data at the entry point, ensuring the use of controlled vocabularies and ontologies if properly set up.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":7,
        "total_chunks":11,
        "content":"a at the entry point, ensuring the use of controlled vocabularies and ontologies if properly set up. While user friendly for single uploads, this type of upload can become very cumbersome for batch upload. Spreadsheet files enable controlling data at the entry point, thanks to native validation features of spreadsheet tools (e.g Excel). It is at the same time very convenient for batch uploads and users generally like having a file that they can store and easily re-open to check what they have provided. Text files (e.g. TSV, CSV, JSON, XML, and so on) are very practical to automate batch submissions on the user side, since scripts can easily generate these files. It is recommended to specify to the users which encoding should be used (e.g. UTF-8). There is however no data control at the entry point and only upon submission to the data brokering database. All data validation is therefore performed upon loading into the database, and error handling should be carefully evaluated prior to implementation.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":8,
        "total_chunks":11,
        "content":"loading into the database, and error handling should be carefully evaluated prior to implementation. Examples include automatically informing the user of errors and asking them to re-submit, or involving data curators who may correct obvious mistakes and can be in contact with data providers to clarify data validation errors. Some automation may also be implemented to map terms to a controlled list of terms or an ontology even in the case of minor typos. Sharing data to public repositories\nDescription\nOften, a goal of the broker is to publish the collected and harmonised data in an open archive for the benefit of both the data owners and the wider scientific community. This supports sharing data with collaborators, referencing for publication and provides a long-term storage solution. Once relevant repositories are identified for data submission and sharing, being an official data broker for a repository will generally give you additional rights such as the possibility to submit data on behalf of data producers, as well as providing a list of authors and address of the data providers.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":9,
        "total_chunks":11,
        "content":" behalf of data producers, as well as providing a list of authors and address of the data providers. This is important to ensure that data producers can claim authorship (e.g. via ORCiD) and are given credit for their work. Considerations\n\nDoes the repository have a broker-like account? This is usually referred to as a Broker or Teams account and is not always well advertised on the repository web page. Do not hesitate to contact the repository mailing-list for more information on the existence of brokering-like accounts and ask for the related additional rights. As a data broker, you generally wish to submit large amounts of data continuously. Hence, having access to a submission command-line-interface (CLI) or API is generally preferred over a user interface. Solutions\n\nFor example, {% tool \"european-nucleotide-archive\" %} offers a submission CLI and API as well as an official data broker role.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_brokering_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_brokering.md",
        "file_name":"data_brokering.md",
        "chunk_index":10,
        "total_chunks":11,
        "content":"pean-nucleotide-archive\" %} offers a submission CLI and API as well as an official data broker role. For more information on data submission as a broker, please visit: https:\/\/ena-docs.readthedocs.io\/en\/latest\/faq\/data_brokering.html?highlight=broker\n{% tool \"ena-upload-tool\" %}, a collaboratively developed and compiled Galaxy tools and workflows necessary to clean, assemble and submit sequences to the {% tool \"european-nucleotide-archive\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_brokering.md",
            "language":"en",
            "frontmatter":{
                "title":"Data brokering",
                "contributors":[
                    "Aitana Neves",
                    "Parul Tewatia",
                    "Wolmar Nyberg kerstrm",
                    "Carla Cummins",
                    "Nils Peder Willassen",
                    "Nazeefa Fatima"
                ],
                "description":"Information on brokering data to data repositories on behalf of data producers.",
                "page_id":"data_brokering",
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "registry_url":"https:\/\/tess.elixir-europe.org",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22submission%22#materials"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_compliance_monitoring_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Christophe Trefois\n- Wei Gu\n- Pinar Alper\n- Markus Englund\n- Vera Ortseifen\ndescription: How to measure compliance to data management regulations and standards. faircookbook:\n- name: Creating a data\/variable dictionary\n  url: https:\/\/w3id.org\/faircookbook\/FCB025\n- name: Assessing with FAIR Evaluator\n  url: https:\/\/w3id.org\/faircookbook\/FCB049\n- name: Assessing with FAIRshake\n  url: https:\/\/w3id.org\/faircookbook\/FCB050\npage_id: compliance\nrelated_pages:\n  tool_assembly:\n  - transmed\ntitle: Compliance monitoring & measurement",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"compliance_monitoring.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":0,
        "total_chunks":9,
        "content":"How can you measure and document data management capabilities? Description\nBeing able to reliably measure and document capabilities in data management, data protection and information security is important for research institutions. By knowing their capabilities institutions can spot areas of improvement and direct human and IT resources accordingly. Also, having capabilities documented or formalised by certifications saves a good deal of effort during data management planning. Considerations\n\nAre you being asked to describe information security and data protection arrangements for a project DMP and you find yourself repeating similar descriptions across DMPs of projects? Contact your institution's Data Protection Officer (DPO) and Chief Information Security Officer (CISO). They may be able to provide you with a standard description of data protection and information security measures for institutional data platforms.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":1,
        "total_chunks":9,
        "content":"d description of data protection and information security measures for institutional data platforms. Inquire whether the platforms you will use for your project's data management have an information security or data privacy certification. Are you providing a data service, such as data hosting, curation or archival and want to document and assess your service's capabilities? Consider measuring the FAIR maturity of your services and the FAIRness of your data assets using community adopted standard metrics. Solutions\n\nFAIR data\nGO-FAIR Initiative provides a framework for designing metrics for the evaluation of FAIRness. RDA developed a first set of guidelines and a checklist related to the implementation of the FAIR indicators. The FAIRplus project with its {% tool \"fair-cookbook\" %} provides services, tools, and indicators necessary for the assessment or the evaluation of data against the FAIR Principles. {% tool \"fair-evaluation-services\" %} are an automated approach to evaluate FAIRness of data services.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":2,
        "total_chunks":9,
        "content":" tool \"fair-evaluation-services\" %} are an automated approach to evaluate FAIRness of data services. {% tool \"fairassist-org\" %} aims to collect and describe existing resources for the assessment and\/or evaluation of digital objects against the FAIR principles. The {% tool \"fair-wizard\" %} utilizes FAIRification resources developed by the FAIRplus project and other platforms, suggests FAIRification materials based on the FAIRification requirements, and designs FAIRification solutions for data owners, data stewards, and other people involved in FAIRification. The {% tool \"fairshake\" %} evaluates the FAIRness of Digital Objects. Information Security, Data Protection, Accountability\n21 CFR part 11 is a standard, which outlines criteria for electronic records in an IT system to be as valid as signed paper\nrecords. It is widely adopted in lab information systems and applications used in clinical trials and medical research. {% tool \"iso-iec-27001\" %} is an international standard for the management of information security.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":3,
        "total_chunks":9,
        "content":" {% tool \"iso-iec-27001\" %} is an international standard for the management of information security. It is adopted by some universities and research institutes to certify their data centres. ISO\/IEC 27018 is a standard aimed to be a code of practice for protection of personally identifiable information (PII) in public clouds. How can you ethically access genetic resources of another country? Description If during your research project you need to access or transport genetic resources and\/or associated traditional knowledge from any country, you should comply to all relevant (inter)national legislation. One important legislation in this case is the Nagoya Protocol. The Nagoya Protocol specifies the Access and Benefit-Sharing (ABS) principles, established by the Convention on Biological Diversity (CBD), for countries providing and using genetic resources in a legally binding way. Article 3 of CBD clarifies, that states have sovereign rights over their own (biological and genetic) resources. Negotiations concluded in 2014 with the Nagoya Protocol on ABS.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":4,
        "total_chunks":9,
        "content":" (biological and genetic) resources. Negotiations concluded in 2014 with the Nagoya Protocol on ABS. Since then, working with genetic resources and associated data of another country requires more preparatory measures. The aim of the Nagoya protocol is to ensure fair and equitable sharing of benefits arising from utilisation of genetic resources and from traditional knowledge associated with genetic resources. Many countries, as well as the EU, are parties of the Nagoya Protocol and information on this can be found at the ABS Clearing House. By enactment of EU Regulation No. 511\/2014 the obligations were implemented in the EU on 12.10.2014. Here you can find a short video about ABS  Simply Explained. Genetic resources are defined as all genetic material of actual or potential value. Essentially, the term encompasses all living organisms (plants, animals and microbes) that carry genetic material potentially useful to humans. Genetic resources can be taken from the wild, domesticated or cultivated.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":5,
        "total_chunks":9,
        "content":"entially useful to humans. Genetic resources can be taken from the wild, domesticated or cultivated. They are sourced from: natural environments (in situ) or human-made collections (ex situ) (e.g. botanical gardens, gene banks, seed banks and microbial culture collections).\". The definition of traditional knowledge associated with genetic resources is left to the Parties of the Protocol instead. However, in the context of the Nagoya Protocol, the term is used in relation to the knowledge, innovations and practices of indigenous and local communities that result from the close interaction of such communities with their natural environment, and specifically to knowledge that may provide lead information for scientific discoveries on the genetic or biochemical properties of genetic resources. It is characteristic of traditional knowledge that it is not known outside the community holding such knowledge..",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":6,
        "total_chunks":9,
        "content":"ristic of traditional knowledge that it is not known outside the community holding such knowledge.. Considerations\n\nSince ABS regulations and Nagoya Protocol put high demands on documentation, this legal aspect is time consuming and therefore needs to be taken into account when planning the research project. ABS is not relevant for all genetic resources. It applies only to resources that have been accessed from a provider country after October 12, 2014. Some genetic resources are explicitly excluded, like for example human genomes, some crops and some viruses. Moreover, there are countries who are party of the Nagoya Protocol, but have no ABS legislation in place. If ABS is relevant to the project it should be part of the Data Management Plan. You must comply with the Nagoya Protocol and other national legislation before accessing the genetic resources. When negotiating the Mutually Agreed Terms (MAT), it is very important to think about the future reusability of the data generated based on the genetic resources.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":7,
        "total_chunks":9,
        "content":"mportant to think about the future reusability of the data generated based on the genetic resources. When sharing this data, it is important to include the necessary metadata regarding ABS and to clarify the legal basis, in order to make the data reusable to others again. Solutions\n\nIn the planning stage of your research project, allow extra time to familiarise yourself with the legal requirements. In order to determine if the Nagoya Protocol applies to your research, take a look at:\nthe European documents Sharing nature's genetic resources  ABS and Access and Benefit Sharing;\nthe dedicated websites Nagoya Protocol or ABS Clearing-House;\nlook for \"Nagoya Protocol checklists for researchers\" available in your institution to determine if the Nagoya Protocol applies to your research;\nask help to legal experts and get in contact with the corresponding office in your country or the legal team in your institution.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_compliance_monitoring_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/compliance_monitoring.md",
        "file_name":"compliance_monitoring.md",
        "chunk_index":8,
        "total_chunks":9,
        "content":" get in contact with the corresponding office in your country or the legal team in your institution. If ABS principles and Nagoya Protocol apply to your project, make sure to:\ninvestigate the conditions for accessing the genetic resources and\/or the associated traditional knowledge in the country of origin;\nmake a Prior Informed Consent (PIC) with the country that will provide the genetic resources and\/or the associated traditional knowledge, to clarify the goal of your research and how you will use the requested resources;\nnegotiate a Mutually Agreed Terms (MAT) to establish how to share the resulting benefits. The benefits for the provider of the genetic resources and\/or the associated traditional knowledge can be monetary, transfer of knowledge and technology, training, etc.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"compliance_monitoring.md",
            "language":"en",
            "frontmatter":{
                "title":"Compliance monitoring & measurement",
                "contributors":[
                    "Christophe Trefois",
                    "Wei Gu",
                    "Pinar Alper",
                    "Markus Englund",
                    "Vera Ortseifen"
                ],
                "description":"How to measure compliance to data management regulations and standards.",
                "page_id":"compliance",
                "related_pages":{
                    "tool_assembly":[
                        "transmed"
                    ]
                },
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Assessing with FAIR Evaluator",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB049"
                    },
                    {
                        "name":"Assessing with FAIRshake",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB050"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_discoverability_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Aina Jen Cortada\n- Laura Portell Silva\ndescription: How to make data discoverable\npage_id: data_discoverability\ntitle: Data discoverability",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_discoverability.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_discoverability_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":0,
        "total_chunks":10,
        "content":"How can you make your data more discoverable?\nDescription\nData discovery involves processes and tools that help users understand what data is available, where it is stored, and how to access it. It includes querying datasets to find specific information based on given conditions. However, for data to be discoverable, it must be well-prepared. Making your data discoverable maximises its impact and utility, enabling others to find, access, and use it effectively. Discoverable data promotes transparency, reproducibility, and scientific progress. Achieving this requires detailed metadata and documentation, depositing data in public and institutional repositories, and using standardised formats for interoperability. Considerations\n\nDetailed Metadata: Provide comprehensive metadata for your datasets, including titles, descriptions, keywords, creators, dates, and other relevant information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":1,
        "total_chunks":10,
        "content":"datasets, including titles, descriptions, keywords, creators, dates, and other relevant information. Documentation: Include thorough documentation that explains the dataset, its structure, how it was collected and processed, and any limitations. Standard Schemas: Use standardised metadata schemas to ensure consistency and interoperability. Standard Formats: Use widely accepted data formats to ensure compatibility and ease of use. Public Repositories: Deposit your data in reputable public data repositories that are indexed by search engines and widely used by the research community. Solutions\n\nThere are several appropriate tools to create detailed (or comprehensive) metadata and document data properly for the project. Check the Documentation and metadata page for more information. Some scientific communities utilise platforms such as {% tool \"cedar\" %}, {% tool \"semares\" %}, {% tool \"fairdom-seek\" %}, {% tool \"fairdomhub\" %}, and {% tool \"copo\" %} for managing metadata and data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":2,
        "total_chunks":10,
        "content":"ol \"fairdom-seek\" %}, {% tool \"fairdomhub\" %}, and {% tool \"copo\" %} for managing metadata and data. Various standards exist for different data types, from general dataset descriptions such as {% tool \"data-catalog-vocabulary\" %}, {% tool \"dublincore\" %}, {% tool \"schema-org\" %} and {% tool \"bioschemas\" %}, to those tailored for specific data types, such as {% tool \"miabis\" %} for biosamples. Hence, selecting the appropriate standard at the project's outset is crucial. Typically, if you choose a suitable data repository for your data, it will come with an integrated metadata scheme, simplifying your work by eliminating the need to develop a separate metadata profile. Decide at the beginning of the project the right repository for your data type. To search for it, you can use the {% tool \"elixir-deposition-databases-for-biomolecular-data\" %}, {% tool \"re3data\" %} or {% tool \"fairsharing\" %} at Databases.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":3,
        "total_chunks":10,
        "content":"atabases-for-biomolecular-data\" %}, {% tool \"re3data\" %} or {% tool \"fairsharing\" %} at Databases. If your chosen repository lacks some of the metadata fields you wish to include and you need to add a separate file with this information (such as in Zenodo), you should adhere to the appropriate metadata schema. To identify the correct schema, you have several options:\n{% tool \"rda-standards\" %}\n{% tool \"fairsharing\" %} at Standards and Collections\n{% tool \"data-curation-centre-metadata-list\" %}\nThe ideal file formats vary based on the type of data, the availability and common acceptance of open file formats, and the research domain. There isn't a universal solution, so selecting the most suitable format for your specific needs is essential. The Data Organisation page provides a table with recommended file formats and best practices for research data management. How can you discover controlled access data? Description\nDiscovering research data for re-analysis can occur at different levels of granularity.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":4,
        "total_chunks":10,
        "content":" Description\nDiscovering research data for re-analysis can occur at different levels of granularity. Initially, researchers browse online catalogues that describe studies, datasets, related publications, variables, and some data distributions. This basic discovery may suffice if the datasets meet all the criteria. However, to find dataset that meet specific combinations of attributes  such as identifying datasets with particular combinations of attributes, like 'adults diagnosed with COVID-19 in the last year, fully vaccinated, with no underlying health conditions' (for example)  researchers must either contact the authors or request data access and verify themselves. This process is feasible for a small number of datasets and cooperative data controllers but it is usually time-consuming and uncertain. To streamline this, data discovery at the source allows users to query data non-disclosively, determining its relevance before requesting full access.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":5,
        "total_chunks":10,
        "content":"llows users to query data non-disclosively, determining its relevance before requesting full access. Considerations\n\nDetailed Metadata: ensure comprehensive metadata for your datasets, including detailed descriptions of studies, datasets, variables, and any available distributions. Data Catalogs and Repositories: use well-maintained online catalogs and repositories that support controlled access data, and check for advanced search features to filter datasets by specific attributes. Data Access Policies: get familiar with the data access policies of different repositories and datasets, understanding the requirements and procedures for requesting access to controlled data. Ethical and Legal Compliance: ensure compliance with ethical guidelines and legal regulations governing data use and sharing, and obtain necessary approvals from institutional review boards or ethics committees if required. Check the GDPR compliance and Ethical aspects pages for more information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":6,
        "total_chunks":10,
        "content":"cs committees if required. Check the GDPR compliance and Ethical aspects pages for more information. Data Access Request Process: be aware that the process for requesting and obtaining data access can be time-consuming, and prepare detailed justifications for data access requests, including research objectives and intended analyses. Privacy and Security Measures: implement robust privacy and security measures to protect sensitive data during discovery and after access is granted, ensuring data handling practices comply with data protection regulations. Check the Data sensitivity page for more information. Solutions\n{% tool \"beacon\" %}, developed through the Global Alliance for Genomics and Health (GA4GH) Discovery workstream, and with substantial support from ELIXIR, serves as a data discovery protocol and specification defining an open standard for discovering genomic and phenoclinic data in biomedical research and clinical applications.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":7,
        "total_chunks":10,
        "content":"ndard for discovering genomic and phenoclinic data in biomedical research and clinical applications. The latest version, {% tool \"beacon-v2\" %}, introduced expanded query options, enabling the retrieval of biological or technical (meta)data through filters defined via CURIEs. This includes, but not limited to, parameters such as phenotypes, disease codes, sex, or age, providing researchers with a nuanced approach to data inquiries. Beacon v2 is organised in two main blocks: the Beacon Framework and the Beacon Model. The Framework defines the format for the requests and responses, whereas the Model defines the structure of the biological data response. This dual-system approach not only broadens the scope for diverse Models  using different domains such as images, pathogens, or infectious diseases  but also reinforces the adaptability of the Framework. The overall function of these components is to provide the instructions to design a REST API that could be implemented as a stand-alone product or, preferably, extending existing data management solutions.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":8,
        "total_chunks":10,
        "content":"e implemented as a stand-alone product or, preferably, extending existing data management solutions. Consequently, the 'beaconised' data represents a significant enhancement in data discoverability with minimal risks. Currently, there are two ways to implement a Beacon:\n\nAPI on top of existing tools: This APIs is targeted to those organizations equipped with well-organised and structured data housed in databases, whether SQL or NoSQL, and possess the necessary resources and expertise to interpret and implement the Beacon v2 specification and construct an API on top of an existing tool. {% include image.html file=\"beacon-api. JPG\" inline=true caption=\"Figure 1. Beacon API functionality (Source)\" alt=\"Beacon API\" max-width=\"30em\"%}\n\n{% tool \"beacon-ri\" %}: an out-of-the-box example implementation of the Beacon v2 protocol. It is an open-source toolkit based on Python programming language and consists of tools for loading metadata, e.g. phenotypic data, from a CSV file and genomic variants from a VCF file into a MongoDB database.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_content_data_discoverability_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_discoverability.md",
        "file_name":"data_discoverability.md",
        "chunk_index":9,
        "total_chunks":10,
        "content":" e.g. phenotypic data, from a CSV file and genomic variants from a VCF file into a MongoDB database. It also features the Beacon query engine (REST API) and comes bundled with an example dataset (CINECA synthetic cohort EUROPE UK1) comprising synthetic data. You can find the GitHub Repository for Beacon v2 here. {% include image.html file=\"beacon-ri. JPG\" inline=true caption=\"Figure 2. Beacon RI functionality. (Source)\" alt=\"Beacon RI\" max-width=\"30em\" %}\nBuilding on B2RI, the {% tool \"b4omop\" %} software allows for the integration of a Beacon onto any OMOP Common Data Model (CDM) database. This enables organizations using the OMOP CDM to leverage the Beacon framework for querying and sharing genomic and phenotypic data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_discoverability.md",
            "language":"en",
            "frontmatter":{
                "title":"Data discoverability",
                "description":"How to make data discoverable",
                "contributors":[
                    "Aina Jen Cortada",
                    "Laura Portell Silva"
                ],
                "page_id":"data_discoverability"
            }
        }
    },
    {
        "id":"md_fm_costs_data_management_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Siiri Fuchs\n- Minna Ahokas\n- Robert Andrews\n- Anna Strachotova\n- Nazeefa Fatima\ndescription: Budgeting and costing for data management\npage_id: costs\nrelated_pages: null\ntitle: Costs of data management",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"costs_data_management.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_costs_data_management_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":0,
        "total_chunks":8,
        "content":"How to estimate the costs of data management? Description\nThe processes of data management will incur costs. The expenses may consist of peoples time, tools and services needed for managing the research data during the whole life cycle of the project. You should estimate these costs and address the resources needed in your data management plan. Considerations\n\nBudgeting and costing for your data management is often dependent upon local and temporal circumstances, institutional resources, services, and policies. You have to take into account even items such as investments (site services, infrastructure), operations (network, electricity, maintenance) and personnel costs. Most research funders will cover justifiable RDM costs. In research funding applications remember, that there are typically two types of eligible costs. Direct costs referring to eg. staff time and equipment and indirect costs including things like administrative and financial management.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"costs_data_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Costs of data management",
                "description":"Budgeting and costing for data management",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Robert Andrews",
                    "Anna Strachotova",
                    "Nazeefa Fatima"
                ],
                "page_id":"costs",
                "related_pages":null
            }
        }
    },
    {
        "id":"md_content_costs_data_management_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":1,
        "total_chunks":8,
        "content":"time and equipment and indirect costs including things like administrative and financial management. Note that there may be costs of data even beyond the end of the project. Planning and implementing data management well can save you from arising costs later on during your research project. The bigger your project (or e.g. infrastructure) is or the more partners are involved, it is useful to consider the measures needed to implement and operationalise data management. For example, would you need a dedicated data manager?, should roles and responsibilities about various data management activities be allocated?, do you need training, other resources, or extra time? All of these aspects are important to be taken into consideration when addressing data management costs. Solutions\n\nTo get an overview of possible costs in your research project, you can go through different research life cycle phases and activities specific for your project.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"costs_data_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Costs of data management",
                "description":"Budgeting and costing for data management",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Robert Andrews",
                    "Anna Strachotova",
                    "Nazeefa Fatima"
                ],
                "page_id":"costs",
                "related_pages":null
            }
        }
    },
    {
        "id":"md_content_costs_data_management_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":2,
        "total_chunks":8,
        "content":"t, you can go through different research life cycle phases and activities specific for your project. Some organisations have created tools, for their users, to help formulate and budget data management costs; such as {% tool \"data-stewardship-wizard-storage-costs-evaluator\" %}, the {% tool \"uk-data-service-data-management-costing-tool\" %} developed by the UK Data Service, and the {% tool \"tu-delft-data-management-costing-tool\" %}. These tools can help to budget for personnel costs and\/or additional costs that are needed to preserve and share research data beyond a research project. Costs for data stewards\n\nPersonnel costs for data stewards is an eligible cost in many projects although with limitations on the number of full time employee (FTE). Check if this cost is eligible in your grant. Consider which data management tasks will be carried out by a data steward, and how many person-months will be needed for that. Costs for data collection\n\nCollecting and reusing data: Collecting data sometimes involves equipment or services that may incur costs.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"costs_data_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Costs of data management",
                "description":"Budgeting and costing for data management",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Robert Andrews",
                    "Anna Strachotova",
                    "Nazeefa Fatima"
                ],
                "page_id":"costs",
                "related_pages":null
            }
        }
    },
    {
        "id":"md_content_costs_data_management_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":3,
        "total_chunks":8,
        "content":"ing and reusing data: Collecting data sometimes involves equipment or services that may incur costs. On the other hand, if you reuse data from a data repository it is worth checking whether there are some costs involved using the service. Granularity of data: When collecting data it can be tempting to collect more data than is required to answer the research question. Hence, it is important to consider what data is needed as the more data you have, the more expensive it gets to store, clean, and transfer the data. Organizing and formatting data: Keeping data organized from the start of the project will help to manage the data later. Keep an up-to-date data catalogue\/registry of data provenance and plan beforehand a clear file structure, names and templates so the involved costs and time spent on organizing the data are lower. Costs for data processing and data documentation\n\nAnonymisation & pseudonymisation: When working with sensitive or confidential data, consider the possibility of anonymising or pseudonymising the data for controlled or public release.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"costs_data_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Costs of data management",
                "description":"Budgeting and costing for data management",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Robert Andrews",
                    "Anna Strachotova",
                    "Nazeefa Fatima"
                ],
                "page_id":"costs",
                "related_pages":null
            }
        }
    },
    {
        "id":"md_content_costs_data_management_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":4,
        "total_chunks":8,
        "content":"consider the possibility of anonymising or pseudonymising the data for controlled or public release. Costs may rise either from time spent on anonymise data or if the service needs to be bought from an expert. Digitisation: Some project data can be in a paper-based or analogue format that needs to be digitised. Consider if special services, equipment or software are needed and if results need to be manually checked. These may incur direct costs or time consumed. Data documentation: To make data understandable, it needs to be documented, meaning creating information, which enables the interpretations of the data correctly and independently. Describing the data context, methodology, creation process, what the variables and abbreviations mean, as well as how the data was processed and quality controlled takes time. Data cleaning: Cleaning data files or verifying data take time and accuracy. At the end of the project cleaning data files for sharing purposes take much more time than keeping the data well organised during the project while collecting and processing it.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"costs_data_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Costs of data management",
                "description":"Budgeting and costing for data management",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Robert Andrews",
                    "Anna Strachotova",
                    "Nazeefa Fatima"
                ],
                "page_id":"costs",
                "related_pages":null
            }
        }
    },
    {
        "id":"md_content_costs_data_management_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":5,
        "total_chunks":8,
        "content":"ore time than keeping the data well organised during the project while collecting and processing it. Costs for data storing, access control and security measures\n\nData storage and back-up: Regardless of data types your research project has, the data needs to be stored in a secure place with adequate access control. Consider your needs for active data storage during the lifetime of the project, as well as archiving needs beyond the end of the study. Find out storing costs from your local service provider. Access and security: To protect data from unauthorised use, consider what kind of access control and security measures does your data need. Especially, if you work with sensitive or confidential data, there might be solutions that incur costs, for example if special protected servers or services or software for encrypting data are needed. Costs for making data available (publishing\/sharing) and preserving\n\nData sharing: Publishing and sharing data is highly recommended and there are many services available for that.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"costs_data_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Costs of data management",
                "description":"Budgeting and costing for data management",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Robert Andrews",
                    "Anna Strachotova",
                    "Nazeefa Fatima"
                ],
                "page_id":"costs",
                "related_pages":null
            }
        }
    },
    {
        "id":"md_content_costs_data_management_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":6,
        "total_chunks":8,
        "content":"g: Publishing and sharing data is highly recommended and there are many services available for that. Depending on what service suits your needs, there can be costs that the service provider charges to keep the data available such as a sum per GB or per year. Take also into consideration that cleaning the data to a format that it can be shared as well as creating discovery metadata will take time. The most straightforward and often most cost-effective way to make data available is to deposit it in a public data repository service. Data reuse: When making your research data available to others, you have to consider if other parties hold copyright in the data and if you need to seek copyright clearance before sharing data. There may incur costs from juridicial advice and time required to seek copyright clearance. Read more about licensing research data. File formats: Data analysis sometimes involves data conversion, that changes the structure in data organisation.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"costs_data_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Costs of data management",
                "description":"Budgeting and costing for data management",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Robert Andrews",
                    "Anna Strachotova",
                    "Nazeefa Fatima"
                ],
                "page_id":"costs",
                "related_pages":null
            }
        }
    },
    {
        "id":"md_content_costs_data_management_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/costs_data_management.md",
        "file_name":"costs_data_management.md",
        "chunk_index":7,
        "total_chunks":8,
        "content":": Data analysis sometimes involves data conversion, that changes the structure in data organisation. Converting data to a different (open or standard) format for sharing or preserving data can incur costs, and therefore, it is important to ask: is there additional software or hardware required for data conversion? How much additional space is required to store new files? Does converted data need to be stored elsewhere, and do the source files need to be transferred too?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"costs_data_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Costs of data management",
                "description":"Budgeting and costing for data management",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Robert Andrews",
                    "Anna Strachotova",
                    "Nazeefa Fatima"
                ],
                "page_id":"costs",
                "related_pages":null
            }
        }
    },
    {
        "id":"md_fm_storage_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"contributors:\n- Ulrike Wittig\n- Elin Kronander\n- Munazah Andrabi\n- Flora D'Anna\n- Flavio Licciulli\n- Ott Oopkaup\n- Marcus Lundberg\n- Thanasis Vergoulis\n- Frederik Coppens\n- Olivier Collin\n- Nadia Tonello\n- Korbinian Bsl\ndescription: How to find appropriate storage solutions.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"storage.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_storage_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"vier Collin\n- Nadia Tonello\n- Korbinian Bsl\ndescription: How to find appropriate storage solutions. dsw:\n- name: Data storage systems and file naming conventions\n  uuid: bc5e3dbf-2923-4025-a49a-f204b01d4018\n- name: How long will this data set be kept?\n  uuid: d4e6a244-07fb-4573-b93f-c20a9409ac7c\n- name: Will you be storing data in an \"object store\" or a \"document store\" system?\n  uuid: dc39957e-688a-4f71-a6a8-57f52509e7cf\nfaircookbook:\n- name: Licensing Software\n  url: https:\/\/w3id.org\/faircookbook\/FCB033\n- name: Making Computational Workflows FAIR\n  url: https:\/\/w3id.org\/faircookbook\/FCB062\n- name: Depositing to generic repositories - Zenodo use case\n  url: https:\/\/w3id.org\/faircookbook\/FCB009\n- name: Registering datasets with Wikidata\n  url: https:\/\/w3id.org\/faircookbook\/FCB060\npage_id: storage\nrelated_pages:\n  tool_assembly:\n  - nels\n  - tsd\n  - ome\n  - transmed\n  - xnat_pic\ntitle: Data storage\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"storage.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_storage_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":0,
        "total_chunks":12,
        "content":"What features do you need in a storage solution when collecting data? Description\nThe need for Data storage arises early on in a research project, as space will be required to put your data when starting collection or generation. Therefore, it is a good practice to think about storage solutions during the data management planning phase, and request storage in advance and\/or pay for it. The storage solution for your data should fulfil certain criteria (e.g. space, access & transfer speed, duration of storage, etc.), which should be discussed with the IT team. You may choose a tiered storage system for assigning data to various types of storage media based on requirements for access, performance, recovery and cost. Using tiered storage allows you to classify data according to levels of importance and assign it to the appropriate storage tiers or move it to different tier for e.g. once analysis is completed you have the option to move data to lower tier for preservation or archiving.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":1,
        "total_chunks":12,
        "content":" analysis is completed you have the option to move data to lower tier for preservation or archiving. Tiered Storage is classified as Cold or Hot Storage. Hot storage is associated with fast access speed, high access frequency, high value data and consists of faster drives such as the Solid State Drives (SSD). This storage is usually located in close proximity to the user such as on campus and incurs high costs. Cold storage is associated with low access speed and frequency and consists of slower drives or tapes. This storage is usually off-premises and incurs low cost. Considerations\nWhen looking for solutions to store your data during the collection or generation phase, you should consider the following aspects. The volume of your data is an important discerning factor to determine the appropriate storage solution. At the minimum, try to estimate the volume of raw data that you are going to generate or collect. What kind of access\/transfer speed and access frequency will be required for your data. Knowing where the data will come from is also crucial.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":2,
        "total_chunks":12,
        "content":"ess frequency will be required for your data. Knowing where the data will come from is also crucial. If the data comes from an external facility or needs to be transferred to a different server, you should think about an appropriate data transfer method. It is a good practice to have a copy of the original raw data in a separate location, to keep it untouched and unchanged (not editable). Knowing for how long the raw data, as well as data processing pipelines and analysis workflows need to be stored, especially after the end of the project, is also a relevant aspect for storage. It is highly recommended to have metadata, such as an identifier and file description, associated with your data (see Documentation and metadata page). This is useful if you want to retrieve the data years later or if your data needs to be shared with your colleagues for collaboration. Make sure to keep metadata together with the data or establish a clear link between data and metadata files.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":3,
        "total_chunks":12,
        "content":"e to keep metadata together with the data or establish a clear link between data and metadata files. In addition to the original read-only raw (meta)data files, you need storage for files used for data processing and analysis as well as the workflows\/processes used to produce the data. For these, you should consider:\nwho is allowed  to access the data (in case of collaborative projects), how do they expect to access the data and for what purpose;\ncheck if you have the rights to give access to the data, in case of legal limitations or third party rights (for instance, collaboration with industry);\n\nconsult policy for data sharing outside the institute\/country (see Compliance monitoring page). Keeping track of the changes (version control), conflict resolution and back-tracing capabilities. Solutions\n\nProvide an estimate about the volume of your raw data (i.e., is it in the order of Megabytes, Gigabytes or Terabytes?) to the IT support in your institute when consulting for storage solutions. Clarify if your data needs to be transferred from one location to another.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":4,
        "total_chunks":12,
        "content":"ng for storage solutions. Clarify if your data needs to be transferred from one location to another. Try to provide IT with as much information as possible about the system where the data will come from. See our Data transfer page for additional information. Ask for a tiered storage solution that gives you easy and fast access to the data for processing and analysis. Explain to the IT support what machine or infrastructure you need to access the data from and if other researchers should have access as well (in case of collaborative projects). Ask if the storage solution includes an automatic management of versioning, conflict resolution and back-tracing capabilities (see also our Data organisation page). Ask the IT support in your institute if they offer technical solutions to keep a copy of your (raw)data secure and untouched (snapshot, read-only access, backup). You could also keep a copy of the original data file in a separate folder as read-only.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":5,
        "total_chunks":12,
        "content":" backup). You could also keep a copy of the original data file in a separate folder as read-only. For small data files and private or collaborative projects within your institute, commonly accessible Cloud Storage is usually provided by the institute, such as {% tool \"nextcloud\" %} (on-premises), {% tool \"microsoft-onedrive\" %}, {% tool \"dropbox\" %}, {% tool \"box\" %}, etc. Do not use personal accounts on similar services for this purpose, adhere to the policies of your institute. For large data sets consider cloud storage services, such as {% tool \"sciencemesh\" %}, {% tool \"openstack\" %}) and cloud synchronization and sharing services ({% tool \"cs3\" %}), such as {% tool \"cernbox\" %} or {% tool \"seafile\" %} It is a requirement from the funders or universities to store raw data and data analysis workflows (for reproducible results) for a certain amount of time after the end of the project (see our Preserve page). This is usually a requirement.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":6,
        "total_chunks":12,
        "content":" amount of time after the end of the project (see our Preserve page). This is usually a requirement. Check the data policy for your project or institute to know if a copy of the data should be also stored at your institute for a specific time after the project. This helps you budget for storage costs and helps your IT support with estimation of storage resources needed. Make sure to generate good documentation (i.e., README file) and metadata together with the data. Follow best practices for folder structure, file naming and versioning systems (see our Data organisation page). Check if your institute provides a (meta)data management system, such as {% tool \"irods\" %}, {% tool \"dataverse\" %}, {% tool \"fairdom-seek\" %} or {% tool \"osf\" %}. How do you estimate computational resources for data processing and analysis? Description In order to process and analyse your data, you will need access to computational resources. This ranges from your laptop, local compute clusters to High Performance Computing (HPC) infrastructures.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":7,
        "total_chunks":12,
        "content":"ranges from your laptop, local compute clusters to High Performance Computing (HPC) infrastructures. However, it can be difficult to be able to estimate the amount of computational resource needed for a process or an analysis. Considerations\nBelow, you can find some aspects that you need to consider to be able to estimate the computational resource needed for data processing and analysis. The volume of total data is an important discerning factor to estimate the computational resources needed. Consider how much data volume you need concurrently or at once. For example, consider the possibility to analyse a large dataset by downloading or accessing only a subset of the data at a  time (e.g., stream 1 TB at a time from a big dataset of 500 TB). Define the expected speed and the reliability of connection between storage and compute. Determine which software you are going to use. If it is a proprietary software, you should check possible licensing issues. Check if it only runs on specific operative systems (Windows, MacOS, Linux,). Establish if and what reference datasets you need.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":8,
        "total_chunks":12,
        "content":"ific operative systems (Windows, MacOS, Linux,). Establish if and what reference datasets you need. In the case of collaborative projects, define who can access the data and the computational resource for analysis (specify from what device, if possible). Check policy about data access between different Countries. Try to establish a versioning system. Solutions\n\nTry to estimate the volume of:\nraw data files necessary for the process\/analysis;\ndata files generated during the computational analysis as intermediate files;\nresults data files. Communicate your expectations about speed and the reliability of connection between storage and compute to the IT team. This could depend on the communication protocols that the compute and storage systems use. It is recommended to ask about the time span for analysis to colleagues or bioinformatic support that have done similar work before. This could save you money and time.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":9,
        "total_chunks":12,
        "content":"ues or bioinformatic support that have done similar work before. This could save you money and time. If you need some reference datasets (e.g the reference genomes such as human genome.), ask IT if they provide it or consult  bioinformaticians that can set up automated public reference dataset retrieval. For small data files and private projects, using the computational resources of your own laptop might be fine, but make sure to preserve the reproducibility of your work by using data analysis software such as {% tool \"galaxy\" %} or {% tool \"r-markdown\" %}. For small data volume and small collaborative projects, a commonly accessible cloud storage, such as {% tool \"nextcloud\" %} (on-premises) or {% tool \"owncloud\" %} might be fine. Adhere to the policies of your institute. For large data volume and bigger collaborative projects, you need a large storage volume on fast hardware that is closely tied to a computational resource accessible to multiple users, such as {% tool \"rucio\" %}, {% tool \"transmart\" %}, {% tool \"semares\" %} or {% tool \"research-data-management-platform\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":10,
        "total_chunks":12,
        "content":" %}, {% tool \"transmart\" %}, {% tool \"semares\" %} or {% tool \"research-data-management-platform\" %}. Where should you store the data after the end of the project? Description\nAfter the end of the project, all the relevant (meta)data (to guarantee reproducibility) should be preserved for a certain amount of time, that is usually defined by funders or institution policy. However, where to preserve data that are not needed for active processing or analysis anymore is a common question in data management. Considerations\n\nData preservation doesnt refer to a place nor to a specific storage solution, but rather to the way or how data can be stored. As described in our Preservation page, numerous precautions need to be implemented by people with a variety of technical skills to preserve data. Estimate the volume of the (meta)data files that need to be preserved after the end of the project. Consider using a compressed file format to minimize the data volume. Define the amount of time (hours, days) that you could wait in case the data needs to be reanalysed in the future.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_storage_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/storage.md",
        "file_name":"storage.md",
        "chunk_index":11,
        "total_chunks":12,
        "content":"nt of time (hours, days) that you could wait in case the data needs to be reanalysed in the future. It is a good practice to publish your data in public data repositories. Usually, data publication in repositories is a requirement for scientific journals and funders. Repositories preserve your data for a long time, sometimes for free. See our Data publication page for more information. Institutes or universities could have specific policies for data preservation. For example, your institute can ask you to preserve the data internally for 5 years after the project, even if the same data is available in public repositories. Solutions\n\nBased on the funders or institutional policy about data preservation, the data volume and the retrieval time span, discuss with the IT team what preservation solutions they can offer (i.e., data archiving services in your Country) and the costs, so that you can budget for it in your DMP. Publish your data in public repositories, and they will preserve the data for you.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"storage.md",
            "language":"en",
            "frontmatter":{
                "title":"Data storage",
                "contributors":[
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Munazah Andrabi",
                    "Flora D'Anna",
                    "Flavio Licciulli",
                    "Ott Oopkaup",
                    "Marcus Lundberg",
                    "Thanasis Vergoulis",
                    "Frederik Coppens",
                    "Olivier Collin",
                    "Nadia Tonello",
                    "Korbinian Bsl"
                ],
                "description":"How to find appropriate storage solutions.",
                "page_id":"storage",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "tsd",
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+storage%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    },
                    {
                        "name":"How long will this data set be kept?",
                        "uuid":"d4e6a244-07fb-4573-b93f-c20a9409ac7c"
                    },
                    {
                        "name":"Will you be storing data in an \"object store\" or a \"document store\" system?",
                        "uuid":"dc39957e-688a-4f71-a6a8-57f52509e7cf"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    },
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    },
                    {
                        "name":"Registering datasets with Wikidata",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB060"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_provenance_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_provenance.md",
        "file_name":"data_provenance.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Flora D'Anna\n- Korbinian Bsl\n- Nazeefa Fatima\ndescription: How to record information about data provenance. page_id: data_provenance\nrelated_pages:\n  tool_assembly: []\ntitle: Data provenance\ntraining:\n- name: null\n  registry: null\n  url: null",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_provenance.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_provenance_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_provenance.md",
        "file_name":"data_provenance.md",
        "chunk_index":0,
        "total_chunks":4,
        "content":"How to document and track your data provenance? Description\nProvenance is the documentation of why and how the data (but also datasets, computational analysis and other research output) was produced, where, when and by whom. Data provenance is often used interchangeably with the term data lineage, although their definition might slightly differs in some contexts. Data provenance\/lineage means tracing the movements and the changes of the data that occurred between their origin and their destination system. Well-documented data provenance is essential for assessing authenticity, credibility, trustworthiness, quality (it helps finding errors) and reusability of data, as well as the reproducibility of the results. However, knowing whats the best way to document provenance can be challenging due to the large amount and variety of the information that need to be recorded. Considerations\n\nProvence is part of documentation and metadata.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_provenance.md",
            "language":"en",
            "frontmatter":{
                "title":"Data provenance",
                "description":"How to record information about data provenance.",
                "contributors":[
                    "Flora D'Anna",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "page_id":"data_provenance",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_provenance_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_provenance.md",
        "file_name":"data_provenance.md",
        "chunk_index":1,
        "total_chunks":4,
        "content":"nformation that need to be recorded. Considerations\n\nProvence is part of documentation and metadata. Many aspects of data documentation and metadata are related to provenance information, such as history log, versioning, licence, citation, identifiers, etc. Moreover, data provenance is related to several other aspects of data management, namely data access rights, governance, privacy and security. Provence information can be recorded:\nas free text and unstructured information (mainly readable for humans, not for machines\/software), describing data collection and processing method.\naccording to metadata schemas or standards, that can be generic (e.g. {% tool \"dublincore\" %}) or discipline specific such as ISO19115-2.\naccording to Provenance Data Model ({% tool \"prov-dm-the-prov-data-model\" %}) and ontology (PROV-O). As for documentation and metadata, the medium to capture provenance information can also varies.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_provenance.md",
            "language":"en",
            "frontmatter":{
                "title":"Data provenance",
                "description":"How to record information about data provenance.",
                "contributors":[
                    "Flora D'Anna",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "page_id":"data_provenance",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_provenance_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_provenance.md",
        "file_name":"data_provenance.md",
        "chunk_index":2,
        "total_chunks":4,
        "content":"O). As for documentation and metadata, the medium to capture provenance information can also varies. Provenance trails can be captured \nin text files or spreadsheets\nin registries or databases\nin dedicated software\/platforms (such as LIMS)\ninternally and automatically by software tools during their processing activity (such as workflow management systems) As for documentation and metadata, provenance information can be recorded and displayed\/visualised in machine-readable (see Machine actionability page) and\/or human-readable form. Solutions\n\nRecord provenance according to schemas or defined profiles. These can be generic or domain-specific, and can be found in {% tool \"rda-standards\" %} or {% tool \"fairsharing\" %}. Use metadata schemas containing provenance information in your README file and in any kind of data documentation and metadata file.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_provenance.md",
            "language":"en",
            "frontmatter":{
                "title":"Data provenance",
                "description":"How to record information about data provenance.",
                "contributors":[
                    "Flora D'Anna",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "page_id":"data_provenance",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_provenance_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_provenance.md",
        "file_name":"data_provenance.md",
        "chunk_index":3,
        "total_chunks":4,
        "content":" provenance information in your README file and in any kind of data documentation and metadata file. Best practices for documentation and metadata, and data organisation should be applied for provenance file as well.\nImplement serialisation specification of the PROV-MODEL in your data management tools to record provenance in machine-actionable format (RDF, Linked data, owl, xml, etc.). Use RO-Crate specifications and\/or specific profiles for provenance (e.g., RO-Crate profiles to capture the provenance of workflow runs). Make use of tools and software that help you record provenance in a manual or an automated way. Use:\nElectronic Data Capture (EDC) systems, Laboratory Information Management Systems (LIMS) or similar tools. Workflow management systems (such as Kepler, {% tool \"galaxy\" %}, Taverna, VisTrails); provenance information embedded in such software or tools are usually available to users of the same tool or can be exported as separated file in several formats, such as {% tool \"research-object-crate\" %}. Registries such as {% tool \"workflowhub\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_provenance.md",
            "language":"en",
            "frontmatter":{
                "title":"Data provenance",
                "description":"How to record information about data provenance.",
                "contributors":[
                    "Flora D'Anna",
                    "Korbinian Bsl",
                    "Nazeefa Fatima"
                ],
                "page_id":"data_provenance",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":null,
                        "registry":null,
                        "url":null
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_identifiers_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Markus Englund\n- Flavio Licciulli\n- Nick Juty\n- Olivier Collin\n- Ulrike Wittig\n- Ivan Mieti\n- Karel Berka\n- Shuxin Zhang\n- Hinri Kerstens\n- Flora D'Anna\n- Yvonne Kallberg\n- Rob Hooft\ndescription: How to use identifiers for research data. dsw:\n- name: Will you make explicit cross-reference between physical samples and your digital\n    data?\n  uuid: 9e238002-da35-4f9b-a9b7-8fe3613a3c03\n- name: Will this data be assigned a persistent identifier?\n  uuid: d21fdb06-22bf-418e-aa40-dc5ef1485f56\nfaircookbook:\n- name: Creating resolvable identifiers\n  url: https:\/\/w3id.org\/faircookbook\/FCB077\n- name: Interlinking data from different sources\n  url: https:\/\/w3id.org\/faircookbook\/FCB016\n- name: Introducing unique, persistent identifiers\n  url: https:\/\/w3id.org\/faircookbook\/FCB006\n- name: Minting identifiers with Globus Minid client\n  url: https:\/\/w3id.org\/faircookbook\/FCB008\npage_id: identifiers\nrelated_pages:\n  tool_assembly: []\ntitle: Identifiers",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"identifiers.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_identifiers_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":0,
        "total_chunks":15,
        "content":"Which types of identifiers can you use during data collection? Description\nA lot of (meta)data is collected in the form of tables, representing quantitative or qualitative measurements (values in cells) of certain named properties (variables in columns) of a range of subjects or samples (records or observations in rows). It can help your research a lot if you make sure you can address each of these records, variables and values unambiguously, i.e. if each has a unique identifier. This is also true for (meta)data that is not in tabular format (key:value format, unstructured data, etc.). Identifiers should always be used for metadata and data independently of the format. If the research institute or group has a centralised and structured system (such as a central electronic database) in place to describe and store (meta)data, this process can be quite straightforward for the researcher.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":1,
        "total_chunks":15,
        "content":"lace to describe and store (meta)data, this process can be quite straightforward for the researcher. However, if there is no such system, often researchers have to set up an internal database to keep track of each record or observation in a study. This situation can be quite challenging for many reasons, one of which is assigning identifiers. The use of identifiers for records, variables and values will increase the reusability and interoperability of the data for you, your future self and others. Considerations\n\nAt the beginning of your research project, check if your institute or research group has a centralised database where data must be entered during data collection. Usually, large and international research projects, industries, research institutes or hospitals have a centralised electronic database, an Electronic Data Capture (EDC) system, a Laboratory Information Management System (LIMS) or an Electronic Lab Notebook (ELN) with a user interface for data entry.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":2,
        "total_chunks":15,
        "content":"n Management System (LIMS) or an Electronic Lab Notebook (ELN) with a user interface for data entry. More details about using ELNs are given by e.g. {% tool \"university-of-cambridge-electronic-research-notebook-products\" %} and {% tool \"harvard-medical-school-electronic-lab-notebooks\" %}. If you can choose how to manage your data entry system, consider what the level of exposure of the identifier for each record or observation in the dataset should be. Define the context in which the identifier should be used and is unique. This is a key aspect of defining what kind of identifier for each individual record is appropriate in your case. Should the identifier of a record or observation be unique within your spreadsheet, your entire research project files or across the whole institute? What is the reference system (or target audience\") of your identifier? Will your reference system change in due time? If it will be opened up later, assigning globally unique identifiers from the beginning may save time.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":3,
        "total_chunks":15,
        "content":" it will be opened up later, assigning globally unique identifiers from the beginning may save time. Will the identifiers for individual records or observations be made openly accessible on the internet, during data collection? If the identifier of an individual record or observation should be unique only within your research group (within an intranet), and it will not be available on the internet, it can be considered an internal or local identifier. A local identifier is unique only in a specific local context (e.g. single collection or dataset). Local identifiers can be applied not only for individual records or observations in a dataset but also for each variable or even value (columns and cells in a tabular dataset, respectively). Identifiers for an individual record, variable and value in a dataset can be assigned by using ontology terms (see metadata page) or accession numbers provided by public databases such as EBI and {% tool \"national-center-for-biotechnology-information\" %} repositories.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":4,
        "total_chunks":15,
        "content":"c databases such as EBI and {% tool \"national-center-for-biotechnology-information\" %} repositories. Here there are few examples for tabular (meta)data, but the same type of identifiers can be applied independently of the (meta)data structure and format. The patient ID is in its own row, a column header is the variable disease from the EFO ontology (ID EFO:0000408), and the value in the cell is the child term chronic fatigue syndrome (ID EFO:0004540) of disease. The specimen ID is in its own row, a column header is the variable Ensembl gene ID from the {% tool \"ensembl\" %} genome browser and the value in the cell is the identifier for BRCA1 gene ENSG00000012048. On top of identifiers for domain-specific metadata, more general fields such as research organisation, project participants, and funders are also typically described using identifiers.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":5,
        "total_chunks":15,
        "content":"arch organisation, project participants, and funders are also typically described using identifiers. Solutions\n\nIf your institute or research group uses centralised electronic databases (EDC, LIMS, ELN, etc.), follow the related guidelines for generating and assigning identifiers to individual records or observations, within the database. Some institutes have a centralised way of providing identifiers; ask the responsible team for help. Internal or local identifiers should be unique names based on specific naming conventions and formal patterns, such as regular expression. Encode the regular expression into your spreadsheet or software and make sure to describe your regular expression in the documentation (README file or codebook). Avoid ambiguity. Identifiers that identify specimens (such as a biopsy or a blood sample), animal or plant models or patients could be written to the specimen tubes, the animal or plant model tags and patients files, respectively. Avoid embedding meaning into your local identifier.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":6,
        "total_chunks":15,
        "content":"ant model tags and patients files, respectively. Avoid embedding meaning into your local identifier. If you need to convey meaning in a short name implement a label for human readability only (Lesson 4. Avoid embedding meaning or relying on it for uniqueness). Do not use problematic characters and patterns in your local identifier (Lesson 5. Avoid embedding meaning or relying on it for uniqueness). Problematic strings can be misinterpreted by some software. In this case, it is better to fix the bugs or explicitly declare this possible issue in documentation. Ontology terms or accession numbers provided by public databases, such as EBI and NCBI repositories, can be applied to uniquely identify genes, proteins, chemical compounds, diseases, species, etc. Choose exactly one for each type to be the most interoperable with yourself. Identifiers for molecules, assigned by EBI and NCBI repositories, keep track of relations between identifiers (for instance, different versions of a molecule).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":7,
        "total_chunks":15,
        "content":"ories, keep track of relations between identifiers (for instance, different versions of a molecule). You can also submit your newly identified molecules to EBI or NCBI repositories to get a unique identifier. Applying ontologies to variables keeps clear structure and relations between variables (i.e., \"compound & dose\", \"variable & unit\"). Some pieces of software that allow you to integrate ontology terms into a spreadsheet are: {% tool \"rightfield\" %} and {% tool \"onotomaton\" %}. If you keep track of each record in a tabular format that gets new rows every day, use a versioning system to track the changes. Many cloud storage services offer automatic versioning or keep a versioning log (see data organisation page). Some parts of the tabular (meta)data file must be stable to be useful: do not delete or duplicate essential columns. Generate documentation about your tabular (meta)data file (README file, Codebook, etc.).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":8,
        "total_chunks":15,
        "content":"al columns. Generate documentation about your tabular (meta)data file (README file, Codebook, etc.). If you collect data from a database that is frequently updated (dynamic or evolving database), it is recommended to keep track not only of the database ID, but also of the used version (by timestamp, or by recording date and time of data collection) and of the exact queries that you performed. In this way, the exact queries can be re-executed against the timestamped data store (Data citation of evolving data). If you reuse an existing dataset, keep the provided identifier for provenance and give a new identifier according to your system, but preserve the relation with the original identifier to be able to trace back to the source. Use a spreadsheet or create a mapping file to keep the relation between provenance and internal identifier. To set up a centralised machine-readable database, an EDC, a LIMS or an ELN for large research projects or institutes (available on intranet), highly specialised technical skills in databases, programming and computer science might be needed.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":9,
        "total_chunks":15,
        "content":" highly specialised technical skills in databases, programming and computer science might be needed. We encourage you to talk to the IT team or experts in the field to find software and tools to implement such a system. Pieces of software to make a machine-readable system for databases and data collection are available. Their interfaces are quite user-friendly, but command-line skills might be needed depending on the kind of use that you need. {% tool \"molgenis\" %} is a modular web application for scientific data. MOLGENIS was born from molecular genetics research but has grown to be used in many scientific areas such as biobanking, rare disease research, patient registries, and even energy research. MOLGENIS provides researchers with user-friendly and scalable software infrastructures to capture, exchange, and exploit the large amounts of data produced by scientific organisations all around the world. {% tool \"castor\" %} is an EDC system for researchers and institutions. With Castor, you can create and customise your own database in no time.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":10,
        "total_chunks":15,
        "content":"esearchers and institutions. With Castor, you can create and customise your own database in no time. Without any prior technical knowledge, you can build a study in just a few clicks using an intuitive Form Builder. Simply define your data points and start collecting high-quality data, all you need is a web browser. {% tool \"redcap\" %} is a secure web application for building and managing online surveys and databases. While REDCap can be used to collect virtually any type of data in any environment, it is specifically geared to support online and offline data capture for research studies and operations. We do not encourage setting up a centralised electronic database that will be exposed to the internet, unless really necessary. We encourage you to use existing and professional deposition databases to publish and share your datasets (see below).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":11,
        "total_chunks":15,
        "content":"o use existing and professional deposition databases to publish and share your datasets (see below). For generic fields to enter either your metadata entries or data management plan, it is very common to use:\n{% tool \"ror\" %} to indicate affiliation\n{% tool \"orcid\" %} to indicate the contributors\n{% tool \"ofr\" %} to indicate the funder \n\nWhich type of identifiers should you use for data publication? Description\nWhen all records and measurements have been collected and you are ready to share your entire dataset with others, it is good practice to assign globally unique persistent identifiers to make your dataset more FAIR. \"A Globally Unique Identifier (GUID) is a unique number that can be used as an identifier for anything in the universe and the uniqueness of a GUID relies on the algorithm that was used to generate it\" (What is a GUID?). A persistent identifier (PID) is a long-lasting reference to a resource. That resource might be a publication, dataset or person.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":12,
        "total_chunks":15,
        "content":" is a long-lasting reference to a resource. That resource might be a publication, dataset or person. Equally, it could be a scientific sample, funding body, set of geographical coordinates, unpublished report, or piece of software. Whatever it is, the primary purpose of the PID is to provide the information required to reliably identify, verify, and locate it. A PID may be connected to a set of metadata describing an item rather than to the item itself\" (What is a persistent identifier, OpenAIRE). This means that any dataset with a PID will be findable even if the location of the dataset and its web address (URL) changes. The central registry that manages PID will ensure that the given PID will point you to the digital resource's current location. There are different types of PID, such as DOI, PURL, Handle, IGSN and URN. The GO FAIR Foundation provides examples of GUID, PID and services that supply identifiers. Considerations\nPIDs are essential to make your digital object (datasets or resources) citable, enabling you to claim and receive credit for your research output.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":13,
        "total_chunks":15,
        "content":" (datasets or resources) citable, enabling you to claim and receive credit for your research output. In turn, when you reuse someone else research output, you have to cite it. There are different ways to obtain a globally unique persistent identifier, and you need to decide which one is the best solution for your dataset or resource. * By publishing into an existing public repository. For most types of data, this is usually the best option because the repository will assign a globally unique persistent identifier or an accession number. Update your internal database to keep the relationship with public identifiers. * By opening up your local database to the public. This requires that the resource has a sustainability plan, as well as policies for versioning and naming of identifiers. While this option could be a viable solution if there is no public repository that allows for the right level of exposure of your data, it puts a lot of responsibility on your shoulders for future maintenance and availability.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_identifiers_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/identifiers.md",
        "file_name":"identifiers.md",
        "chunk_index":14,
        "total_chunks":15,
        "content":"our data, it puts a lot of responsibility on your shoulders for future maintenance and availability. Solutions\n\nIf you want to publish your data into an existing public repository, please see our data publication page. The repository will provide globally unique persistent identifiers for your data. Check their guidelines if you need to edit or update your dataset after publication. Generic repositories (such as {% tool \"zenodo\" %} and {% tool \"figshare\" %}) use versioning DOI to update a public dataset or document. If you want to publish your data in an institutional public repository, ask the institution to obtain a namespace at {% tool \"identifiers-org\" %} in order to obtain globally unique persistent identifiers for your data. If you have the resources and skills to open up your database to the public, obtain a namespace at {% tool \"identifiers-org\" %} in order to acquire globally unique persistent identifiers for your data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"identifiers.md",
            "language":"en",
            "frontmatter":{
                "title":"Identifiers",
                "contributors":[
                    "Markus Englund",
                    "Flavio Licciulli",
                    "Nick Juty",
                    "Olivier Collin",
                    "Ulrike Wittig",
                    "Ivan Mieti",
                    "Karel Berka",
                    "Shuxin Zhang",
                    "Hinri Kerstens",
                    "Flora D'Anna",
                    "Yvonne Kallberg",
                    "Rob Hooft"
                ],
                "description":"How to use identifiers for research data.",
                "page_id":"identifiers",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Will you make explicit cross-reference between physical samples and your digital data?",
                        "uuid":"9e238002-da35-4f9b-a9b7-8fe3613a3c03"
                    },
                    {
                        "name":"Will this data be assigned a persistent identifier?",
                        "uuid":"d21fdb06-22bf-418e-aa40-dc5ef1485f56"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating resolvable identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB077"
                    },
                    {
                        "name":"Interlinking data from different sources",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB016"
                    },
                    {
                        "name":"Introducing unique, persistent identifiers",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB006"
                    },
                    {
                        "name":"Minting identifiers with Globus Minid client",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB008"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_transfer_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Olivier Collin\n- Alan R Williams\n- Flora D'Anna\n- Frederik Delaere\n- Munazah Andrabi\n- Marina Popleteeva\n- Nazeefa Fatima\ndescription: How to transfer data files. dsw:\n- name: How will the raw data be transported?\n  uuid: 2e8d6e55-36ea-46eb-a921-65e550bce5dc\n- name: How will your first data come in?\n  uuid: f4065e54-d27a-45de-be4c-10384feacd0d\nfaircookbook:\n- name: Transferring data with SFTP protocol\n  url: https:\/\/w3id.org\/faircookbook\/FCB014\n- name: Downloading data with Aspera protocol\n  url: https:\/\/w3id.org\/faircookbook\/FCB015\n- name: Creating file checksums\n  url: https:\/\/w3id.org\/faircookbook\/FCB052\npage_id: transfer\nrelated_pages:\n  tool_assembly: []\ntitle: Data transfer\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_transfer.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_transfer_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":0,
        "total_chunks":9,
        "content":"How do you transfer large data files? Description\nOften, research in Life Sciences generates massive amounts of digital data, such as output files of omics techniques (genomics, transcriptomics, metabolomics, proteomics, etc.). Large data files cannot be sent by email because they exceed the file size limit of most common email servers. Moreover, some data cannot be sent by email due to its sensitive nature. So, how can large data files be transferred from a local computer to a distant one? Considerations\nThere are many aspects to consider when dealing with data transfer. The size or volume of the data and the capacity or bandwidth of the network that links your local computer with the distant computer are crucial aspects. Data size and bandwidth are tightly linked since transferring large volumes of data on a low bandwidth network will be so time consuming that it could be simpler to send the data on a hard drive through carrier services.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_transfer_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":1,
        "total_chunks":9,
        "content":"o time consuming that it could be simpler to send the data on a hard drive through carrier services. You need to be aware of the legal and ethical implications of your data transfer. For personal data, you have to ensure compliance with various legal and ethical frameworks, including the GDPR. You might have to establish a data processing or joint data controller agreement before you can transfer the data. We highly recommend you to check the human data pages of the RDMkit. For data relevant for later patenting or other types of commercialization you  might want to establish a non-disclosure or other type of agreement with the other party to protect your interest. You might also have to consider other laws and regulations, for instance regarding biosecurity of data affecting pathogens or other aspects of potential dual-use. The technical protocol you choose for your data transfer should meet your requirement for data security resulting these implications. You can interact with the IT departments at both locations in order to establish your strategy.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_transfer_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":2,
        "total_chunks":9,
        "content":"ons. You can interact with the IT departments at both locations in order to establish your strategy. If you have the technical skills and knowledge, consider using appropriate File Transfer Protocols. Consider using Cloud Storage Services (see Data storage page), that provide data sharing solutions, or specialised data transfer services available in your institute or country. Consider pros and cons of transferring data by shipping hard disks through carrier services (time, costs, security). This is not a recommended method, unless good internet connection is not available. During a transfer, some data might become corrupted. Thus, it is important to check if the files you transferred have conserved their integrity. This can be done with hash algorithms. A checksum file is calculated for each file before transfer and compared to a checksum calculated on the transferred files. If the checksums are the same, then the files are not corrupted.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_transfer_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":3,
        "total_chunks":9,
        "content":"alculated on the transferred files. If the checksums are the same, then the files are not corrupted. Since data transfer involves so many technical aspects, it is a good idea to interact with your technical\/IT team in order to avoid any problem if you want to transfer a large amount of data. Solutions\nPreferable transfer channel depends on the volume of your data and number of files. However, there are several general approaches to help you with the task. * Try to optimise and ease your data transfer by archiving your data in a single file. This can be done with two tools available on most systems. * tar (tape archive) will create an archive, a single file containing several files or directories. * gzip: since tar does not compress the archive created, a compression tool such as gzip is often used to reduce the size of the archive. Ask the IT team of your institution or organisation about available services for data transfer.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_transfer_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":4,
        "total_chunks":9,
        "content":"ive. Ask the IT team of your institution or organisation about available services for data transfer. Usually, for small data volume or limited number of files universities and professional organisations can provide:\n\nSecure server- or cloud-based applications where you should store work-related data files, synchronize files from different computers and share files by sending a link for access or download. This solution is ideal in case of a small number of files, since files need to be downloaded one by one and this can be inconvenient. Examples of these kinds of applications are NextCloud, {% tool \"box\" %}, {% tool \"owncloud\" %} (see Data storage page). Access to Office 365 (Software as a Service, or SaaS) that includes cloud storage on {% tool \"microsoft-onedrive\" %}, and SharePoint for collaborations and files sharing - you can transfer your data with these services by generating and sending a link for access or download of specific files.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_transfer_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":5,
        "total_chunks":9,
        "content":" data with these services by generating and sending a link for access or download of specific files. Cloud synchronization and sharing services (CS3) for that can be used in science, education and research have been implemented by companies (e.g. {% tool \"seafile\" %}), institutions such as CERN (e.g. {% tool \"reva\" %}, {% tool \"rucio\" %}) and initiatives (e.g. {% tool \"sciencemesh\" %}). Usually, universities and institutions strongly discourage the use of personal accounts on {% tool \"google-drive\" %}, Amazon Drive, {% tool \"dropbox\" %} and similar, to share and transfer work related data, and especially sensitive or personal data. Moreover, it is not allowed to store human data in clouds which are not hosted in the EU. Institutions and professional organisations could also make use of Infrastructure as a Service (IaaS), such as {% tool \"microsoft-azure\" %}, {% tool \"amazon-web-services\" %} (Amazon Simple Storage Service or S3), Oracle Cloud Infrastructure or Google Cloud Platform. A useful comparison of cloud-computing software and providers is on Wikipedia.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_transfer_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":6,
        "total_chunks":9,
        "content":"oogle Cloud Platform. A useful comparison of cloud-computing software and providers is on Wikipedia. Cloud-computing infrastructures, services and platforms offer a variety of file hosting services; a comparison of file hosting services is available on Wikipedia. If you are considering transferring data from or to cloud-based services ({% tool \"microsoft-azure\" %} or Amazon S3) by shipping hard disks through carrier services, it is useful to know that services such as Amazon Snowball and Azure Data Box Disk will help you with the shipping of hard disks or appliances through carrier services. Countries could provide national file sender services (browser based or other) which could be useful for one time transfer of data files, limited in number and volume (for instance, up to 100 GB or 250 GB), from person to person. Importantly, an academic account is usually needed to use these kinds of services, therefore contact the IT team in your institute for more information. If you have the technical skills and the knowledge, you can use the most common data transfer protocols.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_transfer_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":7,
        "total_chunks":9,
        "content":"ou have the technical skills and the knowledge, you can use the most common data transfer protocols. These protocols are useful for data volume larger than 50GB or for hundreds of data files. Applications suitable for small to mid size data available on any operating system and that can be used either through command-line (directly or with tools like {% tool \"curl\" %}) or through a graphical interface, are:\n\nFTP (File Transfer Protocol) will transfer files between a client and an FTP server, which will require an account in order to transfer the files. Be sure to use a secure version of this protocol, such as FTPS or SFTP (SSH File Transfer Protocol). A possible tool with graphical interface is {% tool \"filezilla\" %}. HTTP (HyperText Transfer Protocol). Rsync (remote synchronization) can be used to transfer files between two computers and to keep the files synchronized between these two computers. SCP (secure copy protocol) will securely transfer files between a client and a server. It will require an account on the server and can use SSH key based authentication.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_transfer_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_transfer.md",
        "file_name":"data_transfer.md",
        "chunk_index":8,
        "total_chunks":9,
        "content":"ent and a server. It will require an account on the server and can use SSH key based authentication. A possible tool with graphical interface is {% tool \"winscp\" %}. For massive amounts of data, additional protocols have been developed, parallelizing the flow of data. These transfer solutions require specific tools and as such they are available mostly on large computational centres. FASP protocol implemented in {% tool \"ibm-aspera\" %}. GridFTP protocol used by {% tool \"globus\" %}. Several algorithms can be used for checksum calculation. MD5 checksums can be generated and verified in command line of all operational systems or throught tools with a graphical interface, e.g. MD5Summer for Windows. SHA-2 set is more secured but slower than MD5. SHA checksums can also be generated and verified in command line of all operational systems.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_transfer.md",
            "language":"en",
            "frontmatter":{
                "title":"Data transfer",
                "contributors":[
                    "Olivier Collin",
                    "Alan R Williams",
                    "Flora D'Anna",
                    "Frederik Delaere",
                    "Munazah Andrabi",
                    "Marina Popleteeva",
                    "Nazeefa Fatima"
                ],
                "description":"How to transfer data files.",
                "page_id":"transfer",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+transfer%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will the raw data be transported?",
                        "uuid":"2e8d6e55-36ea-46eb-a921-65e550bce5dc"
                    },
                    {
                        "name":"How will your first data come in?",
                        "uuid":"f4065e54-d27a-45de-be4c-10384feacd0d"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_metadata_management_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"contributors:\n- Flora D'Anna\n- Marco Carraro\n- Yvonne Kallberg\n- Markus Englund\n- Marco Roos\n- Korbinian Bsl\n- Rob Hooft\n- Elin Kronander\n- Marina Popleteeva\n- Gil Poiares-Oliveira\ndescription: How to document and describe your data.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"metadata_management.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_metadata_management_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"nder\n- Marina Popleteeva\n- Gil Poiares-Oliveira\ndescription: How to document and describe your data. dsw:\n- name: Will the metadata be available even when the data no longer exists. uuid: 3b3fbcc6-c405-4151-8dce-e11dbd46b1bd\n- name: How will you be collecting and keeping your metadata. uuid: 8c962e6f-17ee-4b22-8ebb-9f06f779e3b3\nfaircookbook:\n- name: Introducing terminologies and ontologies\n  url: https:\/\/w3id. org\/faircookbook\/FCB019\n- name: Creating a data\/variable dictionary\n  url: https:\/\/w3id. org\/faircookbook\/FCB025\n- name: Creating a metadata profile\n  url: https:\/\/w3id. org\/faircookbook\/FCB026\n- name: Introducing Search Engine Optimization (SEO)\n  url: https:\/\/w3id. org\/faircookbook\/FCB010\n- name: Selecting terminologies and ontologies\n  url: https:\/\/w3id. org\/faircookbook\/FCB020\n- name: Requesting new terms from terminologies and ontologies\n  url: https:\/\/w3id. org\/faircookbook\/FCB021\n- name: Introducing ontology-related tools and services\n  url: https:\/\/w3id.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"metadata_management.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_metadata_management_md_2",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"org\/faircookbook\/FCB021\n- name: Introducing ontology-related tools and services\n  url: https:\/\/w3id. org\/faircookbook\/FCB022\npage_id: metadata\nrelated_pages:\n  tool_assembly:\n  - nels\n  - transmed\n  - plant_geno_assembly\n  - marine_assembly\ntitle: Documentation and metadata.",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"metadata_management.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_metadata_management_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":0,
        "total_chunks":18,
        "content":"How can you document data during the project? Description\nData documentation could be defined as the clear description of everything that a new data user or your future-self would need to know in order to find, understand, reproduce and reuse your data, independently. Data documentation should clearly describe how you generated or used the data, why, and where to find the related files. It could be used also as onboarding documentation for new colleagues, even if the responsible researcher leaves the project. Due to the large variety of experiments, techniques and collaborative studies that usually occur within the same project, it is challenging to keep good documentation. However, lack of good data documentation often leads to data loss, not reproducible results and therefore, waste of money and time for scientists. Here we provide best practices and guidelines to help you properly document your data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":1,
        "total_chunks":18,
        "content":"r scientists. Here we provide best practices and guidelines to help you properly document your data. Considerations\n\n\nWrite the documentation in such a way that someone else who is known to the field cannot misinterpret any of the data. It is best practice to use one appropriate tool or an integration of multiple tools (also called tool assembly or ecosystem) for data documentation during a project. Suitable tools for data documentation are Electronic Lab Notebooks (ELNs), Electronic Data Capture (EDC) systems, Laboratory Information Management Systems (LIMS). Moreover, online platforms for collaborative research and file sharing services (such as {% tool \"openscienceframework\" %}) could also be used as ELN or data management systems. Check with your institute or other relevant infrastructures to know what is offered. Independently of the tools you will use, data documentation is needed at two levels: documentation about the entire study or project and documentation about individual records, observations or data points.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":2,
        "total_chunks":18,
        "content":"the entire study or project and documentation about individual records, observations or data points. Study-level documentation describes the project title and summary, study aims, authors, institutions involved, funds, methods, licence and identifier for each dataset, folders structure, file naming conventions, versioning system, relation between files or tables and other general information. Data-level documentation provides information about individual records or data point, such as the meaning of each variable name, label, ID or type (numeric, string, regular expression, date, etc.), units (i.e., cm, kg), experimental factors, categories, controlled vocabulary or ontology terms accepted as values for each variable, missing values code and so on. An example could be a data file that contains a \"sex\" field: someone known to the field could try to misinterpret that from \"external sex organs present at birth\" to \"chromosomal XX or XY\" or \"high or low testosterone level\" or \"social gender\" or other.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":3,
        "total_chunks":18,
        "content":"at birth\" to \"chromosomal XX or XY\" or \"high or low testosterone level\" or \"social gender\" or other. In order to avoid this, the way the assignment is made must be part of the documentation or of the data itself (controlled vocabulary). Both the study- and data-level documentation must be generated as early as possible in the research process and also maintained, in order to be accurate and complete\n\n\nDocumentation is also required when publishing your data. General-purpose repositories usually require only study-level documentation, while discipline-specific repositories generally require both study-level and data-level documentation. Importantly, repositories often accept data and documentation in a very strict format: they can require a predefined set of attributes or fields (metadata checklists) to be filled, ontology terms to be used, specific (meta)data schemas (e.g., ISA model, MAGE-TAB) to be adopted.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":4,
        "total_chunks":18,
        "content":"d, ontology terms to be used, specific (meta)data schemas (e.g., ISA model, MAGE-TAB) to be adopted. We recommend familiarising yourself with  the requirements of the repositories that could be appropriate for publishing your data already at the beginning of the project, so that you can start documenting and formatting your data accordingly as early as possible. Make sure the documentation is kept close to the data, so that nobody will be exposed to the data without being able to find the documentation. Solutions\n\nThere are many appropriate tools for data documentation during the project. Check with your institute to know what is offered. Electronic Lab Notebooks (ELNs) are usually better for more disparate and unstructured information that requires flexibility. Researchers can use an ELN (such as {% tool \"elabftw\" %}) in a personalised way and adapt it to document their everyday work. Laboratory Information Management Systems (LIMS) typically follow pre-defined and highly structured experimental workflow.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":5,
        "total_chunks":18,
        "content":" Management Systems (LIMS) typically follow pre-defined and highly structured experimental workflow. LIMS are used to document and track biological samples through the experimental processes and can support direct import of data from sources such as instruments. Electronic Data Capture (EDC) systems are usually designated for collection of clinical trial data. Online platforms for collaborative research and file sharing services, which integrate with several data management tools, could also be used for data documentation during the project. For instance, {% tool \"openscienceframework\" %} has integrations with Mendeley, {% tool \"dropbox\" %}, {% tool \"github\" %}, {% tool \"figshare\" %}, etc. There is a major area of overlap between the aforementioned tools for data documentation, so it is better to choose the tool(s) that best address your specific need. Some tools can be used at the same time to address different needs and they can be complementary.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":6,
        "total_chunks":18,
        "content":"d. Some tools can be used at the same time to address different needs and they can be complementary. Comparative lists and tools can help with the choice:\n\n{% tool \"harvard-medical-school-electronic-lab-notebooks\" %}\n{% tool \"university-of-cambridge-electronic-research-notebook-products\" %}\n{% tool \"publisso\" %} - Documenting research data: Electronic Lab(oratory) Notebooks\n{% tool \"eln-finder\" %}\n\n\n\nIndependently of the tools, you should agree on and establish a data organisation system for files (or tables in a database) together with your team or Data Management Working Group:\n\nFolder structure\nFile naming convention\n\nVersioning system\n\n\nThe established data organisation system has to be described in detail in the documentation, preferably in open and machine-readable formats (i.e., XML, JSON, CSV, RDF, HTML). The description of the data organisation system has to be placed in the folder at the highest level (e.g. Project folder).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":7,
        "total_chunks":18,
        "content":"ata organisation system has to be placed in the folder at the highest level (e.g. Project folder). Study-level and data-level documentation can be provided as\n\nREADME file\n{% tool \"create-a-codebook\" %}\nData dictionary (see an example)\nData list\n\nEach of these files can be made in several formats depending on the features available in your data documentation tool, your needs or skills. Machine-readable or -actionable formats (such as .xml, .json, .csv, .rdf) are preferred to non-machine-readable ones (.txt, .xls, .pdf). README.txt is an exception since its main purpose is to be human-readable, i.e. not intended to be machine-readable or -actionable. Also non-proprietary formats are preferred over proprietary ones. Highly structured data documentation is called metadata. Generating metadata in a machine-readable or -actionable format makes your data more FAIR . Metadata provides structured and searchable information so that a user can find existing data, evaluate its reusability and cite it.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":8,
        "total_chunks":18,
        "content":" searchable information so that a user can find existing data, evaluate its reusability and cite it. It is good practice to use international standard metadata schemas to organise and store your (meta)data in a structured way. A metadata schema describes the relations, such as hierarchy, of the elements that belong to the structure. It is also good practice to use international standard metadata checklists to describe the content your (meta)data. A (meta)data checklist is a fixed set of attributes about the data that needs to be provided. Some attributes are mandatory, some are only recommended or optional. International standard metadata schemas and checklists are developed by and accepted as standards by communities. There are many standard metadata schemas and checklists, some generic, while others discipline-specific. See the paragraph about how to find standard metadata. You can use the attributes of metadata schemas and checklists in a format that is not machine-readable or -actionable (e.g., by copying the metadata fields in a Codebook.xls).",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":9,
        "total_chunks":18,
        "content":"hat is not machine-readable or -actionable (e.g., by copying the metadata fields in a Codebook.xls). However, using standard metadata in a machine-readable or -actionable format will increase the findability of your data. Metadata schemas and checklists usually rely on ontologies and controlled vocabularies, which make your data more reusable and interoperable. See the paragraph about how to find ontologies and controlled vocabularies. We recommend familiarising yourself with the requirements of the repositories that could be appropriate for publishing your data already at the beginning of the project, so that you can start documenting and formatting your data according to their requirements as early as possible. Platforms for management of metadata and data used by some scientific communities: {% tool \"cedar\" %}, {% tool \"semares\" %}, {% tool \"fairdom-seek\" %}, {% tool \"fairdomhub\" %}, {% tool \"copo\" %}. How do you find appropriate standard metadata for datasets or samples?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":10,
        "total_chunks":18,
        "content":"omhub\" %}, {% tool \"copo\" %}. How do you find appropriate standard metadata for datasets or samples? Description\nThere are multiple standards for different types of data, ranging from generic dataset descriptions (e.g. {% tool \"data-catalog-vocabulary\" %}, {% tool \"dublincore\" %}, {% tool \"schema-org\" %} and {% tool \"bioschemas\" %}) to specific data types (e.g. {% tool \"miabis\" %} for biosamples). Therefore, how to find standard metadata, and how to find an appropriate repository for depositing your data are relevant questions. Considerations\n\nDecide at the beginning of the project what are the {% tool \"elixir-deposition-databases-for-biomolecular-data\" %} for your data types. Note that you can use several repositories if you have different data types. Distinguish between generic (e.g. Zenodo) and data type (technique) specific repositories (e.g. EBI repositories). Solutions\n\nIf you have a repository in mind:\nGo to the repository website and check the help, \"guide\" or how to submit tab to find information about required metadata.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":11,
        "total_chunks":18,
        "content":"te and check the help, \"guide\" or how to submit tab to find information about required metadata. On the repository website, go through the submission process (try to submit some dummy data) to identify metadata requirements. For instance, if you consider publishing your transcriptomic data in ArrayExpress, you can make your metadata spreadsheet by using Annotare 2.0 submission tool, at the beginning of the project. Be aware that data type specific repositories usually have check-lists for metadata. For example, the European Nucleotide Archive provides sample checklists that can also be downloaded as a spreadsheet after log in.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":12,
        "total_chunks":18,
        "content":"eotide Archive provides sample checklists that can also be downloaded as a spreadsheet after log in. If you do not know yet what repository you will use, look for what is the recommended minimal information (i.e. Minimum Information about your topic, e.g. {% tool \"miame\" %}, {% tool \"minseqe\" %}, or {% tool \"miappe\" %}) required for your type of data in your community, or other metadata, at the following resources:\n\n{% tool \"min-info-standards\" %}\n{% tool \"rda-standards\" %}\n{% tool \"fairsharing\" %} at Standards and Collections\n{% tool \"data-curation-centre-metadata-list\" %}\n\nHow do you find appropriate vocabularies or ontologies?\nDescription\nVocabularies and ontologies are describe concepts and relationships within a knowledge domain. Used wisely, they can enable both humans and computers to understand your data. There is no clear-cut division between the terms \"vocabulary\" and \"ontology\", but the latter is more commonly used when dealing with complex (and perhaps more formal) collections of terms and relationships. Ontologies typically provide an identifier.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":13,
        "total_chunks":18,
        "content":"aps more formal) collections of terms and relationships. Ontologies typically provide an identifier. There are many vocabularies and ontologies available on the web. Finding a suitable one can be difficult and time-consuming. Considerations\n\nCheck whether you really need to find a suitable ontology or vocabulary yourself. Perhaps the repository where you are about to submit your data have recommendations? Or the journal where you plan to publish your results?\nUnderstand your goal with sharing data. Which formal requirements (by e.g. by funder or publisher) need to be fulfilled? Which parts of your data would benefit the most from adopting ontologies? Learn the basics about ontologies. This will be helpful when you search for terms in ontologies and want to understand how terms are related to one another. Accept that one ontology may not be sufficient to describe your data. It is very common that you have to combine terms from more than one ontology. Accept terms that are good enough. Sometimes you you cannot find a term that perfectly match what you want to express.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":14,
        "total_chunks":18,
        "content":"are good enough. Sometimes you you cannot find a term that perfectly match what you want to express. Choosing the best available term is often better than not choosing a term at all. Note that the same concept may also be present in multiple ontologies. Solutions\n\nDefine a list of terms that you want to find ontologies for. Include in the list also any alternative term names that you are aware of. Search for your listed terms on dedicated web portals. These are a few:\n{% tool \"linked-open-vocabularies\" %}\n{% tool \"ontology-lookup-service\" %}\n{% tool \"ontobee\" %}\n{% tool \"bioportal\" %}\n{% tool \"agroportal\" %}\n{% tool \"the-open-biological-and-biomedical-ontology-foundry\" %}\n{% tool \"evidence-and-conclusion-ontology\" %} What do you write in a README file? Description\nA README file is typically a text file written in text (.txt) or markdown (.md) format. The content could either be on study-level or data-level. This is a file for a potential user of your data, including yourself, it is not meant to be machine-actionable.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":15,
        "total_chunks":18,
        "content":"ile for a potential user of your data, including yourself, it is not meant to be machine-actionable. Considerations\n\nREADME file can be updated with time to include information which was not available before. It is a good practice to create a first version when starting a new project. For complex projects, consider to write README files on several levels, not only in the top level of the project. Solutions\nBelow you will find examples of README files for study-level and data-level. For more information you might want to check documentation page from ELIXIR Belgium node.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_16",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":16,
        "total_chunks":18,
        "content":"ata-level. For more information you might want to check documentation page from ELIXIR Belgium node. Study\/project level README\nThis README file was generated on [YYYY-MM-DD] by [NAME]\n\nGENERAL INFORMATION\n- Study\/project title:\n- Description: <provide a short description of the study\/project>\n- Principle Investigator:\n- Link to Data management plan\n\nORGANIZATION\n- Folder structure: similar to folder structure example above (below)\n- File naming conventions (with examples) <unless your project is big and you have README files in every subfolder with this information provided there>\n- File formats: <Provide a list of all file formats present in this study\/project>\n\nData level README\nThis README file was generated on [YYYY-MM-DD] by [NAME]\n\nGENERAL INFORMATION\n- Dataset title:\n- Description: <provide description of the dataset origin, steps used in its generation, content and its purpose>\n\nORGANIZATION\n- Folder structure: similar to folder structure example above (below)\n- File naming conventions: <provide explanation of the elements used, allowed values and examples> \n- File formats: <Provide a list of all file formats present in this dataset>\n\nDATA COLLECTION\n- Institutional catalog ID (if applicable):\n- Date of data collection: <provide single date, range, or approximate date.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_metadata_management_md_17",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/metadata_management.md",
        "file_name":"metadata_management.md",
        "chunk_index":17,
        "total_chunks":18,
        "content":"log ID (if applicable):\n- Date of data collection: <provide single date, range, or approximate date. suggested format YYYY-MM-DD>\n- Link to electronic lab book (codebook) where the following is described (if it does not exist, include it here):\n  - Methods used for data collection (including references, documentation (e. g. consent form template), links):\n  - Geographic location of collection (if applicable):\n  - Experimental & environmental conditions of collection (if applicable):\n  - Standards and calibration for data collection (if applicable):\n  - Uncertainty, precision and accuracy of measurements (if applicable):\n  - Known problems & caveats (sampling, blanks, etc. ):\n  - Codes or symbols used to record missing data with description (if applicable):\n- Link to data dictionary:\n\nDATA RE-USE\n- DOI\/accession number (if dataset is published): \n- License (if any):\n- Use restrictions (if any):\n- Recommended citation for the data (if any):.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"metadata_management.md",
            "language":"en",
            "frontmatter":{
                "title":"Documentation and metadata",
                "contributors":[
                    "Flora D'Anna",
                    "Marco Carraro",
                    "Yvonne Kallberg",
                    "Markus Englund",
                    "Marco Roos",
                    "Korbinian Bsl",
                    "Rob Hooft",
                    "Elin Kronander",
                    "Marina Popleteeva",
                    "Gil Poiares-Oliveira"
                ],
                "description":"How to document and describe your data.",
                "page_id":"metadata",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "transmed",
                        "plant_geno_assembly",
                        "marine_assembly"
                    ]
                },
                "dsw":[
                    {
                        "name":"Will the metadata be available even when the data no longer exists?",
                        "uuid":"3b3fbcc6-c405-4151-8dce-e11dbd46b1bd"
                    },
                    {
                        "name":"How will you be collecting and keeping your metadata?",
                        "uuid":"8c962e6f-17ee-4b22-8ebb-9f06f779e3b3"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB019"
                    },
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Introducing Search Engine Optimization (SEO)",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB010"
                    },
                    {
                        "name":"Selecting terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB020"
                    },
                    {
                        "name":"Requesting new terms from terminologies and ontologies",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB021"
                    },
                    {
                        "name":"Introducing ontology-related tools and services",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB022"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_organisation_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Siiri Fuchs\n- Minna Ahokas\n- Yvonne Kallberg\n- Ivan Mieti\n- Marina Popleteeva\n- Naeem Muhammad\ndescription: Best practices to name and organise research data. dsw:\n- name: How will you do file naming and file organization?\n  uuid: 8e886b55-3287-48e7-b353-daf6ab40f7d8\n- name: Are you using a filesystem with files and folders?\n  uuid: a12aa967-28a5-4a9b-8df8-f7c533205ea4\n- name: Data storage systems and file naming conventions\n  uuid: bc5e3dbf-2923-4025-a49a-f204b01d4018\nfaircookbook:\n- name: Creating a data\/variable dictionary\n  url: https:\/\/w3id.org\/faircookbook\/FCB025\n- name: Creating a metadata profile\n  url: https:\/\/w3id.org\/faircookbook\/FCB026\n- name: Surveying extraction, transformation, load (ETL) tools\n  url: https:\/\/w3id.org\/faircookbook\/FCB031\npage_id: data_organisation\nrelated_pages:\n  tool_assembly:\n  - ome\n  - transmed\n  - xnat_pic\ntitle: Data organisation",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_organisation.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_organisation_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":0,
        "total_chunks":10,
        "content":"What is the best way to name a file? Description\nBrief and descriptive file names are important in keeping your data files organised. A file name is the principal identifier for a file and a good name gives information what the file contains and helps in sorting them, but only if you have been consistent with the naming. Considerations\n\nBest practice is to develop a file naming convention with elements that are important to your project already when the project starts. When working in collaboration with others, it is important to follow the same file naming convention. Solutions\nTips for naming files\n\nBalance with the amount of elements: too many makes it difficult to understand vs too few makes it general. Order the elements from general to specific. Use meaningful abbreviations. Use underscore (_), hyphen (- ) or capitalized letters to separate elements in the name. Dont use spaces or special characters: ?!& , * % # ; * ( ) @$ ^ ~  { } [ ] < >.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":1,
        "total_chunks":10,
        "content":"ments in the name. Dont use spaces or special characters: ?!& , * % # ; * ( ) @$ ^ ~  { } [ ] < >. Use date format ISO8601: YYYYMMDD, and time if needed HHMMSS. Include a unique identifier (see: Identifiers)\nInclude a version number if appropriate: minimum two digits (V02) and extend it, if needed for minor corrections (V02-03). The leading zeros, will ensure the files are sorted correctly. Write your file naming convention down and explain abbreviations in your data documentation. If you need to rename a lot of files in order to organize your project data and manage your files better, it is possible to use applications like {% tool \"bulk-rename-utility\" %} (Windows, free) and {% tool \"renamer4mac\" %} (Mac). Example elements to include in the file name\n\nDate of creation\nProject number \/ Experiment \/ Acronym\nType of data (Sample ID, Analysis, Conditions, Modifications, etc.) Location \/ Coordinates\nName \/ Initials of the creator\nVersion number\nReserve the last 3-letters for file format (e.g. .xls, .rtf, .mov, .tif, .doc)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":2,
        "total_chunks":10,
        "content":"reator\nVersion number\nReserve the last 3-letters for file format (e.g. .xls, .rtf, .mov, .tif, .doc) Examples of good file names\n* Honeybee project, experiment 2 done in Helsinki, data file created on the second of December 2020\n  * File name: 20201202_HB_EXP2_HEL_DATA_V03.xls\n  * Explanation: Time_ProjectAbbreviation_ExperimentNumber_Location_TypeOfData_VersionNumber\n* Cropped image of an ant head taken on the third of December 2020 by Meg Megson\n  * File name: 20201203_MM_HEAD_CROPPED_V1.psd\n  * Explanation: Time_CreatorData_TypeModification_Version\nHow to choose the appropriate file formats?\nDescription\nFile formats play an important role when you try to open files later or another person would like to work with the data. Some file formats keep structured data and even permit metadata inclusion, hereby enabling machine-readability and promoting interoperability. Others are easy for humans to understand. Each type of format has use cases.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":3,
        "total_chunks":10,
        "content":"oting interoperability. Others are easy for humans to understand. Each type of format has use cases. However, as a general principle, choosing open and widely supported file formats ensures long-term compatibility and accessibility in the foreseen future. Considerations\nWhen making a selection for an appropriate file format, you should consider the following factors whenever feasible:\n- non-proprietary;\n- based on open standard;\n- commonly used in your research domain;\n- uncompressed;\n- unencrypted. It is important to differentiate between file formats intended for active phase (data acquisition, data reduction and primary data analysis) and those designed for long-term storage or reuse (sharing, publishing and archiving). For the latter purpose, we recommend utilizing file formats that adhere to open standards, have a broad acceptance, and are unlikely to become obsolete. In the active phase, it is fine to use proprietary device-specific file formats if needed.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":4,
        "total_chunks":10,
        "content":"obsolete. In the active phase, it is fine to use proprietary device-specific file formats if needed. This is acceptable until you reach the phase of sharing the data for subsequent analysis, and for data validation or control with other team members. At this point, you need to convert (or export) the data for it be usable by members without access to proprietary software or instrumentation that generated it. Solutions\nThe best file formats depend on data types, availability and common acceptance of open file formats and research domain. There is no one size fits all solution. You need to choose the best for your case. The following table lists the recommended file formats for best practices in research data management. Acceptable and non-recommended file formats represent commonly used file formats that do not fulfill above-mentioned criteria (listed under 'Considerations'). Type\nPreferred\nAcceptable\nNon-recommended\n\n\n\n\nRich text documents\nODT (.odt)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":5,
        "total_chunks":10,
        "content":"nder 'Considerations'). Type\nPreferred\nAcceptable\nNon-recommended\n\n\n\n\nRich text documents\nODT (.odt) Markdown (.md) LaTeX (.tex) for read-only documents: PDF\/A (.pdf)\nOffice Open XML (.docx)\nMicrosoft Word (.doc) PDF other than PDF\/A (.pdf) Plain text documents\nUnicode text (.txt)\n\nNon-Unicode text (.txt) Tabular data\nCSV (.csv, .tsv) Office Open XML Workbook (.xlsx)\nMicrosoft Excel (.xls)\n\n\nContainers and compression\nZIP (.zip)\ntar (.tar) gzip (.gz) bzip2 (.bz2)\nRAR (.rar) 7-Zip (.7z) Raster images\nTIFF (.tif, .tiff)  DICOM (.dcm)\nproprietary microscopy formats (CZI, LIF, NEF) PNG (.png)\nJPEG (.jpg, .jpeg) PS (.ps) EPS (.eps) BMP (.bmp)\n\n\nVector images\nSVG (.svg) PS (.ps) EPS (.eps) Adobe Illustrator (.ai) WMF\/EMF (.wmf, .emf) CDR (.cdr) Audio\nMatroska (.mka) FLAC (.flac)\nWAVE (.wav) MP3 (.mp3)\n\n\n\nVideo\nMatroska (.mkv)\nMPEG\/MPG animation (.mpg, .mp4, .mjpeg)\nAVI (.avi) QuickTime (.mov, .qt) Machine-readable metadata\nJSON (.json) XML (.xml) For domain-specific file formats, please check the appropriate domain page. How do you manage file versioning?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":6,
        "total_chunks":10,
        "content":"-specific file formats, please check the appropriate domain page. How do you manage file versioning? Description\nFile versioning is a way to keep track of changes made to files and datasets. While the implementation of a good file naming convention will indicate that different versions exist, this will not explain the difference between two (or more) versions. File versioning will enable transparency about which actions and changes were made and when. This makes it easy to backtrack and find something that was present in a previous version, but was later deleted or changed. Considerations\n\nDo you need to collaborate on files, perhaps at the same time? Is there a need to be able to backtrack and restore a previous version? Will there be many changes made? Solutions\n\nSmaller demands of versioning can be managed manually e.g. by keeping a log where the changes for each respective file is documented, version by version.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":7,
        "total_chunks":10,
        "content":" e.g. by keeping a log where the changes for each respective file is documented, version by version. For automatic management of versioning, conflict resolution and back-tracing capabilities, use a proper version control software such as {% tool \"git\" %}, hosted by e.g. {% tool \"github\" %}, {% tool \"gitlab\" %} and {% tool \"bitbucket\" %}. Use a Cloud Storage service (see Data storage page) that provides automatic file versioning. It can be very handy for spreadsheets, text files and slides. How do you organise files in a folder structure? Description\nA carefully planned folder structure, with intelligible folder names and an intuitive design, is the foundation for good data organisation. The folder structure gives an overview of which information can be found where, enabling present as well as future stakeholders to understand what files have been produced in the project. Considerations\n\nThe decisions on how to organise the files should be made during planning and design of the project, so that the strategy can be implemented from the start.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":8,
        "total_chunks":10,
        "content":"e during planning and design of the project, so that the strategy can be implemented from the start. Consider to consistently apply the same strategy in every project within the research group. Solutions\nFolders should:\n* follow a structure with folders and subfolders that correspond to the project design and workflow\n* have a self-explanatory name that is only as long as is necessary\n* have a unique name  avoid assigning the same name to a folder and a subfolder\nThe top folder should have a README.txt file describing the folder structure and what files are contained within the folders. For information on the content of a README file see corresponding section on Documentation and metadata page. See also A Quick Guide to Organizing Computational Biology Projects. An example:\nproject\/  \n  code\/                 code needed to go from input files to final results   \n  data\/                 raw and primary data (never edit!)",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_organisation_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_organisation.md",
        "file_name":"data_organisation.md",
        "chunk_index":9,
        "total_chunks":10,
        "content":"o go from input files to final results   \n  data\/                 raw and primary data (never edit!) raw_external\/  \n     raw_internal\/\n     meta\/  \n  doc\/                  documentation of the study  \n  intermediate\/         output files from intermediate analysis steps  \n  logs\/                 logs from the different analysis steps  \n  notebooks\/            notebooks that document your day-to-day work  \n  results\/              output from workflows and analyses  \n     figures\/  \n     reports\/  \n     tables\/  \n  scratch\/              temporary files that can safely be deleted or lost  \n  README.txt            file and folder description\n\n\nStructured directories can be made by using {% tool \"cookiecutter\" %},a command-line utility that creates projects from cookiecutters (project templates), e.g. creating a Python package project from a Python package project template.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_organisation.md",
            "language":"en",
            "frontmatter":{
                "title":"Data organisation",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Yvonne Kallberg",
                    "Ivan Mieti",
                    "Marina Popleteeva",
                    "Naeem Muhammad"
                ],
                "description":"Best practices to name and organise research data.",
                "page_id":"data_organisation",
                "related_pages":{
                    "tool_assembly":[
                        "ome",
                        "transmed",
                        "xnat_pic"
                    ]
                },
                "dsw":[
                    {
                        "name":"How will you do file naming and file organization?",
                        "uuid":"8e886b55-3287-48e7-b353-daf6ab40f7d8"
                    },
                    {
                        "name":"Are you using a filesystem with files and folders?",
                        "uuid":"a12aa967-28a5-4a9b-8df8-f7c533205ea4"
                    },
                    {
                        "name":"Data storage systems and file naming conventions",
                        "uuid":"bc5e3dbf-2923-4025-a49a-f204b01d4018"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Creating a data\/variable dictionary",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB025"
                    },
                    {
                        "name":"Creating a metadata profile",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB026"
                    },
                    {
                        "name":"Surveying extraction, transformation, load (ETL) tools",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB031"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_security_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"contributors:\n- Pinar Alper\n- Yvonne Kallberg\n- Vilem Ded\n- Eva Csosz\n- Niclas Jareborg\ndescription: How do you ensure that your data is handled securely. dsw:\n- name: What technical and procedural safeguards have been established for processing\n    the data?\n  uuid: a30f5047-33c1-45a7-8b3f-b1b90c364fc9\nfaircookbook:\n- name: Downloading data with Aspera protocol\n  url: https:\/\/w3id.org\/faircookbook\/FCB015\n- name: Transferring data with SFTP protocol\n  url: https:\/\/w3id.org\/faircookbook\/FCB014\n- name: Creating file checksums\n  url: https:\/\/w3id.org\/faircookbook\/FCB052\n- name: Validating checksums to verify file integrity\n  url: https:\/\/w3id.org\/faircookbook\/FCB053\n- name: Data Protection Impact Assessment and Data Privacy\n  url: https:\/\/w3id.org\/faircookbook\/FCB074\npage_id: data_security\nredirect_from: data_protection\nrelated_pages:\n  tool_assembly:\n  - tsd\n  - transmed\ntitle: Data security\ntraining:\n- name:",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_security.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_data_security_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"otection\nrelated_pages:\n  tool_assembly:\n  - tsd\n  - transmed\ntitle: Data security\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_security.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_security_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":0,
        "total_chunks":8,
        "content":"How do you ensure that your data is handled securely? Description\nTo protect your research data, code, and other information assets you should establish adequate Information security measures. Information security relies on combinations of technical and procedural measures that work together to ensure protection of the data at a suitable level. To note is that failure by humans to follow the procedural measures often poses a higher vulnerability to security risks than shortcomings of the technical measures. Considerations\n\nInformation security is usually described as containing three main aspects - Confidentiality, Integrity, and Availability. Confidentiality is about measures to ensure that data is kept confidential from those that do not have rights to access the data. Integrity is about measures to ensure that data is not corrupted or destroyed during storage or transmission.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_security.md",
            "language":"en",
            "frontmatter":{
                "title":"Data security",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg"
                ],
                "description":"How do you ensure that your data is handled securely.",
                "page_id":"data_security",
                "redirect_from":"data_protection",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"What technical and procedural safeguards have been established for processing the data?",
                        "uuid":"a30f5047-33c1-45a7-8b3f-b1b90c364fc9"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    },
                    {
                        "name":"Validating checksums to verify file integrity",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB053"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_security_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":1,
        "total_chunks":8,
        "content":" is about measures to ensure that data is not corrupted or destroyed during storage or transmission. Availability is about measures that ensure access to the data is possible at the time of need or access does not require an inordinate amount of time. What information security measures that need to be established should be defined at the planning stage (e.g. when doing a risk assessment for a GDPR Data Protection Impact Assessment). This should identify information security risks, and define measures to mitigate those risks. Balance the cost and effort for protecting your data at an appropriate level. For this, it is useful to classify the impact of failure for the three different CIA aspects to guide your choices. You should not spend more resources than necessary if the impact of failure is low enough that you can easily cope with it. Nor should you spend too few resources on protective measures for aspects where the impact is high.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_security.md",
            "language":"en",
            "frontmatter":{
                "title":"Data security",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg"
                ],
                "description":"How do you ensure that your data is handled securely.",
                "page_id":"data_security",
                "redirect_from":"data_protection",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"What technical and procedural safeguards have been established for processing the data?",
                        "uuid":"a30f5047-33c1-45a7-8b3f-b1b90c364fc9"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    },
                    {
                        "name":"Validating checksums to verify file integrity",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB053"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_security_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":2,
        "total_chunks":8,
        "content":" Nor should you spend too few resources on protective measures for aspects where the impact is high. For example, the Availability aspect will probably differ a lot if your data is used in a clinical versus a research setting, where protecting against a system failure in the research setting can be a lot less resource demanding than in the clinical setting. Ensure that everyone that works with the data knows what is expected of them, how the Information Security measures are to be implemented, and who is responsible for ensuring that they are followed and performed as agreed. Be sure to contact the IT or Information security office at your institution to get guidance and support to address these issues. They should be able to provide you with suitable solutions for your needs. Solution\n\nBelow is a non-exhaustive list of good practices that might be relevant depending on the level of protection required. Note that some of these might be quite costly, such as investing in hardware or hiring highly specialized staff to ensure high levels of security.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_security.md",
            "language":"en",
            "frontmatter":{
                "title":"Data security",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg"
                ],
                "description":"How do you ensure that your data is handled securely.",
                "page_id":"data_security",
                "redirect_from":"data_protection",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"What technical and procedural safeguards have been established for processing the data?",
                        "uuid":"a30f5047-33c1-45a7-8b3f-b1b90c364fc9"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    },
                    {
                        "name":"Validating checksums to verify file integrity",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB053"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_security_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":3,
        "total_chunks":8,
        "content":" such as investing in hardware or hiring highly specialized staff to ensure high levels of security. More on costs for RDM is available on the Costs of data management page. Confidentiality\nUse password protection on all computers\nUse two-factor authentication, i.e. using two ways of identification in order to obtain access to the (remote) data\nSet file and folder permissions, e.g. use read-only access for data that should never be changed, and limit access to only those who needs it\nApply a Lock screen policy to prevent unauthorised access of systems from those who do not have access rights and permissions. Use encrypted data transfers to avoid eavesdropping\nConsider implementing systems monitoring measures in order to ensure that hacking attempts are detected\nDecide on procedures on how systems can be physically accessed. Should data be allowed to reside on personal laptops, or only on designated stationery systems? Should stationary systems be physically protected in locked compartments only accessible to a limited number of individuals?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_security.md",
            "language":"en",
            "frontmatter":{
                "title":"Data security",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg"
                ],
                "description":"How do you ensure that your data is handled securely.",
                "page_id":"data_security",
                "redirect_from":"data_protection",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"What technical and procedural safeguards have been established for processing the data?",
                        "uuid":"a30f5047-33c1-45a7-8b3f-b1b90c364fc9"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    },
                    {
                        "name":"Validating checksums to verify file integrity",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB053"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_security_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":4,
        "total_chunks":8,
        "content":"s be physically protected in locked compartments only accessible to a limited number of individuals? Integrity\nGenerate checksums for all files as soon as possible, preferably upon file creation. Keep the number of copies to a minimum to facilitate its management. Adopt a data release workflow which ensures the data are versioned and preserved. Each version shall be protected against any change by users, e.g. by setting permissions to read-only. Perform quality checks both upon data collection to ensure accuracy and on a regular basis to discover potential integrity errors. Define, document and adopt a back-up strategy for your data. Utilise available tools for data management (data warehouses) ensuring data integrity by default. Availability\nSet up disaster recovery procedures with instructions on what data, how, and by who, recovery of data should be done in case an incident of system failure or data loss happens.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_security.md",
            "language":"en",
            "frontmatter":{
                "title":"Data security",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg"
                ],
                "description":"How do you ensure that your data is handled securely.",
                "page_id":"data_security",
                "redirect_from":"data_protection",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"What technical and procedural safeguards have been established for processing the data?",
                        "uuid":"a30f5047-33c1-45a7-8b3f-b1b90c364fc9"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    },
                    {
                        "name":"Validating checksums to verify file integrity",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB053"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_security_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":5,
        "total_chunks":8,
        "content":" by who, recovery of data should be done in case an incident of system failure or data loss happens. If high availability is a must, consider designing a redundant computing and storage strategy where there are physically separated compute and storage resources, that ensures that the data is available at all times even in the event of system failure. Organisational Measures\nThe procedures on how the technical protection measures are to be used, and who is responsible for what, must be understood by all personnel that work with the data, code, and other information assets. The procedures should be documented, and staff should have access to relevant training to follow the procedures. This is often the most vulnerable part in an Information Security strategy. Policies are an important component of data management and they are essential for information security. Organisations use policies to announce to their staff and third parties the expectations, roles and responsibilities in data handling.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_security.md",
            "language":"en",
            "frontmatter":{
                "title":"Data security",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg"
                ],
                "description":"How do you ensure that your data is handled securely.",
                "page_id":"data_security",
                "redirect_from":"data_protection",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"What technical and procedural safeguards have been established for processing the data?",
                        "uuid":"a30f5047-33c1-45a7-8b3f-b1b90c364fc9"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    },
                    {
                        "name":"Validating checksums to verify file integrity",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB053"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_security_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":6,
        "total_chunks":8,
        "content":"unce to their staff and third parties the expectations, roles and responsibilities in data handling. Policies typically cover data classification, storage\/backup, transfer, retention\/archival, deletion\/destruction, acceptable use of IT platforms and the reporting of security incidents and data breaches. In some cases research data requirements would be addressed in dedicated policies. Therefore, at the planning phase, it is important to understand institutional data policies applicable to the projects data. If the data is considered sensitive as per the institutional data classification, this will have an impact on the IT platforms that can be used to store and transmit the data as well as the specific procedures to be followed. Information inventories and documentation is another requirement for projects dealing with sensitive data. At the planning phase you should identify the various categories of data that will be processed in the project e.g. personal health and biomedical data, sensitive habitat data, IP restricted data from the industry.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_security.md",
            "language":"en",
            "frontmatter":{
                "title":"Data security",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg"
                ],
                "description":"How do you ensure that your data is handled securely.",
                "page_id":"data_security",
                "redirect_from":"data_protection",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"What technical and procedural safeguards have been established for processing the data?",
                        "uuid":"a30f5047-33c1-45a7-8b3f-b1b90c364fc9"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    },
                    {
                        "name":"Validating checksums to verify file integrity",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB053"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_security_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_security.md",
        "file_name":"data_security.md",
        "chunk_index":7,
        "total_chunks":8,
        "content":". personal health and biomedical data, sensitive habitat data, IP restricted data from the industry. You should document which platforms will be used to process the data and the applicable security measures in case certain measures are applied to restricted classes of data. See the next section for GDPR-specific documentation requirements. See the Data Sensitivity page for more information on sensitive data. ISO\/IEC 27001 is an international information security standard adopted by data processing centres worldwide. Some universities and research institutes also acquire an ISO 27001 certification for their IT environments. Such certifications allow institutions to consistently and thoroughly identify information security risks and put in place best practice information security controls. These controls would include all above mentioned technical and organisational safeguards and more.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_security.md",
            "language":"en",
            "frontmatter":{
                "title":"Data security",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg"
                ],
                "description":"How do you ensure that your data is handled securely.",
                "page_id":"data_security",
                "redirect_from":"data_protection",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"What technical and procedural safeguards have been established for processing the data?",
                        "uuid":"a30f5047-33c1-45a7-8b3f-b1b90c364fc9"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Downloading data with Aspera protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB015"
                    },
                    {
                        "name":"Transferring data with SFTP protocol",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB014"
                    },
                    {
                        "name":"Creating file checksums",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB052"
                    },
                    {
                        "name":"Validating checksums to verify file integrity",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB053"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_publication_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Munazah Andrabi\n- Ulrike Wittig\n- Elin Kronander\n- Flora D'Anna\n- Aitana Neves\n- Nazeefa Fatima\n- Carla Cummins\n- Korbinian Bsl\n- Marina Popleteeva\ndescription: How to prepare data and find repositories for publication.\nfaircookbook:\n- name: Depositing to generic repositories - Zenodo use case\n  url: https:\/\/w3id.org\/faircookbook\/FCB009\npage_id: data_publication\nrelated_pages:\n  tool_assembly: []\ntitle: Data publication",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_publication.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_publication_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":0,
        "total_chunks":12,
        "content":"Can you really deposit your data in a public repository? Description Sometimes it is difficult to determine if publishing data you have at hand is the right thing to do. Some reasons for hesitations might be that you have not used the data in a publication yet and don't want to be scooped, that the data contains personal information about patients or that the data was collected or produced in a collaboration. Considerations\n\nPublishing data does not necessarily mean open access nor public. Data can be published with closed or restricted access. Data doesn't have to be published immediately while you are still working on the project. Data can be made available during the revision of the paper or after the publication of the paper. Make sure to have the rights or permissions to publish the data. Is the data commercially-sensitive? Does the data contain confidential\/restricted information? Who controls the data?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":1,
        "total_chunks":12,
        "content":"rcially-sensitive? Does the data contain confidential\/restricted information? Who controls the data? Solutions\n\nIf ethical, legal or contractual issues apply to your data type (e.g. personal or sensitive data, confidential or third-party data, data with copyright, data with potential economic or commercial value, intellectual property or IP data, etc.), ask for help and advice from the Legal Team, Tech Transfer Office, and\/or Data Protection Officer of your institute. Decide what is the right type of access for your data, for instance:\nOpen access. Registered access or with authentication procedure. Controlled access or via Data Access Committees (DACs). Decide what licence should be applied to your metadata and data. Certain repositories offer solutions for depositing data that need to be under restricted access. This allows for data to be findable even when it can not be published openly. One example is the {% tool \"the-european-genome-phenome-archive\" %} that can be used to deposit potentially identifiable genetic and phenotypic human data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":2,
        "total_chunks":12,
        "content":"-archive\" %} that can be used to deposit potentially identifiable genetic and phenotypic human data. Many repositories provide the option to put an embargo on a deposited dataset. This might be useful if you prefer to use the data in a publication before making it available for others to use. Establish an agreement outlining the controllership of the data and each collaborators' rights and responsibilities. Even if the data cannot be published, it is good practice to publish the metadata of your datasets. Which repository should you use to publish your data? Description\nOnce you have completed your experiments and have performed quality control of your data it is good scientific practice to share your data in a public repository. Publishing your data is often required by funders and publishers. The most suitable repository will depend on the data type and your discipline. Considerations\n\nWhat type of data are you planning to publish? Does the repository need to provide solutions for restricted access for sensitive data? Do you have the rights to publish the data via the repository?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":3,
        "total_chunks":12,
        "content":"restricted access for sensitive data? Do you have the rights to publish the data via the repository? How sustainable is the repository, will the data remain public over time? How FAIR is the repository? Does the funding agency or the scientific journal pose specific requirements regarding data sharing? What are the repository's policies concerning licences and data reuse?\n\nSolutions\n\nBased on the possible ethical, legal and contractual implications of your data, decides:\nThe right type of access for your data. The licence that should be applied to your metadata and data. Check if\/what discipline-specific repositories can apply the necessary access conditions and licences to your (meta)data.\nDiscipline-specific repositories: if a discipline-specific repository, recognised by the community, exists this should be your first choice since discipline-specific repositories often increases the FAIRness of the data. The {% tool \"embl-ebi-s-data-submission-wizard\" %} can help you choose a suitable repository based on your data type.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":4,
        "total_chunks":12,
        "content":"-ebi-s-data-submission-wizard\" %} can help you choose a suitable repository based on your data type. There are lists of discipline-specific, community-recognised repositories e.g.:\n{% tool \"elixir-deposition-databases-for-biomolecular-data\" %} including {% tool \"arrayexpress\" %}, {% tool \"biomodels\" %}, {% tool \"biostudies\" %}, {% tool \"european-nucleotide-archive\" %}, {% tool \"pdb\" %}, {% tool \"pride\" %}\nScientific Data journal's recommended repositories\n{% tool \"wellcome-open-research-data-guidelines\" %} Check if there are repositories available for specific data formats, such as images (e.g. {% tool \"bioimagearchive\" %}, {% tool \"empiar\" %}) or earth and environmental science data (e.g. {% tool \"pangaea\" %}). General-purpose and institutional repositories: For other cases, a repository that accepts data of different types and disciplines should be considered. It could be a general-purpose repository, such as {% tool \"zenodo\" %}, {% tool \"mendeley-data\" %}, {% tool \"figshare\" %}, {% tool \"dryad\" %} or a centralised repository provided by your institution or university.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":5,
        "total_chunks":12,
        "content":"hare\" %}, {% tool \"dryad\" %} or a centralised repository provided by your institution or university. {% tool \"re3data\" %} or {% tool \"repository-finder\" %} gather information about existing repositories and allows you to filter them based on access and licence types. {% tool \"re3data\" %} and {% tool \"fairsharing\" %} websites gather features of repositories, which you can filter by discipline, data type, taxonomy and many other features. How do you prepare your data for publication in data repositories? Description\nOnce you have decided where to publish your data, you will have to make your (meta)data ready for repository submission. For this reason it is recommended to become aware of repository's requirements before start collecting the data. Considerations\n\nWhat file formats should be used for the data? How is the data uploaded? What metadata do you need to provide? Under which licence should the data be published?\nShould sensitive data and metadata be anonymised or pseudonymised prior to a publication? This could notably be the case if you work with human data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":6,
        "total_chunks":12,
        "content":"or pseudonymised prior to a publication? This could notably be the case if you work with human data. After data is submitted to a public repository, should the original copy of the data be retained at the central brokering platform and linked to its public counterpart? Or should it be removed and replaced with the ID of the public record? Solutions\n\nLearn the following information about the chosen repositories:\nRequired metadata schemas\nRequired ontologies or controlled vocabularies\nAccepted file formats for data and metadata\nCosts for sharing and storing data\n\n\nRepositories generally have information about data formats, metadata requirements and how data can be uploaded under a section called \"submit\", \"submit data\", \"for submitters\" or something similar. Read this section in detail. To ascertain re-usability data should be released with a clear and accessible data usage licence. We suggest making your data available under licences that permit free reuse of data, e.g. a Creative Commons licence, such as CC0 or CC-BY.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":7,
        "total_chunks":12,
        "content":"nder licences that permit free reuse of data, e.g. a Creative Commons licence, such as CC0 or CC-BY. Note that every repository can have one default licence for all datasets. For instance, sequence data submitted to for example {% tool \"european-nucleotide-archive\" %} are implicitly free to reuse by others as specified in the {% tool \"international-nucleotide-sequence-database-collaboration\" %}. See the corresponding pages for more detailed information about metadata, licences and data transfer. There are many tools available to remove human reads from your non-human data, e.g. {% tool \"metagen-fastqc\" %}\n\nHow do you update or delete a published entry from a data repository? Description\nYou will sometimes need to update or delete some entries that were incomplete or wrongly submitted for publication. Note however that upon creation of a new record, data is generally tagged for distribution and selected metadata fields may be exchanged with other repositories.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":8,
        "total_chunks":12,
        "content":"rally tagged for distribution and selected metadata fields may be exchanged with other repositories. Thus, redistribution of updated records may not be triggered automatically and updating records fully can be a time consuming and manual process for the repository. Also, in general, submitted data may not be deleted, but may be suppressed from public view upon request. In a nutshell, it is therefore safer to make sure to submit the right entry from the start, rather than updating it or asking for its withdrawal at a later stage. Considerations\n\nDoes the repository offer the possibility to update a submission? For the data submitter, is this a manual procedure (e.g. email, web interface) or is it available through an Application Programming Interface (API) or Command Line Interface (CLI)? Does the repository offer the possibility to delete (or hide) submissions? Does the repository have a test-server where data can be submitted for testing purpose?\n\nSolutions\nSolutions are very much repository-dependent.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":9,
        "total_chunks":12,
        "content":" data can be submitted for testing purpose?\n\nSolutions\nSolutions are very much repository-dependent. For example, on the {% tool \"european-nucleotide-archive\" %}, entries can be easily updated using a CLI. However, the updated information is not automatically redistributed to other registries linked to ENA. Upon email request, entries may also be suppressed from public view. Note that ENA also has a test server to make test submissions before submitting to the actual production server, which can be very useful when sending large batches of data to test for any systematic errors. Please check these points with your repository of choice. Should you include datasets accession numbers in pre-prints or theses? Description\nResearchers often deposit their data in public databases (e.g., {% tool \"arrayexpress\" %}, {% tool \"gene-expression-omnibus\" %}) and receive an accession number for that data. Often researchers put data under embargo until the final publication - a period of time during which a dataset remains unavailable to the public.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":10,
        "total_chunks":12,
        "content":"l the final publication - a period of time during which a dataset remains unavailable to the public. Including accession number(s) in a pre-print or a thesis could finish embargo and make the dataset publicly available, even before the final publication. Including accession number(s) depends on whether the researcher wants to make the data publicly accessible early or keep it private until later. Considerations\n\nPre-prints and theses are often treated as citable publications. Some databases may release data as soon as an accession number is cited in a pre-print or in a published thesis. Policies vary between repositories  some release data proactively, while others do so only upon inquiry. Once an accession number is made public in a pre-print, the dataset may become publicly accessible, even if the preprint is intended to be temporary and even if a second manuscript describing the same data is pending. Solutions\n\nIf public availability before final publication is not an issue, citing the accession number ensures accessibility.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_publication_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_publication.md",
        "file_name":"data_publication.md",
        "chunk_index":11,
        "total_chunks":12,
        "content":"ability before final publication is not an issue, citing the accession number ensures accessibility. Check the guidelines or policies of the data repository of interest before deciding whether to include the accession number in a pre-print. For example, GEO's policy requires that data be publicly accessible once an accession number is cited, even if the manuscript is a pre-print. More information can be found here: GEO FAQ. To avoid unintended data release, authors should refrain from including accession numbers in pre-prints or mask them.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_publication.md",
            "language":"en",
            "frontmatter":{
                "title":"Data publication",
                "contributors":[
                    "Munazah Andrabi",
                    "Ulrike Wittig",
                    "Elin Kronander",
                    "Flora D'Anna",
                    "Aitana Neves",
                    "Nazeefa Fatima",
                    "Carla Cummins",
                    "Korbinian Bsl",
                    "Marina Popleteeva"
                ],
                "description":"How to prepare data and find repositories for publication.",
                "page_id":"data_publication",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "faircookbook":[
                    {
                        "name":"Depositing to generic repositories - Zenodo use case",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB009"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_gdpr_compliance_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/gdpr_compliance.md",
        "file_name":"gdpr_compliance.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Pinar Alper\n- Yvonne Kallberg\n- Vilem Ded\n- Eva Csosz\n- Niclas Jareborg\n- Laura Portell Silva\ndescription: How to protect your research data, and how to make research data compliant\n  to GDPR. dsw:\n- name: Will you collect any data connected to a person, \"personal data\"?\n  uuid: 49c009cb-a38c-4836-9780-8a8b3dd1cbac\n- name: Do you need a Data Protection Impact Assessment?\n  uuid: 8915bd25-db22-4ed6-bcc8-b1bbdc52989e\nfaircookbook:\n- name: Licensing Data\n  url: https:\/\/w3id.org\/faircookbook\/FCB034\n- name: Declaring data permitted uses\n  url: https:\/\/w3id.org\/faircookbook\/FCB035\n- name: Data Protection Impact Assessment and Data Privacy\n  url: https:\/\/w3id.org\/faircookbook\/FCB074\npage_id: gdpr_compliance\nrelated_pages:\n  tool_assembly:\n  - tsd\n  - transmed\n  your_tasks:\n  - data_security\ntitle: GDPR compliance\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"gdpr_compliance.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_gdpr_compliance_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/gdpr_compliance.md",
        "file_name":"gdpr_compliance.md",
        "chunk_index":0,
        "total_chunks":6,
        "content":"How do you protect research data under GDPR?\nDescription\nWhere scientific research involves the processing of data concerning identifiable people in the European Union (EU), it is subject to the General Data Protection Regulation (GDPR). The GDPR applies a \"special regime\" to research, providing derogations from some obligations given appropriate criteria are met and safeguards are in place. The criteria are to follow standards in research method and ethics, as well as to aim for societal benefit rather than serving private interests in research. The safeguards are a multitude and include:\n  * data collection with informed consent under ethical oversight and accountability;\n  * ensuring lawful processing and exchange of human-subject information;\n  * putting in place organisational and technical data protection measures such as encryption and pseudonymisation. The practical impact of the GDPR on research is, then, establishing these safeguards within projects.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gdpr_compliance.md",
            "language":"en",
            "frontmatter":{
                "title":"GDPR compliance",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg",
                    "Laura Portell Silva"
                ],
                "description":"How to protect your research data, and how to make research data compliant to GDPR.",
                "page_id":"gdpr_compliance",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ],
                    "your_tasks":[
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Do you need a Data Protection Impact Assessment?",
                        "uuid":"8915bd25-db22-4ed6-bcc8-b1bbdc52989e"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gdpr_compliance_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/gdpr_compliance.md",
        "file_name":"gdpr_compliance.md",
        "chunk_index":1,
        "total_chunks":6,
        "content":"he practical impact of the GDPR on research is, then, establishing these safeguards within projects. Considerations\nSeek expert help for the interpretation of GDPR legal requirements to practicable measures. * Research institutes appoint Data Protection Officers (DPO). Before starting a project you should contact your DPO to be informed of GDPR compliance requirements for your institution. * Each EU country has its own national implementation of the GDPR. If your project involves a multi-national consortium, the requirements of all participating countries need to be met and you should inform the project coordinator of any country-specific requirements. * Legal offices in research institutes provide model agreements, which cater for various research scenarios and consortia setups. You should inform your local legal office of your project's setup and identify the necessary agreements to be signed. Assess your project under the GDPR. * Determine your GDPR role.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gdpr_compliance.md",
            "language":"en",
            "frontmatter":{
                "title":"GDPR compliance",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg",
                    "Laura Portell Silva"
                ],
                "description":"How to protect your research data, and how to make research data compliant to GDPR.",
                "page_id":"gdpr_compliance",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ],
                    "your_tasks":[
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Do you need a Data Protection Impact Assessment?",
                        "uuid":"8915bd25-db22-4ed6-bcc8-b1bbdc52989e"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gdpr_compliance_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/gdpr_compliance.md",
        "file_name":"gdpr_compliance.md",
        "chunk_index":2,
        "total_chunks":6,
        "content":"e necessary agreements to be signed. Assess your project under the GDPR. * Determine your GDPR role. Are you a data controller, who determines the purposes and means of the processing, or, are you a data processor, who acts under instructions from the controller? * If you are a controller, you need to check whether your processing poses high privacy risks for data subjects, and if so, perform a  Data Protection Impact Assessment (DPIA).\n     * The GDPR lists certain data e.g. race, ethnicity, health, genetic, biometric data as special category, requiring heightened protection. Your research will be considered high-risk processing if it involves special category data or if it includes some specified types of processing. * A DPIA is often a prerequisite for ethics applications. Your DPO or local ethics advisory board can help determine whether your project requires a DPIA. * Performing the DPIA while writing the DMP will allow you to reuse information and save time. * An outcome of the DPIA will be a listing of risks and corresponding mitigations.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gdpr_compliance.md",
            "language":"en",
            "frontmatter":{
                "title":"GDPR compliance",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg",
                    "Laura Portell Silva"
                ],
                "description":"How to protect your research data, and how to make research data compliant to GDPR.",
                "page_id":"gdpr_compliance",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ],
                    "your_tasks":[
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Do you need a Data Protection Impact Assessment?",
                        "uuid":"8915bd25-db22-4ed6-bcc8-b1bbdc52989e"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gdpr_compliance_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/gdpr_compliance.md",
        "file_name":"gdpr_compliance.md",
        "chunk_index":3,
        "total_chunks":6,
        "content":"on and save time. * An outcome of the DPIA will be a listing of risks and corresponding mitigations. Mitigations identify the data protection measures you will adopt, both technical and organisational. Apply technical and organisational measures for data protection. These include:\n  * institutional policies and codes of conduct;\n  * staff training;\n  * user authentication, authorisation, data level access control;\n  * data privacy measures such as pseudonymisation, anonymisation and encryption;\n  * arrangements that will enable data subjects to exercise their rights. Ensure you know your data: while the GDPR governs pseudonymous data, anonymous data falls outside its scope. * According to the GDPR, 'pseudonymisation' involves processing personal data so that it cannot be directly linked to an individual without additional information, which must be kept separately and secured with technical and organizational measures. The inclusion of 'additional information' retains the potential for individual identification, hence pseudonymous data remains within the realm of personal data. *",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gdpr_compliance.md",
            "language":"en",
            "frontmatter":{
                "title":"GDPR compliance",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg",
                    "Laura Portell Silva"
                ],
                "description":"How to protect your research data, and how to make research data compliant to GDPR.",
                "page_id":"gdpr_compliance",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ],
                    "your_tasks":[
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Do you need a Data Protection Impact Assessment?",
                        "uuid":"8915bd25-db22-4ed6-bcc8-b1bbdc52989e"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gdpr_compliance_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/gdpr_compliance.md",
        "file_name":"gdpr_compliance.md",
        "chunk_index":4,
        "total_chunks":6,
        "content":" for individual identification, hence pseudonymous data remains within the realm of personal data. * Conversely, anonymous data lacks associations with specific individuals. Once data achieves genuine anonymity, rendering individuals unidentifiable, it falls beyond the regulatory reach of the GDPR. Record your data processing. To meet GDPR's accountability requirement you should maintain records on the following:\n  * project stakeholders and their GDPR roles (controller, processor);\n  * purpose of your data processing;\n  * description of data subjects and the data;\n  * description of data recipients, particularly those outside the EU;\n  * logs of data transfers to recipients and the safeguards put in place for transfers, such as data sharing agreements;\n  * time limits for keeping different categories of personal data;\n  * description of organisational and technical data protection measures.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gdpr_compliance.md",
            "language":"en",
            "frontmatter":{
                "title":"GDPR compliance",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg",
                    "Laura Portell Silva"
                ],
                "description":"How to protect your research data, and how to make research data compliant to GDPR.",
                "page_id":"gdpr_compliance",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ],
                    "your_tasks":[
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Do you need a Data Protection Impact Assessment?",
                        "uuid":"8915bd25-db22-4ed6-bcc8-b1bbdc52989e"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_gdpr_compliance_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/gdpr_compliance.md",
        "file_name":"gdpr_compliance.md",
        "chunk_index":5,
        "total_chunks":6,
        "content":"tegories of personal data;\n  * description of organisational and technical data protection measures. Solution\n\nEuropean Data Protection Supervisor's \"Preliminary opinion on Data Protection and Scientific Research\"\n{% tool \"bbmri-eric-s-elsi-knowledge-base\" %} contains a glossary, agreement templates and guidance. {% tool \"daisy\" %} and {% tool \"erpa\" %} are software tools from ELIXIR that allow the record-keeping of data processing activities in research projects. {% tool \"dawid\" %} is a software tool from ELIXIR that allows the generation of tailor-made data-sharing agreements\n{% tool \"dpia-knowledge-model\" %} is designed to leverage {% tool \"data-stewardship-wizard\" %} to perform DPIA. {% tool \"tryggve-elsi-checklist\" %} is a list of Ethical, Legal, and Societal Implications (ELSI) to consider for research projects on human subjects.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"gdpr_compliance.md",
            "language":"en",
            "frontmatter":{
                "title":"GDPR compliance",
                "contributors":[
                    "Pinar Alper",
                    "Yvonne Kallberg",
                    "Vilem Ded",
                    "Eva Csosz",
                    "Niclas Jareborg",
                    "Laura Portell Silva"
                ],
                "description":"How to protect your research data, and how to make research data compliant to GDPR.",
                "page_id":"gdpr_compliance",
                "related_pages":{
                    "tool_assembly":[
                        "tsd",
                        "transmed"
                    ],
                    "your_tasks":[
                        "data_security"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=data+protection#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"Will you collect any data connected to a person, \"personal data\"?",
                        "uuid":"49c009cb-a38c-4836-9780-8a8b3dd1cbac"
                    },
                    {
                        "name":"Do you need a Data Protection Impact Assessment?",
                        "uuid":"8915bd25-db22-4ed6-bcc8-b1bbdc52989e"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    },
                    {
                        "name":"Data Protection Impact Assessment and Data Privacy",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB074"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_data_analysis_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":0,
        "total_chunks":2,
        "content":"contributors:\n- Olivier Collin\n- Stian Soiland-Reyes\n- Michael R. Crusoe\n- Sven Twardziok\ndescription: How to make data analysis FAIR. dsw:\n- name: How will you make sure to know what exactly has been run? uuid: 1991077f-04ae-4808-90a5-e4b2f82e30bf\n- name: Did you choose the workflow engine you will be using? uuid: a1c37c05-57ff-499c-b58c-e90f511241fa\n- name: Will you use a central repository for all tools and their versions as used\n    in your project? uuid: decb7c9c-c6dc-4027-8c0e-18934c852ca6\n- name: How will you work with your data?",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_analysis.md",
            "language":"en"
        }
    },
    {
        "id":"md_fm_data_analysis_md_1",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":1,
        "total_chunks":2,
        "content":"n your project? uuid: decb7c9c-c6dc-4027-8c0e-18934c852ca6\n- name: How will you work with your data? uuid: df36fb68-131c-4f31-a42b-684abf523bbc\nfaircookbook:\n- name: Introducing Provenance Information\n  url: https:\/\/w3id.org\/faircookbook\/FCB036\n- name: Making Computational Workflows FAIR\n  url: https:\/\/w3id.org\/faircookbook\/FCB062\npage_id: data_analysis\nrelated_pages:\n  tool_assembly:\n  - nels\n  - xnat_pic\n  - transmed\n  - ome\n  - galaxy\ntitle: Data analysis\ntraining:\n- name: Training in TeSS\n  registry: TeSS\n  url: https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"data_analysis.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_data_analysis_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":0,
        "total_chunks":16,
        "content":"What are the best practices for data analysis?\nDescription\nWhen carrying out your analysis, you should also keep in mind that all your data analysis has to be reproducible. This will complement your research data management approach since your data will be FAIR compliant but also your tools and analysis environments. In other words, you should be able to tell what data and what code or tools were used to generate your results. This will help to tackle reproducibility problems but also will improve the impact of your research through collaborations with scientists who will reproduce your in silico experiments. Considerations\nThere are many ways that will bring reproducibility to your data analysis. You can act at several levels:\n\nby providing your code;\nby providing your execution environment;\nby providing your workflows;\nby providing your data analysis execution. Solutions\n\nMake your code available.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":1,
        "total_chunks":16,
        "content":"ding your workflows;\nby providing your data analysis execution. Solutions\n\nMake your code available. If you have to develop a software for your data analysis, it is always a good idea to publish your code. The git versioning system offers both a way to release your code but offers also a versioning system. You can also use Git to interact with your software users. Be sure to specify a license for your code (see the licensing section). Use package and environment management system. By using package and environment management systems like {% tool \"conda\" %} and its bioinformatics specialized channel {% tool \"bioconda\" %}, researchers that have got access to your code will be able to easily install specific versions of tools, even older ones, in an isolated environment. They will be able to compile\/run your code in an equivalent computational environment, including any dependencies such as the correct version of R or particular libraries and command-line tools your code use. You can also share and preserve your setup by specifying in a environment file which tools you installed.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":2,
        "total_chunks":16,
        "content":"an also share and preserve your setup by specifying in a environment file which tools you installed. Use container environments. As an alternative to package management systems you can consider container environments like {% tool \"docker\" %} or {% tool \"singularity\" %}. Use workflow management systems. Scientific Workflow management systems will help you organize and automate how computational tools are to be executed. Compared to composing tools using a standalone script, workflow systems also help document the different computational analyses applied to your data, and can help with scalability, such as cloud execution. Reproducibility is also enhanced by the use of workflows, as they typically have bindings for specifying software packages or containers for the tools you use from the workflow, allowing others to re-run your workflow without needing to pre-install every piece of software it needs.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":3,
        "total_chunks":16,
        "content":"wing others to re-run your workflow without needing to pre-install every piece of software it needs. It is a flourishing field and many other workflow management systems are available, some of which are general-purpose (e.g. any command line tool), while others are domain-specific and have tighter tool integration. Among the many workflow management systems available, one can mention\nWorkflow platforms that manage your data and provide an interface (web, GUI, APIs) to run complex pipelines and review their results. For instance: {% tool \"galaxy\" %} and {% tool \"arvados\" %} ({% tool \"common-workflow-language\" %}-based), open source. Workflow runners that take a workflow written in a proprietary or standardized format (such as the {% tool \"common-workflow-language\" %}) and execute it locally or on a remote compute infrastructure. For instance, {% tool \"cwl-in-toil\" %}, the reference CWL runner ({% tool \"cwltool\" %}), {% tool \"nextflow\" %}, {% tool \"snakemake\" %}, {% tool \"cromwell\" %}. Use notebooks.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":4,
        "total_chunks":16,
        "content":" \"cwltool\" %}), {% tool \"nextflow\" %}, {% tool \"snakemake\" %}, {% tool \"cromwell\" %}. Use notebooks. Using notebooks, you will be able to create reproducible documents mixing text and code; which can help explain your analysis choices; but also be used as an exploratory method to examine data in detail. Notebooks can be used in conjunction with the other solutions mentioned above, as typically the notebook can be converted to a script. Some of the most well-known notebooks systems are: {% tool \"jupyter\" %}, with built-in support for code in Python, R and Julia, and many other {% tool \"jupyter-kernels\" %}; {% tool \"rstudio\" %} based on R. See the table below for additional tools. How can you use package and environment management systems? Description\nBy using package and environment management systems like {% tool \"conda\" %} and its bioinformatics specialized channel {% tool \"bioconda\" %}, you will be able to easily install specific versions of tools, even older ones, in an isolated environment.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":5,
        "total_chunks":16,
        "content":"l be able to easily install specific versions of tools, even older ones, in an isolated environment. You can also share and preserve your setup by specifying in a environment file which tools you installed. Considerations\nConda works by making a nested folder containing the traditional UNIX directory structure bin\/ lib\/ but installed from Conda's repositories instead of from a Linux distribution. As such Conda enables consistent installation of computational tools independent of your distribution or operating system version. Conda is available for Linux, macOS and Windows, giving consistent experience across operating systems (although not all software is available for all OSes). Package management systems work particularly well for installing free and Open Source software, but can also be useful for creating an isolated environment for installing commercial software packages; for instance if they requires an older Python version than you have pre-installed.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_6",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":6,
        "total_chunks":16,
        "content":"oftware packages; for instance if they requires an older Python version than you have pre-installed. Conda is one example of a generic package management, but individual programming languages typically have their environment management and package repositories. You may want to consider submitting a release of your own code, or at least the general bits of it, to the package repositories for your programming language. Solutions\n\nMacOS-specific package management systems: {% tool \"homebrew\" %}, {% tool \"macports\" %}. Windows-specific package management systems: {% tool \"chocolatey\" %} and {% tool \"windows-package-manager\" %} winget. Linux distributions also have their own package management systems (rpm\/yum\/dnf, deb\/apt) that have a wide variety of tools available, but at the cost of less flexibility in terms of the tool versions, to ensure they exist co-installed. Language-specific virtual environments and repositories including: rvm and RubyGems for Ruby, pip and venv for Python, npm for NodeJS\/Javascript, renv and CRAN for R, Apache Maven or Gradle for Java.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_7",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":7,
        "total_chunks":16,
        "content":"nd venv for Python, npm for NodeJS\/Javascript, renv and CRAN for R, Apache Maven or Gradle for Java. Tips and tricks to navigate the landscape of software package management solutions:\nManage the software you need in an OS-independent way by listing all relevant packages in your Conda environment via the environment.yaml file. If you need conflicting versions of some tools\/libraries for different operations, make separate Conda environments. If you need a few open source libraries for your Python script, none of which require compiling, make a requirements.txt and reference pip packages. How can you use container environments?\nDescription\nContainer environments like {% tool \"docker\" %} or {% tool \"singularity\" %} allow you to easily install specific versions of tools, even older ones, in an isolated environment. Considerations\nIn short containers works almost like a virtual machine (VMs), in that it re-creates a whole Linux distribution with separation of processes, files and network. * Containers are more lightweight than VMs since they don't virtualize hardware.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_8",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":8,
        "total_chunks":16,
        "content":" files and network. * Containers are more lightweight than VMs since they don't virtualize hardware. This allows a container to run with a fixed version of the distribution independent of the host, and have just the right, minimal dependencies installed. * The container isolation also adds a level of isolation, which although not as secure as VMs, can reduce the attack vectors. For instance if the database container was compromised by unwelcome visitors, they would not have access to modify the web server configuration, and the container would not be able to expose additional services to the Internet. * A big advantage of containers is that there are large registries of community-provided container images. * Note that modifying things inside a container is harder than in a usual machine, as changes from the image are lost when a container is recreated.\n* Typically containers run just one tool or applications, and for service deployment this is useful for instance to run mySQL database in a separate container from a NodeJS application.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_9",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":9,
        "total_chunks":16,
        "content":"this is useful for instance to run mySQL database in a separate container from a NodeJS application. Solutions\n\n{% tool \"docker\" %} is the most well-known container runtime, followed by {% tool \"singularity\" %}. These require (and could be used to access) system administrator privileges to be set up. {% tool \"udocker\" %} and {% tool \"podman\" %} are also user space alternatives that have compatible command line usage. Large registries of community-provided container images are {% tool \"podman\" %} and RedHat Quay.io. These are often ready-to-go, not requiring any additional configuration or installations, allowing your application to quickly have access to open source server solutions. {% tool \"biocontainers\" %} have a large selection of bioinformatics tools. To customize a Docker image, it is possible to use techniques such as {% tool \"volumes\" %} to store data and {% tool \"dockerfile-reference\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_10",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":10,
        "total_chunks":16,
        "content":" to use techniques such as {% tool \"volumes\" %} to store data and {% tool \"dockerfile-reference\" %}. This is useful for installing your own application inside a new container image, based on a suitable base image where you can do your apt install and software setup in a reproducible fashion - and share your own application as an image on {% tool \"docker-hub\" %}. Container linkage can be done by container composition using tools like {% tool \"docker-compose-overview\" %}. More advanced container deployment solutions like {% tool \"kubernetes\" %} and Computational Workflow Management systems can also manage cloud instances and handle analytical usage. {% tool \"openstack\" %} is an open-source platform that uses pooled virtual resources to build and manage private and public clouds. It provides a stable base for deploying and managing containers, allowing for faster application deployment and simplified management. Tips and tricks to navigate the landscape of container solutions: If you just need to run a database server, describe how to run it as a Docker\/Singularity container.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_11",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":11,
        "total_chunks":16,
        "content":"If you just need to run a database server, describe how to run it as a Docker\/Singularity container. If you need several servers running, connected together, set up containers in Docker Compose. If you need to install many things, some of which are not available as packages, make a new Dockerfile recipe to build container image. If you need to use multiple tools in a pipeline, find Conda or container images, compose them in a Computational Workflow. If you need to run tools in a cloud instance, but it has nothing preinstalled, use Conda or containers to ensure installation on cloud VM matches your local machine. If you just need a particular open source tool installed, e.g. ImageMagick, check the document how to install: For Ubuntu 20.04, try apt install imagemagick. Domain specific solutions that make use of containers to benchmark and reproducibly deploy workflows exist, including {% tool \"biaflows\" %} for bioimage data. How can you use workflow management systems for reproducible data analysis?",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_12",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":12,
        "total_chunks":16,
        "content":"s\" %} for bioimage data. How can you use workflow management systems for reproducible data analysis? Description\nUsing containerization together with workflow management systems provides several benefits for data analysis, including:\n\nReproducibility: By using containerized environments and workflow management systems, you can ensure that your analysis is reproducible, as the environment in which the analysis is executed is exactly the same each time. Portability: Containerized environments can be easily moved between different computing environments, allowing you to execute your analysis on different computing resources or share your analysis with collaborators. Scalability: Workflow management systems can be used to execute analyses on large computing clusters (like the EuroHPC supercomputer {% tool \"lumi\" %}) or cloud computing resources, enabling you to scale your analysis as needed. Considerations\nCreating an analysis workflow involves several steps that require careful consideration.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_13",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":13,
        "total_chunks":16,
        "content":"siderations\nCreating an analysis workflow involves several steps that require careful consideration. The following steps can help you create a workflow and run it locally or in the cloud:\n\nBefore creating a workflow, it is important to define the scope and objectives of the analysis. This will help you to determine the type of data to collect, the analysis methods to use, and the resources required for the analysis. After defining the scope and objectives, the next step is to determine the tools and software to use. You need to choose software that is compatible with the type of data you want to analyze and the analysis methods you plan to use. Once you have determined the tools and software to use, the next step is to create the workflow. This involves breaking down the analysis process into small, manageable steps that can be automated. Each step should be clearly defined, and the inputs and outputs of each step should be documented. If you want to use containers, you can now define the container images for the execution of the entire workflow or for the individual steps.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_14",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":14,
        "total_chunks":16,
        "content":"ow define the container images for the execution of the entire workflow or for the individual steps. After creating the workflow, it is important to test it to ensure that it works as expected. You can do this by running a test dataset through the workflow and checking the outputs to ensure they match the expected results. Once you have tested the workflow, the next step is to run it on your dataset. Depending on the size of your data, you can run the workflow locally on your computer or on a remote workflow management system. Solutions\n\nMost workflow management systems provide detailed tutorials and documentation for creating workflows and including containerization technologies. Here are documentations for Nextflow, Snakemake, Cromwell, CWL. The {% tool \"biocontainers\" %} project provides a platform for storing and sharing containers that can used in your workflow. The {% tool \"bio-tools\" %} repository lists state of the art tools and databases from the field of bioinformatics ordered by collections and communities.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_data_analysis_md_15",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/data_analysis.md",
        "file_name":"data_analysis.md",
        "chunk_index":15,
        "total_chunks":16,
        "content":"the art tools and databases from the field of bioinformatics ordered by collections and communities. {% tool \"openebench\" %} is a framework for monitoring and  benchmarking analysis tools and workflows. {% tool \"workflowhub\" %} and {% tool \"dockstore\" %} are two popular services for sharing and re-using workflows. {% tool \"life-monitor\" %} is a service designed to facilitate the long-term viability and reusability of published computational workflows. The ELIXIR Cloud and AAI project supports a framework for executing workflows in the cloud via the standards developed by the GA4GH community.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"data_analysis.md",
            "language":"en",
            "frontmatter":{
                "title":"Data analysis",
                "contributors":[
                    "Olivier Collin",
                    "Stian Soiland-Reyes",
                    "Michael R. Crusoe",
                    "Sven Twardziok"
                ],
                "description":"How to make data analysis FAIR.",
                "page_id":"data_analysis",
                "related_pages":{
                    "tool_assembly":[
                        "nels",
                        "xnat_pic",
                        "transmed",
                        "ome",
                        "galaxy"
                    ]
                },
                "training":[
                    {
                        "name":"Training in TeSS",
                        "registry":"TeSS",
                        "url":"https:\/\/tess.elixir-europe.org\/search?q=%22data+analysis%22#materials"
                    }
                ],
                "dsw":[
                    {
                        "name":"How will you make sure to know what exactly has been run?",
                        "uuid":"1991077f-04ae-4808-90a5-e4b2f82e30bf"
                    },
                    {
                        "name":"Did you choose the workflow engine you will be using?",
                        "uuid":"a1c37c05-57ff-499c-b58c-e90f511241fa"
                    },
                    {
                        "name":"Will you use a central repository for all tools and their versions as used in your project?",
                        "uuid":"decb7c9c-c6dc-4027-8c0e-18934c852ca6"
                    },
                    {
                        "name":"How will you work with your data?",
                        "uuid":"df36fb68-131c-4f31-a42b-684abf523bbc"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Introducing Provenance Information",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB036"
                    },
                    {
                        "name":"Making Computational Workflows FAIR",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB062"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_licensing_md_0",
        "source":"markdown_frontmatter",
        "file_path":"pages\/your_tasks\/licensing.md",
        "file_name":"licensing.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"contributors:\n- Siiri Fuchs\n- Minna Ahokas\n- Nicola Soranzo\n- Rob Hooft\ndescription: How to license research data. dsw:\n- name: Licenses under which this distribution of the data set will be available\n  uuid: 3d89e23d-ff5c-45da-97a8-169ad8c39be6\n- name: Will a license be assigned to your datasets?\n  uuid: ae28a862-5020-44c2-8c78-3abc185b190f\nfaircookbook:\n- name: Licensing\n  url: https:\/\/w3id.org\/faircookbook\/FCB032\n- name: Licensing Software\n  url: https:\/\/w3id.org\/faircookbook\/FCB033\n- name: Licensing Data\n  url: https:\/\/w3id.org\/faircookbook\/FCB034\n- name: Declaring data permitted uses\n  url: https:\/\/w3id.org\/faircookbook\/FCB035\npage_id: licensing\nrelated_pages:\n  tool_assembly: []\ntitle: Licensing",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"licensing.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_licensing_md_0",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/licensing.md",
        "file_name":"licensing.md",
        "chunk_index":0,
        "total_chunks":6,
        "content":"Why should you assign a licence to your research data? Description\nLoosely said, a licence defines what a user is allowed to do with a dataset. This can take into account ownership rights (copyright) as well as subject rights if the data is describing human beings. There are large differences between how copyrights and subject rights are to be addressed. * Complying with copyright is primarily the responsibility of the user of the data. Copyright laws allow only the creator of a work to reproduce and use it. If anyone else wants to use the work, then that person needs explicit permission from the holder of the copyright. A copyright licence describes the nature of this agreement, and does not need a signature: the user can never deny the existence of any conditions, because without the licence they would not be able to use the work at all. * Complying with subject rights is primarily the responsibility of the controller (frequently called: owner) of the data.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"licensing.md",
            "language":"en",
            "frontmatter":{
                "title":"Licensing",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Nicola Soranzo",
                    "Rob Hooft"
                ],
                "description":"How to license research data.",
                "page_id":"licensing",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Licenses under which this distribution of the data set will be available",
                        "uuid":"3d89e23d-ff5c-45da-97a8-169ad8c39be6"
                    },
                    {
                        "name":"Will a license be assigned to your datasets?",
                        "uuid":"ae28a862-5020-44c2-8c78-3abc185b190f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    },
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_licensing_md_1",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/licensing.md",
        "file_name":"licensing.md",
        "chunk_index":1,
        "total_chunks":6,
        "content":"ect rights is primarily the responsibility of the controller (frequently called: owner) of the data. In Europe, the GDPR is an important law specifying the rights of subjects, and it is the controller of the data who needs to ensure that any usage of the data has a legal basis; not only his or her own use of the data, but also the use by others. If others use data about human subjects, this will require contracts between the controller and such others. These contracts, unlike copyright licences, will require a signature. Important contract forms are Data Transfer Agreements and Data Processing Agreements. Licensing is an important aspect of meeting the principle of reusability (the R in FAIR) in FAIR data management. As part of the publication process, you need to decide under which licence the data is released. Considerations\n\nIf you are producing a dataset and make it available to others, you should be explicit about what others are allowed to do with it. A document describing that is called a licence.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"licensing.md",
            "language":"en",
            "frontmatter":{
                "title":"Licensing",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Nicola Soranzo",
                    "Rob Hooft"
                ],
                "description":"How to license research data.",
                "page_id":"licensing",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Licenses under which this distribution of the data set will be available",
                        "uuid":"3d89e23d-ff5c-45da-97a8-169ad8c39be6"
                    },
                    {
                        "name":"Will a license be assigned to your datasets?",
                        "uuid":"ae28a862-5020-44c2-8c78-3abc185b190f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    },
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_licensing_md_2",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/licensing.md",
        "file_name":"licensing.md",
        "chunk_index":2,
        "total_chunks":6,
        "content":"xplicit about what others are allowed to do with it. A document describing that is called a licence. If you are reusing a dataset that comes from somewhere, you will want to have a licence that explains what you can do with it. Without a licence, reusing a dataset could be setting you up for legal trouble. Note that different interpretations of copyright laws think differently about copyrights on data. Under some jurisdictions, some data is explicitly not subject to copyrights. An example is data describing the earth under the laws of the United States of America. Copyright law specifies that it only applies to a \"creative work\", and arguably, just collecting data does not have sufficiently creative steps to claim copyrights. Relying on this as a reuser of data, however, is dangerous. Look for a licence and apply it. As a data producer you should be aware that you may not be able to uphold licence restrictions in court, because it may be decided that the dataset is not copyrightable in the first place.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"licensing.md",
            "language":"en",
            "frontmatter":{
                "title":"Licensing",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Nicola Soranzo",
                    "Rob Hooft"
                ],
                "description":"How to license research data.",
                "page_id":"licensing",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Licenses under which this distribution of the data set will be available",
                        "uuid":"3d89e23d-ff5c-45da-97a8-169ad8c39be6"
                    },
                    {
                        "name":"Will a license be assigned to your datasets?",
                        "uuid":"ae28a862-5020-44c2-8c78-3abc185b190f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    },
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_licensing_md_3",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/licensing.md",
        "file_name":"licensing.md",
        "chunk_index":3,
        "total_chunks":6,
        "content":"ctions in court, because it may be decided that the dataset is not copyrightable in the first place. It is therefore best to apply a permissive licence, not asserting strong copyrights. Be sure of data ownership before publishing data. Are there rights belonging to a third party? Solutions\n\nMake your research data available under an appropriate licence, which defines the degree of publicity and rights to use your data. Choose a licence that ensures your data is correctly attributed and makes the terms of reusing your data explicit to the user. What licence should you apply to your research data? Description\nWhat licence you should apply to your research data depends on what rights protect your research data. Which licence to choose might be governed by university policy or funders mandates. Research data can have varying degrees of publicity. There are circumstances in which data may be subject to restrictions eg. if datasets contain sensitive information. Considerations\n\nIf possible, choose and apply the least restrictive licence to ensure the widest possible reuse.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"licensing.md",
            "language":"en",
            "frontmatter":{
                "title":"Licensing",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Nicola Soranzo",
                    "Rob Hooft"
                ],
                "description":"How to license research data.",
                "page_id":"licensing",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Licenses under which this distribution of the data set will be available",
                        "uuid":"3d89e23d-ff5c-45da-97a8-169ad8c39be6"
                    },
                    {
                        "name":"Will a license be assigned to your datasets?",
                        "uuid":"ae28a862-5020-44c2-8c78-3abc185b190f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    },
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_licensing_md_4",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/licensing.md",
        "file_name":"licensing.md",
        "chunk_index":4,
        "total_chunks":6,
        "content":"ns\n\nIf possible, choose and apply the least restrictive licence to ensure the widest possible reuse. Remember that if you publish your data in a data repository of your choice, a licence agreement will be applied to your data. Repositories can be selected based on data licence and sharing policy by using {% tool \"re3data\" %}. ELIXIR data resources ideally have terms of use or a licence that enables the reuse and remixing of data. Remember that the rights granted in a licence cannot be revoked once it has been applied. Solutions\n\nApply to your data one of the {% tool \"open-definition-conformant-licenses\" %}, so that your data can be shared and reused. The Open Definition sets out principles that define the meaning of \"open\" in relation to data and content. Creative Commons licenses are the best known open data licences and are available in human-readable and machine-readable forms, with different levels of permissions. {% tool \"creative-commons-license-chooser\" %} helps you choose the right Creative Commons licence for your needs.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"licensing.md",
            "language":"en",
            "frontmatter":{
                "title":"Licensing",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Nicola Soranzo",
                    "Rob Hooft"
                ],
                "description":"How to license research data.",
                "page_id":"licensing",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Licenses under which this distribution of the data set will be available",
                        "uuid":"3d89e23d-ff5c-45da-97a8-169ad8c39be6"
                    },
                    {
                        "name":"Will a license be assigned to your datasets?",
                        "uuid":"ae28a862-5020-44c2-8c78-3abc185b190f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    },
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_content_licensing_md_5",
        "source":"markdown_content",
        "file_path":"pages\/your_tasks\/licensing.md",
        "file_name":"licensing.md",
        "chunk_index":5,
        "total_chunks":6,
        "content":"tive-commons-license-chooser\" %} helps you choose the right Creative Commons licence for your needs. The video tutorial from Kingsborough E-Learning shows how to add a Creative Commons licence to your work in practice. The following tools helps you find the right licence for your software and data. {% tool \"eudat-licence-selector-wizard\" %}. {% tool \"choose-a-license\" %} is an online guide provided by GitHub to help you choose a license for open-source projects. {% tool \"data-world-data-license-list\" %} provides list of common license types for datasets. If your research data is a database or a dataset, consider putting it in the public domain by using the Creative Commons CC0 tool. CC0 let you waive all your rights to the work (\"No Rights Reserved\"). Additional guidance about licences can be found on the DCC page about {% tool \"how-to-license-research-data-dcc\" %}.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"licensing.md",
            "language":"en",
            "frontmatter":{
                "title":"Licensing",
                "contributors":[
                    "Siiri Fuchs",
                    "Minna Ahokas",
                    "Nicola Soranzo",
                    "Rob Hooft"
                ],
                "description":"How to license research data.",
                "page_id":"licensing",
                "related_pages":{
                    "tool_assembly":[

                    ]
                },
                "dsw":[
                    {
                        "name":"Licenses under which this distribution of the data set will be available",
                        "uuid":"3d89e23d-ff5c-45da-97a8-169ad8c39be6"
                    },
                    {
                        "name":"Will a license be assigned to your datasets?",
                        "uuid":"ae28a862-5020-44c2-8c78-3abc185b190f"
                    }
                ],
                "faircookbook":[
                    {
                        "name":"Licensing",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB032"
                    },
                    {
                        "name":"Licensing Software",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB033"
                    },
                    {
                        "name":"Licensing Data",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB034"
                    },
                    {
                        "name":"Declaring data permitted uses",
                        "url":"https:\/\/w3id.org\/faircookbook\/FCB035"
                    }
                ]
            }
        }
    },
    {
        "id":"md_fm_CODE_OF_CONDUCT_md_0",
        "source":"markdown_frontmatter",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"search_exclude: true\nsidebar: contribute\ntitle: Code of Conduct\ntoc: false",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_0",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":0,
        "total_chunks":18,
        "content":"We value the participation of every member of our community and want to ensure that every contributor has an enjoyable and fulfilling experience. Accordingly, everyone who participates in the RDMkit is expected to show respect and courtesy to other community members at all times. All project members, are dedicated to a harassment-free experience for everyone, regardless of gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age or religion. We do not tolerate harassment by and\/or of members of our community in any form. We are particularly motivated to support new and\/or anxious collaborators, people who are looking to learn and develop their skills, and anyone who has experienced discrimination in the past. To make clear what is expected, we ask all members of the community to conform to the following Code of Conduct.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_1",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":1,
        "total_chunks":18,
        "content":"r what is expected, we ask all members of the community to conform to the following Code of Conduct. 1 Introduction\n2 Code of Conduct\n2.1 Expected behaviour\n2.2 Unacceptable behaviour\n2.3 Consequences of unacceptable behaviour\n2.4 Feedback\n3 Incident reporting guidelines\n3.1 Contact points\n3.2 What to do if someone is in physical danger\n3.3 Code of Conduct enforcement\n4 Enforcement manual\n4.1 The RDM Code of Conduct group\n4.2 Urgent situations: acting unilaterally\n4.3 Less-urgent situations\n4.4 Resolutions\n5 Acknowledgements\n\n1 Introduction\nThe RDMkit is a community-oriented and -led project under the auspices of the ELIXIR Research Infrastructure. We value the involvement of everyone in the community. We are committed to creating a friendly and respectful place for learning, teaching and contributing. All participants in our in-person events and online communications are expected to show respect and courtesy to others at all times. To make clear what is expected, everyone participating in activities associated with the RDMkit is required to conform to this Code of Conduct.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_2",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":2,
        "total_chunks":18,
        "content":"rticipating in activities associated with the RDMkit is required to conform to this Code of Conduct. This Code of Conduct applies to all spaces managed by the RDMkit including, but not limited to, in-person focus groups and workshops, and communications online via GitHub. For events ELIXIR operates a Code of Conduct. For issues around Code of Conduct please contact rdm-coc@elixir-europe.org. \nReports will be reviewed by the RDM CoC group, unless there is a conflict of interest, and will be kept confidential. 2 Code of Conduct\nThe RDMkit team are dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. As such, we do not tolerate behaviour that is disrespectful to our community members or that excludes, intimidates, or causes discomfort to others.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_3",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":3,
        "total_chunks":18,
        "content":"isrespectful to our community members or that excludes, intimidates, or causes discomfort to others. We do not tolerate discrimination or harassment based on characteristics that include, but are not limited to: gender identity and expression, sexual orientation, disability, physical appearance, body size, citizenship, nationality, ethnic or social origin, pregnancy, familial status, veteran status, genetic information, religion or belief (or lack thereof), membership of a national minority, property, age, education, socio-economic status, technical choices, and experience level. Everyone who participates in the RDMkit activities is required to conform to this Code of Conduct. This Code of Conduct applies to all spaces managed by the RDMkit including, but not limited to, in person focus groups and workshops, and communications online via GitHub. By participating, contributors indicate their acceptance of the procedures by which the RDMkit project core development team resolves any Code of Conduct incidents, which may include storage and processing of their personal information.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_4",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":4,
        "total_chunks":18,
        "content":"y Code of Conduct incidents, which may include storage and processing of their personal information. 2.1 Expected behaviour\nWe are confident that our community members will together build a supportive and collaborative atmosphere at our events and during online communications. The following bullet points set out explicitly what we hope you will consider to be appropriate community guidelines:\n\nBe respectful of different viewpoints and experiences. Do not engage in homophobic, racist, transphobic, ageist, ableist, sexist, or otherwise exclusionary behaviour. Use welcoming and inclusive language. Exclusionary comments or jokes, threats or violent language are not acceptable. Do not address others in an angry, intimidating, or demeaning manner. Be considerate of the ways the words you choose may impact others. Be patient and respectful of the fact that English is a second (or third or fourth!) language for some participants. Do not harass people. Harassment includes unwanted physical contact, sexual attention, or repeated social contact.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_5",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":5,
        "total_chunks":18,
        "content":"people. Harassment includes unwanted physical contact, sexual attention, or repeated social contact. Know that consent is explicit, conscious and continuousnot implied. If you are unsure whether your behaviour towards another person is welcome, ask them. If someone tells you to stop, do so. Respect the privacy and safety of others. Do not take photographs of others without their permission. Do not share other participants personal experiences without their express permission. Note that posting (or threatening to post) personally identifying information of others without their consent (\"doxing\") is a form of harassment. Be considerate of others participation. Everyone should have an opportunity to be heard. In update sessions, please keep comments succinct so as to allow maximum engagement by all participants. Do not interrupt others on the basis of disagreement; hold such comments until they have finished speaking. Dont be a bystander. If you see something inappropriate happening, speak up.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_6",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":6,
        "total_chunks":18,
        "content":"ave finished speaking. Dont be a bystander. If you see something inappropriate happening, speak up. If you don't feel comfortable intervening but feel someone should, please feel free to ask a member of the Code of Conduct response team for support. Do not gaslight. Gaslighting is a tactic in which a person or entity, in order to gain more power, makes a victim question their reality. Sometimes you don't even know you are doing it. Look out for the signs in yourself and in others 5 tactics for gaslighting\nAs an overriding general rule, please be intentional in your actions and humble in your mistakes. All interactions should be professional regardless of platform: either online or in-person. See this explanation of the four social rules - no feigning surprise, no well-actually's, no back-seat driving, no subtle -isms - for further recommendations for inclusive behaviours.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_7",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":7,
        "total_chunks":18,
        "content":"lly's, no back-seat driving, no subtle -isms - for further recommendations for inclusive behaviours. 2.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_8",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":8,
        "total_chunks":18,
        "content":"2. 2 Unacceptable behaviour\nExamples of unacceptable behaviour by the RDMkit community members at any project event or platform include:\n\nwritten or verbal comments which have the effect of excluding people on the basis of membership of any specific group\ncausing someone to fear for their safety, such as through stalking, following, or intimidation\nviolent threats or language directed against another person\nthe display of sexual or violent images\nunwelcome sexual attention\nnonconsensual or unwelcome physical contact\nsustained disruption of talks, events or communications\ninsults or put downs\nsexist, racist, homophobic, transphobic, ableist, or exclusionary jokes\nexcessive swearing\nincitement to violence, suicide, or self-harm\ncontinuing to initiate interaction (including photography or recording) with someone after being asked to stop\npublication of private communication without consent\ntactics that make a victim question their reality such as passive-aggressive and gaslighting behaviours\n\n2.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_9",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":9,
        "total_chunks":18,
        "content":" that make a victim question their reality such as passive-aggressive and gaslighting behaviours\n\n2. 3 Consequences of unacceptable behaviour\nParticipants who are asked to stop any inappropriate behaviour are expected to comply immediately. This applies to all RDMkit community events and platforms, either online or in-person. If a participant engages in behaviour that violates this Code of Conduct, any member of the core development team may warn the offender, ask them to leave the event or platform (without refund), or impose any other appropriate sanctions (see the enforcement manual for details). 2.4 Feedback\nThis Code of Conduct is not intended as a static set of rules by which everyone must abide. Rather, you are invited to make suggestions for updates or clarifications by contacting the RDM CoC Group or by making a pull request to this document on GitHub. 3 Incident reporting guidelines\n3.1 Contact points\nIf you feel able to, please contact the RDM CoC group.\n3.2",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_10",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":10,
        "total_chunks":18,
        "content":"t reporting guidelines\n3.1 Contact points\nIf you feel able to, please contact the RDM CoC group.\n3.2 What to do if someone is in physical danger\nIf you believe someone is in physical danger, please contact the appropriate emergency responders. 3.3 Code of Conduct enforcement\nA detailed enforcement policy is available in the Enforcement Manual below. 4 Enforcement manual\nThis is the enforcement manual followed by the RDMkit project team. It's used when we respond to an issue to make sure we're consistent and fair. Enforcement of the Code of Conduct should be respectful and not include any harassing behaviours. 4.1 The RDM Code of Conduct group\nThe members of the RDM Code of Conduct group are:\n\nCarole Goble\nDaniel Faria\nFrederik Coppens\n\nAs the community grows, we will seek to build a larger committee including members outside of the core development team.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_11",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":11,
        "total_chunks":18,
        "content":"ws, we will seek to build a larger committee including members outside of the core development team. 4.2 Urgent situations: acting unilaterally\nIf the incident involves physical danger, or involves a threat to anyone's safety (e.g. threats of violence), any member of the community may -- and should -- act unilaterally to protect the safety of any community member. This can include contacting law enforcement (or other local personnel) and speaking on behalf of the RDMkit team. If the act is ongoing, any community member may act immediately, before reaching consensus, to diffuse the situation. In ongoing situations, any member may at their discretion employ any of the tools available in this enforcement manual, including bans and blocks online, or removal from a physical space. In situations where an individual community member acts unilaterally, they must inform the Toolkit Code of Conduct Allies as soon as possible, and report their actions for review within 24 hours.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_12",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":12,
        "total_chunks":18,
        "content":"kit Code of Conduct Allies as soon as possible, and report their actions for review within 24 hours. 4.3 Less-urgent situations\nUpon receiving a report of an incident, the RDM CoC group will review the incident and determine, to the best of their ability:\n\nwhether this is an ongoing situation\nwhether there is a threat to anyone's physical safety\nwhat happened\nwhether this event constitutes a Code of Conduct violation\nwho, if anyone, was the bad actor\n\nThis information will be collected either in person or in writing. The RDM CoC group will provide a written summary of the information surrounding the incident. All participants will be anonymised in the summary report, referred to as \"Community Member 1\", \"Community Member 2\", or \"Research Team Member 1\". The \"de-anonymising key\" will be kept in a separate file and only accessed to link repeated reports against the same person over time. The RDM CoC group will aim to have a resolution agreed upon within one week.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_13",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":13,
        "total_chunks":18,
        "content":" same person over time. The RDM CoC group will aim to have a resolution agreed upon within one week. In the event that a resolution can't be determined in that time, a member of the RDM CoC group will respond to the reporter(s) with an update and projected timeline for resolution. 4.4 Resolutions\nThe RDM CoC group will seek to agree on a resolution by consensus of all members investigating the report in question. If the committee cannot reach consensus within a week, Niklas Blomberg, as Director of ELIXIR, will decide on an appropriate resolution. Possible responses may include:\n\nA mediated conversation or agreement between the impacted community members. A request for a verbal or written apology, public or private, from a community member. A public announcement clarifying community responsibilities under the Code of Conduct. Nothing, if the issue reported is not a violation or outside of the scope of this Code of Conduct. A private in-person conversation between a member of the research team and the individual(s) involved.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_14",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":14,
        "total_chunks":18,
        "content":"private in-person conversation between a member of the research team and the individual(s) involved. In this case, the person who has the conversation will provide a written summary for record keeping. A private written reprimand from a member of the research team to the individual(s) involved. In this case, the research team member will deliver that reprimand to the individual(s) over email, cc'ing the RDM CoC group for record keeping. A public announcement of an incident, ideally in the same venue that the violation occurred (i.e. on the listserv for a listserv violation; GitHub for a GitHub violation, etc.). The committee may choose to publish this message elsewhere for posterity. An imposed \"time out\" from online spaces. Niklas Blomberg will communicate this \"time out\" to the individual(s) involved. A permanent or temporary ban from some or all RDMkit spaces (GitHub, in-person events, etc.). The research team will maintain records of all such bans so that they may be reviewed in the future, extended to a Code of Conduct safety team as it is built, or otherwise maintained.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_15",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":15,
        "total_chunks":18,
        "content":"ed in the future, extended to a Code of Conduct safety team as it is built, or otherwise maintained. If a member of the community is removed from an event they will not be reimbursed for any part of the event that they miss. Once a resolution is agreed upon, but before it is enacted, a member of the RDM CoC group will contact the original reporter and any other affected parties and explain the proposed resolution. The RDM CoC group will ask if this resolution is acceptable, and must note feedback for the record. However, the RDM CoC group is not required to act on this feedback. 5 Acknowledgements\nThis code is adapted from the Turing Way Project Code of Conduct which in turn was adapted from Carpentries Code of Conduct, and the with sections from the Alan Turing Institute Data Study Group Code of Conduct. All are used under the creative commons attribution license. The Carpentries Code of Conduct was adapted from guidelines written by the Django Project, which was itself based on the Ada Initiative template and the PyCon 2013 Procedure for Handling Harassment Incidents.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_16",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":16,
        "total_chunks":18,
        "content":"based on the Ada Initiative template and the PyCon 2013 Procedure for Handling Harassment Incidents. Contributors to the Carpentries Code of Conduct were: Adam Obeng, Aleksandra Pawlik, Bill Mills, Carol Willing, Erin Becker, Hilmar Lapp, Kara Woo, Karin Lagesen, Pauline Barmby, Sheila Miguez, Simon Waldman, Tracy Teal. The Turing Institute Data Study Group Code of Conduct was heavily adapted from the Citizen Lab Summer Institute 2017 Code of Conduct (2019 version) and used under a CC BY 2.5 CA license. Citizen Lab based their Code of Conduct on the xvzf Code of Conduct, the Contributor Covenant, the Django Code of Conduct and Reporting Guide and we are also grateful for this guidance from Ada Initiative. This code of conduct is aligned with the ELIXIR Code of Conduct for events. We really appreciate the work that all of the communities linked to above have put into creating such a well-considered process.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_content_CODE_OF_CONDUCT_md_17",
        "source":"markdown_content",
        "file_path":"CODE_OF_CONDUCT.md",
        "file_name":"CODE_OF_CONDUCT.md",
        "chunk_index":17,
        "total_chunks":18,
        "content":"k that all of the communities linked to above have put into creating such a well-considered process. This Code of Conduct is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0 CA) license which means you are free to share and adapt the work so long as the attribution to Kirstie Whitaker and the Turing Way community is retained, along with the attribution to the Carpentries, the Alan Turing Institute Data Study Group organising team, Citizen Lab and the other resources.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CODE_OF_CONDUCT.md",
            "language":"en",
            "frontmatter":{
                "title":"Code of Conduct",
                "sidebar":"contribute",
                "search_exclude":true,
                "toc":false
            }
        }
    },
    {
        "id":"md_fm_404_md_0",
        "source":"markdown_frontmatter",
        "file_path":"404.md",
        "file_name":"404.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"search_exclude: true\ntitle: Page Not Found",
        "metadata":{
            "source_type":"markdown_frontmatter",
            "original_file":"404.md",
            "language":"en"
        }
    },
    {
        "id":"md_content_404_md_0",
        "source":"markdown_content",
        "file_path":"404.md",
        "file_name":"404.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"Sorry, but the page you were trying to view does not exist. Try searching for it or looking at the URL to see if it looks correct.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"404.md",
            "language":"en",
            "frontmatter":{
                "title":"Page Not Found",
                "search_exclude":true
            }
        }
    },
    {
        "id":"md_content_CONTRIBUTING_md_0",
        "source":"markdown_content",
        "file_path":"CONTRIBUTING.md",
        "file_name":"CONTRIBUTING.md",
        "chunk_index":0,
        "total_chunks":1,
        "content":"Contributing to the ELIXIR RDMkit\nThank you very much for taking the time to contribute! Code of Conduct\nThis project is governed by a code of conduct. By participating you are expected to respect this code. You can report inappropriate behaviour to rdm-coc@elixir-europe.org. How to contribute\nYou can create new pages or report errors or typos in two ways:\n - Use the GitHub web interface (How to contribute)\n - Send a text file with your suggested changes to the editors (rdm-editors@elixir-europe.org). Reporting a bug or a typo\nBugs or remarks are tracked as GitHub issues. You can create an issue and choose the appropriate template to fill in. Adding a new page or changing an existing page\nSee our How to contribute page.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"CONTRIBUTING.md",
            "language":"en",
            "frontmatter":{

            }
        }
    },
    {
        "id":"md_content_README_md_0",
        "source":"markdown_content",
        "file_path":"README.md",
        "file_name":"README.md",
        "chunk_index":0,
        "total_chunks":3,
        "content":"RDMkit\nThe ELIXIR Research Data Management Kit\nRDMkit is an online guide containing good data management practices applicable to research projects from the beginning to the end. Developed and managed by people who work every day with life science data, RDMkit has guidelines, information and pointers, organised in many different ways to help you with problems throughout the datas life cycle. You will find helpful advice for where you are in the datas life cycle (from collection planning to archiving) and for what kind of data problem you may have. Our up to date tools and resources lists are smartly cross-linked to these guidelines. We also have tailored help for different areas of biology and their specialist data types, and real examples of how tools have been assembled to support data management. Our goal is to make data management easier for you, and to help you make your data FAIR  - Findable, Accessible, Interoperable and Reusable.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"README.md",
            "language":"en",
            "frontmatter":{

            }
        }
    },
    {
        "id":"md_content_README_md_1",
        "source":"markdown_content",
        "file_path":"README.md",
        "file_name":"README.md",
        "chunk_index":1,
        "total_chunks":3,
        "content":"er for you, and to help you make your data FAIR  - Findable, Accessible, Interoperable and Reusable. Contribute\nRDMkit is an open community project, and you are welcome to join us! The content of the material is developed in Markdown and a templating system (Jekyll) is used to format the Markdown pages and generate a website at (https:\/\/rdmkit.elixir-europe.org\/). Do you want to help with this project? Please check out following pages for more information:\n\nCode of Conduct\nHow to contribute\n\nDo you which to contact the editors of this project? Use rdm-editors@elixir-europe.org\nIf you want to build the website locally, please have a look at our Git tutorial. RDMkit is an ELIXIR product\nELIXIR is an intergovernmental organisation that brings together life science resources from across Europe. These resources include databases, software tools, training materials, cloud storage and supercomputers. All the ELIXIR National nodes and the special EMBL-EBI node have come to support data management within the Nodes and for data stewards, researchers and institutional data managers.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"README.md",
            "language":"en",
            "frontmatter":{

            }
        }
    },
    {
        "id":"md_content_README_md_2",
        "source":"markdown_content",
        "file_path":"README.md",
        "file_name":"README.md",
        "chunk_index":2,
        "total_chunks":3,
        "content":"data management within the Nodes and for data stewards, researchers and institutional data managers. The idea is to support data management at the point of creation and enable data to be \"FAIR by Design\". The development of a Research Data Management Kit will provide researchers with a strategy to manage their data to international standards. License\nThe process documents and data are made available under a CC-BY license. Software are made available under an MIT license. More information about our license can be found on our license page. Acknowledgements\nThe RDMkit was supported by ELIXIR-CONVERGE and it is coordinated by ELIXIR Europe and NIH. Custom icons\nWe would like to thank Xnia Prez Sitj for creating the custom icons for the RDMkit. Her work has added to the visual appeal and usability of our toolkit.",
        "metadata":{
            "source_type":"markdown_content",
            "original_file":"README.md",
            "language":"en",
            "frontmatter":{

            }
        }
    }
]